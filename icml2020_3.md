# ICML2020-3
ICML2020 papers with abstract [:link:](https://proceedings.icml.cc/book/2020)

### 661.[Topologically Densified Distributions](https://proceedings.icml.cc/book/3901.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4001-Paper.pdf)
  Christoph Hofer, Florian Graf, Marc Niethammer, Roland Kwitt [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4001-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4001-Supplemental.pdf)
> <p>We study regularization in the context of small sample-size learning with over-parametrized neural networks. Specifically, we shift focus from architectural properties, such as norms on the network weights, to properties of the internal representations before a linear classifier. Specifically, we impose a topological constraint on samples drawn from the probability measure induced in that space. This provably leads to mass concentration effects around the representations of training instances, i.e., a property beneficial for generalization. By leveraging previous work to impose topological constrains in a neural network setting, we provide empirical evidence (across various vision benchmarks) to support our claim for better generalization.</p> 
### 662.[Low-loss connection of weight vectors: distribution-based approaches](https://proceedings.icml.cc/book/3902.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4015-Paper.pdf)
  Ivan Anokhin, Dmitry Yarotsky [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4015-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4015-Supplemental.pdf)
> <p>Recent research shows that sublevel sets of the loss surfaces of overparameterized networks are connected, exactly or approximately. We describe and compare experimentally a panel of methods used to connect two low-loss points by a low-loss curve on this surface. Our methods vary in accuracy and complexity. Most of our methods are based on ''macroscopic'' distributional assumptions and are insensitive to the detailed properties of the points to be connected. Some methods require a prior training of a ''global connection model'' which can then be applied to any pair of points. The accuracy of the method generally correlates with its complexity and sensitivity to the endpoint detail.</p> 
### 663.[Graph Filtration Learning](https://proceedings.icml.cc/book/3903.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4020-Paper.pdf)
  Christoph Hofer, Florian Graf, Bastian Rieck, Marc Niethammer, Roland Kwitt [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4020-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4020-Supplemental.pdf)
> <p>We propose an approach to learning with graph-structured data in the problem domain of graph classification. In particular, we present a novel type of readout operation to aggregate node features into a graph-level representation. To this end, we leverage persistent homology computed via a real-valued, learnable, filter function. We establish the theoretical foundation for differentiating through the persistent homology computation. Empirically, we show that this type of readout operation compares favorably to previous techniques, especially when the graph connectivity structure is informative for the learning problem.</p> 
### 664.[Differentiable Product Quantization for Learning Compact Embedding Layers](https://proceedings.icml.cc/book/3904.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4025-Paper.pdf)
  Ting Chen, Lala Li, Yizhou Sun [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4025-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4025-Supplemental.pdf)
> <p>Embedding layers are commonly used to map discrete symbols into continuous embedding vectors that reflect their semantic meanings. Despite their effectiveness, the number of parameters in an embedding layer increases linearly with the number of symbols and poses a critical challenge on memory and storage constraints. In this work, we propose a generic and end-to-end learnable compression framework termed differentiable product quantization (DPQ). We present two instantiations of DPQ that leverage different approximation techniques to enable differentiability in end-to-end learning. Our method can readily serve as a drop-in alternative for any existing embedding layer. Empirically, DPQ offers significant compression ratios (14-238x) at negligible or no performance cost on 10 datasets across three different language tasks.</p> 
### 665.[Scalable Exact Inference in Multi-Output Gaussian Processes](https://proceedings.icml.cc/book/3905.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4027-Paper.pdf)
  Wessel Bruinsma, Eric Perim Martins, William Tebbutt, Scott Hosking, Arno Solin, Richard Turner [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4027-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4027-Supplemental.pdf)
> <p>Multi-output Gaussian processes (MOGPs) leverage the flexibility and interpretability of GPs while capturing structure across outputs, which is desirable, for example, in spatio-temporal modelling. The key problem with MOGPs is their computational scaling O(n^3 p^3), which is cubic in the number of both inputs n (e.g., time points or locations) and outputs p. For this reason, a popular class of MOGPs assumes that the data live around a low-dimensional linear subspace, reducing the complexity to O(n^3 m^3). However, this cost is still cubic in the dimensionality of the subspace m, which is still prohibitively expensive for many applications. We propose the use of a sufficient statistic of the data to accelerate inference and learning in MOGPs with orthogonal bases. The method achieves linear scaling in m, hence allowing these models to scale to virtually any m, without sacrificing significant expressivity or requiring approximation. This advance opens up a wide range of real-world tasks and can be combined with existing GP approximations in a plug-and-play way. We demonstrate the efficacy of the method on various synthetic and real-world data sets.</p> 
### 666.[Lower Complexity Bounds for Finite-Sum Convex-Concave Minimax Optimization Problems](https://proceedings.icml.cc/book/3906.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4031-Paper.pdf)
  Guangzeng Xie, Luo Luo, yijiang lian, Zhihua Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4031-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4031-Supplemental.pdf)
> This paper studies the lower bound complexity for minimax optimization problem whose objective function is the average of $n$ individual smooth convex-concave functions. We consider the algorithm which gets access to gradient and proximal oracle for each individual component. For the strongly-convex-strongly-concave case, we prove such an algorithm can not reach an $\varepsilon$-suboptimal point in fewer than $\Omega\left((n+\kappa)\log(1/\varepsilon)\right)$ iterations, where $\kappa$ is the condition number of the objective function. This lower bound matches the upper bound of the existing incremental first-order oracle algorithm stochastic variance-reduced extragradient. We develop a novel construction to show the above result, which partitions the tridiagonal matrix of classical examples into $n$ groups. This construction is friendly to the analysis of incremental gradient and proximal oracle and we also extend the analysis to general convex-concave cases.
### 667.[Near-optimal Regret Bounds for Stochastic Shortest Path](https://proceedings.icml.cc/book/3907.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4035-Paper.pdf)
  Aviv Rosenberg, Alon Cohen, Yishay Mansour, Haim Kaplan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4035-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4035-Supplemental.pdf)
> Stochastic shortest path (SSP) is a well-known problem in planning and control, in which an agent has to reach a goal state in minimum total expected cost. In the learning formulation of the problem, the agent is unaware of the environment dynamics (i.e., the transition function) and has to repeatedly play for a given number of episodes, while learning  the problem&#x27;s optimal solution.  Unlike other well-studied models in reinforcement learning (RL), the length of an episode is not predetermined (or bounded) and is influenced by the agent&#x27;s actions.  Recently, \cite{tarbouriech2019noregret} studied this problem in the context of regret minimization, and provided an algorithm whose regret bound is inversely proportional to the square root of the minimum instantaneous cost. In this work we  remove this dependence on the minimum cost---we give an algorithm that guarantees a regret bound of $\widetilde{O}(B^{3/2} S \sqrt{A K})$, where $B$ is an upper bound on the expected cost of the optimal policy, $S$ is the number of states, $A$ is the number of actions and $K$  is the total number of episodes. We additionally show that any learning algorithm must have at least $\Omega(B \sqrt{S A K})$ regret in the worst case.
### 668.[The Usual Suspects? Reassessing Blame for VAE Posterior Collapse](https://proceedings.icml.cc/book/3908.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4042-Paper.pdf)
  Bin Dai, Ziyu Wang, David Wipf [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4042-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4042-Supplemental.pdf)
> <p>In narrow asymptotic settings Gaussian VAE models of continuous data have been shown to possess global optima aligned with ground-truth distributions. Even so, it is well known that poor solutions whereby the latent posterior collapses to an uninformative prior are sometimes obtained in practice. However, contrary to conventional wisdom that largely assigns blame for this phenomena on the undue influence of KL-divergence regularization, we will argue that posterior collapse is, at least in part, a direct consequence of bad local minima inherent to the loss surface of deep autoencoder networks. In particular, we prove that even small nonlinear perturbations of affine VAE decoder models can produce such minima, and in deeper models, analogous minima can force the VAE to behave like an aggressive truncation operator, provably discarding information along all latent dimensions in certain circumstances. Regardless, the underlying message here is not meant to undercut valuable existing explanations of posterior collapse, but rather, to refine the discussion and elucidate alternative risk factors that may have been previously underappreciated.</p> 
### 669.[It&#x27;s Not What Machines Can Learn, It&#x27;s What We Cannot Teach](https://proceedings.icml.cc/book/3909.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4045-Paper.pdf)
  Gal Yehuda, Moshe Gabel, Assaf Schuster [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4045-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4045-Supplemental.pdf)
> <p>Can deep neural networks learn to solve any task, and in particular problems of high complexity? This question attracts a lot of interest, with recent works tackling computationally hard tasks such as the traveling salesman problem and satisfiability. In this work we offer a different perspective on this question. Given the common assumption that NP != coNP we prove that any polynomial-time sample generator for an NP-hard problem samples, in fact, from an easier sub-problem. We empirically explore a case study, Conjunctive Query Containment, and show how common data generation techniques generate biased data-sets that lead practitioners to over-estimate model accuracy. Our results suggest that machine learning approaches that require training on a dense uniform sampling from the target distribution cannot be used to solve computationally hard problems, the reason being the difficulty of generating sufficiently large and unbiased training sets.</p> 
### 670.[Guided Learning of Nonconvex Models through Successive Functional Gradient Optimization](https://proceedings.icml.cc/book/3910.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4056-Paper.pdf)
  Rie Johnson, Tong Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4056-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4056-Supplemental.pdf)
> <p>This paper presents a framework of successive functional gradient optimization for training nonconvex models such as neural networks, where training is driven by mirror descent in a function space.  We provide a theoretical analysis and empirical study of the training method derived from this framework.  It is shown that the method leads to better performance than that of standard training techniques.</p> 
### 671.[A Markov Decision Process Model for Socio-Economic Systems Impacted by Climate Change](https://proceedings.icml.cc/book/3911.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4061-Paper.pdf)
  Salman Sadiq Shuvo, Yasin Yilmaz, Alan Bush, Mark Hafen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4061-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4061-Supplemental.zip)
> <p>Coastal communities are at high risk of natural hazards due to unremitting global warming and sea level rise. Both the catastrophic impacts, e.g., tidal flooding and storm surges, and the long-term impacts, e.g., beach erosion, inundation of low lying areas, and saltwater intrusion into aquifers, cause economic, social, and ecological losses. Creating policies through appropriate modeling of the responses of stakeholders, such as government, businesses, and residents, to climate change and sea level rise scenarios can help to reduce these losses. In this work, we propose a Markov decision process (MDP) formulation for an agent (government) which interacts with the environment (nature and residents) to deal with the impacts of climate change, in particular sea level rise. Through theoretical analysis we show that a reasonable government's policy on infrastructure development ought to be proactive and based on detected sea levels in order to minimize the expected total cost, as opposed to a straightforward government that reacts to observed costs from nature. We also provide a deep reinforcement learning-based scenario planning tool considering different government and resident types in terms of cooperation, and different sea level rise projections by the National Oceanic and Atmospheric Administration (NOAA). </p> 
### 672.[Can Stochastic Zeroth-Order Frank-Wolfe Method Converge Faster for Non-Convex Problems?](https://proceedings.icml.cc/book/3912.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4063-Paper.pdf)
  Hongchang Gao, Heng Huang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4063-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4063-Supplemental.pdf)
> Frank-Wolfe algorithm is an efficient method for optimizing  non-convex constrained problems. However, most of existing methods focus on the first-order case. In real-world applications, the gradient is not always available. To address the problem  of lacking gradient in many applications, we propose two new stochastic zeroth-order Frank-Wolfe algorithms and theoretically proved that they have a faster convergence rate than existing methods for non-convex problems. Specifically, the function queries oracle of the proposed faster zeroth-order Frank-Wolfe (FZFW) method is $O(\frac{n^{1/2}d}{\epsilon^2})$  which can match the iteration complexity of the first-order counterpart approximately. As for the proposed faster zeroth-order conditional gradient sliding (FZCGS) method, its function queries oracle is  improved to $O(\frac{n^{1/2}d}{\epsilon})$, indicating that its iteration complexity is even better than that of its first-order counterpart NCGS-VR. In other words, the iteration complelxity of the  accelerated first-order Frank-Wolfe method NCGS-VR is suboptimal.  Then, we  proposed a new algorithm to improve its IFO (incremental first-order oracle) to $O(\frac{n^{1/2}}{\epsilon})$. At last, the empirical studies on benchmark datasets validate our theoretical results.
### 673.[Distance Metric Learning with Joint Representation Diversification](https://proceedings.icml.cc/book/3913.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4066-Paper.pdf)
  Xu Chu, Yang Lin, Xiting Wang, Xin Gao, Qi Tong, Hailong Yu, Yasha Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4066-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4066-Supplemental.pdf)
> <p>Distance metric learning (DML) is to learn a representation space equipped with a metric, such that examples from the same class are closer than examples from different classes with respect to the metric. The recent success of deep neural networks motivates many DML losses that encourage the intra-class compactness and inter-class separability. However, overemphasizing intra-class compactness may potentially cause the neural networks to filter out information that contributes to discriminating examples from unseen classes, resulting in a less generalizable representation. In contrast, we propose not to penalize intra-class distances explicitly and use a Joint Representation Similarity (JRS) regularizer that focuses on penalizing inter-class distributional similarities in a DML framework. The proposed JRS regularizer diversifies the joint distributions of representations from different classes in multiple neural layers based on cross-covariance operators in Reproducing Kernel Hilbert Space (RKHS). Experiments on three well-known benchmark datasets (Cub-200-2011, Cars-196, and Stanford Online Products) demonstrate the effectiveness of the proposed approach.</p> 
### 674.[Meta-Learning with Shared Amortized Variational Inference](https://proceedings.icml.cc/book/3914.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4070-Paper.pdf)
  Ekaterina Iakovleva, Karteek Alahari, Jakob Verbeek [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4070-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4070-Supplemental.pdf)
> <p>In the context of an empirical Bayes model for meta-learning where a subset of model parameters is treated as latent variables, we propose a novel scheme for amortized variational inference. This approach is based on the conditional variational autoencoder framework, which allows to learn the conditional prior distribution over model parameters given limited training data. In our model, we share the same amortized inference network between the prior and posterior distributions over the model parameters. While the posterior inference leverages both the test and the train data, including the labels, the prior inference is based on the train data only.  We show that in earlier approaches based on Monte-Carlo approximation the prior collapses to a Dirac delta function. In contrast, our variational approach prevents this collapse and preserves uncertainty over the model parameters. We evaluate our approach on standard benchmark datasets, including miniImageNet, and obtain results demonstrating the advantage of our approach over previous work.</p> 
### 675.[Causal Effect Identifiability under Partial-Observability](https://proceedings.icml.cc/book/3915.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4071-Paper.pdf)
  Sanghack Lee, Elias Bareinboim [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4071-Metadata.json)
> <p>Causal effect identifiability is concerned with establishing the effect of intervening on a set of variables on another set of variables from observational or interventional distributions under causal assumptions that are usually encoded in the form of a causal graph. Most of the results of this literature implicitly assume that every variable modeled in the graph is measured in the available distributions. In practice, however, the data collections of the different studies considered do not measure the same variables, consistently. In this paper, we study the causal effect identifiability problem when the available distributions may be associated with different sets of variables, which we refer to as identification under partial-observability. We study a number of properties of the factors that comprise a causal effect under various levels of abstraction, and then characterize the relationship between them with respect to their status relative to the identification of a targeted intervention. We establish a sufficient graphical criterion for determining whether the effects are identifiable from partially-observed distributions. Finally, building on these graphical properties, we develop an algorithm that returns a formula for a causal effect in terms of the available distributions.</p> 
### 676.[Continuous Graph Neural Networks](https://proceedings.icml.cc/book/3916.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4075-Paper.pdf)
  Louis-Pascal Xhonneux, Meng Qu, Jian Tang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4075-Metadata.json)
> <p>This  paper  builds  on  the  connection  between graph  neural  networks  and  traditional  dynamical systems. We propose continuous graph neural networks (CGNN), which generalise existing graph neural networks with discrete dynamics in that they can be viewed as a specific discretisation scheme. The key idea is how to characterise the continuous dynamics of node representations, i.e. the derivatives of node representations, w.r.t. time.Inspired by existing diffusion-based methods on graphs (e.g. PageRank and epidemic models on social networks), we define the derivatives as a combination of the current node representations,the representations of neighbors, and the initial values of the nodes. We propose and analyse two possible dynamics on graphs—including each dimension of node representations (a.k.a. the feature channel) change independently or interact with each other—both with theoretical justification. The proposed continuous graph neural net-works are robust to over-smoothing and hence allow us to build deeper networks, which in turn are able to capture the long-range dependencies between nodes. Experimental results on the task of node classification demonstrate the effectiveness of our proposed approach over competitive baselines.</p> 
### 677.[Restarted Bayesian Online Change-point Detector achieves Optimal Detection Delay](https://proceedings.icml.cc/book/3917.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4076-Paper.pdf)
  REDA ALAMI, Odalric-Ambrym Maillard, Raphaël Féraud [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4076-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4076-Supplemental.pdf)
> <p>In this paper, we consider the problem of sequential change-point detection where both the change-points and the distributions before and after the change are assumed to be unknown. For this key problem in statistical and sequential learning theory,  we derive a variant of the Bayesian Online Change Point Detector proposed by \cite{adams2007bayesian} which is easier to analyze than the original version while keeping its powerful message-passing algorithm.      We provide a non-asymptotic analysis of the false-alarm rate and the detection delay that matches the existing lower-bound. We further provide the first explicit high-probability control of the detection delay for such approach. Experiments on synthetic and real-world data show that this proposal compares favorably with the state-of-art change-point detection strategy, namely the Improved Generalized Likelihood Ratio (Improved GLR) while outperforming the original Bayesian Online Change Point Detection strategy.</p> 
### 678.[Robust learning with the Hilbert-Schmidt independence criterion](https://proceedings.icml.cc/book/3918.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4081-Paper.pdf)
  Daniel Greenfeld, Uri Shalit [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4081-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4081-Supplemental.pdf)
> We investigate the use of a non-parametric independence measure, the Hilbert-Schmidt Independence Criterion (HSIC), as a loss-function for learning robust regression and classification models. This loss-function encourages learning models where the distribution of the residuals between the label and the model prediction is statistically independent of the distribution of the instances themselves. This loss-function was first proposed by \citet{mooij2009regression} in the context of learning causal graphs. We adapt it to the task of learning for unsupervised covariate shift: learning on a source domain without access to any instances or labels from the unknown target domain, but with the assumption that $p(y|x)$  (the conditional probability of labels given instances) remains the same in the target domain. We show that the proposed loss is expected to give rise to models that generalize well on a class of target domains characterised by the complexity of their description within a reproducing kernel Hilbert space. Experiments on unsupervised covariate shift tasks  demonstrate that models learned with the proposed loss-function outperform models learned with standard loss functions, achieving state-of-the-art results on a challenging cell-microscopy unsupervised covariate shift task.
### 679.[Bayesian Experimental Design for Implicit Models by Mutual Information Neural Estimation](https://proceedings.icml.cc/book/3919.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4094-Paper.pdf)
  Steven Kleinegesse, Michael Gutmann [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4094-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4094-Supplemental.pdf)
> <p>Implicit stochastic models, where the data-generation distribution is intractable but sampling is possible, are ubiquitous in the natural sciences. The models typically have free parameters that need to be inferred from data collected in scientific experiments. A fundamental question is how to design the experiments so that the collected data are most useful. The field of Bayesian experimental design advocates that, ideally, we should choose designs that maximise the mutual information (MI) between the data and the parameters. For implicit models, however, this approach is severely hampered by the high computational cost of computing posteriors and maximising MI, in particular when we have more than a handful of design variables to optimise. In this paper, we propose a new approach to Bayesian experimental design for implicit models that leverages recent advances in neural MI estimation to deal with these issues. We show that training a neural network to maximise a lower bound on MI allows us to jointly determine the optimal design and the posterior. Simulation studies illustrate that this gracefully extends Bayesian experimental design for implicit models to higher design dimensions.</p> 
### 680.[Fast Differentiable Sorting and Ranking](https://proceedings.icml.cc/book/3920.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4126-Paper.pdf)
  Mathieu Blondel, Olivier Teboul, Quentin Berthet, Josip Djolonga [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4126-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4126-Supplemental.pdf)
> Sorting is an elementary building block of modern software.  In machine learning and statistics, it is commonly used in robust statistics, order statistics and ranking metrics. However, sorting is a piecewise linear function and as a result includes many kinks at which it is non-differentiable.  More problematic, the ranking operator is a piecewise constant function, meaning that its derivatives are null or undefined. While numerous works have proposed differentiable proxies to sorting and ranking, they do not achieve the $O(n \log n)$ time complexity one could expect from a sorting or ranking operation. In this paper, we propose the first differentiable sorting and ranking operators with $O(n \log n)$ time and $O(n)$ space complexity.  Our proposal in addition enjoys exact computation and differentiation.  We achieve this feat by casting differentiable sorting and ranking as projections onto a permutahedron, the convex hull of permutations, and using a reduction to isotonic optimization.  Empirically, we confirm that our approach is an order of magnitude faster than existing approaches. We also showcase two novel applications: differentiable Spearman&#x27;s rank coefficient and differentiable least trimmed squares.
### 681.[Learning for Dose Allocation in Adaptive Clinical Trials with Safety Constraints](https://proceedings.icml.cc/book/3921.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4129-Paper.pdf)
  Cong Shen, Zhiyang Wang, Sofia Villar, Mihaela van der Schaar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4129-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4129-Supplemental.pdf)
> <p>Phase I dose-finding trials are increasingly challenging as the relationship between efficacy and toxicity of new compounds (or combination of them) becomes more complex. Despite this, most commonly used methods in practice focus on identifying a Maximum Tolerated Dose (MTD) by learning only from toxicity events. We present a novel adaptive clinical trial methodology, called Safe Efficacy Exploration Dose Allocation (SEEDA), that aims at maximizing the cumulative efficacies while satisfying the toxicity safety constraint with high probability. We evaluate performance objectives that have operational meanings in practical clinical trials, including cumulative efficacy, recommendation/allocation success probabilities, toxicity violation probability, and sample efficiency. An extended SEEDA-Plateau algorithm that is tailored for the increase-then-plateau efficacy behavior of molecularly targeted agents (MTA) is also presented. Through numerical experiments using both synthetic and real-world datasets, we show that SEEDA outperforms state-of-the-art clinical trial designs by finding the optimal dose with higher success rate and fewer patients.</p> 
### 682.[Tuning-free Plug-and-Play Proximal Algorithm for Inverse Imaging Problems](https://proceedings.icml.cc/book/3922.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4134-Paper.pdf)
  Kaixuan Wei, Angelica I Aviles-Rivero, Jingwei Liang, Ying Fu, Carola-Bibiane Schönlieb, Hua Huang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4134-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4134-Supplemental.pdf)
> <p>Plug-and-play (PnP) is a non-convex framework that combines ADMM or other proximal algorithms  with advanced denoiser priors.  Recently, PnP has achieved great empirical  success, especially with the integration of deep learning-based denoisers. However, a key problem of PnP based approaches is that they require manual parameter tweaking. It is necessary to obtain high-quality results across the high discrepancy in terms of imaging conditions and varying scene content. In this work, we present a tuning-free PnP proximal algorithm, which can automatically  determine the internal parameters including  the penalty parameter, the denoising strength  and the terminal time. A key part of our approach is to develop a policy network for automatic search of parameters, which can be effectively learned via mixed model-free and model-based deep reinforcement learning. We demonstrate, through numerical and visual experiments, that the learned policy can customize different parameters for different states, and often more efficient and effective than existing handcrafted criteria. Moreover, we discuss the practical considerations of the plugged denoisers, which together with our learned policy yield  state-of-the-art results. This is prevalent on both linear and nonlinear exemplary inverse imaging problems, and in particular, we show promising results on Compressed Sensing MRI and phase retrieval. </p> 
### 683.[Consistent Estimators for Learning to Defer to an Expert](https://proceedings.icml.cc/book/3923.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4138-Paper.pdf)
  Hussein Mozannar, David Sontag [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4138-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4138-Supplemental.pdf)
> <p>Learning algorithms are often used in conjunction with expert decision makers in practical scenarios, however this fact is largely ignored when designing these algorithms. In this paper we explore how to learn predictors that can either predict or choose to defer the decision to a downstream expert. Given samples of the expert's decisions, we give a procedure based on learning a classifier and a rejector and analyze it theoretically. Our approach is based on a reduction to cost sensitive learning where we give a novel calibrated surrogate loss that resolves the open problem of (Ni et al., 2019) for multiclass rejection learning. We show the effectiveness of the new surrogate loss and approach on image and text classification tasks.</p> 
### 684.[A Graph to Graphs Framework for Retrosynthesis Prediction](https://proceedings.icml.cc/book/3924.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4152-Paper.pdf)
  Chence Shi, Minkai Xu, Hongyu Guo, Ming Zhang, Jian Tang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4152-Metadata.json)
> <p>A fundamental problem in computational chemistry is to find a set of reactants to synthesize a target molecule, a.k.a. retrosynthesis prediction. Existing state-of-the-art methods rely on matching the target molecule with a large set of reaction templates, which are very computational expensive and also suffer from the problem of coverage. In this paper, we propose a novel template-free approach called G2Gs by transforming a target molecular graph into a set of reactant molecular graphs. G2Gs first splits the target molecular graph into a set of synthons by identifying the reaction centers, and then translates the synthons to the final reactant graphs via a variational graph translation framework.  Experimental results show that G2Gs significantly outperforms existing template-free approaches with up to 63% improvement in terms of the top-1 accuracy and is close to the performance of state-of-the-art template-based approaches, but does not require domain knowledge and is much more scalable. </p> 
### 685.[Fast computation of Nash Equilibria in Imperfect Information Games](https://proceedings.icml.cc/book/3925.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4157-Paper.pdf)
  Remi Munos, Julien Perolat, Jean-Baptiste Lespiau, Mark Rowland, Bart De Vylder, Marc Lanctot, Finbarr Timbers, Daniel Hennes, Shayegan Omidshafiei, Audrunas Gruslys, Mohammad Gheshlaghi Azar, Edward Lockhart, Karl Tuyls [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4157-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4157-Supplemental.pdf)
> <p>We introduce and analyze a class of algorithms, called Mirror Ascent against an Improved Opponent (MAIO), for computing Nash equilibria in two-player zero-sum games, both in normal form and in sequential imperfect information form. These algorithms update the policy of each player with a mirror-descent step to minimize the loss of playing against an improved opponent. We establish a convergence result to the set of Nash equilibria where the speed of convergence depends on the amount of improvement of the opponent policies. In addition, if the improved opponent is a best response, then an exponential convergence rate is achieved. </p> 
### 686.[Invariant Rationalization](https://proceedings.icml.cc/book/3926.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4158-Paper.pdf)
  Shiyu Chang, Yang Zhang, Mo Yu, Tommi Jaakkola [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4158-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4158-Supplemental.pdf)
> <p>Selective rationalization improves neural network interpretability by identifying a small subset of input features — the rationale — that best explains or supports the prediction. A typical rationalization criterion, i.e. maximum mutual information (MMI), finds the rationale that maximizes the prediction performance based only on the rationale. However, MMI can be problematic because it picks up spurious correlations between the input features and the output.  Instead, we introduce a game-theoretic invariant rationalization criterion where the rationales are constrained to enable the same predictor to be optimal across different environments. We show both theoretically and empirically that the proposed rationales can rule out spurious correlations and generalize better to different test scenarios. The resulting explanations also align better with human judgments. </p> 
### 687.[Accelerated Stochastic Gradient-free and Projection-free Methods](https://proceedings.icml.cc/book/3927.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4168-Paper.pdf)
  Feihu Huang, Lue Tao, Songcan Chen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4168-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4168-Supplemental.zip)
> In the paper, we propose a class of accelerated stochastic gradient-free and projection-free (a.k.a., zeroth-order Frank Wolfe) methods to solve the problem of constrained stochastic and finite-sum nonconvex optimization. Specifically, we propose an accelerated stochastic zeroth-order Frank Wolfe (Acc-SZOFW) method based on the variance reduced technique and a novel momentum technique. Moreover, under some mild conditions, we prove that the Acc-SZOFW has the function query complexity of $O(d\sqrt{n}\epsilon^{-2})$ for finding an $\epsilon$-stationary point in the finite-sum problem, which improves the exiting best result by a factor of $O(\sqrt{n}\epsilon^{-2})$, and has the function query complexity of $O(d\epsilon^{-3})$ in the stochastic problem, which improves the exiting best result by a factor of $O(\epsilon^{-1})$. Further, we propose a novel accelerated stochastic zeroth-order Frank Wolfe (Acc-SZOFW*) to relax the large mini-batch size required in the Acc-SZOFW. In particular, we prove that the Acc-SZOFW* still has the function query complexity of $O(d\epsilon^{-3})$ in the stochastic problem. Finally, we use extensive experiments including black-box adversarial attack and robust black-box classification to verify the efficiency of our algorithms.
### 688.[Efficient Optimistic Exploration in Linear-Quadratic Regulators via Lagrangian Relaxation](https://proceedings.icml.cc/book/3928.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4171-Paper.pdf)
  Marc Abeille, Alessandro Lazaric [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4171-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4171-Supplemental.pdf)
> We study the exploration-exploitation dilemma in the linear quadratic regulator (LQR) setting. Inspired by the extended value iteration algorithm used in optimistic algorithms for finite MDPs, we propose to relax the optimistic optimization of \ofulq and cast it into a constrained \textit{extended} LQR problem, where an additional control variable implicitly selects the system dynamics within a confidence interval. We then move to the corresponding Lagrangian formulation for which we prove strong duality. As a result, we show that an $\epsilon$- optimistic controller can be computed efficiently by solving at most $O\big(\log(1/\epsilon)\big)$ Riccati equations. Finally, we prove that relaxing the original \ofu problem does not impact the learning performance, thus recovering the $\wt O(\sqrt{T})$ regret of \ofulq.
### 689.[Implicit Regularization of Random Feature Models](https://proceedings.icml.cc/book/3929.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4184-Paper.pdf)
  Arthur Jacot, berfin simsek, Francesco Spadaro, Clement Hongler, Franck Gabriel [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4184-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4184-Supplemental.pdf)
> Random Features (RF) models are used as efficient parametric approximations of kernel methods. We investigate, by means of random matrix theory, the connection between Gaussian RF models and Kernel Ridge Regression (KRR). For a Gaussian RF model with $P$ features, $N$ data points, and a ridge $\lambda$, we show that the average (i.e. expected) RF predictor is close to a KRR predictor with an \textit{effective ridge} $\tilde{\lambda}$. We show that $\tilde{\lambda} &gt; \lambda$ and $\tilde{\lambda} \searrow \lambda$ monotonically as $P$ grows, thus revealing the \textit{implicit regularization effect} of finite RF sampling. We then compare the risk (i.e. test error) of the $\tilde{\lambda}$-KRR predictor with the average risk of the $\lambda$-RF predictor and obtain a precise and explicit bound on their difference. Finally, we empirically find an extremely good agreement between the test errors of the average $\lambda$-RF predictor and $\tilde{\lambda}$-KRR predictor. 
### 690.[Missing Data Imputation using Optimal Transport](https://proceedings.icml.cc/book/3930.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4195-Paper.pdf)
  Boris Muzellec, Julie Josse, Claire Boyer, Marco Cuturi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4195-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4195-Supplemental.pdf)
> <p>Missing data is a crucial issue when applying machine learning algorithms to real-world datasets. Starting from the simple assumption that two batches extracted randomly from the same dataset should share the same distribution, we leverage optimal transport distances to quantify that criterion and turn it into a loss function to impute missing data values. We propose practical methods to minimize these losses using end-to-end learning, that can exploit or not parametric assumptions on the underlying distributions of values. We evaluate our methods on datasets from the UCI repository, in MCAR, MAR and MNAR settings. These experiments show that OT-based methods match or out-perform state-of-the-art imputation methods, even for high percentages of missing values. </p> 
### 691.[Unsupervised Speech Decomposition via Triple Information Bottleneck](https://proceedings.icml.cc/book/3931.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4198-Paper.pdf)
  Kaizhi Qian, Yang Zhang, Shiyu Chang, Mark Hasegawa-Johnson, David Cox [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4198-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4198-Supplemental.pdf)
> <p>Speech information can be roughly decomposed into four components: language content, timbre, pitch, and rhythm. Obtaining disentangled representations of these components is useful in many speech analysis and generation applications. Recently, state-of-the-art voice conversion systems have led to speech representations that can disentangle speaker-dependent and independent information. However, these systems can only disentangle timbre, while information about pitch, rhythm and content is still mixed together. Further disentangling the remaining speech components is an under-determined problem in the absence of explicit annotations for each component, which are difficult and expensive to obtain. In this paper, we propose SpeechFlow, which can blindly decompose speech into its four components by introducing three carefully designed information bottlenecks. SpeechFlow is among the first algorithms that can separately perform style transfer on timbre, pitch and rhythm without text labels.</p> 
### 692.[Provable Representation Learning for Imitation Learning via Bi-level Optimization](https://proceedings.icml.cc/book/3932.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4201-Paper.pdf)
  Sanjeev Arora, Simon Du, Sham Kakade, Yuping Luo, Nikunj Umesh Saunshi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4201-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4201-Supplemental.pdf)
> <p>A common strategy in modern learning systems is to learn a representation that is useful for many tasks, a.k.a. representation learning. We study this strategy in the imitation learning setting for Markov decision processes (MDPs) where multiple experts' trajectories are available. We formulate representation learning  as a bi-level optimization problem where the <code>outer" optimization tries to learn the joint representation and the</code>inner" optimization encodes the imitation learning setup and tries to learn task-specific parameters. We instantiate this framework for the imitation learning settings of behavior cloning and observation-alone. Theoretically, we show using our framework that representation learning can provide sample complexity benefits for imitation learning in both settings. We also provide proof-of-concept experiments to verify our theory.</p> 
### 693.[Convergence of a Stochastic Gradient Method with Momentum for Non-Smooth Non-Convex Optimization](https://proceedings.icml.cc/book/3933.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4205-Paper.pdf)
  Vien Mai, Mikael Johansson [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4205-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4205-Supplemental.pdf)
> <p>Stochastic gradient methods with momentum are widely used in applications and at the core of optimization subroutines in many popular machine learning libraries. However, their sample complexities have never been obtained for problems that are non-convex and non-smooth. This paper establishes the convergence rate of a stochastic subgradient method with a momentum term of Polyak type for a broad class of non-smooth, non-convex, and constrained optimization problems. Our key innovation is the construction of a special Lyapunov function for which the proven complexity can be achieved without any tunning of the momentum parameter. For smooth problems, we extend the known complexity bound to the constrained case and demonstrate how the unconstrained case can be analyzed under weaker assumptions than the state-of-the art. Numerical results confirm our theoretical developments.</p> 
### 694.[XTREME: A Massively Multilingual Multi-task Benchmark for Evaluating Cross-lingual Generalisation](https://proceedings.icml.cc/book/3934.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4220-Paper.pdf)
  Junjie Hu, Sebastian Ruder, Aditya Siddhant, Graham Neubig, Orhan Firat, Melvin Johnson [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4220-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4220-Supplemental.pdf)
> <p>Much recent progress in applications of machine learning models to NLP has been driven by benchmarks that evaluate models across a wide variety of tasks. However, these broad-coverage benchmarks have been mostly limited to English, and despite an increasing interest in multilingual models, a benchmark that enables the comprehensive evaluation of such methods on a diverse range of languages and tasks is still missing. To this end, we introduce the Cross-lingual TRansfer Evaluation of Multilingual Encoders (XTREME) benchmark, a multi-task benchmark for evaluating the cross-lingual generalization capabilities of multilingual representations across 40 languages and 9 tasks. We demonstrate that while models tested on English reach human performance on many tasks, there is still a sizable gap in the performance of cross-lingually transferred models, particularly on syntactic and sentence retrieval tasks. There is also a wide spread of results across languages. We will release the benchmark to encourage research on cross-lingual learning methods that transfer linguistic knowledge across a diverse and representative set of languages and tasks.</p> 
### 695.[Fair k-Centers via Maximum Matching](https://proceedings.icml.cc/book/3935.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4221-Paper.pdf)
  Matthew Jones, Thy Nguyen, Huy Nguyen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4221-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4221-Supplemental.zip)
> <p>The field of algorithms has seen a push for fairness, or the removal of inherent bias, in recent history. In data summarization, where a much smaller subset of a data set is chosen to represent the whole of the data, fairness can be introduced by guaranteeing each "demographic group" a specific portion of the representative subset. Specifically, this paper examines this fair variant of the k-centers problem, where a subset of the data with cardinality k is chosen to minimize distance to the rest of the data. Previous papers working on this problem presented both a 3-approximation algorithm with a super-linear runtime and a linear-time algorithm whose approximation factor is exponential in the number of demographic groups. This paper combines the best parts of each algorithm , by presenting a linear-time algorithm with a guaranteed 3-approximation factor, and provides empirical evidence of both the algorithm's runtime and effectiveness.</p> 
### 696.[Efficiently sampling functions from Gaussian process posteriors](https://proceedings.icml.cc/book/3936.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4232-Paper.pdf)
  James Wilson, Viacheslav Borovitskiy, Alexander Terenin, Peter Mostowsky, Marc Deisenroth [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4232-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4232-Supplemental.pdf)
> <p>Gaussian processes are the gold standard for many real-world modeling problems, especially in cases where a method's success hinges upon its ability to faithfully represent predictive uncertainty. These problems typically exist as parts of larger frameworks, where quantities of interest are ultimately defined by integrating over posterior distributions. However, these algorithms' inner workings rarely allow for closed-form integration, giving rise to a need for Monte Carlo methods. Despite substantial progress in scaling up Gaussian processes to large training sets, methods for accurately generating draws from their posterior distributions still scale cubically in the number of test locations. We identify a factorization of Gaussian processes that naturally lends itself to efficient sampling, by allowing accurate representation of entire function draws. Building off of this factorization, we propose decoupled sampling, an easy-to-use and general-purpose approach for fast posterior sampling. As a drop-in approach to sampling, decoupled sampling seamlessly pairs with sparse approximations to Gaussian processes to afford scalability both during training and at test time. In a series of experiments designed to test sampling schemes' statistical behavior and practical ramifications, we empirically show that functions drawn using decoupled sampling faithfully represent Gaussian process posteriors at a fraction of the cost.</p> 
### 697.[Characterizing Distribution Equivalence and Structure Learning for Cyclic and Acyclic Directed Graphs](https://proceedings.icml.cc/book/3937.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4241-Paper.pdf)
  AmirEmad Ghassami, Alan Yang, Negar Kiyavash, Kun Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4241-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4241-Supplemental.pdf)
> <p>The main approach to defining equivalence among acyclic directed causal graphical models is based on the conditional independence relationships in the distributions that the causal models can generate, in terms of the Markov equivalence. However, it is known that when cycles are allowed in the causal structure, conditional independence may not be a suitable notion for equivalence of two structures, as it does not reflect all the information in the distribution that is useful for identification of the underlying structure. In this paper, we present a general, unified notion of equivalence for linear Gaussian causal directed graphical models, whether they are cyclic or acyclic. In our proposed definition of equivalence, two structures are equivalent if they can generate the same set of data distributions. We also propose a weaker notion of equivalence called quasi-equivalence, which we show is the extent of identifiability from observational data. We propose analytic as well as graphical methods for characterizing the equivalence of two structures. Additionally, we propose a score-based method for learning the structure from observational data, which successfully deals with both acyclic and cyclic structures.</p> 
### 698.[Inverse Active Sensing: Modeling and Understanding Timely Decision-Making](https://proceedings.icml.cc/book/3938.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4242-Paper.pdf)
  Daniel Jarrett, Mihaela van der Schaar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4242-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4242-Supplemental.pdf)
> <p>Evidence-based decision-making entails collecting (costly) observations about an underlying phenomenon of interest, and subsequently committing to an (informed) decision on the basis of accumulated evidence. In this setting, <em>active sensing</em> is the goal-oriented problem of efficiently selecting which acquisitions to make, and when and what decision to settle on. As its complement, <em>inverse active sensing</em> seeks to uncover an agent's preferences and strategy given their observable decision-making behavior. In this paper, we develop an expressive, unified framework for the general setting of evidence-based decision-making under endogenous, context-dependent time pressure---which requires negotiating (subjective) tradeoffs between accuracy, speediness, and cost of information. Using this language, we demonstrate how it enables <em>modeling</em> intuitive notions of surprise, suspense, and optimality in decision strategies (the forward problem). Finally, we illustrate how this formulation enables <em>understanding</em> decision-making behavior by quantifying preferences implicit in observed decision strategies (the inverse problem).</p> 
### 699.[On Second-Order Group Influence Functions for Black-Box Predictions](https://proceedings.icml.cc/book/3939.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4261-Paper.pdf)
  Samyadeep Basu, Xuchen You, Soheil Feizi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4261-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4261-Supplemental.pdf)
> <p>With the rapid adoption of machine learning systems in sensitive applications, there is an increasing need to make black-box models explainable. Often we want to identify an influential group of training samples in a particular test prediction for a given machine learning model. Existing influence functions tackle this problem by using first-order approximations of the effect of removing a sample from the training set on model parameters. To compute the influence of a group of training samples (rather than an individual point) in model predictions, the change in optimal model parameters after removing that group from the training set can be large. Thus, in such cases, the first-order approximation can be loose. In this paper, we address this issue and propose second-order influence functions for identifying influential groups in test-time predictions. For linear models, across different sizes and types of groups, we show that using the proposed second-order influence function improves the correlation between the computed influence values and the ground truth ones. We also show that second-order influence functions could be used with optimization techniques to improve the selection of the most influential group for a test-sample.</p> 
### 700.[Safe Imitation Learning via Fast Bayesian Reward Inference from Preferences](https://proceedings.icml.cc/book/3940.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4269-Paper.pdf)
  Daniel Brown, Scott Niekum, Russell Coleman, Ravi Srinivasan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4269-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4269-Supplemental.pdf)
> <p>Bayesian reward learning from demonstrations enables rigorous safety and uncertainty analysis when performing imitation learning. However, Bayesian reward learning methods are typically computationally intractable for complex control problems. We propose a highly efficient Bayesian reward learning algorithm that scales to high-dimensional imitation learning problems by first pre-training a low-dimensional feature encoding via self-supervised tasks and then leveraging preferences over demonstrations to perform fast Bayesian inference via sampling. We evaluate our proposed approach on the task of learning to play Atari games from demonstrations, without access to the game score, and achieve state-of-the-art imitation learning performance. Furthermore, we also demonstrate that our approach enables efficient high-confidence performance bounds for any evaluation policy. We show that these high-confidence performance bounds can be used to accurately rank the performance and risk of a variety of different evaluation policies, despite not having samples of the true reward function. </p> 
### 701.[Randomly Projected Additive Gaussian Processes for Regression](https://proceedings.icml.cc/book/3941.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4272-Paper.pdf)
  Ian Delbridge, David Bindel, Andrew Wilson [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4272-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4272-Supplemental.pdf)
> <p>Gaussian processes (GPs) provide flexible distributions over functions, with inductive biases controlled by a kernel. However, in many applications  Gaussian processes can struggle with even moderate input dimensionality. Learning a low dimensional projection can help alleviate this curse of dimensionality, but introduces many trainable hyperparameters, which can be cumbersome, especially in the small data regime. We use additive sums of kernels for GP regression, where each kernel operates on a different random projection of its inputs. Surprisingly, we find that as the number of random projections increases, the predictive performance of this approach quickly converges to the performance of a kernel operating on the original full dimensional inputs, over a wide range of data sets, even if we are projecting into a single dimension. As a consequence, many problems can remarkably be reduced to one dimensional input spaces, without learning a transformation. We prove this convergence and its rate, and additionally propose a deterministic approach that converges more quickly than purely random projections. Moreover, we demonstrate our approach can achieve faster inference and improved predictive accuracy for high-dimensional inputs compared to kernels in the original input space. </p> 
### 702.[Attentive Group Equivariant Convolutional Networks](https://proceedings.icml.cc/book/3942.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4274-Paper.pdf)
  David Romero, Erik Bekkers, Jakub Tomczak, Mark Hoogendoorn [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4274-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4274-Supplemental.pdf)
> <p>Although group convolutional networks are able to learn powerful representations based on symmetry patterns, they lack explicit means to learn meaningful relationships among them (e.g., relative positions and poses). In this paper, we present attentive group equivariant convolutions, a generalization of the group convolution, in which attention is applied during the course of convolution to accentuate meaningful symmetry combinations and suppress non-plausible, misleading ones. We indicate that prior work on visual attention can be described as special cases of our proposed framework and show empirically that our attentive group equivariant convolutional networks consistently outperform conventional group convolutional networks on benchmark image datasets. Simultaneously, we provide interpretability to the learned concepts through the visualization of equivariant attention maps.</p> 
### 703.[Learning Compound Tasks without Task-specific Knowledge via Imitation and Self-supervised Learning](https://proceedings.icml.cc/book/3943.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4283-Paper.pdf)
  Sang-Hyun Lee, Seung-Woo Seo [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4283-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4283-Supplemental.pdf)
> <p>Most real-world tasks are compound tasks that consist of multiple simpler sub-tasks. The main challenge of learning compound tasks is that we have no explicit supervision to learn the hierarchical structure of compound tasks. To address this challenge, previous imitation learning methods exploit task-specific knowledge, e.g., labeling demonstrations manually or specifying termination conditions for each sub-task. However, the need for task-specific knowledge makes it difficult to scale imitation learning to real-world tasks. In this paper, we propose an imitation learning method that can learn compound tasks without task-specific knowledge. The key idea behind our method is to leverage a self-supervised learning framework to learn the hierarchical structure of compound tasks. Our work also proposes a task-agnostic regularization technique to prevent unstable switching between sub-tasks, which has been a common degenerate case in previous works. We evaluate our method against several baselines on compound tasks. The results show that our method achieves state-of-the-art performance on compound tasks, outperforming prior imitation learning methods.</p> 
### 704.[Confidence Sets and Hypothesis Testing in a Likelihood-Free Inference Setting](https://proceedings.icml.cc/book/3944.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4284-Paper.pdf)
  Niccolo Dalmasso, Rafael Izbicki, Ann Lee [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4284-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4284-Supplemental.pdf)
> <p>Parameter estimation, statistical tests and confidence sets are the cornerstones of classical statistics that  allow  scientists to make inferences about the underlying process that generated the observed data. A key question is whether one can still construct hypothesis tests and confidence sets with proper coverage and high power in a so-called likelihood-free inference (LFI) setting, where the likelihood is not explicitly known but one can forward-simulate observable data according to a stochastic model. In this paper, we present ACORE (Approximate Computation via Odds Ratio Estimation), a frequentist approach to LFI that first formulates the classical likelihood ratio test (LRT) as a parametrized classification problem, and then uses the equivalence of tests and confidence sets to build confidence regions for parameters of interest. We also present a goodness-of-fit test for checking whether the constructed tests and confidence regions are valid. ACORE is based on the key observation that the LRT statistic, the rejection probability of the test, and the coverage of the confidence set are  conditional distribution functions which often vary smoothly as a function of the the parameters of interest. Hence, instead of relying solely on  samples simulated at fixed parameter settings (as is the convention in standard Monte Carlo solutions), one can leverage machine learning tools and data simulated in the neighborhood of a parameter to improve estimates of quantities of interest. We demonstrate the efficacy of ACORE with both theoretical and empirical results.</p> 
### 705.[Curvature-corrected learning dynamics in deep neural networks](https://proceedings.icml.cc/book/3945.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4285-Paper.pdf)
  Dongsung Huh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4285-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4285-Supplemental.pdf)
> <p>Deep neural networks exhibit highly non-convex loss landscape, which results in complex learning dynamics under steepest gradient descent. Second order optimization methods, such as natural gradient descent, can facilitate learning by compensating for ill-conditioned curvature. However, the exact nature of such curvature-corrected learning process remains largely unknown. Here, we derive exact solutions to curvature-corrected learning rules for the restricted case of deep linear neural networks. Our analysis reveals that natural gradient descent follows the same path as gradient descent, only adjusting the temporal dynamics along the path. This preserves the implicit bias of gradient-based learning, such as weight balance across layers. However, block-diagonal approximations of natural gradient, which are widely used in most second order methods (e.g. K-FAC), significantly distort the dynamics to follow highly divergent paths, destroying weight balance across layers. We introduce partially curvature-corrected learning rule, which provides most of the benefit of full curvature correction in terms of convergence speed with superior numerical stability while preserving the core property of gradient descent under block-diagonal approximations.</p> 
### 706.[Tightening Exploration in Upper Confidence Reinforcement Learning](https://proceedings.icml.cc/book/3946.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4290-Paper.pdf)
  Hippolyte Bourel, Odalric-Ambrym Maillard, Mohammad Sadegh Talebi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4290-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4290-Supplemental.pdf)
> <p>The upper confidence reinforcement learning (UCRL2) strategy introduced in \citep{jaksch2010near} is a popular method to perform regret minimization in unknown discrete Markov Decision Processes under the average-reward criterion. Despite its nice and generic theoretical regret guarantees, this strategy and its variants have remained until now mostly theoretical as numerical experiments on simple environments exhibit long burn-in phases before the learning takes place. Motivated by practical efficiency, we present UCRL3, following  the lines of UCRL2, but with two key modifications:     First, it uses state-of-the-art time-uniform concentration inequalities to compute confidence sets on the reward and transition distributions for each state-action pair. To further tighten exploration, we introduce an adaptive computation of the support of each transition distributions. This enables to revisit the extended value iteration procedure to optimize over distributions with reduced support by disregarding low probability transitions, while still ensuring near-optimism.     We demonstrate, through numerical experiments on standard environments, that reducing exploration this way yields a substantial numerical improvement compared to UCRL2 and its variants. On the theoretical side, these key modifications enable to derive a regret bound for UCRL3 improving on UCRL2,  that for the first time makes appear a notion of local diameter and effective support, thanks to variance-aware concentration bounds.</p> 
### 707.[Bootstrap Latent-Predictive Representations for Multitask Reinforcement Learning](https://proceedings.icml.cc/book/3947.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4302-Paper.pdf)
  Zhaohan Guo, Bernardo Avila Pires, Mohammad Gheshlaghi Azar, Bilal Piot, Florent Altché, Jean-Bastien Grill, Remi Munos [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4302-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4302-Supplemental.zip)
> <p>Learning a good representation is an essential component for deep reinforcement learning (RL).  Representation learning is especially important in multitask and partially observable settings where building a representation of the unknown environment is crucial to solve the tasks.  Here we introduce Predictions of Bootstrapped Latents (PBL), a simple and flexible self-supervised representation learning algorithm for multitask deep RL. PBL builds on multistep predictive representations of future observations, and focuses on capturing structured information about environment dynamics. Specifically, PBL trains its representation by predicting latent embeddings of future observations. These latent embeddings are themselves trained to be predictive of the aforementioned representations. These predictions form a bootstrapping effect, allowing the agent to learn more about the key aspects of the environment dynamics. In addition, by defining prediction tasks completely in latent space, PBL provides the flexibility of using multimodal observations involving pixel images, language instructions, rewards and more.  We show in our experiments that PBL delivers across-the-board improved performance over state of the art deep RL agents in the DMLab-30 multitask setting. </p> 
### 708.[Discriminative Adversarial Search for Abstractive Summarization](https://proceedings.icml.cc/book/3948.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4307-Paper.pdf)
  Thomas Scialom, Paul-Alexis Dray, Sylvain Lamprier, Benjamin Piwowarski, Jacopo Staiano [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4307-Metadata.json)
> <p>We introduce a novel approach for sequence decoding, Discriminative Adversarial Search (DAS), which has the desirable properties of alleviating the effects of exposure bias without requiring external metrics. Inspired by Generative Adversarial Networks (GANs), wherein a discriminator is used to improve the generator, our method differs from GANs in that the generator parameters are not updated at training time and the discriminator is used to drive sequence generation at inference time. </p>  <p>We investigate the effectiveness of the proposed approach on the task of Abstractive Summarization: the results obtained show that a naive application of DAS improves over the state-of-the-art methods, with further gains obtained via discriminator retraining. Moreover, we show how DAS can be effective for cross-domain adaptation. Finally, all results reported are obtained without additional rule-based filtering strategies, commonly used by the best performing systems available: this indicates that DAS can effectively be deployed without relying on post-hoc modifications of the generated outputs.</p> 
### 709.[A Swiss Army Knife for Minimax Optimal Transport](https://proceedings.icml.cc/book/3949.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4328-Paper.pdf)
  Sofien Dhouib, Ievgen Redko, Tanguy Kerdoncuff, Rémi Emonet, Marc Sebban [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4328-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4328-Supplemental.pdf)
> <p>The Optimal transport (OT) problem and its associated Wasserstein distance have recently become a topic of great interest in the machine learning community. However, the underlying optimization problem is known to have two major restrictions: (i) it largely depends on the choice of the cost function and (ii) its sample complexity scales exponentially with the dimension. In this paper, we propose a general formulation of a minimax OT problem that can tackle these restrictions by jointly optimizing the cost matrix and the transport plan, allowing us to define a robust distance between distributions. We propose to use a cutting-set method to solve this general problem and show its links and advantages compared to other existing minimax OT approaches. Additionally, we use this method to define a notion of stability allowing us to select the most robust cost matrix. Finally, we provide an experimental study highlighting the efficiency of our approach.</p> 
### 710.[Invariant Causal Prediction for Block MDPs](https://proceedings.icml.cc/book/3950.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4334-Paper.pdf)
  Clare Lyle, Amy Zhang, Angelos Filos, Shagun Sodhani, Marta Kwiatkowska, Yarin Gal, Doina Precup, Joelle Pineau [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4334-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4334-Supplemental.pdf)
> <p>Generalization across environments is critical to the successful application of reinforcement learning (RL) algorithms to real-world challenges. In this work we propose a method for learning state abstractions which generalize to novel observation distributions in the multi-environment RL setting. We prove that for certain classes of environments, this approach outputs, with high probability, a state abstraction corresponding to the causal feature set with respect to the return. We give empirical evidence that analogous methods for the nonlinear setting can also attain improved generalization over single- and multi-task baselines. Lastly, we provide bounds on model generalization error in the multi-environment setting, in the process showing a connection between causal variable identification and the state abstraction framework for MDPs.</p> 
### 711.[Involutive MCMC: One Way to Derive Them All](https://proceedings.icml.cc/book/3951.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4339-Paper.pdf)
  Kirill Neklyudov, Max Welling, Evgenii Egorov, Dmitry Vetrov [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4339-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4339-Supplemental.zip)
> <p>Markov Chain Monte Carlo (MCMC) is a computational approach to fundamental problems such as inference, integration, optimization, and simulation. The field has developed a broad spectrum of algorithms, varying in the way they are motivated, the way they are applied and how efficiently they sample. Despite all the differences, many of them share the same core principle, which we unify as the Involutive MCMC (iMCMC) framework. Building upon this, we describe a wide range of MCMC algorithms in terms of iMCMC, and formulate a number of "tricks" which one can use as design principles for developing new MCMC algorithms. Thus, iMCMC provides a unified view of many known MCMC algorithms, which facilitates the derivation of powerful extensions. We demonstrate the latter with two examples where we transform known reversible MCMC algorithms into more efficient irreversible ones.</p> 
### 712.[Adversarial Learning Guarantees for Linear Hypotheses and Neural Networks](https://proceedings.icml.cc/book/3952.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4342-Paper.pdf)
  Pranjal Awasthi, Natalie Frank, Mehryar Mohri [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4342-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4342-Supplemental.pdf)
> Adversarial or test time robustness measures the susceptibility of a classifier to perturbations to the test input. While there has been a flurry of recent work on designing defenses against such perturbations, the theory of adversarial robustness is not well understood. In order to make progress on this, we focus on the problem of understanding generalization in adversarial settings, via the lens of Rademacher complexity.  We give upper and lower bounds for the adversarial empirical Rademacher complexity of linear hypotheses with adversarial perturbations measured in $l_r$-norm for an arbitrary $r \geq 1$. This generalizes the recent result of Yin et al.~\cite{YinRamchandranBartlett2019} that studies the case of $r = \infty$, and provides a finer analysis of the dependence on the input dimensionality as compared to the recent work of Khim and Loh~\cite{khim2018adversarial} on linear hypothesis classes and additionally provides matching lower bounds.  We then extend our analysis to provide Rademacher complexity lower and upper bounds for a single ReLU unit. Finally, we give adversarial Rademacher complexity bounds for feed-forward neural networks with one hidden layer. Unlike previous works we directly provide bounds on the adversarial Rademacher complexity of the given network, as opposed to a bound on a surrogate. A by-product of our analysis also leads to tighter bounds for the Rademacher complexity of linear hypotheses, for which we give a detailed analysis and present a comparison with existing bounds.  
### 713.[Deep Reinforcement Learning with Smooth Policy](https://proceedings.icml.cc/book/3953.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4344-Paper.pdf)
  Qianli Shen, Yan Li, Haoming Jiang, Zhaoran Wang, Tuo Zhao [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4344-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4344-Supplemental.pdf)
> Deep neural networks have been widely adopted in modern reinforcement learning (RL) algorithms with great empirical successes in various domains.  However, the large search space of training a neural network requires a significant amount of data, which makes the current RL algorithms not sample efficient. Motivated by the fact that many environments with continuous state space have smooth transitions, we propose to learn a smooth policy that behaves smoothly with respect to the state. In contrast to policy parameterized by linear/reproducing kernel functions, where simple regularization techniques suffice to control smoothness, for neural network based reinforcement learning algorithms, there is no readily available solution to learn a smooth policy. In this paper, we develop a new training framework --- \textbf{S}mooth \textbf{R}egularized \textbf{R}einforcement \textbf{L}earning ($\textbf{SR}^2\textbf{L}$), where the policy is trained with smoothness-inducing regularization. Such regularization effectively constrains the search space of the learning algorithms and enforces smoothness in the learned policy. We apply the proposed framework to both on-policy (TRPO) and off-policy algorithm (DDPG). Through extensive experiments, we demonstrate that our method achieves improved sample efficiency. 
### 714.[On the Power of Compressed Sensing with Generative Models ](https://proceedings.icml.cc/book/3954.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4345-Paper.pdf)
  Akshay Kamath, Eric Price, Sushrut Karmalkar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4345-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4345-Supplemental.pdf)
> The goal of compressed sensing is to learn a structured signal $x$ from a limited number of noisy linear measurements $y \approx Ax$.  In traditional compressed sensing, ``structure&#x27;&#x27; is represented by sparsity in some known basis.  Inspired by the success of deep learning in modeling images, recent work starting with Bora et.al has instead considered structure to come from a generative model $G: \R^k \to \R^n$. In this paper, we prove results that (i)establish the difficulty of this task and show that existing bounds are tight and (ii) demonstrate that the latter task is a generalization of the former.  First, we provide a lower bound matching the upper bound of Bora et.al. for compressed sensing from $L$-Lipschitz generative models $G$.  In particular, there exists such a function that requires roughly $\Omega(k \log L)$ linear measurements for sparse recovery to be possible. This holds even for the more relaxed goal of \emph{nonuniform} recovery.  Second, we show that generative models generalize sparsity as a representation of structure. In particular, we construct a ReLU-based neural network $G: \R^{k} \to \R^n$ with $O(1)$ layers and $O(n)$ activations per layer, such that the range of $G$ contains all $k$-sparse vectors.
### 715.[Laplacian Regularized Few-Shot Learning](https://proceedings.icml.cc/book/3955.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4348-Paper.pdf)
  Imtiaz Ziko, Jose Dolz, Eric Granger, Ismail Ben Ayed [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4348-Metadata.json)
> <p>Few-shot learning attempts to generalize to unlabeled query samples of new classes, which are unseen during training, given just a few labeled examples of those classes. It has received substantial research interest recently, with a large body of works based on complex meta-learning strategies and architecture  choices. We propose a Laplacian-regularization objective for few-shot tasks, which  integrates two types of potentials: (1) unary potentials assigning query samples to the nearest class prototype and (2) pairwise Laplacian potentials encouraging nearby query samples to have consistent predictions.We optimize a tight upper bound of a concave-convex relaxation of our objective, thereby guaranteeing convergence, while computing independent updates for each query sample. Following the standard experimental setting for few-shot learning, our LaplacianShot technique outperforms state-of-the-art methods significantly, while using simple cross-entropy training on the base classes. In the 1-shot setting on the standard miniImageNet and tieredImageNet benchmarks, and on the recent meta-iNat benchmark, across various networks, LaplacianShot consistently pro-vides 3 − 4% improvement in accuracy over the best-performing state-of-the-art method.</p> 
### 716.[Neural Datalog Through Time: Informed Temporal Modeling via Logical Specification](https://proceedings.icml.cc/book/3956.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4356-Paper.pdf)
  Hongyuan Mei, Guanghui Qin, Minjie Xu, Jason Eisner [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4356-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4356-Supplemental.pdf)
> <p>Learning how to predict future events from patterns of past events is difficult when the set of possible event types is large. Many of the patterns detected in the data by training an everything-affects-everything model will be spurious. To exploit known structure, we propose using a deductive database to track facts over time, where each fact has a time-varying state—a vector computed by a neural net whose topology is determined by the fact’s provenance and experience. The possible events at any time correspond to structured facts, whose probabilities are modeled along with their states. In both synthetic and real-world domains, we show that neural models derived from concise Datalog programs achieve better generalization by encoding appropriate domain knowledge into the model architecture.</p> 
### 717.[Up or Down? Adaptive Rounding for Post-Training Quantization](https://proceedings.icml.cc/book/3957.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4365-Paper.pdf)
  Markus Nagel, Rana Ali Amjad, Marinus van Baalen, Christos Louizos, Tijmen Blankevoort [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4365-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4365-Supplemental.pdf)
> <p>When quantizing neural networks, assigning each floating-point weight to its nearest fixed-point value is the predominant approach. We find that, perhaps surprisingly, this is not the best we can do. In this paper, we propose AdaRound, a better weight-rounding mechanism for post-training quantization that adapts to the data and the task loss. AdaRound is fast, does not require fine-tuning of the network, and only uses a small amount of unlabelled data. We start by theoretically analyzing the rounding problem for a pre-trained neural network. By approximating the task loss with a Taylor series expansion, the rounding task is posed as a quadratic unconstrained binary optimization problem. We simplify this to a layer-wise local loss and propose to optimize this loss with a soft relaxation. AdaRound not only outperforms rounding-to-nearest by a significant margin but also establishes a new state-of-the-art for post-training quantization on several networks and tasks. Without fine-tuning, we can quantize the weights of Resnet18 and Resnet50 to 4 bits while staying within an accuracy loss of 1%.</p> 
### 718.[A quantile-based approach for hyperparameter transfer learning](https://proceedings.icml.cc/book/3958.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4367-Paper.pdf)
  David Salinas, Huibin Shen, Valerio Perrone [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4367-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4367-Supplemental.pdf)
> <p>Bayesian optimization (BO) is a popular methodology to tune the hyperparameters of expensive black-box functions. Traditionally, BO focuses on a single task at a time and is not designed to leverage information from related functions, such as tuning performance objectives of the same algorithm across multiple datasets. In this work, we introduce a novel approach to achieve transfer learning across different datasets as well as different objectives. The main idea is to regress the mapping from hyperparameter to objective quantiles with a semi-parametric Gaussian Copula distribution, which provides robustness against different scales or outliers that can occur in different tasks. We introduce two methods to leverage this estimation: a Thompson sampling strategy as well as a Gaussian Copula process using such quantile estimate as a prior. We show that these strategies can combine the estimation of multiple objectives such as latency and accuracy, steering the optimization toward faster predictions for the same level of accuracy. Experiments on an extensive set of hyperparameter tuning tasks demonstrate significant improvements over state-of-the-art methods for both hyperparameter optimization and neural architecture search.</p> 
### 719.[Inductive Bias-driven Reinforcement Learning For Efficient Schedules in Heterogeneous Clusters](https://proceedings.icml.cc/book/3959.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4373-Paper.pdf)
  Subho Banerjee, Saurabh Jha, Zbigniew Kalbarczyk, Ravishankar Iyer [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4373-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4373-Supplemental.pdf)
> The problem of scheduling of workloads onto heterogeneous processors (e.g., CPUs, GPUs, FPGAs) is of fundamental importance in modern datacenters. Current system schedulers rely on application/system-specific heuristics that have to be built on a case-by-case basis. Recent work has demonstrated ML techniques to automate this heuristic search using black box approaches which require significant training data and time, which make them challenging to use in practice. This paper addresses the challenge in two ways:  (i) a domain-driven Bayesian reinforcement learning (RL) model for scheduling, which inherently models the resource dependencies identified from the  system architecture; and (ii) a sampling-based technique which allows the computation of gradients of a Bayesian model without performing full probabilistic inference. Together, these techniques reduce both the amount of training-data and -time required to produce scheduling policies that significantly outperform black box approaches by up to 2.2$\times$.
### 720.[Adversarial Robustness for Code](https://proceedings.icml.cc/book/3960.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4379-Paper.pdf)
  Pavol Bielik, Martin Vechev [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4379-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4379-Supplemental.pdf)
> <p>Machine learning and deep learning in particular has been recently used to successfully address many tasks in the domain of code including -- finding and fixing bugs, code completion, decompilation, malware detection, type inference and many others. However, the issue of adversarial robustness of models for code has gone largely unnoticed. In this work we address this gap by: (i) developing adversarial attacks for code (a domain with discrete and highly structured inputs), (ii) showing that, similar to other domains, neural models for code are highly vulnerable to adversarial attacks, and (iii) developing a set of novel techniques that enable training robust and accurate models of code.</p> 
### 721.[The Boomerang Sampler](https://proceedings.icml.cc/book/3961.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4401-Paper.pdf)
  Joris Bierkens, Sebastiano Grazzi, Kengo Kamatani, Gareth Roberts [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4401-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4401-Supplemental.pdf)
> This paper introduces the boomerang sampler as a novel class of continuous-time non-reversible Markov chain Monte Carlo algorithms. The methodology begins by representing the target density as a density, $e^{-U}$, with respect to a prescribed (usually) Gaussian measure and constructs a continuous trajectory consisting of a piecewise circular path. The method moves from one circular orbit to another according to a rate function which can be written in terms of $U$. We demonstrate that the method is easy to implement and demonstrate empirically that it can out-perform existing benchmark piecewise deterministic Markov processes such as the bouncy particle sampler and the Zig-Zag. In the Bayesian statistics context, these competitor algorithms are of substantial interest in the large data context due to the fact that they can adopt data subsampling techniques which are exact (ie induce no error in the stationary distribution). We demonstrate theoretically and empirically that we can also construct a control-variate subsampling boomerang sampler which is also exact, and which possesses remarkable scaling properties in the large data limit. We furthermore illustrate a factorised version on the simulation of diffusion bridges.
### 722.[Weakly-Supervised Disentanglement Without Compromises](https://proceedings.icml.cc/book/3962.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4405-Paper.pdf)
  Francesco Locatello, Ben Poole, Gunnar Raetsch, Bernhard Schölkopf, Olivier Bachem, Michael Tschannen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4405-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4405-Supplemental.pdf)
> <p>Intelligent agents should be able to learn useful representations by observing changes in their environment. We model such observations as pairs of non-i.i.d. images sharing at least one of the underlying factors of variation. First, we theoretically show that only knowing how many factors have changed, but not which ones, is sufficient to learn disentangled representations. Second, we provide practical algorithms that learn disentangled representations from pairs of images without requiring annotation of groups, individual factors, or the number of factors that have changed. Third, we perform a large-scale empirical study and show that such pairs of observations are sufficient to reliably learn disentangled representations on several benchmark data sets. Finally, we evaluate our learned representations and find that they are simultaneously useful on a diverse suite of tasks, including generalization under covariate shifts, fairness, and abstract reasoning. Overall, our results demonstrate that weak supervision enables learning of useful disentangled representations in realistic scenarios.</p> 
### 723.[Predictive Sampling with Forecasting Autoregressive Models](https://proceedings.icml.cc/book/3963.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4409-Paper.pdf)
  Auke Wiggers, Emiel Hoogeboom [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4409-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4409-Supplemental.pdf)
> <p>Autoregressive models (ARMs) currently hold state-of-the-art performance in likelihood-based modeling of image and audio data. Generally, neural network based ARMs are designed to allow fast inference, but sampling from these models is impractically slow. In this paper, we introduce the predictive sampling algorithm: a procedure that exploits the fast inference property of ARMs in order to speed up sampling, while keeping the model intact. We propose two variations of predictive sampling, namely sampling with ARM fixed-point iteration and learned forecasting modules. Their effectiveness is demonstrated in two settings: i) explicit likelihood modeling on binary MNIST, SVHN and CIFAR10, and ii) discrete latent modeling in an autoencoder trained on SVHN, CIFAR10 and Imagenet32. Empirically, we show considerable improvements over baselines in number of ARM inference calls and sampling speed.</p> 
### 724.[InfoGAN-CR: Disentangling Generative Adversarial Networks with Contrastive Regularizers](https://proceedings.icml.cc/book/3964.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4410-Paper.pdf)
  Zinan Lin, Kiran Thekumparampil, Giulia Fanti, Sewoong Oh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4410-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4410-Supplemental.pdf)
> <p>Standard deep generative models have latent codes that can be arbitrarily rotated, and a specific coordinate has no meaning. For manipulation and exploration of the samples, we seek a disentangled latent code where each coordinate is associated with a distinct property of the target distribution. Recent advances has been dominated by Variational Autoencoder (VAE)-based methods, while training disentangled generative adversarial networks (GANs) remains challenging. To this end, we make two contributions: a novel approach for training disentangled GANs and a novel approach for selecting the best disentangled model. First, we propose a regularizer that achieves higher disentanglement scores than state-of-the-art VAE- and GAN-based approaches. This contrastive regularizer is inspired by a natural notion of disentanglement: latent traversal. Latent traversal refers to generating images by varying one latent code while fixing the rest. We turn this intuition into a regularizer by adding a discriminator that detects how the latent codes are coupled together, in paired examples. Next, one major weakness of all disentanglement benchmark tests is that all reported scores are  based on hyperparameters  tuned with a predefined disentangled representations on synthetic datasets. This is neither fair nor realistic, as one can arbitrarily improve the performance with more hyperparameter tuning and real datasets do not come with such supervision. We propose an unsupervised model selection scheme based on medoids. Numerical experiments confirm that  thus selected models improve upon the state-of-the-art models selected with supervised hyperparameter tuning. </p> 
### 725.[TrajectoryNet: A Dynamic Optimal Transport Network for Modeling Cellular Dynamics](https://proceedings.icml.cc/book/3965.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4414-Paper.pdf)
  Alexander Tong, Jessie Huang, Guy Wolf, David van Dijk, Smita Krishnaswamy [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4414-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4414-Supplemental.pdf)
> <p>It is increasingly common to encounter data in the form of cross-sectional population measurements over time, particularly in biomedical settings. Recent attempts to model individual trajectories from this data use optimal transport to create pairwise matchings between time points. However, these methods cannot model non-linear paths common in many underlying dynamic systems. We establish a link between continuous normalizing flows and dynamic optimal transport to model the expected paths of points over time. Continuous normalizing flows are generally under constrained, as they are allowed to take an arbitrary path from the source to the target distribution. We present {\em TrajectoryNet}, which controls the continuous paths taken between distributions. We show how this is particularly applicable for studying cellular dynamics in data from single-cell RNA sequencing (scRNA-seq) technologies, and that TrajectoryNet improves upon recently proposed static optimal transport-based models that can be used for interpolating cellular distributions.</p> 
### 726.[The role of regularization in classification of high-dimensional noisy Gaussian mixture](https://proceedings.icml.cc/book/3966.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4431-Paper.pdf)
  Francesca Mignacco, Florent Krzakala, Yue Lu, Pierfrancesco Urbani, Lenka Zdeborova [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4431-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4431-Supplemental.pdf)
> We consider a high-dimensional mixture of two Gaussians in the noisy regime where even an oracle knowing the centers of the clusters misclassifies a small but finite fraction of the points.  We provide a rigorous analysis of the generalization error of regularized convex classifiers, including ridge, hinge and logistic regression, in the high-dimensional limit where the number $n$ of samples and their dimension $d$ goes to infinity while their ratio is fixed to $\alpha=n/d$.   We discuss surprising effects of the regularization that in some cases allows to reach the Bayes-optimal performances, we illustrate the interpolation peak at low regularization, and analyze the role of the respective sizes of the two clusters. 
### 727.[Normalizing Flows on Tori and Spheres](https://proceedings.icml.cc/book/3967.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4436-Paper.pdf)
  Danilo J. Rezende, George Papamakarios, Sebastien Racaniere, Michael Albergo, Gurtej Kanwar, Phiala Shanahan, Kyle Cranmer [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4436-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4436-Supplemental.pdf)
> <p>Normalizing flows are a powerful tool for building expressive distributions in high dimensions. So far, most of the literature has concentrated on learning flows on Euclidean spaces. Some problems however, such as those involving angles, are defined on spaces with more complex geometries, such as tori or spheres. In this paper, we propose and compare expressive and numerically stable flows on such spaces. Our flows are built recursively on the dimension of the space, starting from flows on circles, closed intervals or spheres.</p> 
### 728.[Structured Linear Contextual Bandits: A Sharp and Geometric Smoothed Analysis](https://proceedings.icml.cc/book/3968.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4457-Paper.pdf)
  Vidyashankar Sivakumar, Steven Wu, Arindam Banerjee [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4457-Metadata.json)
> Bandit learning algorithms typically involve the balance of exploration and exploitation. However, in many practical applications, worst-case scenarios needing systematic exploration are seldom encountered. In this work, we consider a smoothed setting for structured linear contextual bandits where the adversarial contexts are perturbed by Gaussian noise and the unknown parameter $\theta^*$ has structure, e.g., sparsity, group sparsity, low rank, etc. We propose simple greedy algorithms for both the single- and multi-parameter (i.e., different parameter for each context) settings and provide a unified regret analysis for $\theta^*$ with any assumed structure. The regret bounds are expressed in terms of geometric quantities such as Gaussian widths associated with the structure of $\theta^*$. We also obtain sharper regret bounds compared to earlier work for the unstructured $\theta^*$ setting as a consequence of our improved analysis. We show there is implicit exploration in the smoothed setting where a simple greedy algorithm works.
### 729.[Simple and sharp analysis of k-means||](https://proceedings.icml.cc/book/3969.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4459-Paper.pdf)
  Vaclav Rozhon [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4459-Metadata.json)
> <p>We present a truly simple analysis of k-means|| (Bahmani et al., PVLDB 2012) -- a distributed variant of the k-means++ algorithm (Arthur and Vassilvitskii, SODA 2007) -- and improve its round complexity from O(log (Var X)), where Var X is the variance of the input data set, to O(log (Var X) / log log (Var X)), which we show to be tight. </p> 
### 730.[Efficient proximal mapping of the path-norm regularizer of shallow networks](https://proceedings.icml.cc/book/3970.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4462-Paper.pdf)
  Fabian Latorre, Paul Rolland, Shaul Nadav Hallak, Volkan Cevher [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4462-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4462-Supplemental.zip)
> We demonstrate two new important properties of the path-norm regularizer for shallow neural networks. First, despite its non-smoothness and non-convexity it allows a closed form proximal operator which can be efficiently computed, allowing the use of stochastic proximal-gradient-type methods for regularized empirical risk minimization. Second, it provides an upper bound on the Lipschitz constant of the network, which is tighter than the trivial layer-wise product of Lipschitz constants, motivating its use for training networks robust to adversarial perturbations. Finally, in practical experiments we show that it provides a better robustness-accuracy trade-off when compared to $\ell_1$-norm regularization or training with a layer-wise constrain of the Lipschitz constant.
### 731.[Regularized Optimal Transport is Ground Cost Adversarial](https://proceedings.icml.cc/book/3971.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4482-Paper.pdf)
  François-Pierre Paty, Marco Cuturi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4482-Metadata.json)
> <p>Regularizing Wasserstein distances has proved to be the key in the recent advances of optimal transport (OT) in machine learning. Most prominent is the entropic regularization of OT, which not only allows for fast computations and differentiation using Sinkhorn algorithm, but also improves stability with respect to data and accuracy in many numerical experiments. Theoretical understanding of these benefits remains unclear, although recent statistical works have shown that entropy-regularized OT mitigates classical OT's curse of dimensionality. In this paper, we adopt a more geometrical point of view, and show using Fenchel duality that any convex regularization of OT can be interpreted as ground cost adversarial. This incidentally gives access to a robust dissimilarity measure on the ground space, which can in turn be used in other applications. We propose algorithms to compute this robust cost, and illustrate the interest of this approach empirically.</p> 
### 732.[Automatic Shortcut Removal for Self-Supervised Representation Learning](https://proceedings.icml.cc/book/3972.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4487-Paper.pdf)
  Matthias Minderer, Olivier Bachem, Neil Houlsby, Michael Tschannen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4487-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4487-Supplemental.pdf)
> <p>In self-supervised visual representation learning, a feature extractor is trained on a "pretext task" for which labels can be generated cheaply. A central challenge in this approach is that the feature extractor quickly learns to exploit low-level visual features such as color aberrations or watermarks and then fails to learn useful semantic representations. Much work has gone into identifying such "shortcut" features and hand-designing schemes to reduce their effect. Here, we propose a general framework for removing shortcut features automatically. Our key assumption is that those features which are the first to be exploited for solving the pretext task may also be the most vulnerable to an adversary trained to make the task harder. We show that this assumption holds across common pretext tasks and datasets by training a "lens" network to make small image changes that maximally reduce performance in the pretext task. Representations learned with the modified images outperform those learned without in all tested cases. Additionally, the modifications made by the lens reveal how the choice of pretext task and dataset affects the features learned by self-supervision.</p> 
### 733.[Fair Learning with Private Demographic Data](https://proceedings.icml.cc/book/3973.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4489-Paper.pdf)
  Hussein Mozannar, Mesrob Ohannessian, Nati Srebro [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4489-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4489-Supplemental.pdf)
> <p>Sensitive attributes such as race are rarely available to learners in real world settings as their collection is often restricted by laws and regulations. We give a scheme that allows individuals to release their sensitive information privately while still allowing any downstream entity to learn non-discriminatory predictors. We show how to adapt non-discriminatory learners to work with privatized protected attributes giving theoretical guarantees on performance. Finally, we highlight how the methodology could apply to learning fair predictors in settings where protected attributes are only available for a subset of the data.</p> 
### 734.[Deep Divergence Learning](https://proceedings.icml.cc/book/3974.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4491-Paper.pdf)
  Kubra Cilingir, Rachel Manzelli, Brian Kulis [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4491-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4491-Supplemental.pdf)
> <p>Classical linear metric learning methods have recently been extended along two distinct lines: deep metric learning methods for learning embeddings of the data using neural networks, and Bregman divergence learning approaches for extending learning Euclidean distances to more general divergence measures such as divergences over distributions.  In this paper, we introduce deep Bregman divergences, which are based on learning and parameterizing functional Bregman divergences using neural networks, and which unify and extend these existing lines of work.  We show in particular how deep metric learning formulations, kernel metric learning, Mahalanobis metric learning, and moment-matching functions for comparing distributions arise as special cases of these divergences in the symmetric setting.  We then describe a deep learning framework for learning general functional Bregman divergences, and show in experiments that this method yields superior performance on benchmark datasets as compared to existing deep metric learning approaches.  We also discuss novel applications, including a semi-supervised distributional clustering problem, and a new loss function for unsupervised data generation.</p> 
### 735.[A new regret analysis for Adam-type algorithms](https://proceedings.icml.cc/book/3975.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4498-Paper.pdf)
  Ahmet Alacaoglu, Yura Malitsky, Panayotis Mertikopoulos, Volkan Cevher [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4498-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4498-Supplemental.pdf)
> In this paper, we focus on a theory-practice gap for Adam and its variants (AMSgrad, AdamNC, etc.). In practice, these algorithms are used with a constant first-order moment parameter $\beta_{1}$ (typically between $0.9$ and $0.99$). In theory, regret guarantees for online convex optimization require a rapidly decaying $\beta_{1}\to0$ schedule. We show that this is an artifact of the standard analysis, and we propose a novel framework that allows us to derive optimal, data-dependent regret bounds with a constant $\beta_{1}$, without further assumptions. We also demonstrate the flexibility of our analysis on a wide range of different algorithms and settings.
### 736.[Accelerated Message Passing for Entropy-Regularized MAP Inference](https://proceedings.icml.cc/book/3976.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4505-Paper.pdf)
  Jonathan Lee, Aldo Pacchiano, Peter Bartlett, Michael Jordan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4505-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4505-Supplemental.pdf)
> Maximum a posteriori (MAP) inference is a fundamental problem in machine learning that involves identifying the most likely configuration of a discrete-valued Markov random field. Due to the difficulty of this combinatorial problem, linear programming (LP) relaxations are commonly used to derive specialized message passing algorithms that are often interpreted as coordinate descent on the dual LP. To achieve more desirable computational properties, a number of methods regularize the LP with an entropy term, leading to a class of smooth message passing algorithms with convergence guarantees. In this paper, we present randomized methods for accelerating these algorithms by leveraging techniques that underlie classical accelerated gradient methods. Crucially, the proposed algorithms incorporate the familiar steps of standard smooth message passing algorithms, which can be viewed as coordinate minimization steps. We show that the accelerated variants achieve faster rates for finding $\epsilon$-optimal points of the unregularized problem. When the LP is tight, we prove that the proposed algorithms recover the true MAP solution in fewer iterations than the best-known results.
### 737.[Dissecting Non-Vacuous Generalization Bounds based on the Mean-Field Approximation](https://proceedings.icml.cc/book/3977.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4506-Paper.pdf)
  Konstantinos Pitas [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4506-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4506-Supplemental.pdf)
> <p>Explaining how overparametrized neural networks simultaneously achieve low risk and zero empirical risk on benchmark datasets is an open problem. PAC-Bayes bounds optimized using variational inference (VI) have been recently proposed as a promising direction in obtaining non-vacuous bounds. We show empirically that this approach gives negligible gains when modelling the posterior as a Gaussian with diagonal covariance---known as the mean-field approximation. We investigate common explanations, such as the failure of VI due to problems in optimization or choosing a suboptimal prior. Our results suggest that investigating richer posteriors is the most promising direction forward.</p> 
### 738.[(Individual) Fairness for k-Clustering](https://proceedings.icml.cc/book/3978.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4507-Paper.pdf)
  Sepideh Mahabadi, Ali Vakilian [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4507-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4507-Supplemental.zip)
> We give a local search based algorithm for $k$-median ($k$-means) clustering from the perspective of individual fairness.  More precisely, for a point $x$ in a point set $P$ of size $n$, let $r(x)$ be the minimum radius such that the ball of radius $r(x)$ centered at $x$ has at least $n/k$ points from $P$. Intuitively, if a set of $k$ random points are chosen from $P$ as centers, every point $x\in P$ expects to have a center within radius $r(x)$. An individually fair clustering provides such a guarantee for every point $x\in P$. This notion of fairness was introduced in [Jung et al., 2019] where they showed how to get an approximately feasible $k$-clustering with respect to this fairness condition.  In this work, we show how to get an approximately \emph{optimal} such fair $k$-clustering. The $k$-median ($k$-means) cost of our solution is within a constant factor of the cost of an optimal fair $k$-clustering, and our solution approximately satisfies the fairness condition (also within a constant factor).  
### 739.[Relaxing Bijectivity Constraints with Continuously Indexed Normalising Flows](https://proceedings.icml.cc/book/3979.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4509-Paper.pdf)
  Rob Cornish, Anthony Caterini, George Deligiannidis, Arnaud Doucet [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4509-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4509-Supplemental.pdf)
> <p>We show that the bijectivity of normalising flows means they are misspecified for modelling target densities whose support has a different topology from the prior. In this case, we prove that the flow must become arbitrarily close to noninvertible in order even to approximate the target closely. This result has implications for all flow-based models, and particularly residual flows (ResFlows), which explicitly control the Lipschitz constant of the bijection used. To address this, we propose continuously indexed flows (CIFs), which replace the single bijection used by normalising flows with a continuously indexed family of bijections, and which intuitively allow rerouting mass that would be misplaced by a single bijection. We prove that CIFs can exactly match the support of the target even when its topology differs from the prior, and obtain empirically better performance for a variety of models on a variety of benchmarks.</p> 
### 740.[Gamification of Pure Exploration for Linear Bandits](https://proceedings.icml.cc/book/3980.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4512-Paper.pdf)
  Rémy Degenne, Pierre Menard, Xuedong Shang, Michal Valko [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4512-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4512-Supplemental.pdf)
> <p>We investigate an active \emph{pure-exploration} setting, that includes \emph{best-arm identification}, in the context of \emph{linear stochastic bandits}.  While asymptotically optimal algorithms exist for standard \emph{multi-armed bandits}, the existence of such algorithms for the best-arm identification in linear bandits has been elusive despite several attempts to address it.  First, we provide a thorough comparison and new insight over different notions of optimality in the linear case, including G-optimality, transductive optimality from optimal experimental design and asymptotic optimality.  Second, we design the first asymptotically optimal algorithm for fixed-confidence pure exploration in linear bandits. As a consequence, our algorithm naturally bypasses the pitfall caused by a simple but difficult instance, that most prior algorithms had to be engineered to deal with explicitly.  Finally, we avoid the need to fully solve an optimal design problem by providing an approach that entails an efficient implementation. </p> 
### 741.[Growing Adaptive Multi-hyperplane Machines](https://proceedings.icml.cc/book/3981.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4516-Paper.pdf)
  Nemanja Djuric, Zhuang Wang, Slobodan Vucetic [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4516-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4516-Supplemental.pdf)
> <p>Adaptive Multi-hyperplane Machine (AMM) is an online algorithm for learning Multi-hyperplane Machine (MM), a classification model which allows multiple hyperplanes per class. AMM is based on Stochastic Gradient Descent (SGD), with training time comparable to linear Support Vector Machine (SVM) and significantly higher accuracy. On the other hand, empirical results indicate there is a large accuracy gap between AMM and non-linear SVMs. In this paper we show that this performance gap is not due to limited representability of MM model, as it can represent arbitrary concepts. We set to explain a connection between AMM and LVQ, and introduce a novel Growing AMM (GAMM) algorithm motivated by Growing LVQ, that imputes duplicate hyperplanes into MM model during SGD training. We provide theoretical results showing that GAMM has favorable convergence properties, and analyze the generalization bound of MM models. Experiments indicate that GAMM achieves significantly improved accuracy on non-linear problems with only slightly slower training compared to AMM. On some tasks GAMM is even more accurate than non-linear SVM and other popular classifiers such as Neural Networks and Random Forests.</p> 
### 742.[Generative Teaching Networks: Accelerating Neural Architecture Search by Learning to Generate Synthetic Training Data](https://proceedings.icml.cc/book/3982.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4522-Paper.pdf)
  Felipe Petroski Such, Aditya Rawal, Joel Lehman, Kenneth Stanley, Jeffrey Clune [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4522-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4522-Supplemental.pdf)
> <p>This paper investigates the intriguing question of whether we can create learning algorithms that automatically generate training data, learning environments, and curricula in order to help AI agents rapidly learn. We show that such algorithms are possible via Generative Teaching Networks (GTNs), a general approach that is, in theory, applicable to supervised, unsupervised, and reinforcement learning, although our experiments only focus on the supervised case. GTNs are deep neural networks that generate data and/or training environments that a learner (e.g. a freshly initialized neural network) trains on for a few SGD steps before being tested on a target task. We then differentiate through the entire learning process via meta-gradients to update the GTN parameters to improve performance on the target task. GTNs have the beneficial property that they can theoretically generate any type of data or training environment, making their potential impact large. This paper introduces GTNs, discusses their potential, and showcases that they can substantially accelerate learning. We also demonstrate a practical and exciting application of GTNs: accelerating the evaluation of candidate architectures for neural architecture search (NAS), which is rate-limited by such evaluations, enabling massive speed-ups in NAS. GTN-NAS improves the NAS state of the art, finding higher performing architectures when controlling for the search proposal mechanism. GTN-NAS also is competitive with the overall state of the art approaches, which achieve top performance while using orders of magnitude less computation than typical NAS methods. Speculating forward, GTNs may represent a first step toward the ambitious goal of algorithms that generate their own training data and, in doing so, open a variety of interesting new research questions and directions.</p> 
### 743.[Structured Prediction with Partial Labelling through the Infimum Loss](https://proceedings.icml.cc/book/3983.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4526-Paper.pdf)
  Vivien Cabannnes, Francis Bach, Alessandro Rudi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4526-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4526-Supplemental.pdf)
> <p>Annotating datasets is one of the main costs in nowadays supervised learning.   The goal of weak supervision is to enable models to learn using only forms of   labelling which are cheaper to collect, as partial labelling. This is a type of   incomplete annotation where, for each datapoint, supervision is cast as a set   of labels containing the real one.  The problem of supervised learning with   partial labelling has been studied for specific instances such as   classification, multi-label, ranking or segmentation, but a general framework   is still missing. This paper provides a unified framework based on structured   prediction and on the concept of {\em infimum loss} to deal with partial   labelling over a wide family of learning problems and loss functions. The   framework leads naturally to explicit algorithms that can be easily   implemented and for which proved statistical consistency and learning rates.   Experiments confirm the superiority of the proposed approach over commonly   used baselines. </p> 
### 744.[ControlVAE: Controllable Variational Autoencoder](https://proceedings.icml.cc/book/3984.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4532-Paper.pdf)
  Huajie Shao, Shuochao Yao, Dachun Sun, Aston Zhang, Shengzhong Liu, Dongxin Liu, Jun Wang, Tarek Abdelzaher [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4532-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4532-Supplemental.pdf)
> <p>Variational Autoencoders (VAE) and their variants have been widely used in a variety of applications, such as dialog generation, image generation and disentangled representation learning. However, the existing VAE models have some limitations in different applications. For example, a VAE easily suffers from KL vanishing in language modeling and low reconstruction quality for disentangling. To address these issues, we propose a novel controllable variational autoencoder framework, ControlVAE, that combines a controller, inspired by automatic control theory, with the basic VAE to improve the performance of resulting generative models. Specifically, we design a new non-linear PI controller, a variant of the proportional-integral-derivative (PID) control, to automatically tune the hyperparameter (weight) added in the VAE objective using the output KL-divergence as feedback during model training. The framework is evaluated using three applications; namely, language modeling, disentangled representation learning, and image generation. The results show that ControlVAE can achieve better disentangling and reconstruction quality than the existing methods. For language modelling, it not only averts the KL-vanishing, but also improves the diversity of generated text. Finally, we also demonstrate that ControlVAE improves the reconstruction quality of generated images compared to the original VAE.</p> 
### 745.[On Semi-parametric Inference for BART](https://proceedings.icml.cc/book/3985.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4533-Paper.pdf)
  Veronika Rockova [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4533-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4533-Supplemental.pdf)
> <p>There has been a growing realization of the potential of Bayesian machine learning as a platform that can provide both flexible modeling, accurate predictions as well as coherent uncertainty statements. In particular, Bayesian Additive Regression Trees (BART) have emerged as one of today’s most effective general approaches to predictive modeling under minimal assumptions. Statistical theoretical developments for machine learning have been mostly concerned with approximability or rates of estimation when recovering infinite dimensional objects (curves or densities). Despite the impressive array of available theoretical results, the literature has been largely silent about uncertainty quantification. In this work, we continue the theoretical investigation of BART initiated recently by Rockova and van der Pas (2017). We focus on statistical inference questions. In particular, we study the Bernstein-von Mises (BvM) phenomenon (i.e. asymptotic normality) for smooth linear functionals of the regression surface within the framework of non-parametric regression with fixed covariates. Our semi-parametric BvM results show that, beyond rate-optimal estimation, BART can be also used for valid statistical inference. </p> 
### 746.[Simple and Scalable Epistemic Uncertainty Estimation Using a Single Deep Deterministic Neural Network](https://proceedings.icml.cc/book/3986.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4538-Paper.pdf)
  Joost van Amersfoort, Lewis Smith, Yee Whye Teh, Yarin Gal [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4538-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4538-Supplemental.pdf)
> <p>We propose a method for training a deterministic deep model that can find and reject out of distribution data points at test time with a single forward pass. Our approach, deterministic uncertainty quantification (DUQ), builds upon ideas of RBF networks. We scale training in these with a novel loss function and centroid updating scheme. By enforcing detectability of changes in the input using a gradient penalty, we are able to reliably detect out of distribution data. Our uncertainty quantification scales well to large datasets, and using a single model, we improve upon Deep Ensembles on notable difficult dataset pairs such as FashionMNIST vs. MNIST, and CIFAR-10 vs. SVHN, while maintaining competitive accuracy.</p> 
### 747.[Ordinal Non-negative Matrix Factorization for Recommendation](https://proceedings.icml.cc/book/3987.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4539-Paper.pdf)
  Olivier Gouvert, Thomas Oberlin, Cedric Fevotte [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4539-Metadata.json)
> <p>We introduce a new non-negative matrix factorization (NMF) method for ordinal data, called OrdNMF. Ordinal data are categorical data which exhibit a natural ordering between the categories. In particular, they can be found in recommender systems, either with explicit data (such as ratings) or implicit data (such as quantized play counts). OrdNMF is a probabilistic latent factor model that generalizes Bernoulli-Poisson factorization (BePoF) and Poisson factorization (PF) applied to binarized data. Contrary to these methods, OrdNMF circumvents binarization and can exploit a more informative representation of the data. We design an efficient variational algorithm based on a suitable model augmentation and related to variational PF. In particular, our algorithm preserves the scalability of PF and can be applied to huge sparse datasets. We report recommendation experiments on explicit and implicit datasets, and show that OrdNMF outperforms BePoF and PF applied to binarized data.</p> 
### 748.[NetGAN without GAN: From Random Walks to Low-Rank Approximations](https://proceedings.icml.cc/book/3988.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4540-Paper.pdf)
  Luca Rendsburg, Holger Heidrich, Ulrike von Luxburg [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4540-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4540-Supplemental.pdf)
> <p>A graph generative model takes a graph as input and is supposed to generate new graphs that ``look like'' the input graph. While most classical models focus on few, hand-selected graph statistics and are too simplistic to reproduce real-world graphs, NetGAN recently emerged as an attractive alternative: by training a GAN to learn the random walk distribution of the input graph, the algorithm is able to reproduce a large number of important network patterns simultaneously, without explicitly specifying any of them. In this paper, we investigate the implicit bias of NetGAN. We find that the root of its generalization properties does not lie in the GAN architecture, but in an inconspicuous low-rank approximation of the logits random walk transition matrix. Step by step we can strip NetGAN of all unnecessary parts, including the GAN, and obtain a highly simplified reformulation that achieves comparable generalization results, but is orders of magnitudes faster and easier to adapt. Being much simpler on the conceptual side, we reveal the implicit inductive bias of the algorithm  --- an important step towards increasing the interpretability, transparency and acceptance of machine learning systems.</p> 
### 749.[On the Iteration Complexity of Hypergradient Computations](https://proceedings.icml.cc/book/3989.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4542-Paper.pdf)
  Riccardo Grazzi, Saverio Salzo, Massimiliano Pontil, Luca Franceschi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4542-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4542-Supplemental.pdf)
> <p>We study a general class of bilevel optimization problems, in which the upper-level objective is defined via the solution of a fixed point equation. Important instances arising in machine learning include hyper-parameter optimization, meta-learning, graph and recurrent neural networks. Typically the gradient of the upper-level objective is not known explicitly or is hard to compute exactly, which has raised the interest in approximation methods. We investigate two popular approaches to compute the hypergradient, based on reverse mode iterative differentiation and approximate implicit differentiation. We present a unified analysis which allows for the first time to quantitatively compare these methods, providing explicit bounds for their iteration complexity. This analysis suggests a hierarchy in terms of computational efficiency among the above methods, with approximate implicit differentiation based on conjugate gradient performing best. We present an extensive experimental comparison among the methods which confirm the theoretical findings.</p> 
### 750.[Skew-Fit: State-Covering Self-Supervised Reinforcement Learning](https://proceedings.icml.cc/book/3990.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4543-Paper.pdf)
  Vitchyr Pong, Murtaza Dalal, Steven Lin, Ashvin Nair, Shikhar Bahl, Sergey Levine [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4543-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4543-Supplemental.pdf)
> <p>Autonomous agents that must exhibit flexible and broad capabilities will need to be equipped with large repertoires of skills. Defining each skill with a manually-designed reward function limits this repertoire and imposes a manual engineering burden. Self-supervised agents that set their own goals can automate this process, but designing appropriate goal setting objectives can be difficult, and often involves heuristic design decisions. In this paper, we propose a formal exploration objective for goal-reaching policies that maximizes state coverage. We show that this objective is equivalent to maximizing goal reaching performance together with the entropy of the goal distribution, where goals correspond to full state observations. To instantiate this principle, we present an algorithm called Skew-Fit for learning a maximum-entropy goal distributions. We prove that, under regularity conditions, Skew-Fit converges to a uniform distribution over the set of valid states, even when we do not know this set beforehand. Our experiments show that combining Skew-Fit for learning goal distributions with existing goal-reaching methods outperforms a variety of prior methods on open-sourced visual goal-reaching tasks. Moreover, we demonstrate that Skew-Fit enables a real-world robot to learn to open a door, entirely from scratch, from pixels, and without any manually-designed reward function.</p> 
### 751.[Stochastic Optimization for Regularized Wasserstein Estimators](https://proceedings.icml.cc/book/3991.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4567-Paper.pdf)
  Marin Ballu, Quentin Berthet, Francis Bach [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4567-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4567-Supplemental.pdf)
> <p>Optimal transport is a foundational problem in optimization, that allows to compare probability distributions while taking into account geometric aspects. Its optimal objective value, the Wasserstein distance, provides an important loss between distributions that has been used in many applications throughout machine learning and statistics. Recent algorithmic progress on this problem and its regularized versions have made these tools increasingly popular. However, existing techniques require solving an optimization problem to obtain a single gradient of the loss, thus slowing down first-order methods to minimize the sum of losses, that require many such gradient computations. In this work, we introduce an algorithm to solve a regularized version of this problem of Wasserstein estimators, with a time per step which is sublinear in the natural dimensions of the problem. We introduce a dual formulation, and optimize it with stochastic gradient steps that can be computed directly from samples, without solving additional optimization problems at each step. Doing so, the estimation and computation tasks are performed jointly. We show that this algorithm can be extended to other tasks, including estimation of Wasserstein barycenters. We provide theoretical guarantees and illustrate the performance of our algorithm with experiments on synthetic data.</p> 
### 752.[LP-SparseMAP: Differentiable Relaxed Optimization for Sparse Structured Prediction](https://proceedings.icml.cc/book/3992.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4569-Paper.pdf)
  Vlad Niculae, Andre Filipe Torres Martins [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4569-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4569-Supplemental.pdf)
> <p>Structured predictors require solving a combinatorial optimization problem over a large number of structures, such as dependency trees or alignments. When embedded as structured hidden layers in a neural net, argmin differentiation and efficient gradient computation are further required. Recently, SparseMAP has been proposed as a differentiable, sparse alternative to maximum a posteriori (MAP) and marginal inference. SparseMAP returns an interpretable combination of a small number of structures; its sparsity being the key to efficient optimization. However, SparseMAP requires access to an exact MAP oracle in the structured model, excluding, e.g., loopy graphical models or logic constraints, which generally require approximate inference. In this paper, we introduce LP-SparseMAP, an extension of SparseMAP addressing this limitation via a local polytope relaxation. LP-SparseMAP uses the flexible and powerful language of factor graphs to define expressive hidden structures, supporting coarse decompositions, hard logic constraints, and higher-order correlations. We derive the forward and backward algorithms needed for using LP-SparseMAP as a structured hidden or output layer. Experiments in three structured tasks show benefits versus SparseMAP and Structured SVM.</p> 
### 753.[Problems with Shapley-value-based explanations as feature importance measures](https://proceedings.icml.cc/book/3993.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4594-Paper.pdf)
  Indra Kumar, Suresh Venkatasubramanian, Carlos  Scheidegger, Sorelle Friedler [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4594-Metadata.json)
> <p>Game-theoretic formulations of feature importance have become popular as a way to "explain" machine learning models. These methods define a cooperative game between the features of a model and distribute influence among these input elements using some form of the game's unique Shapley values. Justification for these methods rests on two pillars: their desirable mathematical properties, and their applicability to specific motivations for explanations. We show that mathematical problems arise when Shapley values are used for feature importance and that the solutions to mitigate these necessarily induce further complexity, such as the need for causal reasoning. We also draw on additional literature to argue that Shapley values do not provide explanations which suit human-centric goals of explainability.</p> 
### 754.[Model-free Reinforcement Learning in Infinite-horizon Average-reward Markov Decision Processes](https://proceedings.icml.cc/book/3994.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4595-Paper.pdf)
  Chen-Yu Wei, Mehdi Jafarnia, Haipeng Luo, Hiteshi Sharma, Rahul Jain [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4595-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4595-Supplemental.pdf)
> <p>Model-free reinforcement learning is known to be memory and computation efficient and more amendable to large scale problems. In this paper, two model-free algorithms are introduced for learning infinite-horizon average-reward Markov Decision Processes (MDPs). The first algorithm reduces the problem to the discounted-reward version and achieves O(T^{2/3}) regret after T steps, under the minimal assumption of weakly communicating MDPs. The second algorithm makes use of recent advances in adaptive algorithms for adversarial multi-armed bandits and improves the regret to O(\sqrt{T}), albeit with a stronger ergodic assumption. To the best of our knowledge, these are the first model-free algorithms with sub-linear regret (that is polynomial in all parameters) in the infinite-horizon average-reward setting.</p> 
### 755.[Near-linear time Gaussian process optimization with adaptive batching and resparsification](https://proceedings.icml.cc/book/3995.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4596-Paper.pdf)
  Daniele Calandriello, Luigi Carratino, Alessandro Lazaric, Michal Valko, Lorenzo Rosasco [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4596-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4596-Supplemental.pdf)
> <p>Gaussian processes (GP) are one of the most successful frameworks to model uncertainty. However, GP optimization (e.g., GP-UCB) suffers from major scalability issues. Experimental time grows linearly with the number of evaluations, unless candidates are selected in batches (e.g., using GP-BUCB) and evaluated in parallel. Furthermore, computational cost is often prohibitive since algorithms such as GP-BUCB require a time at least quadratic in the number of dimensions and iterations to select each batch.</p>  <p>In this paper, we introduce BBKB (Batch Budgeted Kernel Bandits), the first no-regret GP optimization algorithm that provably runs in near-linear time and selects candidates in batches. This is obtained with a new guarantee for the tracking of the posterior variances that allows BBKB to choose increasingly larger batches, improving over GP-BUCB. Moreover, we show that the same bound can be used to adaptively delay costly updates to the sparse GP approximation used by BBKB, achieving a near-constant per-step amortized cost. These findings are then confirmed in several experiments, where BBKB is much faster than state-of-the-art methods.</p> 
### 756.[Parallel Algorithm for Non-Monotone DR-Submodular Maximization](https://proceedings.icml.cc/book/3996.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4609-Paper.pdf)
  Alina Ene, Huy Nguyen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4609-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4609-Supplemental.pdf)
> In this work, we give a new parallel algorithm for the problem of maximizing a non-monotone diminishing returns submodular function subject to a cardinality constraint. For any desired accuracy $\epsilon$, our algorithm achieves a $1/e - \epsilon$ approximation using $O(\log{n} \log(1/\epsilon) / \epsilon^3)$ parallel rounds of function evaluations. The approximation guarantee nearly matches the best approximation guarantee known for the problem in the sequential setting and the number of parallel rounds is nearly-optimal for any constant $\epsilon$. Previous algorithms achieve worse approximation guarantees using $\Omega(\log^2{n})$ parallel rounds. Our experimental evaluation suggests that our algorithm obtains solutions whose objective value nearly matches the value obtained by the state of the art sequential algorithms, and it outperforms previous parallel algorithms in number of parallel rounds, iterations, and solution quality.
### 757.[Structure Adaptive Algorithms for Stochastic Bandits](https://proceedings.icml.cc/book/3997.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4610-Paper.pdf)
  Rémy Degenne, Han Shao, Wouter Koolen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4610-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4610-Supplemental.pdf)
> <p>We study reward maximisation in a wide class of structured stochastic multi-armed bandit problems, where the mean rewards of arms satisfy some given structural constraints, e.g. linear, unimodal, sparse, etc. Our aim is to develop methods that are \emph{flexible} (in that they easily adapt to different structures), \emph{powerful} (in that they perform well empirically and/or provably match instance-dependent lower bounds) and \emph{efficient} in that the per-round computational burden is small. We develop asymptotically optimal algorithms from instance-dependent lower-bounds using iterative saddle-point solvers. Our approach generalises recent iterative methods for pure exploration to reward maximisation, where a major challenge arises from the estimation of the sub-optimality gaps and their reciprocals. Still we manage to achieve all the above desiderata. Notably, our technique avoids the computational cost of the full-blown saddle point oracle employed by previous work, while at the same time enabling finite-time regret bounds.  Our experiments reveal that our method successfully leverages the structural assumptions, while its regret is at worst comparable to that of vanilla UCB.</p> 
### 758.[Spectrum Dependent Learning Curves in Kernel Regression and Wide Neural Networks](https://proceedings.icml.cc/book/3998.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4620-Paper.pdf)
  Blake Bordelon, Abdulkadir Canatar, Cengiz Pehlevan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4620-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4620-Supplemental.pdf)
> <p>A fundamental question in modern machine learning is how overparameterized deep neural networks can generalize. We address this question using 1) an equivalence between training infinitely wide neural networks and performing kernel regression with a deterministic kernel called the Neural Tangent Kernel (NTK), and 2) theoretical tools from statistical physics. We derive analytical expressions for learning curves for kernel regression, and use them to evaluate how the test loss of a trained neural network depends on the number of samples. Our approach allows us not only to compute the total test risk but also the decomposition of the risk due to different spectral components of the kernel. Complementary to recent results showing that during gradient descent, neural networks fit low frequency components first, we identify a new type of frequency principle: as the size of the training set size grows, kernel machines and neural networks begin to fit successively higher frequency modes of the target function. We verify our theory with simulations of kernel regression and training wide artificial neural networks. </p> 
### 759.[Preference modelling with context-dependent salient features](https://proceedings.icml.cc/book/3999.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4621-Paper.pdf)
  Amanda Bower, Laura Balzano [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4621-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4621-Supplemental.pdf)
> <p>We consider the problem of estimating a ranking on a set of items from noisy pairwise comparisons given item features. We address the observation that pairwise comparison data often reflects irrational choice, e.g. intransitivity. Our key observation is that two items compared in isolation from other items may be compared based on only a salient subset of features. Formalizing this framework, we propose the \textit{salient feature preference model} and prove a sample complexity result for learning the parameters of our model and the underlying ranking with maximum likelihood estimation. We also provide empirical results that support our theoretical bounds and illustrate how our model explains systematic intransitivity. Finally we demonstrate the strong performance of maximum likelihood estimation of our model on both synthetic data and two real data sets: the UT Zappos50K data set and comparison data about the compactness of legislative districts in the United States.</p> 
### 760.[Infinite attention: NNGP and NTK for deep attention networks](https://proceedings.icml.cc/book/4000.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4625-Paper.pdf)
  Jiri Hron, Yasaman Bahri, Jascha Sohl-Dickstein, Roman Novak [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4625-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4625-Supplemental.pdf)
> <p>There is a growing amount of literature on the relationship between wide neural networks (NNs) and Gaussian processes (GPs), identifying equivalence between the two for a variety of NN architectures. This equivalence enables, for instance, accurate approximation of the behaviour of wide Bayesian NNs without MCMC or variational approximations, or characterisation of the distribution of randomly initialised wide NNs optimised by gradient descent without ever running an optimiser. We provide a rigorous extension of these results to NNs involving attention layers, showing that unlike single-head attention, which induces non-Gaussian behaviour, multi-head attention architectures behave as GPs as the number of heads tends to infinity.  We further discuss the effects of positional encodings and layer normalisation, and propose modifications of the attention mechanism which lead to improved results for both finite and infinitely wide NNs. We evaluate attention kernels empirically, leading to a moderate improvement upon the previous state-of-the-art on CIFAR-10 for GPs without trainable kernels and advanced data preprocessing. Finally, we release code allowing applications of NNGP/NTK models, with and without attention, to variable-length sequences, with an example on the IMDb reviews dataset.</p> 
### 761.[Fast Learning of Graph Neural Networks with Guaranteed Generalizability: One-hidden-layer Case](https://proceedings.icml.cc/book/4001.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4631-Paper.pdf)
  shuai zhang, Meng Wang, Sijia Liu, Pin-Yu Chen, Jinjun Xiong [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4631-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4631-Supplemental.pdf)
> <p>Although graph neural networks (GNNs) have made great progress recently on learning from graph-structured data in practice, their theoretical guarantee on generalizability remains elusive in the literature. In this paper, we provide a theoretically-grounded generalizability analysis of GNNs with one hidden layer for both regression and binary classification problems. Under the assumption that there exists a ground-truth GNN model (with zero generalization error), the objective of GNN learning is to estimate the ground-truth GNN parameters from the training data. To achieve this objective, we propose a learning algorithm that is built on tensor initialization and accelerated gradient descent. We then show that the proposed learning algorithm converges to the ground-truth GNN model for the regression problem, and to a model sufficiently close to the ground-truth for the binary classification problem. Moreover, for both cases, the convergence rate of the proposed learning algorithm is proven to be linear and faster than the vanilla gradient descent algorithm. We further explore the relationship between the sample complexity of GNNs and their underlying graph properties. Lastly, we provide numerical experiments to demonstrate the validity of our analysis and the effectiveness of the proposed learning algorithm for GNNs.</p> 
### 762.[Efficient Domain Generalization via Common-Specific Low-Rank Decomposition](https://proceedings.icml.cc/book/4002.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4649-Paper.pdf)
  Vihari Piratla, Praneeth Netrapalli, Sunita Sarawagi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4649-Metadata.json)
> <p>Domain generalization refers to the task of training a model which generalizes to new domains that  are  not  seen  during  training.   We  present CSD (Common Specific Decomposition), for this setting, which jointly learns a common component (which generalizes to new domains) and a domain specific component (which overfits on training domains).  The domain specific components are discarded after training and only the common component is retained. The algorithm is extremely simple and involves only modifying the final linear classification layer of any given neural network architecture.  We show that CSD either matches or beats state of the art approaches for domain generalization based on domain erasure and domain perturbed data augmentation. Further diagnostics on rotated MNIST, where domains are interpretable, confirm the hypothesis that CSD successfully disentangles common and domain specific components and hence leads to better domain generalization.</p> 
### 763.[Identifying the Reward Function by Anchor Actions](https://proceedings.icml.cc/book/4003.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4651-Paper.pdf)
  Sinong Geng, Houssam Nassif, Carlos Manzanares, Max Reppen, Ronnie Sircar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4651-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4651-Supplemental.pdf)
> We propose a reward function estimation framework for inverse reinforcement learning with deep energy-based policies. Our method sequentially estimates the policy, the $Q$-function, and the reward. We refer to it as the PQR method. This method does not require the assumption that the reward depends on the state only, but instead allows also for dependency on the choice of action. Moreover, the method allows for the state transitions to be stochastic. To accomplish this, we assume the existence of one anchor action whose reward is known, typically the action of doing nothing, yielding no reward. We present both estimators and algorithms for the PQR method. When the environment transition is known, we prove that the reward estimator of PQR uniquely recovers the true reward. With unknown transitions, convergence analysis is presented for the PQR method. Finally, we apply PQR to both synthetic and real-world datasets, demonstrating superior performance in terms of reward estimation compared to competing methods. 
### 764.[No-Regret and Incentive-Compatible Online Learning](https://proceedings.icml.cc/book/4004.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4656-Paper.pdf)
  Rupert Freeman, David Pennock, Chara Podimata, Jennifer Wortman Vaughan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4656-Metadata.json)
> <p>We study online learning settings in which experts act strategically to maximize their influence on the learning algorithm's predictions by potentially misreporting their beliefs about a sequence of binary events. Our goal is twofold. First, we want the learning algorithm to be no-regret with respect to the best fixed expert in hindsight. Second, we want incentive compatibility, a guarantee that each expert's best strategy is to report his true beliefs about the realization of each event.  To achieve this goal, we build on the literature on wagering mechanisms, a type of multi-agent scoring rule. We provide algorithms that achieve no regret and incentive compatibility for myopic experts for both the full and partial information settings.  In experiments on datasets from FiveThirtyEight, our algorithms have regret comparable to classic no-regret algorithms, which are not incentive-compatible. Finally, we identify an incentive-compatible algorithm for forward-looking strategic agents that exhibits diminishing regret in practice.</p> 
### 765.[Probing Emergent Semantics in Predictive Agents via Question Answering](https://proceedings.icml.cc/book/4005.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4662-Paper.pdf)
  Abhishek Das, Federico Carnevale, Hamza Merzic, Laura Rimell, Rosalia Schneider, Josh Abramson, Alden Hung, Arun Ahuja, Stephen Clark, Greg Wayne, Feilx Hill [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4662-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4662-Supplemental.pdf)
> <p>Recent work has shown how predictive modeling can endow agents with rich knowledge of their surroundings, improving their ability to act in complex environments. We propose question-answering as a general paradigm to decode and understand the representations that such agents develop, applying our method to two recent approaches to predictive modelling - action-conditional CPC (Guo et al., 2018) and SimCore (Gregor et al., 2019). After training agents with these predictive objectives in a visually-rich, 3D environment with an assortment of objects, colors, shapes, and spatial configurations, we probe their internal state representations with a host of synthetic (English) questions, without backpropagating gradients from the question-answering decoder into the agent. The performance of different agents when probed in this way reveals that they learn to encode factual, and seemingly compositional, information about objects, properties and spatial relations from their physical environment. Our approach is intuitive, i.e. humans can easily interpret the responses of the model as opposed to inspecting continuous vectors, and model-agnostic, i.e. applicable to any modeling approach. By revealing the implicit knowledge of objects, quantities, properties and relations acquired by agents as they learn, question-conditional agent probing can stimulate the design and development of stronger predictive learning objectives.</p> 
### 766.[Meta-learning with Stochastic Linear Bandits](https://proceedings.icml.cc/book/4006.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4667-Paper.pdf)
  Leonardo Cella, Alessandro Lazaric, Massimiliano Pontil [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4667-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4667-Supplemental.pdf)
> <p>We investigate meta-learning procedures in the setting of stochastic linear bandits tasks. The goal is to select a learning algorithm which works well on average over a class of bandits tasks, that are sampled from a task-distribution. Inspired by recent work on learning-to-learn linear regression, we consider a class of bandit algorithms that implement a regularized version of the well-known OFUL algorithm, where the regularization is a square euclidean distance to a bias vector. We first study the benefit of the biased OFUL algorithm in terms of regret minimization. We then propose two strategies to estimate the bias within the learning-to-learn setting. We show both theoretically and experimentally, that when the number of tasks grows and the variance of the task-distribution is small, our strategies have a significant advantage over learning the tasks in isolation.</p> 
### 767.[A Unified Theory of Decentralized SGD with Changing Topology and Local Updates](https://proceedings.icml.cc/book/4007.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4675-Paper.pdf)
  Anastasiia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi, Sebastian Stich [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4675-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4675-Supplemental.pdf)
> <p>Decentralized stochastic optimization methods have gained a lot of attention recently, mainly because of their cheap per iteration cost, data locality, and their communication-efficiency. In this paper we introduce a unified convergence analysis that covers a large variety of decentralized SGD methods which so far have required different intuitions, have different applications, and which have been developed separately in various communities. </p>  <p>Our algorithmic framework covers local SGD updates and synchronous and pairwise gossip updates on adaptive network topology. We derive universal convergence rates for smooth (convex and non-convex) problems and the rates interpolate between the heterogeneous (non-identically distributed data) and iid-data settings, recovering linear convergence rates in many special cases, for instance for over-parametrized models. Our proofs rely on weak assumptions (typically improving over prior work in several aspects) and recover (and improve) the best known complexity results for a host of important scenarios, such as for instance coorperative SGD and federated averaging (local SGD).</p> 
### 768.[AdaScale SGD: A User-Friendly Algorithm for Distributed Training](https://proceedings.icml.cc/book/4008.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4682-Paper.pdf)
  Tyler Johnson, Pulkit Agrawal, Haijie Gu, Carlos Guestrin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4682-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4682-Supplemental.pdf)
> <p>When using large-batch training to speed up stochastic gradient descent, learning rates must adapt to new batch sizes in order to maximize speed-ups and preserve model quality.  Re-tuning learning rates is resource intensive, while fixed scaling rules often degrade model quality.  We propose AdaScale SGD, an algorithm that reliably adapts learning rates to large-batch training.  By continually adapting to the gradient's variance, AdaScale automatically achieves speed-ups for a wide range of batch sizes.  We formally describe this quality with AdaScale’s convergence bound, which maintains final objective values, even as batch sizes grow large and the number of iterations decreases.  In empirical comparisons, AdaScale trains well beyond the batch size limits of popular “linear learning rate scaling” rules.  This includes large-batch training with no model degradation for machine translation, image classification, object detection, and speech recognition tasks.  AdaScale's qualitative behavior is similar to that of "warm-up" heuristics, but unlike warm-up, this behavior emerges naturally from a principled mechanism. The algorithm introduces negligible computational overhead and no new hyperparameters, making AdaScale an attractive choice for large-scale training in practice.</p> 
### 769.[Kinematic State Abstraction and Provably Efficient Rich-Observation Reinforcement Learning](https://proceedings.icml.cc/book/4009.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4686-Paper.pdf)
  Dipendra Misra, Mikael Henaff, Akshay Krishnamurthy, John Langford [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4686-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4686-Supplemental.pdf)
> <p>We present an algorithm, HOMER, for exploration and reinforcement learning in rich observation environments that are summarizable by an unknown latent state space. The algorithm interleaves representation learning to identify a new notion of kinematic state abstraction with strategic exploration to reach new states using the learned abstraction. The algorithm provably explores the environment with sample complexity scaling polynomially in the number of latent states and the time horizon, and, crucially, with no dependence on the size of the observation space, which could be infinitely large. This exploration guarantee further enables sample-efficient global policy optimization for any reward function. On the computational side, we  show that the algorithm can be implemented efficiently whenever certain supervised learning problems are tractable.  Empirically, we evaluate HOMER on a challenging exploration problem, where we show that the algorithm is more sample efficient than standard reinforcement learning baselines.</p> 
### 770.[Logistic Regression for Massive Data with Rare Events](https://proceedings.icml.cc/book/4010.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4690-Paper.pdf)
  HaiYing Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4690-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4690-Supplemental.zip)
> <p>This paper studies binary logistic regression for rare events data, or imbalanced data, where the number of events (observations in one class, often called cases) is significantly smaller than the number of nonevents (observations in the other class, often called controls). We first derive the asymptotic distribution of the maximum likelihood estimator (MLE) of the unknown parameter, which shows that the asymptotic variance convergences to zero in a rate of the inverse of the number of the events instead of the inverse of the full data sample size. This indicates that the available information in rare events data is at the scale of the number of events instead of the full data sample size. Furthermore, we prove that under-sampling a small proportion of the nonevents, the resulting under-sampled estimator may have identical asymptotic distribution to the full data MLE. This demonstrates the advantage of under-sampling nonevents for rare events data, because this procedure may significantly reduce the computation and/or data collection costs. Another common practice in analyzing rare events data is to over-sample (replicate) the events, which has a higher computational cost. We show that this procedure may even result in efficiency loss in terms of parameter estimation.</p> 
### 771.[Automated Synthetic-to-Real Generalization](https://proceedings.icml.cc/book/4011.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4697-Paper.pdf)
  Wuyang Chen, Zhiding Yu, Zhangyang Wang, Anima Anandkumar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4697-Metadata.json)
> <p>Models trained on synthetic images often face degraded generalization to real data. To remedy such domain gaps, synthetic training often starts with ImageNet pretrained models in domain generalization and adaptation as they contain the representation from real images. However, the role of ImageNet representation is seldom discussed despite common practices that leverage this knowledge implicitly to maintain generalization ability. An example is the careful hand tuning of learning rates across different network layers which can be laborious and non-scalable. We treat this as a learning without forgetting problem and propose a learning-to-optimize (L2O) method to automate layer-wise learning rates. With comprehensive experiments, we demonstrate that the proposed method can significantly improve the synthetic-to-real generalization performance without seeing and training on real data, while benefiting downstream tasks such as domain adaptation.</p> 
### 772.[Online Learning with Dependent Stochastic Feedback Graphs](https://proceedings.icml.cc/book/4012.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4700-Paper.pdf)
  Corinna Cortes, Giulia DeSalvo, Claudio Gentile, Mehryar Mohri, Ningshan Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4700-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4700-Supplemental.pdf)
> <p>A general framework for online learning with partial information is one where feedback graphs specify which losses can be observed by the learner. We study a challenging scenario where feedback graphs vary stochastically with time and, more importantly, where graphs and losses are dependent. This scenario appears in several real-world applications that we describe where the outcome of actions are correlated. We devise a new algorithm for this setting that exploits the stochastic properties of the graphs and that benefits from favorable regret guarantees. We present a detailed theoretical analysis of this algorithm, and also report the results of a series of experiments on real-world datasets, which show that our algorithm outperforms standard baselines for online learning with feedback graphs.</p> 
### 773.[Sparse Sinkhorn Attention](https://proceedings.icml.cc/book/4013.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4710-Paper.pdf)
  Yi Tay, Dara Bahri, Liu Yang, Don Metzler, Da-Cheng Juan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4710-Metadata.json)
> <p>We propose Sparse Sinkhorn Attention, a new efficient and sparse method for learning to attend. Our method is based on differentiable sorting of internal representations. Concretely, we introduce a meta sorting network that learns to generate latent permutations over sequences. Given sorted sequences, we are then able to compute quasi-global attention with only local windows, improving the memory efficiency of the attention module. To this end, we propose new algorithmic innovations such as Causal Sinkhorn Balancing and SortCut, a dynamic sequence truncation method for tailoring Sinkhorn Attention for encoding and/or decoding purposes. Via extensive experiments on algorithmic seq2seq sorting, language modeling, pixel-wise image generation, document classification and natural language inference, we demonstrate that our memory efficient Sinkhorn Attention method is competitive with vanilla attention and consistently outperforms recently proposed efficient Transformer models such as Sparse Transformers.</p> 
### 774.[Online Continual Learning from Imbalanced Data](https://proceedings.icml.cc/book/4014.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4727-Paper.pdf)
  Aristotelis Chrysakis, Marie-Francine Moens [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4727-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4727-Supplemental.pdf)
> <p>A well-documented weakness of neural networks is the fact that they suffer from catastrophic forgetting when trained on data provided by a non-stationary distribution. Recent work in the field of continual learning attempts to understand and overcome this issue. Unfortunately, the majority of relevant work embraces the implicit assumption that the distribution of observed data is perfectly balanced. In contrast, humans and animals learn from observations that are temporally correlated and severely imbalanced. Motivated by this remark, we aim to evaluate memory population methods that are used in online continual learning, when dealing with highly imbalanced and temporally correlated streams of data. More importantly, we introduce a new memory population approach, which we call class-balancing reservoir sampling (CBRS). We demonstrate that CBRS outperforms the state-of-the-art memory population algorithms in a considerably challenging learning setting, over a range of different datasets, and for multiple architectures. Finally, we probe the computational efficiency of CBRS compared to the state of the art, both in terms of time and memory overhead. </p> 
### 775.[Differentially Private Set Union](https://proceedings.icml.cc/book/4015.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4729-Paper.pdf)
  Pankaj  Gulhane, Sivakanth  Gopi, Janardhan Kulkarni, Judy Hanwen Shen, Milad Shokouhi, Sergey Yekhanin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4729-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4729-Supplemental.pdf)
> We study the basic operation of set union in the global model of differential privacy.  In this problem, we are given a universe $U$ of items, possibly of infinite size, and a database $D$ of users. Each user $i$ contributes a subset $W_i \subseteq U$ of items. We want an ($\epsilon$,$\delta$)-differentially private Algorithm  which outputs a subset $S \subset \cup_i W_i$ such that the size of $S$ is as large as possible. The problem arises in countless real world applications, and is particularly important and ubiquitous  in natural language processing (NLP) problems. For example, discovering words, sentences,  $n$-grams etc., from private text data belonging to users is an instance of the set union problem.   Known algorithms for this problem proceed by collecting a (weighted) subset of items from each user, taking the union of such  subsets, and disclosing the items whose noisy counts fall above a certain cutoff threshold. Crucially, in the above process, the contribution of each individual user is always independent from identity of items held by other users, resulting in a wasteful aggregation process, where some items’ counts happen to be very large – far above the cutoff threshold. We deviate from the above paradigm, by allowing users to contribute their items in a {\em dependent fashion}, guided by a policy. In this new setting ensuring privacy is  significantly delicate.  We prove that any policy which has certain {\em contractive} properties would result in a differentially private algorithm. We design two new algorithms, one using Laplace Noise and other Gaussian noise, as specific instances of policies satisfying the contractive properties. Our experiments show that the new algorithms significantly outperform previously known mechanisms for the problem. 
### 776.[The continuous categorical: a novel simplex-valued exponential family](https://proceedings.icml.cc/book/4016.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4730-Paper.pdf)
  Elliott Gordon-Rodriguez, Gabriel Loaiza-Ganem, John Cunningham [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4730-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4730-Supplemental.pdf)
> <p>Simplex-valued data appear throughout statistics and machine learning, for example in the context of transfer learning and compression of deep networks. Existing models for this class of data rely on the Dirichlet distribution or other related loss functions; here we show these standard choices suffer systematically from a number of limitations, including bias and numerical issues that frustrate the use of flexible network models upstream of these distributions. We resolve these limitations by introducing a novel exponential family of distributions for modeling simplex-valued data – the continuous categorical, which arises as a nontrivial multivariate generalization of the recently discovered continuous Bernoulli. Unlike the Dirichlet and other typical choices, the continuous categorical results in a well-behaved probabilistic loss function that produces unbiased estimators, while preserving the mathematical simplicity of the Dirichlet. As well as exploring its theoretical properties, we introduce sampling methods for this distribution that are amenable to the reparameterization trick, and evaluate their performance. Lastly, we demonstrate that the continuous categorical outperforms standard choices empirically, across a simulation study, an applied example on multi-party elections, and a neural network compression task.</p> 
### 777.[Minimax-Optimal Off-Policy Evaluation with Linear Function Approximation](https://proceedings.icml.cc/book/4017.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4735-Paper.pdf)
  Yaqi Duan, Zeyu Jia, Mengdi Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4735-Metadata.json)
> <p>This paper studies the statistical theory of batch data reinforcement learning with function approximation. Consider the off-policy evaluation problem, which is to estimate the cumulative value of a new target policy from logged history generated by unknown behavior policies. We study a regression-based fitted Q iteration method, and show that it is equivalent to a model-based method that estimates a conditional mean embedding of the transition operator. We prove that this method is information-theoretically optimal and has nearly minimal estimation error. In particular, by leveraging contraction property of Markov processes and martingale concentration, we establish a finite-sample instance-dependent error upper bound and a nearly-matching minimax lower bound. The policy evaluation error depends sharply on a restricted chi-square divergence over the function class between the long-term distribution of target policy and the distribution of past data. This restricted chi-square divergence is both instance-dependent and function-class-dependent. It characterizes the statistical limit of off-policy evaluation. Further, we provide an easily computable confidence bound for the policy evaluator, which may be useful for optimistic planning and safe policy improvement.</p> 
### 778.[Enhanced POET: Open-ended Reinforcement Learning through Unbounded Invention of Learning Challenges and their Solutions](https://proceedings.icml.cc/book/4018.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4745-Paper.pdf)
  Rui Wang, Joel Lehman, Aditya Rawal, Jiale Zhi, Yulun Li, Jeffrey Clune, Kenneth Stanley [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4745-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4745-Supplemental.pdf)
> <p>Creating open-ended algorithms, which generate their own never-ending stream of novel and appropriately challenging learning opportunities, could help to automate and accelerate progress in machine learning. A recent step in this direction is the Paired Open-Ended Trailblazer (POET), an algorithm that generates and solves its own challenges, and allows solutions to goal-switch between challenges to avoid local optima. However, the original POET was unable to demonstrate its full creative potential because of limitations of the algorithm itself and because of external issues including a limited problem space and lack of a universal progress measure. Importantly, both limitations pose impediments not only for POET, but for the pursuit of open-endedness in general. Here we introduce and empirically validate two new innovations to the original algorithm, as well as two external innovations designed to help elucidate its full potential.  Together, these four advances enable the most open-ended algorithmic demonstration to date. The algorithmic innovations are (1) a domain-general measure of how meaningfully novel new challenges are, enabling the system to potentially create and solve interesting challenges endlessly, and (2) an efficient heuristic for determining when agents should goal-switch from one problem to another (helping open-ended search better scale). Outside the algorithm itself, to enable a more definitive demonstration of open-endedness, we introduce (3) a novel, more flexible way to encode environmental challenges, and (4) a generic measure of the extent to which a system continues to exhibit open-ended innovation. Enhanced POET produces a diverse range of sophisticated behaviors that solve a wide range of environmental challenges, many of which cannot be solved through other means.</p> 
### 779.[Set Functions for Time Series ](https://proceedings.icml.cc/book/4019.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4750-Paper.pdf)
  Max Horn, Michael Moor, Christian Bock, Bastian Rieck, Karsten Borgwardt [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4750-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4750-Supplemental.pdf)
> <p>Despite the eminent successes of deep neural networks, many architectures are often hard to transfer to irregularly-sampled and asynchronous time series that commonly occur in real-world datasets, especially in healthcare applications. This paper proposes a novel approach for classifying irregularly-sampled time series with unaligned measurements, focusing on high scalability and data efficiency. Our method SeFT (Set Functions for Time Series) is based on recent advances in differentiable set function learning, extremely parallelizable with a beneficial memory footprint, thus scaling well to large datasets of long time series and online monitoring scenarios. Furthermore, our approach permits quantifying per-observation contributions to the classification outcome. We extensively compare our method with existing algorithms on multiple healthcare time series datasets and demonstrate that it performs competitively whilst significantly reducing runtime.</p> 
### 780.[Individual Calibration with Randomized Forecasting](https://proceedings.icml.cc/book/4020.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4753-Paper.pdf)
  Shengjia Zhao, Tengyu Ma, Stefano Ermon [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4753-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4753-Supplemental.pdf)
> <p>Machine learning applications often require calibrated predictions, e.g. a 90\% credible interval should contain the true outcome 90\% of the times. However, typical definitions of calibration only require this to hold on average, and offer no guarantees on predictions made on individual samples. Thus, predictions can be systematically over or under confident on certain subgroups, leading to issues of fairness and potential vulnerabilities. </p>  <p>We show that calibration for individual samples is possible in the regression setup if and only if the predictions are randomized, i.e. outputting randomized credible intervals. Randomization removes systematic bias by trading off bias with variance. We design a training objective to enforce individual calibration and use it to train randomized regression functions. The resulting models are more calibrated for arbitrarily chosen subgroups of the data, and can achieve higher utility in decision making against adversaries that exploit miscalibrated predictions.  </p> 
### 781.[Bayesian Differential Privacy for Machine Learning](https://proceedings.icml.cc/book/4021.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4758-Paper.pdf)
  Aleksei Triastcyn, Boi Faltings [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4758-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4758-Supplemental.pdf)
> <p>Traditional differential privacy is independent of the data distribution. However, this is not well-matched with the modern machine learning context, where models are trained on specific data. As a result, achieving meaningful privacy guarantees in ML often excessively reduces accuracy. We propose Bayesian differential privacy (BDP), which takes into account the data distribution to provide more practical privacy guarantees. We derive a general privacy accounting method under BDP and show that it is a generalisation of the well-known moments accountant. Our experiments demonstrate that in-distribution samples in classic machine learning datasets, such as MNIST and CIFAR-10, enjoy significantly stronger privacy guarantees than postulated by DP, while models maintain high classification accuracy.</p> 
### 782.[Causal Modeling for Fairness In Dynamical Systems](https://proceedings.icml.cc/book/4022.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4770-Paper.pdf)
  Elliot Creager, David Madras, Toniann Pitassi, Richard Zemel [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4770-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4770-Supplemental.pdf)
> <p>In many applications areas---lending, education, and online recommenders, for example---fairness and equity concerns emerge when a machine learning system interacts with a dynamically changing environment to produce both immediate and long-term effects for individuals and demographic groups. We discuss causal directed acyclic graphs (DAGs) as a unifying framework for the recent literature on fairness in such dynamical systems. We show that this formulation affords several new directions of inquiry to the modeler, where sound causal assumptions can be expressed and manipulated. We emphasize the importance of computing interventional quantities in the dynamical fairness setting, and show how causal assumptions enable simulation (when environment dynamics are known) and estimation by adjustment (when dynamics are unknown) of intervention on short- and long-term outcomes, at both the group and individual levels.</p> 
### 783.[Learning General-Purpose Controllers via Locally Communicating Sensorimotor Modules](https://proceedings.icml.cc/book/4023.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4772-Paper.pdf)
  Wenlong Huang, Igor Mordatch, Deepak Pathak [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4772-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4772-Supplemental.pdf)
> <p>Reinforcement learning is typically concerned with learning control policies tailored to a particular agent. We investigate whether there exists a single policy that generalizes to controlling a wide variety of agent morphologies - ones in which even dimensionality of state and action spaces changes. Such a policy would distill general and modular sensorimotor patterns that can be applied to control arbitrary agents. We propose a policy expressed as a collection of identical modular neural network components for each of the agent’s actuators. Every module is only responsible for controlling its own actuator and receives information from its local sensors. In addition, messages are passed between modules, propagating information between distant modules. A single modular policy can successfully generate locomotion behaviors for over 20 planar morphologies such as monopod hoppers, quadrupeds, bipeds and generalize to variants not seen during training - a process that would normally require training and manual hyper-parameter tuning for each morphology. We observe a wide variety of drastically diverse locomotion styles across morphologies as well as centralized coordination emerging via message passing between decentralized modules purely from the reinforcement learning objective.</p> 
### 784.[Visual Grounding of Learned Physical Models](https://proceedings.icml.cc/book/4024.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4780-Paper.pdf)
  Yunzhu Li, Toru Lin, Kexin Yi, Daniel Bear, Daniel Yamins, Jiajun Wu, Josh Tenenbaum, Antonio Torralba [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4780-Metadata.json)
> <p>Humans can intuitively recognize objects’ physical properties and predict their future motion, even when the objects are engaged in complicated interactions with each other. The ability to perform physical reasoning and adapt to new environments, while intrinsic to humans, remains challenging to state-of-the-art computational models. In this work, we present a neural model that simultaneously reasons about physics and make future predictions based on visual and dynamics priors. The visual prior predicts a particle-based representation of the system from visual observations. An inference module operates on those particles, predicting and refining estimates of particle locations, object states, and physical parameters, subject to the constraints imposed by the dynamics prior, which we refer to as visual grounding. We demonstrate the effectiveness of our method in environments involving rigid objects, deformable materials, and fluids. Experiments show that our model can infer the physical properties within a few observations, which allows the model to quickly adapt to unseen scenarios and make accurate predictions into the future.</p> 
### 785.[Task-Oriented Active Perception and Planning in Environments with Partially Known Semantics](https://proceedings.icml.cc/book/4025.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4782-Paper.pdf)
  Mahsa Ghasemi, Erdem Bulgur, Ufuk Topcu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4782-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4782-Supplemental.pdf)
> <p>We consider an agent that is assigned with a temporal logic task in an environment whose semantic representation is only partially known. We represent the semantics of the environment with a set of state properties, called \textit{atomic propositions}. The agent holds a probabilistic belief over the atomic propositions and updates it as new sensory measurements arrive. The goal is to design a policy for the agent that realizes the task with high probability.  We develop a planning strategy that takes the semantic uncertainties into account and by doing so provides probabilistic guarantees on the task success. Furthermore, as new data arrive, the belief over the atomic propositions evolves and, subsequently, the planning strategy adapts accordingly. We evaluate the proposed method on various finite-horizon tasks in planar navigation settings. The empirical results show that the proposed method provides reliable task performance that also improves as the knowledge about the environment enhances.</p> 
### 786.[Test-Time Training for Generalization under Distribution Shifts](https://proceedings.icml.cc/book/4026.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4786-Paper.pdf)
  Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, University of California Moritz Hardt [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4786-Metadata.json)
> <p>We introduce a general approach, called test-time training, for improving the performance of predictive models when training and test data come from different distributions. Test-time training turns a single unlabeled test instance into a self-supervised learning problem, on which we update the model parameters before making a prediction. We show that this simple idea leads to surprising improvements on diverse image classification benchmarks aimed at evaluating robustness to distribution shifts. Theoretical investigations on a convex model reveal helpful intuitions for when we can expect our approach to help.</p> 
### 787.[AutoGAN-Distiller: Searching to Compress Generative Adversarial Networks](https://proceedings.icml.cc/book/4027.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4787-Paper.pdf)
  Yonggan Fu, Wuyang Chen, Haotao Wang, Haoran Li, Yingyan Lin, Zhangyang Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4787-Metadata.json)
> <p>The compression of Generative Adversarial Networks (GANs) has lately drawn attention, due to the increasing demand for deploying GANs into mobile devices for numerous applications such as image translation, enhancement and editing. However, compared to the substantial efforts to compressing other deep models, the research on compressing GANs (usually the generators) remains at its infancy stage. Existing GAN compression algorithms are limited to handling specific GAN architectures and losses. Inspired by the recent success of AutoML in deep compression, we introduce AutoML to GAN compression and develop an AutoGAN-Distiller (AGD) framework. Starting with a specifically designed efficient search space, AGD performs an end-to-end discovery for new efficient generators, given the target computational resource constraints. The search is guided by the original GAN model via knowledge distillation, therefore fulfilling the compression. AGD is fully automatic, standalone (i.e., needing no trained discriminators), and generically applicable to various GAN models. We evaluate AGD in two representative GAN tasks: image translation and super resolution. Without bells and whistles, AGD yields remarkably lightweight yet more competitive compressed models, that largely outperform existing alternatives. Our codes and pretrained models are available at: https://github.com/TAMU-VITA/AGD.</p> 
### 788.[Associative Memory in Iterated Overparameterized Sigmoid Autoencoders](https://proceedings.icml.cc/book/4028.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4796-Paper.pdf)
  Yibo Jiang, Cengiz Pehlevan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4796-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4796-Supplemental.pdf)
> <p>Recent work suggests that overparameterized autoencoders can be trained to implement associative memory via iterative maps. This phenomenon happens when converged input-output Jacobian of the network has all eigenvalue norms strictly below one. In this work, we theoretically analyze this behavior for sigmoid networks by leveraging recent developments in deep learning theories, especially the Neural Tangent Kernel (NTK) theory. We find that overparameterized sigmoid autoencoders can have attractors in the NTK limit for both training with a single example and multiple examples under certain conditions. In particular, for multiple training examples, we find that the norm of the largest Jacobian eigenvalue drops below one with increasing input norm, leading to associative memory. </p> 
### 789.[Adaptive Reward-Poisoning Attacks against Reinforcement Learning](https://proceedings.icml.cc/book/4029.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4819-Paper.pdf)
  Xuezhou Zhang, Yuzhe Ma, Adish Singla, Jerry Zhu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4819-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4819-Supplemental.zip)
> In reward-poisoning attacks against reinforcement learning (RL), an attacker can perturb the environment reward $r_t$ into $r_t+\delta_t$ at each step, with the goal of forcing the RL agent to learn a nefarious policy.  We categorize such attacks by the infinity-norm constraint on $\delta_t$: We provide a lower threshold below which reward-poisoning attack is infeasible and RL is certified to be safe; we provide a corresponding upper threshold above which the attack is feasible.  Feasible attacks can be further categorized as non-adaptive where $\delta_t$ depends only on $(s_t,a_t, s_{t+1})$, or adaptive where $\delta_t$ depends further on the RL agent&#x27;s learning process at time $t$. Non-adaptive attacks have been the focus of prior works. However, we show that under mild conditions, adaptive attacks can achieve the nefarious policy in steps polynomial in state-space size $|S|$, whereas non-adaptive attacks require exponential steps. We provide a constructive proof that a Fast Adaptive Attack strategy achieves the polynomial rate. Finally, we show that empirically an attacker can find effective reward-poisoning attacks using state-of-the-art deep RL techniques.
### 790.[Planning to Explore via Latent Disagreement](https://proceedings.icml.cc/book/4030.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4828-Paper.pdf)
  Ramanan Sekar, Oleh Rybkin, Kostas Daniilidis, Pieter Abbeel, Danijar Hafner, Deepak Pathak [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4828-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4828-Supplemental.pdf)
> <p>To solve complex tasks, intelligent agents first need to explore their environments. However, providing manual feedback to agents during exploration can be challenging. This work focuses on task-agnostic exploration, where an agent explores a visual environment without yet knowing the tasks it will later be asked to solve. While current methods often learn reactive exploration behaviors to maximize retrospective novelty, we learn a world model trained from images to plan for expected surprise. Novelty is estimated as ensemble disagreement in the latent space of the world model. Exploring and learning the world model without rewards, our approach, latent disagreement (LD), efficiently adapts to a range of control tasks with high-dimensional image inputs.</p> 
### 791.[Defense Through Diverse Directions](https://proceedings.icml.cc/book/4031.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4833-Paper.pdf)
  Christopher Bender, Yang Li, Yifeng Shi, Michael K. Reiter, Junier Oliva [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4833-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4833-Supplemental.pdf)
> <p>In this work we develop a novel Bayesian neural network methodology to achieve strong adversarial robustness without the need for online adversarial training. Unlike previous efforts in this direction, we do not rely solely on the stochasticity of network weights by minimizing the divergence between the learned parameter distribution and a prior. Instead, we additionally require that the model maintain some expected uncertainty with respect to all input covariates. We demonstrate that by encouraging the network to distribute evenly across inputs, the network becomes less susceptible to localized, brittle features which imparts a natural robustness to targeted perturbations. We show empirical robustness on several benchmark datasets.</p> 
### 792.[Beyond Synthetic Noise: Deep Learning on Controlled Noisy Labels](https://proceedings.icml.cc/book/4032.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4834-Paper.pdf)
  Lu Jiang, Di Huang, Mason Liu, Weilong Yang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4834-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4834-Supplemental.pdf)
> <p>Performing controlled experiments on noisy data is essential in understanding deep learning across noise levels. Due to the lack of suitable datasets, previous research has only examined deep learning on controlled synthetic label noise, and real-world label noise has never been studied in the controlled setting. This paper makes three contributions. First, we establish the first benchmark of controlled real label noise (obtained from image search). This new benchmark will enable us to study the image search label noise in a controlled setting for the first time. The second contribution is a simple but highly effective method to overcome both synthetic and real noisy labels. We show that our method achieves the best result on our dataset as well as on two public benchmarks (CIFAR and WebVision). Third, we conduct the largest study by far into understanding deep neural networks trained on noisy labels across different noise levels, noise types, network architectures, methods, and training settings. We will release our data and code on GitHub.</p> 
### 793.[Confidence-Calibrated Adversarial Training: Generalizing to Unseen Attacks](https://proceedings.icml.cc/book/4033.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4835-Paper.pdf)
  David Stutz, Matthias Hein, Bernt Schiele [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4835-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4835-Supplemental.pdf)
> Adversarial training yields robust models against a specific threat model, e.g., $L_\infty$ adversarial examples. Typically robustness does not generalize to previously unseen threat models, e.g., other $L_p$ norms, or larger perturbations. Our confidence-calibrated adversarial training (CCAT) tackles this problem by biasing the model towards low confidence predictions on adversarial examples. By allowing to reject examples with low confidence, robustness generalizes beyond the threat model employed during training. CCAT, trained only on $L_\infty$ adversarial examples, increases robustness against larger $L_\infty$, $L_2$, $L_1$ and $L_0$ attacks, adversarial frames, distal adversarial examples and corrupted examples and yields better clean accuracy compared to adversarial training. For thorough evaluation we developed novel white- and black-box attacks directly attacking CCAT by maximizing confidence. For each threat model, we use $7$ attacks with up to $50$ restarts and $5000$ iterations and report worst-case robust test error, extended to our confidence-thresholded setting, across all attacks.
### 794.[Online Control of the False Coverage Rate and False Sign Rate](https://proceedings.icml.cc/book/4034.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4837-Paper.pdf)
  Asaf Weinstein, Aaditya Ramdas [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4837-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4837-Supplemental.pdf)
> The reproducibility debate has caused a renewed interest in changing how one reports uncertainty, from $p$-value for testing a null hypothesis to a confidence interval (CI) for the corresponding parameter. When CIs for multiple selected parameters are being reported, the analog of the false discovery rate (FDR) is the false coverage rate (FCR), which is the expected ratio of number of reported CIs failing to cover their respective parameters to the total number of reported CIs.  Here, we consider the general problem of FCR control in the online setting, where there is an infinite sequence of fixed unknown parameters ordered by time.  While much progress has been made in online testing, a procedure controlling the FDR does not automatically translate to a (nontrivial) procedure that controls the FCR. Therefore, the problem of online FCR control needs to be treated separately.  We propose a novel solution to the problem which only requires the scientist to be able to construct a marginal CI at any given level. If so desired, our framework also yields online FDR control as a special case, or even online sign-classification procedures that control the false sign rate (FSR). Last, all of our methodology applies equally well to prediction intervals, having particular implications for selective conformal inference.
### 795.[Online Convex Optimization in the Random Order Model](https://proceedings.icml.cc/book/4035.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4841-Paper.pdf)
  Dan Garber, Gal Korcia, Kfir Levy [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4841-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4841-Supplemental.pdf)
> <p>Online Convex Optimization (OCO) is a powerful framework for sequential prediction, portraying the natural uncertainty inherent in data-streams as though the data were generated by an almost limitless adversary. However, this view, which is often too pessimistic for real-world data, comes with a price. The complexity of solving many important online tasks in this adversarial framework becomes much worse than that of their offline counterparts.</p>  <p>In this work we consider a natural random-order version of the OCO model, in which the adversary can choose the set of loss functions, but does not get to choose the order in which they are supplied to the learner; Instead, they are observed in uniformly random order. While such a model is clearly not suitable for temporal data, which inherently depends on time, it is very much plausible in distributed settings, in which data is generated by multiple independent sources, or streamed without particular order.</p>  <p>Focusing on two important families of online tasks, one which generalizes online linear and logistic regression, and the other being online PCA, we show that under standard well-conditioned-data assumptions (that are often being made in the corresponding offline settings), standard online gradient descent (OGD) methods become much more efficient in the random-order model. In particular, for the first group of tasks which includes linear regression, we show that OGD guarantees polylogarithmic regret (while the only method to achieve comparable regret in the fully-adversarial setting is the Online-Newton Step method which requires quadratic memory and at least quadratic runtime). This result holds even without assuming the convexity of individual loss functions. In the case of online k-PCA, we show that OGD minimizes regret using only a rank-k SVD on each iteration and requires only linear memory (instead of nearly quadratic memory and/or potentially high-rank SVDs required by algorithms for the fully-adversarial setting).</p> 
### 796.[A Flexible Latent Space Model for Multilayer Networks](https://proceedings.icml.cc/book/4036.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4843-Paper.pdf)
  Xuefei Zhang, Songkai Xue, Ji Zhu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4843-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4843-Supplemental.pdf)
> <p>Entities often interact with each other through multiple types of relations, which are often represented as multilayer networks.  Multilayer networks among the same set of nodes usually share common structures, while each layer can possess its distinct node connecting behaviors. This paper proposes a flexible latent space model for multilayer networks for the purpose of capturing such characteristics. Specifically, the proposed model embeds each node with a latent vector shared among layers and a layer-specific effect for each layer; both elements together with a layer-specific connectivity matrix determine edge formations. To fit the model, we develop a projected gradient descent algorithm for efficient parameter estimation.  We also establish theoretical properties of the maximum likelihood estimators and show that the upper bound of the common latent structure's estimation error is inversely proportional to the number of layers under mild conditions. The superior performance of the proposed model is demonstrated through simulation studies and applications to two real-world data examples.  </p> 
### 797.[Estimation of Bounds on Potential Outcomes For Decision Making](https://proceedings.icml.cc/book/4037.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4845-Paper.pdf)
  Maggie Makar, Fredrik Johansson, John Guttag, David Sontag [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4845-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4845-Supplemental.pdf)
> <p>Estimation of individual treatment effects is often used as the basis for contextual decision making in fields such as healthcare, education, and economics. However, in many real-world applications it is sufficient for the decision maker to have estimates of upper and lower bounds on the potential outcomes under treatment and non-treatment. In these cases, we can get better finite sample efficiency by estimating simple functions that correctly bound the potential outcomes instead of directly estimating the potential outcomes, which may be complex, and hard to estimate. Our theoretical analysis highlights a tradeoff between the complexity of the learning task and the confidence with which the resulting bounds cover the true potential outcomes. Guided by our theoretical findings, we develop an algorithm for learning upper and lower bounds on the potential outcomes under treatment and non-treatment. Our algorithm finds the optimal bound estimates that maximize an objective function defined by the decision maker without violating a required false coverage rate. We demonstrate our algorithm's performance and highlight how it can be used to guide decision making using a clinical dataset, and a well-known causality benchmark. We show that our algorithm outperforms the state-of-the-art, providing tighter intervals without violating the required false coverage rate. </p> 
### 798.[Deep Gaussian Markov Random Fields](https://proceedings.icml.cc/book/4038.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4849-Paper.pdf)
  Per Sidén, Fredrik Lindsten [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4849-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4849-Supplemental.pdf)
> <p>Gaussian Markov random fields (GMRFs) are probabilistic graphical models widely used in spatial statistics and related fields to model dependencies over spatial structures. We establish a formal connection between GMRFs and convolutional neural networks (CNNs). Common GMRFs are special cases of a generative model where the inverse mapping from data to latent variables is given by a 1-layer linear CNN. This connection allows us to generalize GMRFs to multi-layer CNN architectures, effectively increasing the order of the corresponding GMRF in a way which has favorable computational scaling. We describe how well-established tools, such as autodiff and variational inference, can be used for simple and efficient inference and learning of the deep GMRF. We demonstrate the flexibility of the proposed model and show that it outperforms the state-of-the-art on a dataset of satellite temperatures, in terms of prediction and predictive uncertainty.</p> 
### 799.[Generalization Error of Generalized Linear Models in High Dimensions](https://proceedings.icml.cc/book/4039.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4852-Paper.pdf)
  Melikasadat Emami, Mojtaba Sahraee-Ardakan, Parthe Pandit, Sundeep Rangan, Alyson Fletcher [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4852-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4852-Supplemental.pdf)
> <p>At the heart of machine learning lies the question of generalizability of learned rules over previously unseen data.  While over-parameterized models based on neural networks are now ubiquitous in machine learning applications, our understanding of their generalization capabilities is incomplete.  This task is made harder by the non-convexity of the underlying learning problems. <br /> We provide a general framework to characterize the asymptotic generalization error for single-layer neural networks (i.e., generalized linear models) with arbitrary non-linearities, making it applicable to regression as well as classification problems.  This framework enables analyzing the effect of (i) over-parameterization and non-linearity during modeling; and (ii) choices of loss function, initialization, and regularizer during learning.  Our model also captures mismatch between training and test distributions.  As examples, we analyze a few special cases, namely linear regression, and logistic regression.  We are also able to rigorously and analytically explain the \emph{double descent} phenomenon in generalized linear models.  </p> 
### 800.[Poisson Learning: Graph Based Semi-Supervised Learning At Very Low Label Rates](https://proceedings.icml.cc/book/4040.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4874-Paper.pdf)
  Jeff Calder, Brendan Cook, Matthew Thorpe, Dejan Slepcev [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4874-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4874-Supplemental.pdf)
> <p>We propose a new framework, called Poisson learning, for graph based semi-supervised learning at very low label rates. Poisson learning is motivated by the need to address the degeneracy of Laplacian semi-supervised learning at very low label rates. The method replaces the assignment of label values at training points with the placement of sources and sinks, and solves the resulting Poisson equation on the graph. The outcomes are provably more stable and informative than those of Laplacian learning. Poisson learning is fast and efficient to implement, and we present numerical experiments showing the method is superior to other recent approaches to semi-supervised learning at low label rates on the MNIST, FashionMNIST, and the WebKb datasets. We also propose a graph-cut version of Poisson learning, called Poisson MBO, that gives higher accuracy and can incorporate prior knowledge of relative class sizes.</p> 
### 801.[Sequential Transfer in Reinforcement Learning with a Generative Model](https://proceedings.icml.cc/book/4041.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4876-Paper.pdf)
  Andrea Tirinzoni, Riccardo Poiani, Marcello Restelli [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4876-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4876-Supplemental.pdf)
> <p>We are interested in how to design reinforcement learning agents that provably reduce the sample complexity for learning new tasks by transferring knowledge from previously-solved ones. The availability of solutions to related problems poses a fundamental trade-off: whether to seek policies that are expected to immediately achieve high (yet sub-optimal) performance in the new task or whether to seek information to quickly identify an optimal solution, potentially at the cost of poor initial behaviour. In this work, we focus on the second objective when the agent has access to a generative model of state-action pairs. First, given a set of solved tasks containing an approximation of the target one, we design an algorithm that quickly identifies an accurate solution by seeking the state-action pairs that are most informative for this purpose. We derive PAC bounds on its sample complexity which clearly demonstrate the benefits of using this kind of prior knowledge. Then, we show how to learn these approximate tasks sequentially by reducing our transfer setting to a hidden Markov model and employing spectral methods to recover its parameters. Finally, we empirically verify our theoretical findings in simple simulated domains.</p> 
### 802.[Finite-Time Convergence in Continuous-Time Optimization](https://proceedings.icml.cc/book/4042.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4879-Paper.pdf)
  Orlando Romero, mouhacine Benosman [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4879-Metadata.json)
> <p>In this paper, we investigate a Lyapunov-like differential inequality that allows us to establish finite-time stability of a continuous-time state-space dynamical system represented via a multivariate ordinary differential equation or differential inclusion. Equipped with this condition, we successfully synthesize first and second-order dynamical systems that achieve finite-time convergence to the minima of a given sufficiently regular cost function. As a byproduct, we show that the p-rescaled gradient flow (p-RGF) proposed by Wibisono et al. (2016) is indeed finite-time convergent, provided the cost function is gradient dominated of order q in (1,p). Thus, we effectively bridge a gap between the p-RGF and the normalized gradient flow (NGF) (p=\infty) proposed by Cortes (2006) in his seminal paper in the context of multi-agent systems. We discuss strategies to discretize our proposed flows and conclude by conducting some numerical experiments to illustrate our results.</p> 
### 803.[Feature Quantization Improves GAN Training](https://proceedings.icml.cc/book/4043.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4902-Paper.pdf)
  Yang Zhao, Chunyuan Li, Ping Yu, Jianfeng Gao, Changyou Chen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4902-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4902-Supplemental.pdf)
> <p>The instability in GANs' training has been a long-standing problem despite remarkable research efforts. We identify that instability issues stem from difficulties of performing feature matching with mini-batch statistics, due to a fragile balance between the fixed target distribution and the progressively generated distribution. In this work, we propose feature quantizatoin (FQ) for the discriminator, to embed both true and fake data samples into a shared discrete space. The quantized values of FQ are constructed as an evolving dictionary, which is consistent with feature statistics of the recent distribution history. Hence, FQ implicitly enables robust feature matching in a compact space.  Our method can be easily plugged into existing GAN models, with little computational overhead in training. Extensive experimental results show that the proposed FQ-GAN can improve the FID scores of baseline methods by a large margin on a variety of tasks, including three representative GAN models on 10 benchmarks, achieving new state-of-the-art performance.</p> 
### 804.[Temporal Logic Point Processes](https://proceedings.icml.cc/book/4044.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4907-Paper.pdf)
  Shuang Li, Lu Wang, Ruizhi Zhang, xiaofu Chang, Xuqin Liu, Yao Xie, Yuan Qi, Le Song [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4907-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4907-Supplemental.pdf)
> <p>We propose a modeling framework for event data, which excels in small data regime with the ability to incorporate domain knowledge. Our framework will model the intensities of the event starts and ends via a set of first-order temporal logic rules. Using softened representation of temporal relations, and a weighted combination of logic rules, our framework can also deal with uncertainty in event data. Furthermore, many existing point process models can be interpreted as special cases of our framework given simple temporal logic rules. We derive a maximum likelihood estimation procedure for our model, and show that it can lead to accurate predictions when data are sparse and domain knowledge is critical. </p> 
### 805.[Hallucinative Topological Memory for Zero-Shot Visual Planning](https://proceedings.icml.cc/book/4045.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4910-Paper.pdf)
  Thanard Kurutach, Kara Liu, Aviv Tamar, Pieter Abbeel, Christine Tung [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4910-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4910-Supplemental.pdf)
> <p>In visual planning (VP), an agent learns to plan goal-directed behavior from observations of a dynamical system obtained offline, e.g., images obtained from self-supervised robot interaction. Bearing similarity with batch reinforcement learning (RL), VP algorithms essentially combine data-driven perception and planning. Most previous works on VP approached the problem by planning in a learned latent space, resulting in low-quality visual plans, and difficult training algorithms. Here, instead, we propose a simple VP method that plans directly in image space and displays competitive performance. We build on the semi-parametric topological memory (SPTM) method: image samples are treated as nodes in a graph, the graph connectivity is learned from image sequence data, and planning can be performed using conventional graph search methods. We make two modifications to SPTM, to make it suitable for VP. First, we propose an energy-based graph connectivity function that admits stable training using contrastive predictive coding. Second, to allow zero-shot planning in new domains, we learn a conditional VAE model that generates images given a context of the domain, and use these hallucinated samples for building the connectivity graph and planning. We show that this simple approach is competitive with SOTA VP methods, in terms of both image fidelity and success rate when using the plan to guide a trajectory-following controller.</p> 
### 806.[Learning Attentive Meta-Transfer](https://proceedings.icml.cc/book/4046.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4915-Paper.pdf)
  Jaesik Yoon, Gautam Singh, Sungjin Ahn [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4915-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4915-Supplemental.pdf)
> <p>Meta-transfer learning seeks to improve the efficiency of learning a new task via both meta-learning and transfer-learning in a setting with a stream of evolving tasks. While standard attention has been effective in a variety of settings, we question its effectiveness in improving meta-transfer learning since the tasks being learned are dynamic, and the amount of context information can be substantially small. In this paper, using a recently proposed meta-transfer learning model, Sequential Neural Processes (SNP), we first empirically show that it suffers a similar underfitting problem observed in the functions inferred by Neural Processes. However, we further demonstrate that unlike the meta-learning setting, standard attention mechanisms are ineffective in meta-transfer learning.~To resolve, we propose a new attention mechanism, Recurrent Memory Reconstruction (RMR), and demonstrate that providing an imaginary context that is recurrently updated and reconstructed with interaction is crucial in achieving effective attention for meta-transfer learning. Furthermore, incorporating RMR into SNP, we propose Attentive Sequential Neural Processes (ASNP) and demonstrate in various tasks that ASNP significantly outperforms the baselines. </p> 
### 807.[Optimizing Dynamic Structures with Bayesian Generative Search](https://proceedings.icml.cc/book/4047.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4921-Paper.pdf)
  Minh Hoang, Carleton Kingsford [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4921-Metadata.json)
> <p>Kernel selection for kernel-based methods is prohibitively expensive due to the NP-hard nature of discrete optimization. Since gradient-based optimizers are not applicable due to the lack of a differentiable objective function, many state-of-the-art solutions resort to heuristic search or gradient-free optimization. These approaches, however, require imposing restrictive assumptions on the explorable space of structures such as limiting the active candidate pool, thus depending heavily on the intuition of domain experts. This paper instead proposes \textbf{DTERGENS}, a novel generative search framework that constructs and optimizes a high-performance composite kernel expressions generator. \textbf{DTERGENS} does not restrict the space of candidate kernels and is capable of obtaining flexible length expressions by jointly optimizing a generative termination criterion. We demonstrate that our framework explores more diverse kernels and obtains better performance than state-of-the-art approaches on many real-world predictive tasks.</p> 
### 808.[Amortized Finite Element Analysis for Fast PDE-Constrained Optimization](https://proceedings.icml.cc/book/4048.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4931-Paper.pdf)
  Tianju Xue, Alex Beatson, Sigrid Adriaenssens , Ryan Adams [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4931-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4931-Supplemental.pdf)
> <p>Optimizing the parameters of partial differential equations (PDEs), i.e., PDE-constrained optimization (PDE-CO), allows us to model natural systems from observations or perform rational design of structures with complicated mechanical, thermal, or electromagnetic properties.  However, PDE-CO is often computationally prohibitive due to the need to solve the PDE---typically via finite element analysis (FEA)---at each step of the optimization procedure. In this paper we propose amortized finite element analysis (AmorFEA), in which a neural network learns to produce accurate PDE solutions, while preserving many of the advantages of traditional finite element methods. This network is trained to directly minimize the potential energy from which the PDE and finite element method are derived, avoiding the need to generate costly supervised training data by solving PDEs with traditional FEA. As FEA is a variational procedure, AmorFEA is a direct analogue to popular amortized inference approaches in latent variable models, with the finite element basis acting as the variational family. AmorFEA can perform PDE-CO without the need to repeatedly solve the associated PDE, accelerating optimization when compared to a traditional workflow using FEA and the adjoint method.</p> 
### 809.[Preselection Bandits](https://proceedings.icml.cc/book/4049.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4941-Paper.pdf)
  Viktor Bengs, Eyke Hüllermeier [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4941-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4941-Supplemental.zip)
> <p>In this paper, we introduce the Preselection Bandit problem, in which the learner preselects a subset of arms (choice alternatives) for a user, which then chooses the final arm from this subset. The learner is not aware of the user's preferences, but can learn them from observed choices. In our concrete setting, we allow these choices to be stochastic and model the user's actions by means of the Plackett-Luce model. The learner's main task is to preselect subsets that eventually lead to highly preferred choices. To formalize this goal, we introduce a reasonable notion of regret and derive lower bounds on the expected regret. Moreover, we propose algorithms for which the upper bound on expected regret matches the lower bound up to a logarithmic term of the time horizon. </p> 
### 810.[Peer Loss Functions: Learning from Noisy Labels without Knowing Noise Rates](https://proceedings.icml.cc/book/4050.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4950-Paper.pdf)
  Yang Liu, Hongyi Guo [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4950-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4950-Supplemental.pdf)
> <p>Learning with noisy labels is a common problem in supervised learning. Existing approaches require practitioners to specify \emph{noise rates}, i.e., a set of parameters controlling the severity of label noises in the problem. The specifications are either assumed to be given or estimated using additional approaches. In this work, we introduce a new family of loss functions that we name as \emph{peer loss} functions, which enables learning from noisy labels that does not require a priori specification of the noise rates.Our approach uses a standard empirical risk minimization (ERM) framework with peer loss functions. Peer loss functions associate each training sample with a certain form of ``peer" samples, which evaluate a classifier' predictions jointly. </p>  <p>We show that, under mild conditions, performing ERM with peer loss functions on the noisy dataset leads to the optimal or a near optimal classifier as if performing ERM over the clean training data, which we do not have access to. We pair our results with an extensive set of experiments, where we compare with state-of-the-art techniques of learning with noisy labels. Our results show that peer loss functions based method consistently outperforms the baseline benchmarks, as well as some recent new results. Peer loss provides a way to simplify model development when facing potentially noisy training labels, and can be promoted as a robust candidate loss function in such situations.</p> 
### 811.[Rank Aggregation from Pairwise Comparisons in the Presence of Adversarial Corruptions](https://proceedings.icml.cc/book/4051.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4955-Paper.pdf)
  Prathamesh Patil, Arpit Agarwal, Shivani Agarwal, Sanjeev Khanna [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4955-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4955-Supplemental.pdf)
> <p>Rank aggregation from pairwise preferences has widespread applications in recommendation systems and information retrieval. Given the enormous economic and societal impact of these applications, and the consequent incentives for malicious players to manipulate ranking outcomes in their favor, an important challenge is to make rank aggregation algorithms robust to adversarial manipulations in data. In this paper, we initiate the study of robustness in rank aggregation under the popular Bradley-Terry-Luce (BTL) model for pairwise comparisons. We consider a setting where pairwise comparisons are initially generated according to a BTL model, but a fraction of these comparisons are corrupted by an adversary prior to being reported to us. We consider a strong contamination model, where an adversary having complete knowledge of the initial truthful data and the underlying true BTL parameters, can subsequently corrupt the truthful data by inserting, deleting, or changing data points. The goal is to estimate the true score/weight of each item under the BTL model, even in the presence of these corruptions. We characterize the extent of adversarial corruption under which the true BTL parameters are uniquely identifiable. We also provide a novel pruning algorithm that provably cleans the data of adversarial corruption under reasonable conditions on data generation and corruption. We corroborate our theory with experiments on synthetic data showing that previous algorithms are vulnerable to even small amounts of corruption, whereas our algorithm can clean a reasonably high amount of corruption.</p> 
### 812.[Extrapolation for Large-batch Training in Deep Learning](https://proceedings.icml.cc/book/4052.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4956-Paper.pdf)
  Tao LIN, Lingjing Kong, Sebastian Stich, Martin Jaggi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4956-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4956-Supplemental.pdf)
> <p>Deep learning networks are typically trained by Stochastic Gradient Descent (SGD) methods that iteratively improve the model parameters by estimating a gradient on a very small fraction of the training data. A major roadblock faced when increasing the batch size to a substantial fraction of the training data for reducing training time is the persistent degradation in performance (generalization gap). To address this issue, recent work propose to add small perturbations to the model parameters when computing the stochastic gradients and report improved generalization performance due to smoothing effects. However, this approach is poorly understood; it requires often model-specific noise and fine-tuning. To alleviate these drawbacks, we propose to use instead computationally efficient extrapolation (extragradient) to stabilize the optimization trajectory while still benefiting from smoothing to avoid sharp minima. This principled approach is well grounded from an optimization perspective and we show that a host of variations can be covered in a unified framework that we propose. We prove the convergence of this novel scheme and rigorously evaluate its empirical performance on ResNet, LSTM, and Transformer. We demonstrate that in a variety of experiments the scheme allows scaling to much larger batch sizes than before whilst reaching or surpassing SOTA accuracy.</p> 
### 813.[VideoOneNet: Bidirectional Convolutional Recurrent OneNet with Trainable Data Steps for Video Processing](https://proceedings.icml.cc/book/4053.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4967-Paper.pdf)
  Zoltán Milacski, Barnabás Póczos, Andras Lorincz [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4967-Metadata.json)
> <p>Deep Neural Networks (DNNs) achieve the state-of-the-art results on a wide range of image processing tasks, however, the majority of such solutions are problem-specific, like most AI algorithms. The One Network to Solve Them All (OneNet) procedure has been suggested to resolve this issue by exploiting a DNN as the proximal operator in Alternating Direction Method of Multipliers (ADMM) solvers for various imaging problems. In this work, we make two contributions, both facilitating end-to-end learning using backpropagation. First, we generalize OneNet to videos by augmenting its convolutional prior network with bidirectional recurrent connections; second, we extend the fixed fully connected linear ADMM data step with another trainable bidirectional convolutional recurrent network. In our computational experiments on the Rotated MNIST, Scanned CIFAR-10 and UCF-101 data sets, the proposed modifications improve performance by a large margin compared to end-to-end convolutional OneNet and 3D Wavelet sparsity on several video processing problems: pixelwise inpainting-denoising, blockwise inpainting, scattered inpainting, super resolution, compressive sensing, deblurring, frame interpolation, frame prediction and colorization. Our two contributions are complementary, and using them together yields the best results.</p> 
### 814.[Bio-Inspired Hashing for Unsupervised Similarity Search](https://proceedings.icml.cc/book/4054.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4985-Paper.pdf)
  Chaitanya Ryali, John Hopfield, Leopold Grinberg, Dmitry Krotov [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4985-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4985-Supplemental.pdf)
> <p>The fruit fly Drosophila's olfactory circuit has inspired a new locality sensitive hashing (LSH) algorithm, FlyHash. In contrast with classical LSH algorithms that produce low dimensional hash codes, FlyHash produces sparse high-dimensional hash codes and has also been shown to have superior empirical performance compared to classical LSH algorithms in similarity search. However, FlyHash uses random projections and cannot learn from data. Building on inspiration from FlyHash and the ubiquity of sparse expansive representations in neurobiology, our work proposes a novel hashing algorithm BioHash that produces sparse high dimensional hash codes in a data-driven manner. We show that BioHash outperforms previously published benchmarks for various hashing methods. Since our learning algorithm is based on a local and biologically plausible synaptic plasticity rule, our work provides evidence for the proposal that LSH might be a computational reason for the abundance of sparse expansive motifs in a variety of biological systems. We also propose a convolutional variant BioConvHash that further improves performance. From the perspective of computer science, BioHash and BioConvHash are fast, scalable and yield compressed binary representations that are useful for similarity search.</p> 
### 815.[MetaFun: Meta-Learning with Iterative Functional Updates](https://proceedings.icml.cc/book/4055.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4986-Paper.pdf)
  Jin Xu, Jean-Francois Ton, Hyunjik Kim, Adam Kosiorek, Yee Whye Teh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4986-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4986-Supplemental.pdf)
> <p>We develop a functional encoder-decoder approach to supervised meta-learning, where labeled data is encoded into an infinite-dimensional functional representation rather than a finite-dimensional one. Furthermore, rather than directly producing the representation, we learn a neural update rule resembling functional gradient descent which iteratively improves the representation. The final representation is used to condition the decoder to make predictions on unlabeled data. Our approach is the first to demonstrates the success of encoder-decoder style meta-learning methods like conditional neural processes on large-scale few-shot classification benchmarks such as miniImageNet and tieredImageNet, where it achieves state-of-the-art performance.</p> 
### 816.[Learning and Simulation in Generative Structured World Models](https://proceedings.icml.cc/book/4056.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4995-Paper.pdf)
  Zhixuan Lin, Yi-Fu Wu, Skand Peri, Bofeng Fu, Jindong Jiang, Sungjin Ahn [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4995-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4995-Supplemental.pdf)
> <p>Despite several recent advances in object-oriented generative temporal models, there are a few key challenges. First, while many of these achievements are indispensable for a general world model, it is unclear how we can combine the benefits of each method into a unified model. Second, despite using generative model objectives, abilities for object detection and tracking are mainly investigated, leaving the crucial ability of generation largely under question. Third, a few key abilities for more faithful generation such as multi-modal uncertainty and situated behavior are missing. In this paper, we introduce Generative Structured World Models (G-SWM). The G-SWM not only unifies the key properties of previous models in a principled framework but also achieves two crucial new abilities, multi-modal uncertainty and situated behavior. By investigating the generation ability in comparison to the previous models, we demonstrate that G-SWM achieves the best or comparable performance for all experiment settings including a few complex settings that have not been tested before.</p> 
### 817.[Random Hypervolume Scalarizations for Provable Multi-Objective Black Box Optimization](https://proceedings.icml.cc/book/4057.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4996-Paper.pdf)
  Richard Zhang, Daniel Golovin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4996-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4996-Supplemental.pdf)
> Single-objective black box optimization (also known as zeroth-order optimization) is the process of minimizing a scalar objective $f(x)$, given evaluations at adaptively chosen inputs $x$. In this paper, we consider multi-objective optimization, where $f(x)$ outputs a vector of possibly competing objectives and the goal is to converge to the Pareto frontier. Quantitatively, we wish to maximize the standard \emph{hypervolume indicator} metric, which measures the dominated hypervolume of the entire set of chosen inputs. In this paper, we introduce a novel scalarization function, which we term the \emph{hypervolume scalarization}, and show that drawing random scalarizations from an appropriately chosen distribution can be used to efficiently approximate the \emph{hypervolume indicator} metric. We utilize this connection to show that Bayesian optimization with our scalarization via common acquisition functions, such as Thompson Sampling or Upper Confidence Bound, provably converges to the whole Pareto frontier by deriving tight \emph{hypervolume regret} bounds on the order of $\widetilde{O}(\sqrt{T})$. Furthermore, we highlight the general utility of our scalarization framework by showing that any provably convergent single-objective optimization process can be converted to a multi-objective optimization process with provable convergence guarantees. 
### 818.[SGD Learns One-Layer Networks in WGANs](https://proceedings.icml.cc/book/4058.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/4998-Paper.pdf)
  Qi Lei, Jason Lee, Alexandros Dimakis, Constantinos Daskalakis [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/4998-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/4998-Supplemental.pdf)
> <p>Generative adversarial networks (GANs) are a widely used framework for learning generative models. Wasserstein GANs (WGANs), one of the most successful variants of GANs, require solving a minmax optimization problem to global optimality, but are in practice successfully trained using stochastic gradient descent-ascent. In this paper, we show that, when the generator is a one-layer network, stochastic gradient descent-ascent converges to a global solution with polynomial time and sample complexity.</p> 
### 819.[Implicit Class-Conditioned Domain Alignment for Unsupervised Domain Adaptation](https://proceedings.icml.cc/book/4059.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5006-Paper.pdf)
  Xiang Jiang, Qicheng Lao, Stan Matwin, Mohammad Havaei [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5006-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5006-Supplemental.pdf)
> <p>We present an approach for unsupervised domain adaptation---with a strong focus on practical considerations of within-domain class imbalance and between-domain class distribution shift---from a class-conditioned domain alignment perspective. Current methods for class-conditioned domain alignment aim to explicitly minimize a loss function based on pseudo-label estimations of the target domain. However, these methods suffer from pseudo-label bias in the form of error accumulation. We propose a method that removes the need for explicit optimization of model parameters from pseudo-labels directly. Instead, we present a sampling-based implicit alignment approach where the sample selection procedure is implicitly guided by the pseudo-labels. Theoretical analysis shows that implicit alignment facilitates adversarial domain-invariant representation learning. Empirical results and ablation studies confirm the effectiveness of the proposed approach. In particular, our method exhibits superior robustness in the presence of extreme within-domain class imbalance and between-domain class distribution shift.</p> 
### 820.[Interference and Generalization in Temporal Difference Learning](https://proceedings.icml.cc/book/4060.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5012-Paper.pdf)
  Emmanuel Bengio, Joelle Pineau, Doina Precup [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5012-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5012-Supplemental.pdf)
> We study the link between generalization and interference in temporal-difference (TD) learning. Interference is defined as the inner product of two different gradients, representing their alignment; this quantity emerges as being of interest from a variety of observations about neural networks, parameter sharing and the dynamics of learning. We find that TD easily leads to low-interference, under-generalizing parameters, while the effect seems reversed in supervised learning. We hypothesize that the cause can be traced back to the interplay between the dynamics of interference and bootstrapping. This is supported empirically by several observations: the negative relationship between the generalization gap and interference in TD, the negative effect of bootstrapping on interference and the local coherence of targets, and the contrast between the propagation rate of information in TD(0) versus TD($\lambda$) and regression tasks such as Monte-Carlo policy evaluation. We hope that these new findings can guide the future discovery of better bootstrapping methods.
### 821.[CoMic: Co-Training and Mimicry for Reusable Skills](https://proceedings.icml.cc/book/4061.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5013-Paper.pdf)
  Leonard Hasenclever, Fabio Pardo, Raia Hadsell, Nicolas Heess, Josh Merel [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5013-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5013-Supplemental.pdf)
> <p>Learning to control complex bodies and reuse learned behaviors is a longstanding challenge in continuous control. We study the problem of learning reusable humanoid skills by imitating motion capture data and co-training with complementary tasks. We show that it is possible to learn reusable skills through reinforcement learning on 50 times more motion capture data than prior work. We systematically compare a variety of different network architectures across different data regimes both in terms of imitation performance as well as transfer to challenging locomotion tasks. Finally we show that it is possible to interleave the motion capture tracking with training on complementary tasks, enriching the resulting skill space, and enabling the reuse of skills not well covered by the motion capture data such as getting up from the ground or catching a ball.</p> 
### 822.[Provably Efficient Model-based Policy Adaptation](https://proceedings.icml.cc/book/4062.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5014-Paper.pdf)
  Yuda Song, Aditi Mavalankar, Wen Sun, Sicun Gao [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5014-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5014-Supplemental.pdf)
> <p>The high sample complexity of reinforcement learning challenges its use in practice. A promising approach is to quickly adapt pre-trained policies to new environments. Existing methods for this policy adaptation problem typically rely on domain randomization and meta-learning, by sampling from some distribution of target environments during pre-training, and thus face difficulty on out-of-distribution target environments. We propose new model-based mechanisms that are able to make online adaptation in unseen target environments, by combining ideas from no-regret online learning and adaptive control. We prove that the approach learns policies in the target environment that can quickly recover trajectories from the source environment, and establish the rate of convergence in general settings. We demonstrate the benefits of our approach for policy adaptation in a diverse set of continuous control tasks, achieving the performance of state-of-the-art methods with much lower sample complexity. </p> 
### 823.[Optimizer Benchmarking Needs to Account for Hyperparameter Tuning](https://proceedings.icml.cc/book/4063.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5017-Paper.pdf)
  Prabhu Teja Sivaprasad, Florian Mai, Thijs Vogels, Martin Jaggi, Francois Fleuret [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5017-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5017-Supplemental.pdf)
> <p>The performance of optimizers, particularly in deep learning, depends considerably on their chosen hyperparameter configuration. The efficacy of optimizers is often studied under near-optimal problem-specific hyperparameters, and finding these settings may be prohibitively costly for practitioners. In this work, we argue that a fair assessment of optimizers' performance must take the computational cost of hyperparameter tuning into account, i.e., how easy it is to find good hyperparameter configurations using an automatic hyperparameter search. Evaluating a variety of optimizers on an extensive set of standard datasets and architectures, our results indicate that Adam is the most practical solution, particularly in low-budget scenarios.</p> 
### 824.[From Local SGD to Local Fixed Point Methods for Federated Learning](https://proceedings.icml.cc/book/4064.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5019-Paper.pdf)
  Grigory Malinovsky, Dmitry Kovalev, Elnur Gasanov, Laurent CONDAT, Peter Richtarik [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5019-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5019-Supplemental.pdf)
> <p>Most algorithms for solving optimization problems or finding saddle points of convex-concave functions are fixed point algorithms. In this work we consider the generic problem of finding a fixed point of an average of operators, or an approximation thereof, in a distributed setting. Our work is motivated by the needs of federated learning. In this context, each local operator models the computations done locally on a mobile device. We investigate two strategies to achieve such a consensus: one  based on a fixed number of  local steps, and the other based on randomized  computations. In both cases, the goal is to limit communication of the locally-computed variables, which is often the bottleneck in distributed frameworks. We perform convergence analysis of both methods and conduct a number of experiments highlighting the benefits of our approach.</p> 
### 825.[Unraveling Meta-Learning: Understanding Feature Representations for Few-Shot Tasks](https://proceedings.icml.cc/book/4065.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5020-Paper.pdf)
  Micah Goldblum, Liam Fowl, Renkun Ni, Steven Reich, Valeriia Cherepanova, Tom Goldstein [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5020-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5020-Supplemental.pdf)
> <p>Meta-learning algorithms produce feature extractors which achieve state-of-the-art performance on few-shot classification.  While the literature is rich with meta-learning methods, little is known about why the resulting feature extractors perform so well.  We develop a better understanding of the underlying mechanics of meta-learning and the difference between models trained using meta-learning and models which are trained classically.  In doing so, we develop several hypotheses for why meta-learned models perform better.  In addition to visualizations, we design several regularizers inspired by our hypotheses which improve performance on few-shot classification.</p> 
### 826.[Federated Learning with Only Positive Labels](https://proceedings.icml.cc/book/4066.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5034-Paper.pdf)
  Felix Xinnan Yu, Ankit Singh Rawat, Aditya Menon, Sanjiv Kumar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5034-Metadata.json)
> <p>We consider learning a multi-class classification model in the federated setting, where each user has access to the positive data associated with only a single class. As a result, during each federated learning round, the users need to locally update the classifier without having access to the features and the model parameters for the negative labels. Since the loss function at a user is independent of the negative labels, naively employing conventional decentralized learning such as the distributed SGD or Federated Averaging may lead to trivial or extremely poor classifiers. In particular, for the embedding based classifiers, all the class embeddings might collapse to a single point.</p>  <p>To address this problem, we propose a generic framework for training with only positive labels, namely Federated Averaging with Spreadout (FedAwS), where the server imposes a geometric regularizer after each round to encourage classes spread out in the embedding space. We show, both theoretically and empirically, that FedAwS can almost match the performance of conventional learning where users have access to negative labels. We further extend the proposed method to the settings with large output spaces, such as the extreme multi-class classification. </p> 
### 827.[Causal Inference using Gaussian Processes with Structured Latent Confounders](https://proceedings.icml.cc/book/4067.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5045-Paper.pdf)
  Sam Witty, Kenta Takatsu, David Jensen, Vikash Mansinghka [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5045-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5045-Supplemental.zip)
> <p>Latent confounders---unobserved variables that influence both treatment and outcome---can bias estimates of causal effects. In some cases, these confounders are shared across observations, e.g. all students in a school are influenced by the school's culture in addition to any educational interventions they receive individually. This paper shows how to model latent confounders that have this structure and thereby improve estimates of causal effects. The key innovations are a hierarchical Bayesian model, Gaussian processes with structured latent confounders (GP-SLC), and a Monte Carlo inference algorithm for this model based on elliptical slice sampling. GP-SLC provides principled Bayesian uncertainty estimates of individual treatment effect without requiring parametric assumptions about the functional forms relating confounders, covariates, treatment, and outcomes. This paper also proves that, for linear functional forms, accounting for the structure in latent confounders is sufficient for asymptotically consistent estimates of causal effect. Finally, this paper shows GP-SLC is competitive with or more accurate than widely used causal inference techniques such as multi-level linear models and Bayesian additive regression trees. Benchmark datasets include the Infant Health and Development Program and a dataset showing the effect of changing temperatures on state-wide energy consumption across New England.</p> 
### 828.[T-Basis: a Compact Representation for Neural Networks](https://proceedings.icml.cc/book/4068.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5049-Paper.pdf)
  Anton Obukhov, Maxim Rakhuba, Menelaos Kanakis, Stamatios Georgoulis, Dengxin  Dai, Luc Van Gool [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5049-Metadata.json)
> <p>We introduce T-Basis, a novel concept for a compact representation of a set of tensors, each of an arbitrary shape, which is often seen in Neural Networks. Each of the tensors in the set is modelled using Tensor Rings, though the concept is applicable to other Tensor Networks as well. Owing its name to the T-shape of nodes in diagram notation of Tensor Rings, T-Basis is simply a list of equally shaped three-dimensional tensors, used to represent Tensor Ring nodes. Such representation allows us to parameterize the tensor set with a small number of parameters (coefficients of the T-Basis tensors), scaling logarithmically with the size of each tensor in the set, and linearly with the dimensionality of T-Basis. We evaluate the proposed approach on the task of neural network compression, and demonstrate that it reaches high compression rates at acceptable performance drops. Finally, we analyze memory and operation requirements of the compressed networks, and conclude that T-Basis networks are equally well suited for training and inference in resource-constrained environments, as well as usage on the edge devices.</p> 
### 829.[Familywise Error Rate Control by Interactive Unmasking](https://proceedings.icml.cc/book/4069.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5050-Paper.pdf)
  Boyan Duan, Aaditya Ramdas, Larry Wasserman [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5050-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5050-Supplemental.pdf)
> <p>We propose a method for multiple hypothesis testing with familywise error rate (FWER) control, called the i-FWER test. Most testing methods are predefined algorithms that do not allow modifications after observing the data. However, in practice, analysts tend to choose a promising algorithm after observing the data; unfortunately, this violates the validity of the conclusion. The i-FWER test allows much flexibility: a human (or a computer program acting on the human's behalf) may adaptively guide the algorithm in a data-dependent manner. We prove that our test controls FWER if the analysts adhere to a particular protocol of “masking” and “unmasking”. We demonstrate via numerical experiments the power of our test under structured non-nulls, and then explore new forms of masking.</p> 
### 830.[Learning to Branch for Multi-Task Learning](https://proceedings.icml.cc/book/4070.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5057-Paper.pdf)
  Pengsheng Guo, Chen-Yu Lee, Daniel Ulbricht [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5057-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5057-Supplemental.pdf)
> <p>Training multiple tasks jointly in one deep network yields reduced latency during inference and better performance over the single-task counterpart by sharing certain layers of a network. However, over-sharing a network could erroneously enforce over-generalization, causing negative knowledge transfer across tasks. Prior works rely on human intuition or pre-computed task relatedness scores for ad hoc branching structures. They provide sub-optimal end results and often require huge efforts for the trial-and-error process.</p>  <p>In this work, we present an automated multi-task learning algorithm that learns where to share or branch within a network, designing an effective network topology that is directly optimized for multiple objectives across tasks. Specifically, we propose a novel tree-structured design space that casts a tree branching operation as a gumbel-softmax sampling procedure. This enables differentiable network splitting that is end-to-end trainable. We validate the proposed method on controlled synthetic data, CelebA, and Taskonomy. </p> 
### 831.[Augmenting Continuous Time Bayesian Networks with Clocks](https://proceedings.icml.cc/book/4071.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5059-Paper.pdf)
  Nicolai Engelmann, Dominik Linzner, Heinz Koeppl [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5059-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5059-Supplemental.pdf)
> <p>Structured stochastic processes evolving in continuous time present a widely adopted framework to model phenomena occurring in nature and engineering. However, such models are often chosen to satisfy the Markov property to maintain tractability. One of the more popular of such memoryless models is Continuous Time Bayesian Networks (CTBNs). In this work, we lift its restriction to exponential survival times to arbitrary distributions. Current extensions achieve this via auxiliary states, which hinder tractability. To avoid that, we introduce a set of node-wise clocks to construct a collection of graph-coupled semi-Markov chains. We provide algorithms for parameter and structure inference, which make use of local dependencies and conduct experiments on synthetic data and data-sets generated through a benchmark tool for gene regulatory networks. In doing so, we point out advantages compared to current CTBN extensions.</p> 
### 832.[IPBoost – Non-Convex Boosting via Integer Programming](https://proceedings.icml.cc/book/4072.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5068-Paper.pdf)
  Sebastian Pokutta, Marc Pfetsch [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5068-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5068-Supplemental.pdf)
> <p>Recently non-convex optimization approaches for solving machine learning problems have gained significant attention. In this paper we explore non-convex boosting in classification by means of integer programming and demonstrate real-world practicability of the approach while circumvent- ing shortcomings of convex boosting approaches. We report results that are comparable to or better than the current state-of-the-art.</p> 
### 833.[On Efficient Constructions of Checkpoints](https://proceedings.icml.cc/book/4073.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5071-Paper.pdf)
  Yu Chen, Zhenming LIU, Bin Ren, Xin Jin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5071-Metadata.json)
> <p>Efficient construction of checkpoints/snapshots is a critical tool for training and diagnosing deep learning models. In this paper, we propose a lossy compression scheme for checkpoint constructions (called LC-Checkpoint). LC-Checkpoint simultaneously maximizes the compression rate and optimizes the recovery speed, under the assumption that SGD is used to train the model. LC-Checkpoint uses quantization and priority promotion to store the most crucial information for SGD to recover, and then uses a Huffman coding to leverage the non-uniform distribution of the gradient scales. Our extensive experiments show that LC-Checkpoint achieves a compression rate up to 28× and recovery speedup up to 5.77× over a state-of-the-art algorithm (SCAR).</p> 
### 834.[Feature Selection using Stochastic Gates](https://proceedings.icml.cc/book/4074.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5085-Paper.pdf)
  Yutaro Yamada, Ofir Lindenbaum, Sahand Negahban, Yuval Kluger [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5085-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5085-Supplemental.pdf)
> Feature selection problems have been extensively studied in the setting of linear estimation, for instance LASSO, but less emphasis has been placed on feature selection for neural networks.  In this study, we propose a method for feature selection in non-linear function estimation problems. The new procedure is based on directly penalizing the $\ell_0$ norm of features, or the count of the number of selected features. Our $\ell_0$ based regularization relies on a continuous relaxation of the Bernoulli distribution, which allows our model to learn the parameters of the approximate Bernoulli distributions via gradient descent. The proposed framework simultaneously learns a non-linear regression or classification function while selecting a small subset of features. We provide an information-theoretic justification for incorporating Bernoulli distribution for feature selection. Furthermore, we evaluate our method using synthetic and real-life data and demonstrate that our approach outperforms other commonly used methods in terms of predictive performance and feature selection.
### 835.[How to Train Your Neural ODE: the World of Jacobian and Kinetic Regularization](https://proceedings.icml.cc/book/4075.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5090-Paper.pdf)
  Chris Finlay, Joern-Henrik Jacobsen, Levon Nurbekyan, Adam Oberman [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5090-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5090-Supplemental.pdf)
> <p>Training neural ODEs on large datasets has not been tractable due to the necessity of allowing the adaptive numerical ODE solver to refine its step size to very small values. In practice this leads to dynamics equivalent to many hundreds or even thousands of layers. In this paper, we overcome this apparent difficulty by introducing a theoretically-grounded combination of both optimal transport and stability regularizations which encourage neural ODEs to prefer simpler dynamics out of all the dynamics that solve a problem well. Simpler dynamics lead to faster convergence and to fewer discretizations of the solver, considerably decreasing wall-clock time without loss in performance. Our approach allows us to train neural ODE-based generative models to the same performance as the unregularized dynamics, with significant reductions in training time. This brings neural ODEs closer to practical relevance in large-scale applications.</p> 
### 836.[Evaluating Lossy Compression Rates of Deep Generative Models](https://proceedings.icml.cc/book/4076.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5098-Paper.pdf)
  Sicong Huang, Alireza Makhzani, Yanshuai Cao, Roger Grosse [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5098-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5098-Supplemental.pdf)
> <p>Deep generative models have achieved remarkable progress in recent years. Despite this progress, quantitative evaluation and comparison of generative models remains as one of the important challenges. One of the most popular metrics for evaluating generative models is the log-likelihood. While the direct computation of log-likelihood can be intractable, it has been recently shown that the log-likelihood of some of the most interesting generative models such as variational autoencoders (VAE) or generative adversarial networks (GAN) can be efficiently estimated using annealed importance sampling (AIS). In this work, we argue that the log-likelihood metric by itself cannot represent all the different performance characteristics of generative models, and propose to use rate distortion curves to evaluate and compare deep generative models. We show that we can approximate the entire rate distortion curve using one single run of AIS for roughly the same computational cost as a single log-likelihood estimate. We evaluate lossy compression rates of different deep generative models such as VAEs, GANs (and its variants) and adversarial autoencoders (AAE) on MNIST and CIFAR10, and arrive at a number of insights not obtainable from log-likelihoods alone.</p> 
### 837.[Mix-n-Match : Ensemble and Compositional Methods for Uncertainty Calibration in Deep Learning](https://proceedings.icml.cc/book/4077.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5123-Paper.pdf)
  Jize Zhang, Bhavya Kailkhura, T. Yong-Jin Han [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5123-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5123-Supplemental.pdf)
> <p>This paper studies the problem of post-hoc calibration of machine learning classifiers. We introduce the following desiderata for uncertainty calibration: (a) accuracy-preserving, (b) data-efficient, and (c) high expressive power. We show that none of the existing methods satisfy all three requirements, and demonstrate how Mix-n-Match calibration strategies (i.e., ensemble and composition) can help achieve remarkably better data-efficiency and expressive power while provably preserving classification accuracy of the original classifier. We also show that existing calibration error estimators (e.g., histogram-based ECE) are unreliable especially in small-data regime. Therefore, we propose an alternative data-efficient kernel density-based estimator for a reliable evaluation of the calibration performance and prove its asymptotically unbiasedness and consistency.</p> 
### 838.[Learning Adversarially Robust Representations via Worst-Case Mutual Information Maximization](https://proceedings.icml.cc/book/4078.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5124-Paper.pdf)
  Sicheng Zhu, Xiao Zhang, David Evans [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5124-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5124-Supplemental.pdf)
> <p>Training machine learning models to be robust against adversarial inputs poses seemingly insurmountable challenges. To better understand model robustness, we consider the underlying problem of learning robust representations. We develop a general definition of representation vulnerability that captures the maximum change of mutual information between the input and output distributions, under the worst-case input distribution perturbation. We prove a theorem that establishes a lower bound on the minimum adversarial risk that can be achieved for any downstream classifier based on this definition. We then propose an unsupervised learning method for obtaining intrinsically robust representations by maximizing the worst-case mutual information between input and output distributions. Experiments on downstream classification tasks and analyses of saliency maps support the robustness of the representations found using unsupervised learning with our training principle. </p> 
### 839.[Stochastic Regret Minimization in Extensive-Form Games](https://proceedings.icml.cc/book/4079.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5132-Paper.pdf)
  Gabriele Farina, Christian Kroer, Tuomas Sandholm [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5132-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5132-Supplemental.pdf)
> <p>Monte-Carlo counterfactual regret minimization (MCCFR) is the state-of-the-art algorithm for solving sequential games that are too large for full tree traversals. It works by using gradient estimates that can be computed via sampling. However, stochastic methods for sequential games have not been investigated extensively beyond MCCFR. In this paper we develop a new framework for developing stochastic regret minimization methods. This framework allows us to use any regret-minimization algorithm, coupled with any gradient estimator. The MCCFR algorithm can be analyzed as a special case of our framework, and this analysis leads to significantly-stronger theoretical guarantees on convergence, while simultaneously yielding a simplified proof. Our framework allows us to instantiate several new stochastic methods for solving sequential games. We show extensive experiments on three games, where some variants of our methods outperform MCCFR.</p> 
### 840.[Simultaneous Inference for Massive Data: Distributed Bootstrap](https://proceedings.icml.cc/book/4080.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5135-Paper.pdf)
  Yang Yu, Shih-Kang Chao, Guang Cheng [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5135-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5135-Supplemental.pdf)
> <p>In this paper, we propose a bootstrap method applied to massive data processed distributedly in a large number of machines. This new method is computationally efficient in that we bootstrap on the master machine without over-resampling, typically required by existing methods \cite{kleiner2014scalable,sengupta2016subsampled}, while provably achieving optimal statistical efficiency with minimal communication. Our method does not require repeatedly re-fitting the model but only applies multiplier bootstrap in the master machine on the gradients received from the worker machines. Simulations validate our theory.</p> 
### 841.[Stabilizing Differentiable Architecture Search via Perturbation-based Regularization](https://proceedings.icml.cc/book/4081.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5139-Paper.pdf)
  Xiangning Chen, Cho-Jui Hsieh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5139-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5139-Supplemental.pdf)
> <p>Differentiable architecture search (DARTS) is a prevailing NAS solution to identify architectures. Based on the continuous relaxation of the architecture space, DARTS learns a differentiable architecture weight and largely reduces the search cost. However, its stability and generalizability have been challenged for yielding deteriorating architectures as the search proceeds. We find that the precipitous validation loss landscape, which leads to a dramatic performance drop when distilling the final architecture, is an essential factor that causes instability. Based on this observation, we propose a perturbation-based regularization, named SmoothDARTS (SDARTS), to smooth the loss landscape and improve the generalizability of DARTS. In particular, our new formulations stabilize DARTS by either random smoothing or adversarial attack. The search trajectory on NAS-Bench-1Shot1 demonstrates the effectiveness of our approach and due to the improved stability, we achieve performance gain across various search spaces on 4 datasets. Furthermore, we mathematically show that SDARTS implicitly regularizes the Hessian norm of the validation loss, which accounts for a smoother loss landscape and improved performance.</p> 
### 842.[Boosting Frank-Wolfe by Chasing Gradients](https://proceedings.icml.cc/book/4082.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5153-Paper.pdf)
  Cyrille Combettes, Sebastian Pokutta [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5153-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5153-Supplemental.pdf)
> The Frank-Wolfe algorithm has become a popular first-order optimization algorithm for it is simple and projection-free, and it has been successfully applied to a variety of real-world problems. Its main drawback however lies in its convergence rate, which can be excessively slow due to naive descent directions. We propose to speed up the Frank-Wolfe algorithm by better aligning the descent direction with that of the negative gradient via a subroutine. This subroutine chases the negative gradient direction in a matching pursuit-style while still preserving the projection-free property. Although the approach is reasonably natural, it produces very significant results. We derive convergence rates $\mathcal{O}(1/t)$ to $\mathcal{O}(e^{-\omega t})$ of our method and we demonstrate its competitive advantage both per iteration and in CPU time over the state-of-the-art in a series of computational experiments.
### 843.[Concise Explanations of Neural Networks using Adversarial Training](https://proceedings.icml.cc/book/4083.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5160-Paper.pdf)
  Prasad Chalasani, Jiefeng Chen, Amrita Roy Chowdhury, Xi Wu, Somesh Jha [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5160-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5160-Supplemental.pdf)
> We show new connections between adversarial learning and explainability for deep neural networks (DNNs). One form of explanation of the output of a neural network model in terms of its input features, is a vector of feature-attributions, which can be generated by various techniques such as Integrated Gradients (IG), DeepSHAP, LIME, and CXPlain. Two desirable characteristics of an attribution-based explanation are: (1) \textit{sparseness}: the attributions of irrelevant or weakly relevant features should be negligible, thus resulting in \textit{concise} explanations in terms of the significant features, and (2) \textit{stability}: it should not vary significantly within a small local neighborhood of the input. Our first contribution is a theoretical exploration of how these two properties (when using IG-based attributions) are related to adversarial training, for a class of 1-layer networks (which includes logistic regression models for binary and multi-class classification); for these networks we show that (a) adversarial training using an $\ell_\infty$-bounded adversary produces models with sparse attribution vectors, and (b) natural model-training while encouraging stable explanations (via an extra term in the loss function), is equivalent to adversarial training.  Our second contribution is an empirical verification of phenomenon (a), which we show, somewhat surprisingly, occurs \textit{not only in 1-layer networks, but also DNNs trained on standard image datasets}, and extends beyond IG-based attributions,  to those based on DeepSHAP:  adversarial training with $\linf$-bounded perturbations yields significantly sparser attribution vectors, with little degradation in performance on natural test data, compared to natural training. Moreover, the sparseness of the attribution vectors is significantly better than that achievable via $\ell_1$-regularized natural training. 
### 844.[Quantum Boosting](https://proceedings.icml.cc/book/4084.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5169-Paper.pdf)
  Srinivasan Arunachalam, Reevu Maity [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5169-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5169-Supplemental.pdf)
> <p>Boosting is a technique that boosts a weak and inaccurate machine learning algorithm into a strong accurate learning algorithm. The AdaBoost algorithm by Freund and Schapire (for which they were awarded the G{\"o}del prize in 2003) is one of the widely used boosting algorithms, with many applications in theory and practice. Suppose we have a gamma-weak learner for a Boolean concept class C that takes time R(C), then the time complexity of AdaBoost scales as VC(C)poly(R(C), 1/gamma), where VC(C) is the VC-dimension of C. In this paper, we show how quantum techniques can improve the time complexity of classical AdaBoost. To this end, suppose we have a gamma-weak quantum learning algorithm for a Boolean concept class C that takes time Q(C), we introduce a quantum boosting algorithm whose complexity scales as sqrt{VC(C)}poly(Q(C),1/gamma); thereby achieving quadratic quantum improvement over classical AdaBoost in terms of  VC(C). </p> 
### 845.[Information-Theoretic Local Minima Characterization and Regularization](https://proceedings.icml.cc/book/4085.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5176-Paper.pdf)
  Zhiwei Jia, Hao Su [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5176-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5176-Supplemental.pdf)
> <p>Recent advances in deep learning theory have evoked the study of generalizability across different local minima of deep neural networks (DNNs). While current work focused on either discovering properties of good local minima or developing regularization techniques to induce good local minima, no approach exists that can tackle both problems. We achieve these two goals successfully in a unified manner. Specifically, based on the observed Fisher information we propose a metric both strongly indicative of generalizability of local minima and effectively applied as a practical regularizer. We provide theoretical analysis including a generalization bound and empirically demonstrate the success of our approach in both capturing and improving the generalizability of DNNs. Experiments are performed on CIFAR-10 and CIFAR-100 for various network architectures.</p> 
### 846.[Kernel interpolation with continuous volume sampling](https://proceedings.icml.cc/book/4086.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5177-Paper.pdf)
  Ayoub Belhadji, Rémi Bardenet, Pierre Chainais [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5177-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5177-Supplemental.zip)
> <p>A fundamental task in kernel methods is to pick nodes and weights, so as to approximate a given function from an RKHS by the weighted sum of kernel translates located at the nodes. This is the crux of kernel density estimation, kernel quadrature, or interpolation from discrete samples. Furthermore, RKHSs offer a convenient mathematical and computational framework. We introduce and analyse continuous volume sampling (VS), the continuous counterpart -for choosing node locations- of a discrete distribution introduced in (Deshpande &amp; Vempala, 2006). Our contribution is theoretical: we prove almost optimal bounds for interpolation and quadrature under VS. While similar bounds already exist for some specific RKHSs using ad-hoc node constructions, VS offers bounds that apply to any Mercer kernel and depend on the spectrum of the associated integration operator. We emphasize that, unlike previous randomized approaches that rely on regularized leverage scores or determinantal point processes, evaluating the pdf of VS only requires pointwise evaluations of the kernel. VS is thus naturally amenable to MCMC samplers.</p> 
### 847.[Efficient Identification in Linear Structural Causal Models with Auxiliary Cutsets](https://proceedings.icml.cc/book/4087.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5178-Paper.pdf)
  Daniel Kumor, Carlos Cinelli, Elias Bareinboim [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5178-Metadata.json)
> <p>We develop a a new polynomial-time algorithm for identification in linear Structural Causal Models that subsumes previous non-exponential identification methods when applied to direct effects, and unifies several disparate approaches to identification in linear systems. Leveraging these new results and  understanding, we develop a procedure for identifying total causal effects. </p> 
### 848.[Partial Trace Regression and Low-Rank Kraus Decomposition](https://proceedings.icml.cc/book/4088.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5187-Paper.pdf)
  Hachem Kadri, Stephane Ayache, Riikka Huusari, alain rakotomamonjy, Ralaivola Liva [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5187-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5187-Supplemental.pdf)
> <p>The trace regression model, a direct extension to the well-studied linear regression model, allows one to map matrices to real-valued outputs. We here introduce a yet more general model, namely the partial trace regression model, a family of linear mappings from matrix-valued inputs to matrix-valued outputs; this model subsumes the trace regression model and thus the linear regression model. Borrowing tools from quantum information theory, where partial trace operators have been extensively studied, we propose a framework for learning partial trace regression models from data by taking advantage of the so-called low-rank Kraus representation of completely positive maps. We show the relevance of our framework with synthetic and real-world experiments conducted for both i) matrix-to-matrix regression and ii) positive semidefinite matrix completion, two tasks which can be formulated as partial trace regression problems.</p> 
### 849.[Constant Curvature Graph Convolutional Networks](https://proceedings.icml.cc/book/4089.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5188-Paper.pdf)
  Gregor Bachmann, Gary Becigneul, Octavian Ganea [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5188-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5188-Supplemental.pdf)
> <p>Interest has been rising lately towards methods representing data in non-Euclidean spaces (e.g. hyperbolic or elliptical)  that provide specific inductive biases useful for certain real-world data properties, e.g. scale-free, hierarchical or cyclical. However, the popular graph neural networks are currently limited in modeling data only via Euclidean geometry and associated vector space operations. Here, we bridge this gap by proposing mathematically grounded generalizations of graph convolutional networks (GCN) to (products of) constant curvature spaces. We do this by i) introducing a unified gyrovector space formalism that can interpolate smoothly between all geometries of constant curvature irrespective of their sign, ii) leveraging gyro-barycentric coordinates that generalize the classic Euclidean concept of the center of mass. Our class of models smoothly recover their Euclidean counterparts when the curvature goes to zero from either side. Empirically, we outperform Euclidean GCNs in the tasks of node classification and distortion minimization for symbolic data exhibiting non-Euclidean behavior, according to their discrete curvature.</p> 
### 850.[Educating Text Autoencoders: Latent Representation Guidance via Denoising](https://proceedings.icml.cc/book/4090.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5206-Paper.pdf)
  Tianxiao Shen, Jonas Mueller, Regina Barzilay, Tommi Jaakkola [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5206-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5206-Supplemental.pdf)
> <p>Generative autoencoders offer a promising approach for controllable text generation by leveraging their learned sentence representations. However, current models struggle to maintain coherent latent spaces required to perform meaningful text manipulations via latent vector operations. Specifically, we demonstrate by example that neural encoders do not necessarily map similar sentences to nearby latent vectors. A theoretical explanation for this phenomenon establishes that high-capacity autoencoders can learn an arbitrary mapping between sequences and associated latent representations. To remedy this issue, we augment adversarial autoencoders with a denoising objective where original sentences are reconstructed from perturbed  versions (referred as DAAE). We prove that this simple modification guides the latent space geometry of the resulting model by encouraging the encoder to map similar texts to similar latent representations. In empirical comparisons with various types of autoencoders, our model provides the best trade-off between generation quality and reconstruction capacity. Moreover, the improved geometry of the DAAE latent space enables \emph{zero-shot} text style transfer via simple latent vector arithmetic.\footnote{Our code will be publicly released after the review process.}</p> 
### 851.[Generalization via Derandomization](https://proceedings.icml.cc/book/4091.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5208-Paper.pdf)
  Jeffrey Negrea, Daniel Roy, Gintare Karolina Dziugaite [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5208-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5208-Supplemental.pdf)
> <p>We propose to study the generalization error of a learned predictor h^ in terms of that of a surrogate (potentially randomized) classifier that is coupled to h^ and designed to trade empirical risk for control of generalization error. In the case where h^ interpolates the data, it is interesting to consider theoretical surrogate classifiers that are partially derandomized or rerandomized, e.g., fit to the training data but with modified label noise. We show that replacing h^ by its conditional distribution with respect to an arbitrary sigma-field is a viable method to derandomize. We give an example, inspired by the work of Nagarajan and Kolter (2019), where the learned classifier h^ interpolates the training data with high probability, has small risk, and, yet, does not belong to a nonrandom class with a tight uniform bound on two-sided generalization error. At the same time, we bound the risk of h^ in terms of a surrogate that is constructed by conditioning and shown to belong to a nonrandom class with uniformly small generalization error. </p> 
### 852.[Inductive Relation Prediction by Subgraph Reasoning](https://proceedings.icml.cc/book/4092.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5209-Paper.pdf)
  Komal Teru, Etienne Denis, Will Hamilton [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5209-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5209-Supplemental.pdf)
> <p>The dominant paradigm for relation prediction in knowledge graphs involves learning and operating on latent representations (i.e., embeddings) of entities and relations. However, these embedding-based methods do not explicitly capture the compositional logical rules underlying the knowledge graph,  and they are limited to the transductive setting,  where the full set of entities must be known during training. Here, we propose a graph neural network based relation prediction framework,  GraIL, that reasons over local subgraph structures and has a strong inductive bias to learn entity-independent relational semantics.  Unlike embedding-based models, GraIL is naturally inductive and can generalize to unseen entities and graphs after training. We provide theoretical proof and strong empirical evidence that GraIL can rep-resent a useful subset of first-order logic and show that GraIL outperforms existing rule-induction baselines in the inductive setting. We also demonstrate significant gains obtained by ensembling GraIL with various knowledge graph embedding methods in the transductive setting, highlighting the complementary inductive bias of our method.</p> 
### 853.[Logarithmic Regret for Online Control with Adversarial Noise](https://proceedings.icml.cc/book/4093.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5224-Paper.pdf)
  Dylan Foster, Max Simchowitz [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5224-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5224-Supplemental.pdf)
> We consider the problem of online control in a known linear dynamical system subject to adversarial noise. Existing regret bounds for this setting scale as $\sqrt{T}$ unless strong stochastic assumptions are imposed on the noise. We give the first algorithm with logarithmic regret for arbitrary adversarial noise sequences, provided that the state and control costs are given by fixed quadratic functions. We propose a novel analysis that combines a new variant of the performance difference lemma with techniques from optimal control, allowing us to reduce online control to online prediction with delayed feedback. Unlike prior work, which leverages the so-called online convex optimization with memory framework, our analysis \emph{does not} need to bound movement costs of the iterates, leading to logarithmic regret. Our performance difference lemma-based analysis may be of broader interest beyond linear control.
### 854.[Multiresolution Tensor Learning for Efficient and Interpretable Spatial Analysis](https://proceedings.icml.cc/book/4094.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5234-Paper.pdf)
  Jung Yeon Park, Kenneth Carr, Stephan Zheng, Yisong Yue, Rose Yu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5234-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5234-Supplemental.pdf)
> <p>Efficient and interpretable spatial analysis is crucial in many fields such as geology, sports, and climate science. Large-scale spatial data often contains complex higher-order correlations across features and locations. While tensor latent factor models can describe higher-order correlations, they are inherently computationally expensive to train. Furthermore, for spatial analysis, these models should not only be predictive but also be spatially coherent. However, latent factor models are sensitive to initialization and can yield inexplicable results. We develop a novel Multiresolution Tensor Learning (MRTL) algorithm for efficiently learning interpretable spatial patterns. MRTL initializes the latent factors from an approximate full-rank tensor model for improved interpretability and progressively learns from a coarse resolution to the fine resolution for an enormous computation speedup. We also prove the theoretical convergence and computational complexity of MRTL. When applied to two real-world datasets, MRTL demonstrates 4 ~ 5 times speedup compared to a fixed resolution while yielding accurate and interpretable models.</p> 
### 855.[Customizing ML Predictions for Online Algorithms](https://proceedings.icml.cc/book/4095.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5246-Paper.pdf)
  Keerti Anand, Rong Ge, Debmalya Panigrahi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5246-Metadata.json)
> <p>Traditionally, online algorithms optimize the worst-case competitive ratio between the algorithm and the optimal solution. To overcome the inherent pessimism of worst-case analysis, a popular line of recent research incorporates ML advice in the design of online algorithms to improve their performance in typical instances. These papers treat the ML algorithm as a black-box, and redesign online algorithms to take advantage of ML predictions. In this paper, we ask the complementary question: can we redesign ML algorithms to provide better predictions for online algorithms? We explore this question in the context of the classic rent-or-buy problem, and show that incorporating optimization benchmarks directly in ML loss functions leads to significantly better performance. We support this finding both through theoretical bounds and numerical simulations, and posit that ``learning for optimization'' is a fertile area for future research.</p> 
### 856.[Maximum Entropy Gain Exploration for Long Horizon Multi-goal Reinforcement Learning](https://proceedings.icml.cc/book/4096.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5247-Paper.pdf)
  Silviu Pitis, Harris Chan, Stephen Zhao, Bradly Stadie, Jimmy Ba [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5247-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5247-Supplemental.pdf)
> <p>What goals should a multi-goal reinforcement learning agent pursue during training in long-horizon tasks? When the desired (test time) goal distribution is too distant to offer a useful learning signal, we argue that the agent should not pursue unobtainable goals. Instead, it should set its own intrinsic goals that maximize the entropy of the historical achieved goal distribution. We propose to optimize this objective by having the agent pursue past achieved goals in sparsely explored areas of the goal space, which focuses exploration on the frontier of the achievable goal set. We show that our strategy achieves an order of magnitude better sample efficiency than the prior state of the art on long-horizon multi-goal tasks including maze navigation and block stacking. </p> 
### 857.[ Recht-Re Noncommutative Arithmetic-Geometric Mean Conjecture is False](https://proceedings.icml.cc/book/4097.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5263-Paper.pdf)
  Zehua Lai, Lek-Heng Lim [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5263-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5263-Supplemental.zip)
> <p>Stochastic optimization algorithms have become indispensable in machine learning. An unresolved foundational question in this area is the difference between with-replacement sampling and without-replacement sampling --- does the latter have superior convergence rate compared to the former? A groundbreaking result of Recht and Re reduces the problem to a noncommutative analogue of the arithmetic-geometric mean inequality where positive numbers are replaced by n positive definite matrices. If this inequality holds for all n, then without-replacement sampling indeed outperforms with-replacement sampling. The conjectured Recht--Re inequality has so far only been established for n = 2 and a special case of n = 3. We will show that the Recht--Re conjecture is false for general n. Our approach relies on the noncommutative positivstellensatz, which allows us to reduce the conjectured inequality to a semidefinite program and the validity of the conjecture to certain bounds for the optimum values, which we show are false as soon as n = 5.</p> 
### 858.[Predictive Multiplicity in Classification](https://proceedings.icml.cc/book/4098.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5265-Paper.pdf)
  Charles Marx, Flavio Calmon, Berk Ustun [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5265-Metadata.json)
> <p>Prediction problems often admit competing models that perform almost equally well. This effect – called the multiplicity of good models – challenges how we build and deploy predictive models. In this paper, we study a specific notion of model multiplicity – predictive multiplicity – where competing models assign conflicting predictions. Predictive multiplicity signals irreconcilable differences in the predictions of competing models. In applications such as recidivism prediction and credit scoring, evidence of predictive multiplicity challenges model selection and downstream processes that depend on it. We propose measures to evaluate the severity of predictive multiplicity in classification, and develop integer programming methods to compute them efficiently. We apply our methods to evaluate predictive multiplicity in recidivism prediction problems. Our results show that real-world datasets may admit competing models that assign wildly conflicting predictions, and support the need to measure and report predictive multiplicity in model development.</p> 
### 859.[Word-Level Speech Recognition With a Letter to Word Encoder](https://proceedings.icml.cc/book/4099.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5269-Paper.pdf)
  Ronan Collobert, Awni Hannun, Gabriel Synnaeve [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5269-Metadata.json)
> <p>We propose a direct-to-word sequence model which uses a word network to learn word embeddings from letters. The word network can be integrated seamlessly with arbitrary sequence models including Connectionist Temporal Classification and encoder-decoder models with attention. We show our direct-to-word model can achieve word error rate gains over sub-word level models for speech recognition. We also show that our direct-to-word approach retains the ability to predict words not seen at training time without any retraining. Finally, we demonstrate that a word-level model can use a larger stride than a sub-word level model while maintaining accuracy. This makes the model more efficient both for training and inference.</p> 
### 860.[Reducing Sampling Error in Batch Temporal Difference Learning](https://proceedings.icml.cc/book/4100.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5271-Paper.pdf)
  Brahma Pavse, Ishan Durugkar, Josiah Hanna, Peter Stone [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5271-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5271-Supplemental.pdf)
> <p>Temporal difference (TD) learning is one of the main foundations of modern reinforcement learning. This paper studies the use of TD(0) to estimate the value function of a given \textit{evaluation} policy from a batch of data. In this batch setting, we show that TD(0) may converge to an inaccurate value function because the update following an action is weighted according to the number of times that action occurred in the batch -- not the true probability of the action under the evaluation policy. To address this limitation, we introduce \textit{policy sampling error corrected}-TD(0) (PSEC-TD(0)). PSEC-TD(0) first estimates the empirical distribution of actions in each state in the batch and then uses importance sampling to correct for the mismatch between the empirical weighting and the correct weighting for updates following each action. We refine the concept of a certainty-equivalence estimate and argue that PSEC-TD(0) converges to a more desirable fixed-point than TD(0) for a fixed batch of data. Finally, we conduct an empirical evaluation of PSEC-TD(0) on two batch value function learning tasks and show that PSEC-TD(0) produces value function estimates with lower mean squared error than the standard TD(0) algorithm in both discrete and continuous control tasks.</p> 
### 861.[Adaptive Sampling for Estimating Probability Distributions](https://proceedings.icml.cc/book/4101.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5282-Paper.pdf)
  Shubhanshu Shekhar, Tara Javidi, Mohammad Ghavamzadeh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5282-Metadata.json)
> We consider the problem of allocating a fixed budget of samples to a finite set of discrete distributions to learn them uniformly well (minimizing the maximum error) in terms of four common distance measures: $\ell_2^2$, $\ell_1$, $f$-divergence, and separation distance. To present a unified treatment of these distances, we first propose a general \emph{optimistic tracking algorithm} and analyze its sample allocation performance w.r.t.~an oracle. We then instantiate this algorithm for the four distance measures and derive bounds on their regret. We also show that the allocation performance of the proposed algorithm cannot, in general, be improved, by deriving lower-bounds on the expected deviation from the oracle allocation for any adaptive scheme. We verify our theoretical findings through some experiments. Finally, we show that the techniques developed in the paper can be easily extended to learn some classes of continuous distributions as well as to the related setting of minimizing the average error (in terms of the four distances) in learning a set of distributions. 
### 862.[Adversarial Filters of Dataset Biases](https://proceedings.icml.cc/book/4102.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5308-Paper.pdf)
  Ronan Le Bras, Swabha Swayamdipta, Chandra Bhagavatula, Rowan Zellers, Matthew Peters, Ashish Sabharwal, Yejin Choi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5308-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5308-Supplemental.pdf)
> <p>Large neural models have demonstrated human-level performance on language and vision benchmarks such as ImageNet and Stanford Natural Language Inference (SNLI). Yet, their performance degrades considerably when tested on adversarial or out-of-distribution samples. This raises the question of whether these models have learned to solve a dataset rather than the underlying task by overfitting on spurious dataset biases. </p>  <p>We investigate one recently proposed approach, AFLite, which adversarially filters such dataset biases, as a means to mitigate the prevalent overestimation of machine performance. We provide a theoretical understanding for AFLite, by situating it in the generalized framework for optimum bias reduction. Our experiments show that as a result of the substantial reduction of these biases, models trained on the filtered datasets yield better generalization to out-of-distribution tasks, especially when the benchmarks used for training are over-populated with biased samples. We show that AFLite is broadly applicable to a variety of both real and synthetic datasets for reduction of measurable dataset biases and provide extensive supporting analyses. Finally, filtering results in a large drop in model performance (e.g., from 92% to 62% for SNLI), while human performance still remains high. Our work thus shows that such filtered datasets can pose new research challenges for robust generalization by serving as upgraded benchmarks.</p> 
### 863.[Black-Box Variational Inference as a Parametric Approximation to Langevin Dynamics](https://proceedings.icml.cc/book/4103.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5310-Paper.pdf)
  Matthew Hoffman, Yian Ma [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5310-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5310-Supplemental.pdf)
> <p>Variational inference (VI) and Markov chain Monte Carlo (MCMC) are approximate posterior inference algorithms that are often said to have complementary strengths, with VI being fast but biased and MCMC being slower but asymptotically unbiased. In this paper, we analyze gradient-based MCMC and VI procedures and find theoretical and empirical evidence that these procedures are not as different as one might think. In particular, a close examination of the Fokker-Planck equation that governs the Langevin dynamics (LD) MCMC procedure reveals that LD implicitly follows a gradient flow that corresponds to an VI procedure based on optimizing a nonparametric normalizing flow. The evolution under gradient descent of real-world VI approximations that use tractable, parametric flows can thus be seen as an approximation to the evolution of a population of LD-MCMC chains. This result suggests that the transient bias of LD (due to the Markov chain not having burned in) may track that of VI (due to the optimizer not having converged), up to differences due to VI’s asymptotic bias and parameter geometry. Empirically, we find that the transient biases of these algorithms (and their momentum-accelerated counterparts) do evolve similarly. This suggests that practitioners with a limited time budget may get more accurate results by running an MCMC procedure (even if it is stopped before fully burning in) than a VI procedure, as long as the variance of the MCMC estimator can be dealt with (e.g., by running many parallel chains).</p> 
### 864.[Faster Graph Embeddings via Coarsening](https://proceedings.icml.cc/book/4104.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5316-Paper.pdf)
  Matthew Fahrbach, Gramoz Goranci, Sushant Sachdeva, Richard Peng, Chi Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5316-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5316-Supplemental.pdf)
> <p>Graph embeddings are a ubiquitous tool for machine learning tasks, such as node classification and link prediction, on graph-structured data. However, computing the embeddings for large-scale graphs is prohibitively inefficient even if we are interested only in a small subset of relevant vertices. To address this, we present an efficient graph coarsening approach, based on Schur complements, for computing the embedding of the relevant vertices. We prove that these embeddings are preserved exactly by the Schur complement graph that is obtained via Gaussian elimination on the non-relevant vertices. As computing Schur complements is expensive, we give a nearly-linear time algorithm that generates a coarsened graph on the relevant vertices that provably matches the Schur complement in expectation. Our experiments involving prediction tasks on graphs demonstrate that computing embeddings on the coarsened graph, rather than the entire graph, leads to significant time savings without sacrificing accuracy.</p> 
### 865.[Efficient non-conjugate Gaussian process factor models for spike countdata using polynomial approximations](https://proceedings.icml.cc/book/4105.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5317-Paper.pdf)
  Stephen Keeley, David Zoltowski, Jonathan Pillow, Spencer Smith, Yiyi Yu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5317-Metadata.json)
> <p>Gaussian Process Factor Analysis (GPFA) hasbeen broadly applied to the problem of identi-fying smooth, low-dimensional temporal struc-ture underlying large-scale neural recordings.However, spike trains are non-Gaussian, whichmotivates combining GPFA with discrete ob-servation models for binned spike count data.The drawback to this approach is that GPFApriors are not conjugate to count model like-lihoods, which makes inference challenging.Here we address this obstacle by introduc-ing a fast, approximate inference method fornon-conjugate GPFA models. Our approachuses orthogonal second-order polynomials toapproximate the nonlinear terms in the non-conjugate log-likelihood, resulting in a methodwe refer to aspolynomial approximate log-likelihood(PAL) estimators. This approxima-tion allows for accurate closed-form evalua-tion of marginal likelihoods and fast numericaloptimization for parameters and hyperparam-eters. We derive PAL estimators for GPFAmodels with binomial, Poisson, and negativebinomial observations. We find the PAL esti-mation achieves faster convergence times andhigh accuracy compared to existing state-of-the-art inference methods. We also find thatPAL hyperparameters can provide sensible ini-tialization for black box variational inference(BBVI), which will improve BBVI accuracy.We apply these methods to data from mousevisual cortex and primate higher-order visualand parietal cortices. We demonstrate thatPreliminary work. Under review by AISTATS 2020. Do notdistribute.PAL estimators achieve fast and accurate ex-traction of latent structure from multi-neuronspike train data.</p> 
### 866.[Multigrid Neural Memory](https://proceedings.icml.cc/book/4106.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5318-Paper.pdf)
  Tri Huynh, Michael Maire, Matthew Walter [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5318-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5318-Supplemental.pdf)
> <p>We introduce a radical new approach to endowing neural networks with access to long-term and large-scale memory.  Architecting networks with internal multigrid structure and connectivity, while distributing memory cells alongside computation throughout this topology, we observe that coherent memory subsystems emerge as a result of training.  Our design both drastically differs from and is far simpler than prior efforts, such as the recently proposed Differentiable Neural Computer (DNC), which uses intricately crafted controllers to connect neural networks to external memory banks.  Our hierarchical spatial organization, parameterized convolutionally, permits efficient instantiation of large-capacity memories.  Our multigrid topology provides short internal routing pathways, allowing convolutional networks to efficiently approximate the behavior of fully connected networks.  Such networks have an implicit capacity for internal attention; augmented with memory, they learn to read and write specific memory locations in a dynamic data-dependent manner.  We demonstrate these capabilities on synthetic exploration and mapping tasks, where our network is able to self-organize and retain long-term memory for trajectories of thousands of time steps, outperforming the DNC. On tasks without any notion of spatial geometry: sorting, associative recall, question answering, our design functions as a truly generic memory and yields excellent results.</p> 
### 867.[Cautious Adaptation For Reinforcement Learning in Safety-Critical Settings](https://proceedings.icml.cc/book/4107.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5322-Paper.pdf)
  Jesse Zhang, Brian Cheung, Chelsea Finn, Sergey Levine, Dinesh Jayaraman [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5322-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5322-Supplemental.pdf)
> <p>We study the problem of safe adaptation: given a model trained on a variety of past experiences for some task, can this model learn to perform that task in a new situation while avoiding catastrophic failure? This problem setting occurs frequently in real-world reinforcement learning scenarios such as a vehicle adapting to drive in a new city, or a robotic drone adapting a policy trained only in simulation. While learning without catastrophic failures is exceptionally difficult, prior experience can allow us to learn models that make this much easier. These models might not directly transfer to new settings, but can enable cautious adaptation that is substantially safer than na\"{i}ve adaptation as well as learning from scratch. Building on this intuition, we propose risk-averse domain adaptation (RADA). RADA works in two steps: it first trains probabilistic model-based RL agents in a population of source domains to gain experience and capture epistemic uncertainty about the environment dynamics. Then, when dropped into a new environment, it employs a pessimistic exploration policy, selecting actions that have the best worst-case performance as forecasted by the probabilistic model. We show that this simple maximin policy accelerates domain adaptation in a safety-critical driving environment with varying vehicle sizes. We compare our approach against other approaches for adapting to new environments.</p> 
### 868.[Adversarial Nonnegative Matrix Factorization](https://proceedings.icml.cc/book/4108.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5336-Paper.pdf)
  lei luo, yanfu Zhang, Heng Huang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5336-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5336-Supplemental.pdf)
> <p>Nonnegative Matrix Factorization (NMF) has become an increasingly important research topic in machine learning. It targets at searching for two non-negative matrices (\textit{i.e.}, feature matrix \textbf{A} and weight matrix \textbf{X}) whose product can well approximate the original matrix \textbf{Y}. Despite all the practical success, most of existing NMF models are still vulnerable to adversarial attacks. To overcome this limitation, we propose a novel Adversarial NMF (ANMF) approach in which an adversary can exercise some control over the perturbed data generation process. Different from the traditional NMF models which focus on either the regular input or certain types of noise, our model considers potential test adversaries that are beyond the pre-defined constraints, which can cope with various noises (or perturbations). We formulate the proposed model as a bilevel optimization problem and use Alternating Direction Method of Multipliers (ADMM) to solve it with convergence analysis. Theoretically, the robustness analysis of ANMF is established under mild conditions dedicating asymptotically unbiased prediction. Extensive experiments verify that ANMF is robust to a broad categories of perturbations, and achieves state-of-the-art performances on distinct real-world benchmark datasets.</p> 
### 869.[Aligned Cross Entropy for Non-Autoregressive Machine Translation](https://proceedings.icml.cc/book/4109.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5339-Paper.pdf)
  Marjan Ghazvininejad, Vladimir Karpukhin, Luke Zettlemoyer, Omer Levy [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5339-Metadata.json)
> <p>Non-autoregressive machine translation models significantly speed up decoding by allowing for parallel prediction of the entire target sequence. However, modeling word order is more challenging due to the lack of autoregressive factors in the model. This difficultly is compounded during training with cross entropy loss, which can highly penalize small shifts in word order. In this paper, we propose aligned cross entropy (AXE) as an alternate loss function for training of non-autoregressive models. AXE uses a differentiable dynamic program to assign loss based on the best possible monotonic alignment between target tokens and model predictions. AXE-based non-monotonic training of conditional masked language models (CMLMs) improves performance by 3 and 5 BLEU points respectively on WMT 16 EN-RO and WMT 14 EN-DE. It also significantly outperforms the state-of-the-art non-autoregressive models on a range of translation benchmarks.</p> 
### 870.[Model-Agnostic Characterization of Fairness Trade-offs](https://proceedings.icml.cc/book/4110.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5341-Paper.pdf)
  Joon Kim, Jiahao Chen, Ameet Talwalkar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5341-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5341-Supplemental.pdf)
> <p>There exist several inherent trade-offs while designing a fair model, such as those between the model’s predictive accuracy and fairness, or even among different  notions of fairness. In practice, exploring these trade-offs requires significant human and computational resources.  We propose a diagnostic to enable practitioners to explore these trade-offs without training a single model. Our work hinges on the observation that many widely-used fairness definitions can be expressed via the fairness-confusion tensor, an object obtained by splitting the traditional confusion matrix according to protected data attributes. Our diagnostic optimizes accuracy and fairness objectives directly over the elements in this tensor in a data-dependent, yet model-agnostic fashion. We further leverage our tensor-based perspective to generalize existing theoretical impossibility results to a wider range of fairness definitions. Finally, we demonstrate the usefulness of the proposed diagnostic on synthetic and real datasets.</p> 
### 871.[A Distributional Framework For Data Valuation](https://proceedings.icml.cc/book/4111.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5343-Paper.pdf)
  Amirata Ghorbani, Michael Kim, James Zou [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5343-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5343-Supplemental.zip)
> <p>Shapley value is a classic notion from game theory, historically used to quantify the contributions of individuals within groups, and more recently applied to assign values to data points when training machine learning models. Despite its foundational role, a key limitation of the data Shapley framework is that it only provides valuations for points within a fixed data set. It does not account for statistical aspects of the data and does not give a way to reason about points outside the data set. To address these limitations, we propose a novel framework -- distributional Shapley -- where the value of a point is defined in the context of an underlying data distribution. We prove that distributional Shapley has several desirable statistical properties; for example, the values are stable under perturbations to the data points themselves and to the underlying data distribution. We leverage these properties to develop a new algorithm for estimating values from data, which comes with formal guarantees and runs two orders of magnitude faster than state-of-the-art algorithms for computing the (non-distributional) data Shapley values. We apply distributional Shapley to diverse data sets and demonstrate its utility in a data market setting.</p> 
### 872.[Supervised Quantile Normalization for Low Rank Matrix Factorization](https://proceedings.icml.cc/book/4112.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5349-Paper.pdf)
  Marco Cuturi, Olivier Teboul, Jonathan Niles-Weed, Jean-Philippe Vert [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5349-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5349-Supplemental.zip)
> Low rank matrix factorization is a fundamental building block in machine learning, used for instance to summarize gene expression profile data or word-document counts. To be robust to outliers and differences in scale across features, a matrix factorization step is usually preceded by ad-hoc feature normalization steps, such as tf-idf scaling or data whitening. We propose in this work to learn these normalization operators jointly with the factorization itself. More precisely, given a $d\times n$ matrix $X$ of $d$ features measured on $n$ individuals, we propose to learn the parameters of quantile normalization operators that can operate row-wise on the values of $X$ and/or of its factorization $UV$  to improve the quality of the low-rank representation of $X$ itself. This optimization is facilitated by the introduction of differentiable quantile normalization operators derived using regularized optimal transport algorithms.
### 873.[AR-DAE: Towards Unbiased Neural Entropy Gradient Estimation](https://proceedings.icml.cc/book/4113.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5352-Paper.pdf)
  Jae Hyun Lim, Aaron Courville, Christopher Pal, Chin-Wei Huang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5352-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5352-Supplemental.pdf)
> <p>Entropy is ubiquitous in machine learning, but it is in general intractable to compute the entropy of the distribution of an arbitrary continuous random variable. In this paper, we propose the amortized residual denoising autoencoder (AR-DAE) to approximate the gradient of the log density function, which can be used to estimate the gradient of entropy. Amortization allows us to significantly reduce the error of the gradient approximator by approaching asymptotic optimality of a regular DAE, in which case the estimation is in theory unbiased. We conduct theoretical and experimental analyses on the approximation error of the proposed method, as well as extensive studies on heuristics to ensure its robustness. Finally, using the proposed gradient approximator to estimate the gradient of entropy, we demonstrate state-of-the-art performance on density estimation with variational autoencoders and continuous control with soft actor-critic.</p> 
### 874.[Bridging the Gap Between f-GANs and Wasserstein GANs](https://proceedings.icml.cc/book/4114.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5361-Paper.pdf)
  Jiaming Song, Stefano Ermon [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5361-Metadata.json)
> <p>Generative adversarial networks (GANs) variants approximately minimize divergences between the model and the data distribution using a discriminator. Wasserstein GANs (WGANs) enjoy superior empirical performance, however, unlike in f-GANs, the discriminator does not provide an estimate for the ratio between model and data densities, which is useful in applications such as inverse reinforcement learning. To overcome this limitation, we propose an new training objective where we additionally optimize over a set of importance weights over the generated samples. By suitably constraining the feasible set of importance weights, we obtain a family of objectives which includes and generalizes the original f-GAN and WGAN objectives. We show that a natural extension outperforms WGANs while providing density ratios as in f-GAN, and demonstrate empirical success on distribution modeling, density ratio estimation and image generation, where we achieve state-of-the-art FID scores on CIFAR10 generation.</p> 
### 875.[“Other-Play” for Zero-Shot Coordination](https://proceedings.icml.cc/book/4115.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5369-Paper.pdf)
  Hengyuan Hu, Alexander Peysakhovich, Adam Lerer, Jakob Foerster [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5369-Metadata.json)
> <p>We consider the problem of zero-shot coordination - constructing AI agents that can coordinate with novel partners they have not seen before (e.g.humans). Standard Multi-Agent Reinforcement Learning (MARL) methods typically focus on the self-play (SP) setting where agents construct strategies by playing the game with themselves repeatedly. Unfortunately, applying SP naively to the zero-shot coordination problem can produce agents that establish highly specialized conventions that do not carry over to novel partners they have not been trained with. We introduce a novel learning algorithm called other-play (OP), that enhances self-play by looking for more robust strategies. We characterize OP theoretically as well as experimentally. We study the cooperative card game Hanabi and show that OP agents achieve higher scores when paired with independently trained agents as well as with human players than SP agents.</p> 
### 876.[Correlation Clustering with Asymmetric Classification Errors](https://proceedings.icml.cc/book/4116.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5386-Paper.pdf)
  Jafar Jafarov, Sanchit Kalhan, Konstantin Makarychev, Yury Makarychev [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5386-Metadata.json)
> In the Correlation Clustering problem, we are given a weighted graph $G$ with its edges labelled as &quot;similar&quot; or &quot;dissimilar&quot; by a binary classifier. The goal is to produce a clustering that minimizes the weight of &quot;disagreements&quot;: the sum of the weights of &quot;similar&quot; edges across clusters and &quot;dissimilar&quot; edges within clusters. We study the correlation clustering problem under the following assumption: Every &quot;similar&quot; edge $e$ has weight $w_e \in [ \alpha w, w ]$ and every &quot;dissimilar&quot; edge $e$ has weight $w_e \geq \alpha w$ (where $\alpha \leq 1$ and $w &gt; 0$ is a scaling parameter). We give a $(3 + 2 \log_e (1/\alpha))$ approximation algorithm for this problem. This assumption captures well the scenario when classification errors are asymmetric. Additionally, we show an asymptotically matching Linear Programming integrality gap of $\Omega(\log 1/\alpha)$.
### 877.[An Optimistic Perspective on Offline Deep Reinforcement Learning](https://proceedings.icml.cc/book/4117.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5394-Paper.pdf)
  Rishabh Agarwal, Dale Schuurmans, Mohammad Norouzi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5394-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5394-Supplemental.pdf)
> <p>Off-policy reinforcement learning (RL) using a fixed offline dataset of logged interactions is an important consideration in real world applications. This paper studies offline RL using the DQN replay dataset comprising the entire replay experience of a DQN agent on 60 Atari 2600 games. We demonstrate that recent off-policy deep RL algorithms, even when trained solely on this fixed dataset, outperform the fully trained DQN agent. To enhance generalization in the offline setting, we present Random Ensemble Mixture (REM), a robust Q-learning algorithm that enforces optimal Bellman consistency on random convex combinations of multiple Q-value estimates. Offline REM trained on the DQN replay dataset surpasses strong RL baselines. Ablation studies highlight the role of offline dataset size and diversity as well as the algorithm choice in our positive results. Overall, the results here present an optimistic view that robust RL algorithms trained on sufficiently large and diverse offline datasets can lead to high quality policies. The DQN replay dataset can serve as an offline RL benchmark and is open-sourced.</p> 
### 878.[Neural Topic Modeling with Continual Lifelong Learning](https://proceedings.icml.cc/book/4118.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5399-Paper.pdf)
  Pankaj Gupta, Yatin Chaudhary, Thomas Runkler, Hinrich Schuetze [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5399-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5399-Supplemental.pdf)
> <p>Lifelong learning has recently attracted attention in building machine learning systems that continually accumulate and transfer knowledge to help future learning. Unsupervised topic modeling has been popularly used to discover topics from document collections. However, the application of topic modeling is challenging due to data sparsity, e.g., in a small collection of (short) documents and thus, generate incoherent topics and sub-optimal document representations. To address the problem, we propose a lifelong learning framework for neural topic modeling that can continuously process streams of document collections, accumulate topics and guide future topic modeling tasks by knowledge transfer from several sources to better deal with the sparse data. In the lifelong process, we particularly investigate jointly: (1) sharing generative homologies (latent topics) over lifetime to transfer prior knowledge, and (2) minimizing catastrophic forgetting to retain the past learning via novel selective data augmentation, co-training and topic regularization approaches. Given a stream of document collections, we apply the proposed Lifelong Neural Topic Modeling (LNTM) framework in modeling three sparse document collections as future tasks and demonstrate improved performance quantified by perplexity, topic coherence and information retrieval task.</p> 
### 879.[Learning and Evaluating Contextual Embedding of Source Code](https://proceedings.icml.cc/book/4119.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5401-Paper.pdf)
  Aditya Kanade, Petros Maniatis, Gogul Balakrishnan, Kensen Shi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5401-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5401-Supplemental.pdf)
> <p>Recent research has achieved impressive results on understanding and improving source code by building up on machine-learning techniques developed for natural languages. A significant advancement in natural-language understanding has come with the development of pre-trained con-textual embeddings such as BERT. These can be fine-tuned for downstream tasks with less labeled data and training budget, while achieving better accuracies. However, there is no attempt yet to obtain a high-quality contextual embedding of source code, and to evaluate it on multiple tasks simultaneously.</p>  <p>In this paper, we alleviate this gap by curating a code-understanding benchmark and evaluating a learned contextual embedding of source code. More specifically, we curate a massive, deduplicated corpus of Python code from GitHub and train a BERT model, which we call B4C. We also create a benchmark comprising five classification tasks and one program-repair task, akin to code-understanding tasks proposed in the literature before. For comparison, we train different variants of Word2Vec token embeddings, and BiLSTM and Transformer models. For the repair task, we also compare to SOTA models. We show that fine-tuned B4C models give better results, even with shorter training or fewer examples. Future work on source-code embedding could benefit from reusing our benchmark and comparing against B4C as a strong baseline.</p> 
### 880.[Uncertainty quantification for nonconvex tensor completion: Confidence intervals, heteroscedasticity and optimality](https://proceedings.icml.cc/book/4120.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5403-Paper.pdf)
  Changxiao Cai, H. Vincent Poor, Yuxin Chen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5403-Metadata.json)
> <p>We study the distribution and uncertainty of nonconvex optimization for noisy tensor completion --- the problem of estimating a low-rank tensor given incomplete and corrupted observations of its entries. Focusing on a two-stage nonconvex estimation algorithm, we characterize the distribution of this estimator down to fine scales. This distributional theory in turn allows one to construct valid and short confidence intervals for both the unseen tensor entries and its underlying tensor factors. The proposed inferential procedure enjoys several important features: (1) it is fully adaptive to noise heteroscedasticity, and (2) it is data-driven and adapts automatically to unknown noise distributions. Furthermore, our findings unveil the statistical optimality of nonconvex tensor completion: it attains un-improvable estimation accuracy --- including both the rates and the pre-constants --- under i.i.d. Gaussian noise.</p> 
### 881.[Learning with Good Feature Representations in Bandits and in RL with a Generative Model](https://proceedings.icml.cc/book/4121.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5409-Paper.pdf)
  Gellért Weisz, Tor Lattimore, Csaba Szepesvari [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5409-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5409-Supplemental.pdf)
> <p>The construction in the recent paper by Du et al. [2019] implies that searching for a near-optimal action in a bandit sometimes requires examining essentially all the actions, even if the learner is given linear features in R^d that approximate the rewards with a small uniform error. We use the Kiefer-Wolfowitz theorem to prove a positive result that by checking only a few actions, a learner can always find an action that is suboptimal with an error of at most O(ε√d) where ε is the approximation error of the features. Thus, features are useful when the approximation error is small relative to the dimensionality of the features. The idea is applied to stochastic bandits and reinforcement learning with a generative model where the learner has access to d-dimensional linear features that approximate the action-value functions for all policies to an accuracy of ε. For linear bandits, we prove a bound on the regret of order d√(n log(k)) + εn√d log(n) with k the number of actions and n the horizon. For RL we show that approximate policy iteration can learn a policy that is optimal up to an additive error of order ε√d/(1 − γ)^2 and using about d/(ε^2(1 − γ)^4) samples from the generative model. These bounds are independent of the finer details of the features. We also investigate how the structure of the feature set impacts the tradeoff between sample complexity and estimation error.</p> 
### 882.[Angular Visual Hardness](https://proceedings.icml.cc/book/4122.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5423-Paper.pdf)
  Beidi Chen, Weiyang Liu, Zhiding Yu, Jan Kautz, Anshumali Shrivastava, Animesh Garg, Anima Anandkumar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5423-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5423-Supplemental.pdf)
> <p>Recent convolutional neural networks (CNNs) have led to impressive performance but often suffer from poor calibration. They tend to be overconfident, with the model confidence not always reflecting the underlying true ambiguity and hardness. In this paper, we propose angular visual hardness (AVH), a score given by the normalized angular distance between the sample feature embedding and the target classifier to measure sample hardness. We validate this score with in-depth and extensive scientific study and observe that CNN models with the highest accuracy also have the best AVH scores. This agrees with an earlier finding that state-of-art models improve on the classification of harder examples. We observe that the training dynamics of AVH is vastly different compared to the training loss. Specifically, AVH quickly reaches a plateau for all samples even though the training loss keeps improving. This suggests the need for designing better loss functions that can target harder examples more effectively. We also find that AVH has a statistically significant correlation with human visual hardness. Finally, we demonstrate the benefit of AVH to a variety of applications such as self-training for domain adaptation and domain generalization. </p> 
### 883.[Learning the Stein Discrepancy for Training and Evaluating Energy-Based Models without Sampling](https://proceedings.icml.cc/book/4123.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5430-Paper.pdf)
  Will Grathwohl, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud, Richard Zemel [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5430-Metadata.json)
> <p>We present a new method for evaluating and training unnormalized density models. Our approach only requires access to the gradient of the unnormalized model’s log-density. We  estimate the Stein discrepancy between the data density p(x) and the model density q(x) based on a vector function of the data.  We parameterize this function with a neural network and fit its parameters to maximize this discrepancy.  This yields a novel goodness-of-fit test which outperforms existing methods on high dimensional data. Furthermore, optimizing q(x) to minimize this discrepancy produces a novel method for training unnormalized models. This training method can fit large unnormalized models faster than existing approaches. The ability to both learn and compare models is a unique feature of the proposed method.</p> 
### 884.[Variance Reduction and Quasi-Newton for Particle-Based Variational Inference](https://proceedings.icml.cc/book/4124.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5434-Paper.pdf)
  Michael Zhu, Chang Liu, Jun Zhu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5434-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5434-Supplemental.pdf)
> <p>Particle-based Variational Inference methods (ParVIs), like Stein Variational Gradient Descent, are nonparametric variational inference methods that optimize a set of particles to best approximate a target distribution. ParVIs have been proposed as efficient approximate inference algorithms and as potential alternatives to MCMC methods. However, to our knowledge, the quality of the posterior approximation of particles from ParVIs has not been examined before for challenging, large-scale Bayesian inference problems. In this paper, we find that existing ParVI approaches converge insufficiently fast under sample quality metrics, and we propose a novel variance reduction and quasi-Newton preconditioning framework for all ParVIs, by leveraging the Riemannian structure of the Wasserstein space and advanced Riemannian optimization algorithms. Experimental results demonstrate the accelerated convergence of ParVIs for accurate posterior inference in large-scale and ill-conditioned problems.</p> 
### 885.[Better depth-width trade-offs for neural networks through the lens of dynamical systems](https://proceedings.icml.cc/book/4125.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5441-Paper.pdf)
  Evangelos Chatziafratis, Ioannis Panageas, Sai Ganesh Nagarajan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5441-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5441-Supplemental.zip)
> The expressivity of neural networks as a function of their depth, width and type of activation units has been an important question in deep learning theory. Recently, depth separation results for ReLU networks were obtained via a new connection with dynamical systems, using a generalized notion of fixed points of a continuous map $f$, called periodic points. In this work, we strengthen the connection with dynamical systems and we improve the existing width lower bounds along several aspects. Our first main result is period-specific width lower bounds that hold under the stronger notion of $L^1$-approximation error, instead of the weaker classification error. Our second contribution is that we provide sharper width lower bounds, still yielding meaningful exponential depth-width separations, in regimes where previous results wouldn&#x27;t apply. A byproduct of our results is that there exists a universal constant characterizing the depth-width trade-offs, as long as $f$ has odd periods. Technically, our results follow by unveiling a tighter connection between the following three quantities of a given function: its period, its Lipschitz constant and the growth rate of the number of oscillations arising under compositions of the function $f$ with itself.
### 886.[Stochastic Coordinate Minimization with Progressive Precision for Stochastic Convex Optimization](https://proceedings.icml.cc/book/4126.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5461-Paper.pdf)
  Sudeep Salgia, Qing Zhao, Sattar Vakili [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5461-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5461-Supplemental.zip)
> <p>A framework based on iterative coordinate minimization (CM) is developed for stochastic convex optimization. Given that exact coordinate minimization is impossible due to the unknown stochastic nature of the objective function, the crux of the proposed optimization algorithm is an optimal control of the minimization precision in each iteration.  We establish the optimal precision control and the resulting order-optimal regret performance for strongly convex and separably nonsmooth functions.  An interesting finding is that the optimal progression of precision across iterations is independent of the low-dimension CM routine employed, suggesting a general framework for extending low-dimensional optimization routines to high-dimensional problems. The proposed algorithm is amenable to online implementation and inherits the scalability and parallelizability  properties of CM for large-scale optimization. Requiring only a sublinear order of message exchanges,  it also lends itself well to distributed computing as compared with the alternative approach of coordinate gradient descent.</p> 
### 887.[Fundamental Tradeoffs between Invariance and Sensitivity to Adversarial Perturbations](https://proceedings.icml.cc/book/4127.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5465-Paper.pdf)
  Florian Tramer, Jens Behrmann, Nicholas Carlini, Nicolas Papernot, Joern-Henrik Jacobsen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5465-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5465-Supplemental.pdf)
> <p>Adversarial examples are malicious inputs crafted to induce misclassification. Commonly studied \emph{sensitivity-based} adversarial examples introduce semantically-small changes to an input that result in a different model prediction.  This paper studies a complementary failure mode, \emph{invariance-based} adversarial examples, that introduce minimal semantic changes that modify an input's true label yet preserve the model's prediction. We demonstrate fundamental tradeoffs between these two types of adversarial examples.</p>  <p>We show that defenses against sensitivity-based attacks  actively harm a model's accuracy on invariance-based attacks, and that new approaches are needed to resist both attack types. In particular, we break state-of-the-art adversarially-trained and \emph{certifiably-robust} models by generating small perturbations that the models are (provably) robust to, yet that change an input's class according to human labelers. Finally, we formally show that the existence of excessively invariant classifiers arises from the presence of \emph{overly-robust} predictive features in standard datasets. </p> 
### 888.[Learning From Strategic Agents: Accuracy, Improvement, and Causality](https://proceedings.icml.cc/book/4128.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5468-Paper.pdf)
  Yonadav Shavit, Benjamin Edelman, Brian Axelrod [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5468-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5468-Supplemental.pdf)
> <p>In many predictive decision-making scenarios, such as credit scoring and academic testing, a decision-maker must construct a model that accounts for agents' incentives to ``game'' their features in order to receive better decisions. Whereas the strategic classification literature generally assumes that agents' outcomes are not causally dependent on their features (and thus strategic behavior is a form of lying), we join concurrent work in modeling agents' outcomes as a function of their changeable attributes. Our formulation is the first to incorporate a crucial phenomenon: when agents act to change observable features, they may as a side effect perturb unobserved features that causally affect their true outcomes. We consider three distinct desiderata for a decision-maker's model: accurately predicting agents' post-gaming outcomes (accuracy), incentivizing agents to improve these outcomes (improvement), and, in the linear setting, estimating the visible coefficients of the true causal model (causal precision). As our main contribution, we provide the first algorithms for learning accuracy-optimizing, improvement-optimizing, and causal-precision-optimizing linear regression models directly from data, without prior knowledge of agents' possible actions. These algorithms circumvent the hardness result of Miller et al. (2019) by allowing the decision maker to observe agents' responses to a sequence of decision rules, in effect inducing agents to perform causal interventions for free.</p> 
### 889.[Causal Structure Discovery from Distributions Arising from Mixtures of DAGs](https://proceedings.icml.cc/book/4129.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5473-Paper.pdf)
  Basil Saeed, Snigdha Panigrahi, Caroline Uhler [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5473-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5473-Supplemental.pdf)
> <p>We consider distributions arising from a mixture of causal models, where each model is represented by a directed acyclic graph (DAG). We provide a graphical representation of such mixture distributions and prove that this representation encodes the conditional independence relations of the mixture distribution. We  then  consider  the  problem  of  structure  learning  based  on  samples  from  such distributions. Since the mixing variable is latent, we consider causal structure discovery algorithms such as FCI that can deal with latent variables. We show that such algorithms recover a “union” of the component DAGs and can identify variables whose conditional distribution across the component DAGs vary. We demonstrate our results on synthetic and real data showing that the inferred graph identifies nodes that vary between the different mixture components. As an immediate application, we demonstrate how retrieval of this causal information can be used to cluster samples according to each mixture component.</p> 
### 890.[Explainable and Discourse Topic-aware Neural Language Understanding](https://proceedings.icml.cc/book/4130.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5492-Paper.pdf)
  Yatin Chaudhary, Pankaj Gupta, Hinrich Schuetze [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5492-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5492-Supplemental.pdf)
> <p>Marrying topic models and language models expose language understanding to a broader source of document-level context beyond sentences via topics. While introducing topical semantics in language models, existing approaches incorporate latent document topic proportions and ignore topical discourse in sentences of the document. This work extends the line of research by additionally introducing an explainable topic representation in language understanding, obtained from a set of key terms correspondingly for each latent topic of the proportion. Moreover, we retain sentence-topic associations along with document-topic association by modeling topical discourse for every sentence in the document. We present a novel neural composite language model that exploits both the latent and explainable topics along with topical discourse at sentence-level in a joint learning framework of topic and language models. Experiments over a range of tasks such as language modeling, word sense disambiguation, document classification, retrieval and text generation demonstrate ability of the proposed model in improving language understanding.</p> 
### 891.[Understanding Contrastive Representation Learning through Geometry on the Hypersphere](https://proceedings.icml.cc/book/4131.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5503-Paper.pdf)
  Tongzhou Wang, Phillip Isola [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5503-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5503-Supplemental.pdf)
> <p>Contrastive representation learning has been outstandingly successful in practice. In this work, we identify two key properties related to the contrastive loss: (1) alignment (closeness) of features from positive pairs, and (2) uniformity of the induced distribution of the (normalized) features on the hypersphere. We prove that, asymptotically, the contrastive loss indeed optimizes these properties, and analyze their positive effects on downstream tasks. Empirically, we introduce an optimizable metric to quantify each property. Extensive experiments on standard image classification and depth prediction datasets confirm the strong agreement between both metrics and downstream task performance. Remarkably, directly optimizing for these two metrics leads to representations with comparable or better performance at downstream tasks than contrastive learning.</p> 
### 892.[On Learning Language-Invariant Representations for Universal Machine Translation](https://proceedings.icml.cc/book/4132.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5505-Paper.pdf)
  Han Zhao, Junjie Hu, Andrej Risteski [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5505-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5505-Supplemental.pdf)
> <p>The goal of universal machine translation is to learn to translate between any pair of languages, given pairs of translated documents for \emph{some} of these languages. Despite impressive empirical results and an increasing interest in massively multilingual models, theoretical analysis on translation errors made by such universal machine translation models is only nascent. In this paper, we take one step towards better understanding of universal machine translation by first proving an impossibility theorem in the general case. In particular, we derive a lower bound on the translation error in the many-to-one translation setting, which shows that any algorithm aiming to learn shared sentence representations among multiple language pairs has to make a large translation error on at least one of the translation tasks, if no assumption on the structure of the languages is made. On the positive side, we show that if the documents follow a natural encoder-decoder generative process, then we can expect a natural notion of ``generalization'': a linear number of pairs, rather than quadratic, suffices. Our theory also explains what kinds of connection graphs between pairs of languages are better suited: ones with longer paths result in worse sample complexity in terms of the total number of documents per language pair needed.</p> 
### 893.[Compressive sensing with un-trained neural networks: Gradient descent finds a smooth approximation](https://proceedings.icml.cc/book/4133.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5509-Paper.pdf)
  Reinhard Heckel, Mahdi Soltanolkotabi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5509-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5509-Supplemental.zip)
> <p>Un-trained convolutional neural networks have emerged as highly successful tools for image recovery and restoration. They are capable of solving standard inverse problems such as denoising and compressive sensing with excellent results by simply fitting a neural network model to measurements from a single image or signal without the need for any additional training data. For some applications, this critically requires additional regularization in the form of early stopping the optimization. For signal recovery from a few measurements, however, un-trained convolutional networks have an intriguing self-regularizing property: Even though the network can perfectly fit any image, the network recovers a natural image from few measurements when trained with gradient descent until convergence. In this paper, we demonstrate this property numerically and study it theoretically. We show that---without any further regularization---an un-trained convolutional neural network can approximately reconstruct signals and images that are sufficiently structured, from a near minimal number of random measurements.</p> 
### 894.[Representing Unordered Data Using Multiset Automata and Complex Numbers](https://proceedings.icml.cc/book/4134.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5513-Paper.pdf)
  Justin DeBenedetto, David Chiang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5513-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5513-Supplemental.pdf)
> <p>Unordered, variable-sized inputs arise in many settings across multiple fields.  The ability for set- and multiset- oriented neural networks to handle this type of input has been the focus of much work in recent years.  We propose to represent multisets using complex-weighted multiset automata and show how the multiset representations of certain existing neural architectures can be viewed as special cases of ours.  Namely, (1) we provide a new theoretical and intuitive justification for the Transformer model's representation of positions using sinusoidal functions, and (2) we extend the DeepSets model to use complex numbers, enabling it to outperform the existing model on an extension of one of their tasks.  </p> 
### 895.[Mutual Transfer Learning for Massive Data](https://proceedings.icml.cc/book/4135.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5517-Paper.pdf)
  Ching-Wei Cheng, Xingye Qiao, Guang Cheng [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5517-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5517-Supplemental.pdf)
> <p>In the transfer learning problem, the target and the source data domains are typically known. In this article, we study a new paradigm called mutual transfer learning where among many heterogeneous data domains, every data domain could potentially be the target of interest, and it could also be a useful source to help the learning in other data domains. However, it is important to note that given a target not every data domain can be a successful source; only data sets that are similar enough to be thought as from the same population can be useful sources for each other. Under this mutual learnability assumption, a confidence distribution fusion approach is proposed to recover the mutual learnability relation in the transfer learning regime. Our proposed method achieves the same oracle statistical inferential accuracy as if the true learnability structure were known. It can be implemented in an efficient parallel fashion to deal with large-scale data. Simulated and real examples are analyzed to illustrate the usefulness of the proposed method.</p> 
### 896.[The Differentiable Cross-Entropy Method](https://proceedings.icml.cc/book/4136.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5518-Paper.pdf)
  Brandon Amos, Denis Yarats [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5518-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5518-Supplemental.pdf)
> <p>We study the Cross-Entropy Method (CEM) for the non-convex optimization of a continuous and parameterized objective function and introduce a differentiable variant that enables us to differentiate the output of CEM with respect to the objective function's parameters. In the machine learning setting this brings CEM inside of the end-to-end learning pipeline where this has otherwise been impossible. We show applications in a synthetic energy-based structured prediction task and in non-convex continuous control. In the control setting we show how to embed optimal action sequences into a lower-dimensional space. This enables us to use policy optimization to fine-tune modeling components by differentiating through the CEM-based controller.</p> 
### 897.[A Sample Complexity Separation between Non-Convex and Convex Meta-Learning](https://proceedings.icml.cc/book/4137.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5528-Paper.pdf)
  Nikunj Umesh Saunshi, Yi Zhang, Mikhail Khodak, Sanjeev Arora [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5528-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5528-Supplemental.pdf)
> One popular trend in meta-learning is to learn from many training tasks a common initialization for a gradient-based method that can be used to solve a new task with few samples. The theory of meta-learning is still in its early stages, with several recent learning-theoretic analyses of methods such as Reptile \cite{nichol:18} being for {\em convex models}. This work shows that convex-case analysis might be insufficient to understand the success of meta-learning, and that even for non-convex models it is important to look inside the optimization black-box, specifically at properties of the optimization trajectory. We construct a simple meta-learning instance that captures the problem of one-dimensional subspace learning. For the convex formulation of linear regression on this instance, we show that the new task sample complexity of any {\em initialization-based meta-learning} algorithm is $\Omega(d)$, where $d$ is the input dimension. In contrast, for the non-convex formulation of a two layer linear network on the same instance, we show that both Reptile and multi-task representation learning can have new task sample complexity of $\gO(1)$, demonstrating a separation from convex meta-learning. Crucially, analyses of the training dynamics of these methods reveal that they can meta-learn the correct subspace onto which the data should be projected.
### 898.[On the Convergence of Nesterov&#x27;s Accelerated Gradient Method in Stochastic Settings](https://proceedings.icml.cc/book/4138.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5529-Paper.pdf)
  Mahmoud Assran, Michael Rabbat [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5529-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5529-Supplemental.pdf)
> <p>We study Nesterov's accelerated gradient method in the stochastic approximation setting (unbiased gradients with bounded variance) and the finite sum setting (where randomness is due to sampling mini-batches). To build better insight into the behavior of Nesterov's method in stochastic settings, we focus throughout on objectives that are smooth, strongly-convex, and twice continuously differentiable. In the stochastic approximation setting, Nesterov's method converges to a neighborhood of the optimal point at the same accelerated rate as in the deterministic setting. Perhaps surprisingly, in the finite-sum setting we prove that Nesterov's method may diverge with the usual choice of step-size and momentum, unless additional conditions on the problem related to conditioning and data coherence are satisfied. Our results shed light as to why Nesterov's method may fail to converge or achieve acceleration in the finite-sum setting.</p> 
### 899.[The Buckley-Osthus model and the block preferential attachment model: statistical analysis and application](https://proceedings.icml.cc/book/4139.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5537-Paper.pdf)
  Wenpin Tang, Xin Guo, Fengmin Tang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5537-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5537-Supplemental.zip)
> <p>This paper is concerned with statistical estimation of two preferential attachment models: the Buckley-Osthus model and the block preferential attachment model. We prove that the maximum likelihood estimates for both models are consistent. We perform simulation studies to corroborate our theoretical findings. We also apply both models to study the evolution of a real-world network. A list of open problems are presented.</p> 
### 900.[Representations for Stable Off-Policy Reinforcement Learning](https://proceedings.icml.cc/book/4140.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5540-Paper.pdf)
  Dibya Ghosh, Marc Bellemare [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5540-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5540-Supplemental.pdf)
> <p>Reinforcement learning with function approximation can be unstable and even divergent, especially when combined with off-policy learning and Bellman updates. In deep reinforcement learning, these issues have been dealt with empirically by adapting and regularizing the representation, in particular with auxiliary tasks. This suggests that representation learning may provide a means to guarantee stability. In this paper, we formally show that there are indeed nontrivial state representations under which the canonical SARSA algorithm is stable, even when learning off-policy. We analyze representation learning schemes that are based on the transition matrix of a policy, such as proto-value functions, along three axes: approximation error, stability, and ease of estimation. In the most general case of a defective transition matrix, we show that a Schur basis provides convergence guarantees, but is difficult to estimate from samples. For a fixed reward function, we find that an orthogonal basis of the corresponding Krylov subspace is an even better choice. We conclude by empirically demonstrating that these stable representations can be learned using stochastic gradient descent, opening the door to improved techniques for representation learning with deep networks.</p> 
### 901.[Piecewise Linear Regression via a Difference of Convex Functions](https://proceedings.icml.cc/book/4141.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5543-Paper.pdf)
  Ali Siahkamari, Aditya Gangrade, Brian Kulis, Venkatesh Saligrama [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5543-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5543-Supplemental.pdf)
> We present a new piecewise linear regression methodology that utilises fitting a \emph{difference of convex} functions (DC functions) to the data. These are functions $f$ that may be represented as the difference $\phi_1 - \phi_2$ for a choice of \emph{convex} functions $\phi_1, \phi_2$. The method proceeds by estimating piecewise-liner convex functions, in a manner similar to max-affine regression, whose difference approximates the data. The choice of the function is regularised by a new seminorm over the class of DC functions that controls the $\ell_\infty$ Lipschitz constant of the estimate. The resulting methodology can be efficiently implemented via Quadratic programming \emph{even in high dimensions}, and is shown to have close to minimax statistical risk. We empirically validate the method, showing it to be practically implementable, and to outperform existing regression methods in accuracy on real-world datasets. 
### 902.[On the consistency of top-k surrogate losses](https://proceedings.icml.cc/book/4142.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5564-Paper.pdf)
  Forest Yang, Sanmi Koyejo [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5564-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5564-Supplemental.pdf)
> The top-$k$ error is often employed to evaluate performance for challenging classification tasks in computer vision as it is designed to compensate for ambiguity in ground truth labels. This practical success motivates our theoretical analysis of consistent top-$k$ classification. To this end, we provide a characterization of Bayes optimality by defining a top-$k$ preserving property, which is new and fixes a non-uniqueness gap in prior work. Then, we define top-$k$ calibration and show it is necessary and sufficient for consistency.  Based on the top-$k$ calibration analysis, we propose a rich class of top-$k$ calibrated Bregman divergence surrogates. Our analysis continues by showing previously proposed hinge-like top-$k$ surrogate losses are not top-$k$ calibrated and thus inconsistent. On the other hand, we propose two new hinge-like losses, one which is similarly inconsistent, and one which is consistent. Our empirical results highlight theoretical claims, confirming our analysis of the consistency of these losses.
### 903.[Collapsed Amortized Variational Inference for Switching Nonlinear Dynamical Systems](https://proceedings.icml.cc/book/4143.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5565-Paper.pdf)
  Zhe Dong,  Bryan Seybold, Kevin Murphy, Hung Bui [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5565-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5565-Supplemental.pdf)
> <p>We propose an efficient inference method for switching nonlinear dynamical systems. The key idea is to learn an inference network which can be used as a proposal distribution for the continuous latent variables, while performing exact marginalization of the discrete latent variables. This allows us to use the reparameterization trick, and apply end-to-end training with stochastic gradient descent. We show that the proposed method can successfully segment time series data, including videos and 3D human pose, into meaningful ``regimes'' by using the piece-wise nonlinear dynamics. </p> 
### 904.[Boosting Deep Neural Network Efficiency with Dual-Module Inference](https://proceedings.icml.cc/book/4144.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5569-Paper.pdf)
  Liu Liu, Lei Deng, Zhaodong Chen, yuke wang, Shuangchen Li, Jingwei Zhang, Yihua Yang, Zhenyu Gu, Yufei Ding, Yuan Xie [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5569-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5569-Supplemental.pdf)
> <p>Using Deep Neural Networks (DNNs) in machine learning tasks is promising in delivering high-quality results but challenging to meet stringent latency requirements and energy constraints because of the memory-bound and the compute-bound execution pattern of DNNs. We propose a big-little dual-module inference to dynamically skip unnecessary memory access and computation to speedup DNN inference. Leveraging the error-resilient feature of nonlinear activation functions used in DNNs, we propose to use a lightweight little module that approximates the original DNN layer, which is referred to as the big module, to compute activations of the insensitive region that are more error-resilient. The expensive memory access and computation of the big module can be reduced as the results are only used in the sensitive region. For memory-bound models, our method can reduce the overall memory access by 40% on average and achieve 1.54x to 1.75x speedup on a commodity CPU-based server platform with a negligible impact on model quality. In addition, our method can reduce the operations of the compute-bound ResNet model by 3.02x, with only a 0.5% accuracy drop.</p> 
### 905.[Time-Consistent Self-Supervision for Semi-Supervised Learning](https://proceedings.icml.cc/book/4145.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5578-Paper.pdf)
  Tianyi Zhou, Shengjie Wang, Jeff Bilmes [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5578-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5578-Supplemental.pdf)
> <p>Semi-supervised learning (SSL) leverages unlabeled data when training a model with insufficient labeled data. A common strategy for SSL is to enforce the consistency of model outputs between similar samples, e.g., neighbors or data augmentations of the same sample. However, model outputs can vary dramatically on unlabeled data over different training stages, e.g., when using large learning rates. This can introduce harmful noises and inconsistent objectives over time that may lead to concept drift and catastrophic forgetting. In this paper, we study the dynamics of neural net outputs in SSL and show that selecting and using first the unlabeled samples with more consistent outputs over the course of training (i.e., "time-consistency") can improve the final test accuracy and save computation. Under the time-consistent data selection, we design an SSL objective composed of two self-supervised losses, i.e., a consistency loss between a sample and its augmentation, and a contrastive loss encouraging different samples to have different outputs. Our approach achieves SOTA on several SSL benchmarks with much fewer computations.</p> 
### 906.[Selective Dyna-style Planning Under Limited Model Capacity](https://proceedings.icml.cc/book/4146.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5608-Paper.pdf)
  Zaheer SM, Samuel Sokota, Erin Talvitie, Martha White [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5608-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5608-Supplemental.pdf)
> <p>In model-based reinforcement learning, planning with an imperfect model of the environment has the potential to harm learning progress. But even when a model is imperfect, it may still contain information that is useful for planning. In this paper, we investigate the idea of using an imperfect model selectively.  The agent should plan in parts of the state space where the model would be helpful but refrain from using the model where it would be harmful. An effective selective planning mechanism requires estimating predictive uncertainty, which arises out of aleatoric uncertainty and epistemic uncertainty. Prior work has focused on parameter uncertainty, a particular kind of epistemic uncertainty, for selective planning. In this work, we emphasize the importance of structural uncertainty, a distinct kind of epistemic uncertainty that signals the errors due to limited capacity or a misspecified model class.  We show that heteroscedastic regression, under an isotropic Gaussian assumption, can signal structural uncertainty that is complementary to that which is detected by methods designed to detect parameter uncertainty, indicating that considering both parameter and structural uncertainty may be a more promising direction for effective selective planning than either in isolation.</p> 
### 907.[A Pairwise Fair and Community-preserving Approach to k-Center Clustering](https://proceedings.icml.cc/book/4147.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5612-Paper.pdf)
  Brian Brubach, Darshan Chakrabarti, John Dickerson, Samir Khuller, Aravind Srinivasan, Leonidas Tsepenekas [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5612-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5612-Supplemental.zip)
> <p>Clustering is a foundational problem in machine learning with numerous applications. As machine learning increases in ubiquity as a backend for automated systems, concerns about fairness arise. Much of the current literature on fairness deals with discrimination against protected classes in supervised learning (group fairness). We define a different notion of fair clustering wherein the probability that two points (or a community of points) become separated is bounded by an increasing function of their pairwise distance (or community diameter). We capture the situation where data points represent people who gain some benefit from being clustered together. Unfairness arises when certain points are deterministically separated, either arbitrarily or by someone who intends to harm them as in the case of gerrymandering election districts. In response, we formally define two new types of fairness in the clustering setting, pairwise fairness and community preservation. To explore the practicality of our fairness goals, we devise an approach for extending existing k-center algorithms to satisfy these fairness constraints. In doing so, we show that reasonable approximations can be achieved while maintaining fairness. In experiments, we compare the effectiveness of our approach to classical k-center algorithms/heuristics and explore the tradeoff between optimal clustering and fairness.</p> 
### 908.[How recurrent networks implement contextual processing in sentiment analysis](https://proceedings.icml.cc/book/4148.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5618-Paper.pdf)
  Niru Maheswaranathan, David Sussillo [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5618-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5618-Supplemental.pdf)
> <p>Neural networks have a remarkable capacity for contextual processing—using recent or nearby inputs to modify processing of current input. For example, in natural language, contextual processing is necessary to correctly interpret negation (e.g. phrases such as "not bad"). However, our ability to understand how networks process context is limited. Here, we propose general methods for reverse engineering recurrent neural networks (RNNs) to identify and elucidate contextual processing. We apply these methods to understand RNNs trained on sentiment classification. This analysis reveals inputs that induce contextual effects, quantifies the strength and timescale of these effects, and identifies sets of these inputs with similar properties. Additionally, we analyze contextual effects related to differential processing of the beginning and end of documents. Using the insights learned from the RNNs we improve baseline Bag-of-Words models with simple extensions that incorporate contextual modification, recovering greater than 90% of the RNN's performance increase over the baseline. This work yields a new understanding of how RNNs process contextual information, and provides tools that should provide similar insight more broadly.</p> 
### 909.[Smaller, more accurate regression forests using tree alternating optimization](https://proceedings.icml.cc/book/4149.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5621-Paper.pdf)
  Arman Zharmagambetov, Miguel Carreira-Perpinan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5621-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5621-Supplemental.pdf)
> <p>Regression forests (ensembles of regression trees) have long been recognized as the leading off-the-shelf method for regression, where the task is to predict a continuous scalar or vector output. The main approaches are based on bagging, where individual trees are trained independently on bootstrap samples of the data; or on boosting, where individual trees are trained sequentially on the whole data but with adaptively weighted instances. However, both approaches rely on a greedy top-down procedure such as CART to learn an axis-aligned tree, where each decision node tests for a single feature. We instead use the recently proposed Tree Alternating Optimization (TAO) algorithm. This is able to learn an oblique tree, where each decision node tests for a linear combination of features, and which has much higher accuracy than axis-aligned trees. We show that using TAO with the bagging approach produces much better forests than random forests, Adaboost or gradient boosting in every dataset we have tried across a wide range of input and output dimensionality and sample size. The resulting forest has significantly lower test regression error while using shallower trees with fewer parameters and lower inference time overall. This result has an immense practical impact and advocates for the power of optimization in ensemble learning.</p> 
### 910.[Divide and Conquer: Leveraging Intermediate Feature Representations for Quantized Training of Neural Networks](https://proceedings.icml.cc/book/4150.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5636-Paper.pdf)
  Ahmed T. Elthakeb, Prannoy Pilligundla, FatemehSadat Mireshghallah, Alexander Cloninger, Hadi Esmaeilzadeh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5636-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5636-Supplemental.pdf)
> <p>The deep layers of modern neural networks extract a rather rich set of features as an input propagates through the network. This paper sets out to harvest these rich intermediate representations for quantization with minimal accuracy loss while significantly reducing the memory footprint and compute intensity of the DNN. This paper utilizes knowledge distillation through teacher-student paradigm (Hinton et al., 2015) in a novel setting that exploits the feature extraction capability of DNNs for higher-accuracy quantization. As such, our algorithm logically divides a pretrained full-precision DNN to multiple sections, each of which exposes intermediate features to train a team of students independently in the quantized domain. This divide and conquer strategy, in fact, makes the training of each student section possible in isolation while all these independently trained sections are later stitched together to form the equivalent fully quantized network. Our algorithm is a sectional approach towards knowledge distillation and is not treating the intermediate representation as a hint for pretraining before one knowledge distillation pass over the entire network (Romero et al., 2015). Experiments on various DNNs (AlexNet, LeNet, ResNet-18, ResNet-20, SVHN and VGG-11) show that, on average, this approach—called DCQ (Divide and Conquer Quantization)—on average closes the accuracy gap between a state-of-the-art quantized training technique, DoReFa-Net (Zhou et al., 2016) and the full-precision runs by 85% and 92% for binary and ternary quantization of the weights, respectively. Additionally, we show that our approach, DCQ, can improve performance of existing state-of-the art knowledge-distillation based approaches (Mishra et al., 2018) by 1.75% on average for both weight and activation quantization.</p> 
### 911.[From Sets to Multisets: Provable Variational  Inference for Probabilistic Integer Submodular Models](https://proceedings.icml.cc/book/4151.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5642-Paper.pdf)
  Aytunc Sahin, Yatao Bian, Joachim Buhmann, Andreas Krause [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5642-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5642-Supplemental.pdf)
> <p>Submodular functions have been studied extensively in machine learning and data mining. In particular, the optimization of submodular functions over  the integer lattice has recently attracted much interest, because this domain relates naturally to many practical problem settings, such as multilabel graph cut, budget allocation and revenue maximization with discrete assignments. In contrast, the use of these functions for probabilistic modeling has received surprisingly little attention so far.  In this work, we firstly propose the Generalized Multilinear Extension, a continuous DR-Submodular extension for integer submodular functions. We study central properties of this extension and formulate a new probabilistic model which is defined through integer submodular functions. Then, we introduce a method to perform approximate inference for those class of models. Finally, we demonstrate its effectiveness and viability on several real-world social connection graph datasets with integer submodular objectives.</p> 
### 912.[Empirical Study of the Benefits of Overparameterization in Learning Latent Variable Models](https://proceedings.icml.cc/book/4152.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5645-Paper.pdf)
  Rares-Darius Buhai, Yoni Halpern, Yoon Kim, Andrej Risteski, David Sontag [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5645-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5645-Supplemental.pdf)
> <p>One of the most surprising and exciting discoveries in supervised learning was the benefit of overparameterization (i.e. training a very large model) to improving the optimization landscape of a problem, with minimal effect on statistical performance (i.e. generalization). In contrast, unsupervised settings have been under-explored, despite the fact that it was observed that overparameterization can be helpful as early as Dasgupta &amp; Schulman (2007). We perform an empirical study of different aspects of overparameterization in unsupervised learning of latent variable models via synthetic and semi-synthetic experiments. We discuss benefits to different metrics of success (recovering the parameters of the ground-truth model, held-out log-likelihood), sensitivity to variations of the training algorithm, and behavior as the amount of overparameterization increases. We find that across a variety of models (noisy-OR networks, sparse coding, probabilistic context-free grammars) and training algorithms (variational inference, alternating minimization, expectation-maximization), overparameterization can significantly increase the number of ground truth latent variables recovered.</p> 
### 913.[Improving the Gating Mechanism of Recurrent Neural Networks](https://proceedings.icml.cc/book/4153.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5650-Paper.pdf)
  Albert Gu, Caglar Gulcehre, Thomas Paine, Matthew Hoffman, Razvan Pascanu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5650-Metadata.json)
> <p>Gating mechanisms are widely used in neural network models, where they allow gradients to backpropagate easily through depth or time. However, their saturation property introduces problems of its own. For example, in recurrent models these gates need to have outputs near 1 to propagate information over long time-delays, which requires them to operate in their saturation regime and hinders gradient-based learning of the gate mechanism. We address this problem by deriving two synergistic modifications to the standard gating mechanism that are easy to implement, introduce no additional hyperparameters, and improve learnability of the gates when they are close to saturation. We show how these changes are related to and improve on alternative recently proposed gating mechanisms such as chrono-initialization and Ordered Neurons. Empirically, our simple gating mechanisms robustly improve the performance of recurrent models on a range of applications, including synthetic memorization tasks, sequential image classification, language modeling, and reinforcement learning, particularly when long-term dependencies are involved.</p> 
### 914.[Efficient and Scalable Bayesian Neural Nets with Rank-1 Factors](https://proceedings.icml.cc/book/4154.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5657-Paper.pdf)
  Mike Dusenberry, Ghassen Jerfel, Yeming Wen, Yian Ma, Jasper Snoek, Katherine Heller, Balaji Lakshminarayanan, Dustin Tran [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5657-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5657-Supplemental.pdf)
> <p>Bayesian neural networks (BNNs) demonstrate promising success in improving the robustness and uncertainty quantification of modern neural networks. However, they generally struggle with underfitting at scale and parameter efficiency. On the other hand, deep ensembles have emerged as an alternative for uncertainty quantification that, while outperforming BNNs on certain problems, also suffers from efficiency issues. It remains unclear how to combine the strengths of these two approaches and remediate their common issues. To tackle this challenge, we propose a rank-1 parameterization of BNNs, where each weight matrix involves only a distribution on a rank-1 subspace. We also revisit the use of mixture approximate posteriors to capture multiple modes where unlike typical mixtures, this approach admits a significantly smaller memory increase (e.g., only a 0.4\% increase for a ResNet-50 mixture of size 10). We perform a systematic empirical study on the choices of prior, variational posterior, and methods to improve training. For ResNet-50 on ImageNet and Wide ResNet 28-10 on CIFAR-10/100, rank-1 BNNs demonstrate improved performance across log-likelihood, accuracy, and calibration on the test set and out-of-distribution variants.</p> 
### 915.[Analyzing the effect of neural network architecture on training performance](https://proceedings.icml.cc/book/4155.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5664-Paper.pdf)
  Karthik Abinav Sankararaman, Soham De, Zheng Xu, W. Ronny Huang, Tom Goldstein [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5664-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5664-Supplemental.pdf)
> <p>In this paper we study how neural network architecture affects the speed of training. We introduce a simple concept called gradient confusion to help formally analyze this.  When confusion is high, stochastic gradients produced by different data samples may be negatively correlated, slowing down convergence. But when gradient confusion is low, data samples interact harmoniously, and training proceeds quickly. Through novel theoretical and experimental results, we show how the neural net architecture affects gradient confusion, and thus the efficiency of training. We show that for popular initialization techniques used in deep learning, increasing the width of neural networks leads to lower gradient confusion, and thus easier model training. On the other hand, increasing the depth of neural networks has the opposite effect. Finally, we observe that the combination of batch normalization and skip connections reduces gradient confusion, which helps reduce the training burden of very deep networks.</p> 
### 916.[Born-again Tree Ensembles](https://proceedings.icml.cc/book/4156.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5666-Paper.pdf)
  Thibaut Vidal, Maximilian Schiffer [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5666-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5666-Supplemental.pdf)
> <p>The use of machine learning algorithms in finance, medicine, and criminal justice can deeply impact human lives. As a consequence, research into interpretable machine learning has rapidly grown in an attempt to better control and fix possible sources of mistakes and biases. Tree ensembles, in particular, offer a good prediction quality in various domains, but the concurrent use of multiple trees reduces the interpretability of the ensemble. Against this background, we study born-again tree ensembles, i.e., the process of constructing a single decision tree of minimum size that reproduces the exact same behavior as a given tree ensemble. To find such a tree, we develop a dynamic-programming based algorithm that exploits sophisticated pruning and bounding rules to reduce the number of recursive calls. This algorithm generates optimal born-again trees for many datasets of practical interest, leading to classifiers which are typically simpler and more interpretable without any other form of compromise.</p> 
### 917.[Accountable Off-Policy Evaluation via a Kernelized Bellman Statistics](https://proceedings.icml.cc/book/4157.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5668-Paper.pdf)
  Yihao Feng, Tongzheng Ren, Ziyang Tang, Qiang Liu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5668-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5668-Supplemental.pdf)
> <p>Off-policy evaluation plays an important role in modern reinforcement learning. However, most of the existing off-policy evaluation only focus on the value estimation, without providing an accountable confidence interval, that can reflect the uncertainty caused by limited observed data and algorithmic errors. Recently,  Feng  et  al.  (2019) proposed a novel kernel loss for learning value functions, which can also be used to test whether the learned value function satisfies the Bellman equation. In this work, we investigate the statistical properties of the kernel loss, which allows us to find a feasible set that contains the true value function with high probability. We further utilize this set to construct an accountable confidence interval for off-policy value estimation, and a post-hoc diagnosis for existing estimators. Empirical results show that our methods yield a tight yet accountable confidence interval in different settings, which demonstrate the effectiveness of our method.</p> 
### 918.[Improving Transformer Optimization Through Better Initialization ](https://proceedings.icml.cc/book/4158.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5691-Paper.pdf)
  Xiao Shi Huang, Felipe Perez, Jimmy Ba, Maksims Volkovs [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5691-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5691-Supplemental.pdf)
> <p>The Transformer architecture has achieved considerable success in areas such as language modeling and machine translation. The key component of the Transformer is the attention layer that enables the model to focus on important regions within the input sequence. Gradient optimization with attention layers can be notoriously difficult requiring tricks such as learning rate warmup to prevent divergence.  As Transformer models are becoming larger and more expensive to train, recent research has focused on understanding and improving optimization in these models. In this work our contributions are two-fold. We first investigate and empirically validate the source of optimization problems in encoder-decoder Transformer architecture.We then propose a new weight initialization scheme with theoretical justification, which enables training without warmup or layer normalization. Empirical results on public machine translation benchmarks show that our approach achieves leading accuracy, allowing to train deep Transformer models with 200 layers without difficulty. Full code for this work will be released with the final version of this draft.</p> 
### 919.[Learning to Simulate and Design for Structural Engineering](https://proceedings.icml.cc/book/4159.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5700-Paper.pdf)
  Kai-Hung Chang, Chin-Yi Cheng [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5700-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5700-Supplemental.pdf)
> <p>In the architecture and construction industries, structural design for large buildings has always been laborious, time-consuming, and difficult to optimize. It is an iterative process that involves two steps: analyzing the current structural design by a slow and computationally expensive simulation, and then manually revising the design based on professional experience and rules. In this work, we propose an end-to-end learning pipeline to solve the size design optimization problem, which is to design the optimal cross-sections for columns and beams, given the design objectives and building code as constraints. We pre-train a graph neural network as a surrogate model to not only replace the structural simulation for speed but also use its differentiable nature to provide gradient signals to the other graph neural network for size optimization. Our results show that the pre-trained surrogate model can predict simulation results accurately, and the trained optimization model demonstrates the capability of designing convincing cross-section designs for buildings under various scenarios.</p> 
### 920.[Few-shot Relation Extraction via Bayesian Meta-learning on Task Graphs](https://proceedings.icml.cc/book/4160.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5706-Paper.pdf)
  Meng Qu, Tianyu Gao, Louis-Pascal Xhonneux, Jian Tang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5706-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5706-Supplemental.pdf)
> <p>This paper studies few-shot relation extraction, which aims at predicting the relation for a pair of entities in a sentence by training with a few labeled examples in each relation. To more effectively generalize to new relations/tasks, in this paper we study the relationships between different tasks and propose to leverage a global task graph. We propose a novel Bayesian meta-learning approach to effectively learn the posterior distributions of the prototype vectors of tasks, where the initial prior of the prototype vectors is parameterized with a graph neural network on the global task graph. Moreover, to effectively optimize the posterior distributions of the prototype vectors, we propose to use the stochastic gradient Langevin dynamic, which can be related to the MAML algorithm but is able to handle the uncertainty of the prototype vectors. The whole framework can be effectively and efficiently optimized in an end-to-end fashion. Experiments on two benchmark datasets prove the effectiveness of our proposed approach against competitive baselines in both the few-shot and zero-shot settings. </p> 
### 921.[Optimal Differential Privacy Composition for Exponential Mechanisms](https://proceedings.icml.cc/book/4161.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5709-Paper.pdf)
  Jinshuo Dong, David Durfee, Ryan Rogers [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5709-Metadata.json)
> <p>Composition is one of the most important properties of differential privacy (DP), as it allows algorithm designers to build complex private algorithms from DP primitives. We consider precise composition bounds of the overall privacy loss for exponential mechanisms, one of the fundamental classes of mechanisms in DP. Exponential mechanism has also become a fundamental building block in private machine learning, e.g. private PCA and hyper-parameter selection. We give explicit formulations of the optimal privacy loss for both the adaptive and non-adaptive composition of exponential mechanism. For the non-adaptive setting in which each mechanism has the same privacy parameter, we give an efficiently computable formulation of the optimal privacy loss. In the adaptive case, we derive a recursive formula and an efficiently computable upper bound. These precise understandings about the problem lead to a 40\% saving of the privacy budget in a practical application. Furthermore, the algorithm-specific analysis shows a difference in privacy parameters of adaptive and non-adaptive composition, which was widely believed to not exist based on the evidence from general analysis.</p> 
### 922.[Scaling up Hybrid Probabilistic Inference with Logical and Arithmetic Constraints via Message Passing](https://proceedings.icml.cc/book/4162.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5711-Paper.pdf)
  Zhe Zeng, Paolo Morettin, Fanqi Yan, Antonio Vergari, Guy Van den Broeck [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5711-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5711-Supplemental.pdf)
> <p>Weighted model integration (WMI) is a very appealing framework for probabilistic inference: it allows to express the complex dependencies of real-world scenarios where variables are both continuous and discrete, via the language of Satisfiability Modulo Theories (SMT), as well as to compute probabilistic queries with complex logical and arithmetic constraints. Yet, existing WMI solvers are not ready to scale to these problems. They either ignore the intrinsic dependency structure of the problem at all, or they are limited to too restrictive structures. To narrow this gap, we derive a factorized formalism of WMI enabling us to devise a scalable WMI solver based on message passing, MP-WMI. Namely MP-WMI is the first WMI solver which allows to: 1) perform exact inference on the full class of tree-structured WMI problems; 2) compute all the marginal densities in linear time; 3) amortize inference for any query conforming to the problem structure. Experimental results show that our solver dramatically outperforms the existing WMI solvers on a large set of benchmarks.</p> 
### 923.[Accelerating Large-Scale Inference with Anisotropic Vector Quantization](https://proceedings.icml.cc/book/4163.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5722-Paper.pdf)
  Ruiqi Guo, Quan Geng, David Simcha, Felix Chern, Philip Sun, Erik Lindgren, Sanjiv Kumar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5722-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5722-Supplemental.pdf)
> <p>Quantization based techniques are the current state-of-the-art for scaling maximum inner product search to massive databases. Traditional approaches to quantization aim to minimize the reconstruction error of the database points. Based on the observation that for a given query, the database points that have the largest inner products are more relevant, we develop a family of anisotropic quantization loss functions. Under natural statistical assumptions, we show that quantization with these loss functions leads to a new variant of vector quantization that more greatly penalizes the parallel component of a datapoint's residual relative to its orthogonal component. The proposed approach achieves state-of-the-art results on the public benchmarks available at \url{ann-benchmarks.com}.</p> 
### 924.[Convolutional dictionary learning based auto-encoders for natural exponential-family distributions](https://proceedings.icml.cc/book/4164.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5733-Paper.pdf)
  Bahareh Tolooshams, Andrew Song, Simona Temereanca, Demba Ba [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5733-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5733-Supplemental.pdf)
> <p>We introduce a class of auto-encoder neural networks tailored to data from the natural exponential family (e.g., count data). The architectures are inspired by the problem of learning the filters in a convolutional generative model with sparsity constraints, often referred to as convolutional dictionary learning (CDL). Our work is the first to merge the ideas from convolutional generative models and deep learning for data that are naturally modeled with non-Gaussian distribution (e.g., binomial and Poisson). This perspective provides us with a scalable and flexible framework that can be re-purposed for a wide range of tasks and assumptions on the generative model. Specifically, the iterative optimization procedure for solving CDL, an unsupervised task, is mapped to an unfolded and constrained neural network, with iterative adjustments to the inputs to account for the generative distribution. We also show that the framework can easily be extended for discriminative training, appropriate for a supervised task. We demonstrate 1) that fitting the generative model to learn, in an unsupervised fashion, the latent stimulus that underlies neural spiking data leads to better goodness-of-fit compared to other baselines, 2) competitive performance compared to state-of-the-art algorithms for supervised Poisson image denoising, with significantly fewer parameters, and 3) gradient dynamics of shallow binomial auto-encoder.</p> 
### 925.[Strength from Weakness: Fast Learning Using Weak Supervision](https://proceedings.icml.cc/book/4165.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5736-Paper.pdf)
  Joshua Robinson, Stefanie Jegelka, Suvrit Sra [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5736-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5736-Supplemental.pdf)
>  We study generalization properties of weakly supervised learning. That is, learning where only a few ``strong&#x27;&#x27; labels (the actual target of our prediction) are present but many more ``weak&#x27;&#x27; labels are available. In particular, we show that having access to weak labels can significantly accelerate the learning rate for the strong task to the fast rate of $\mathcal{O}(\nicefrac1n)$, where $n$ denotes the number of strongly labeled data points. This acceleration can happen even if by itself the strongly labeled data admits only the slower  $\mathcal{O}(\nicefrac{1}{\sqrt{n}})$ rate. The actual acceleration depends continuously on the number of weak labels available, and on the relation between the two tasks. Our theoretical results are reflected empirically across a range of tasks and illustrate how weak labels speed up learning on the strong task.
### 926.[NADS: Neural Architecture Distribution Search for Uncertainty Awareness](https://proceedings.icml.cc/book/4166.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5738-Paper.pdf)
  Randy Ardywibowo, Shahin Boluki, Xinyu Gong, Zhangyang Wang, Xiaoning Qian [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5738-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5738-Supplemental.pdf)
> <p>Machine learning (ML) systems often encounter Out-of-Distribution (OoD) errors when dealing with testing data coming from a distribution different from training data. It becomes important for ML systems in critical applications to accurately quantify its predictive uncertainty and screen out these anomalous inputs. However, existing OoD detection approaches are prone to errors and even sometimes assign higher likelihoods to OoD samples. Unlike standard learning tasks, there is currently no well established guiding principle for designing OoD detection architectures that can accurately quantify uncertainty. To address these problems, we first seek to identify guiding principles for designing uncertainty-aware architectures, by proposing Neural Architecture Distribution Search (NADS). NADS searches for a distribution of architectures that perform well on a given task, allowing us to identify common building blocks among all uncertainty-aware architectures. With this formulation, we are able to optimize a stochastic OoD detection objective and construct an ensemble of models to perform OoD detection. We perform multiple OoD detection experiments and observe that our NADS performs favorably compared to state-of-the-art OoD detection methods.</p> 
### 927.[Approximating Stacked and Bidirectional Recurrent Architectures with the Delayed Recurrent Neural Network](https://proceedings.icml.cc/book/4167.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5744-Paper.pdf)
  Javier Turek, Shailee Jain, Vy Vo, Mihai Capotă, Alexander Huth, Theodore Willke [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5744-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5744-Supplemental.pdf)
> <p>Recent work has shown that topological enhancements to recurrent neural networks (RNNs) can increase their expressiveness and representational capacity. Two popular enhancements are stacked RNNs, which increases the capacity for learning non-linear functions, and bidirectional processing, which exploits acausal information in a sequence. In this work, we explore the delayed-RNN, which is a single-layer RNN that has a delay between the input and output. We prove that a weight-constrained version of the delayed-RNN is equivalent to a stacked-RNN. We also show that the delay gives rise to partial acausality, much like bidirectional networks. Synthetic experiments confirm that the delayed-RNN can mimic bidirectional networks, solving some acausal tasks similarly, and outperforming them in others. Moreover, we show similar performance to bidirectional networks in a real-world natural language processing task. These results suggest that delayed-RNNs can approximate topologies including stacked RNNs, bidirectional RNNs, and stacked bidirectional RNNs -- but with equivalent or faster runtimes for the delayed-RNNs.</p> 
### 928.[Balancing Competing Objectives with Noisy Data: Score-Based Classifiers for Welfare-Aware Machine Learning](https://proceedings.icml.cc/book/4168.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5746-Paper.pdf)
  Esther Rolf, Max Simchowitz, Sarah Dean, Lydia T. Liu, Daniel Bjorkegren, University of California Moritz Hardt, Joshua  Blumenstock [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5746-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5746-Supplemental.pdf)
> <p>While real-world decisions involve many competing objectives, algorithmic decisions are often evaluated with a single objective function. In this paper, we study algorithmic policies which explicitly trade off between a private objective (such as profit) and a public objective (such as social welfare). We analyze a natural class of policies which trace an empirical Pareto frontier based on learned scores, and focus on how such decisions can be made in noisy or data-limited regimes. Our theoretical results characterize the optimal strategies in this class, bound the Pareto errors due to inaccuracies in the scores, and show an equivalence between optimal strategies and a rich class of fairness-constrained profit-maximizing policies. We then present empirical results in two different contexts --- online content recommendation and sustainable abalone fisheries --- to underscore the generality of our approach to a wide range of practical decisions. Taken together, these results shed light on inherent trade-offs in using machine learning for decisions that impact social welfare.</p> 
### 929.[Time-aware Large Kernel Convolutions](https://proceedings.icml.cc/book/4169.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5762-Paper.pdf)
  Vasileios Lioutas, Yuhong Guo [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5762-Metadata.json)
> To date, most state-of-the-art sequence modeling architectures use attention to build generative models for language based tasks. Some of these models use all the available sequence tokens to generate an attention distribution which results in time complexity of $O(n^2)$. Alternatively, they utilize depthwise convolutions with softmax normalized kernels of size $k$ acting as a limited-window self-attention, resulting in time complexity of $O(k{\cdot}n)$. In this paper, we introduce Time-aware Large Kernel (TaLK) Convolutions, a novel adaptive convolution operation that learns to predict the size of a summation kernel instead of using a fixed-sized kernel matrix. This method yields a time complexity of $O(n)$, effectively making the sequence encoding process linear to the number of tokens. We evaluate the proposed method on large-scale standard machine translation, abstractive summarization and language modeling datasets and show that TaLK Convolutions constitute an efficient improvement over other attention/convolution based approaches.
### 930.[Amortised Learning by Wake-Sleep](https://proceedings.icml.cc/book/4170.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5769-Paper.pdf)
  Li Kevin Wenliang, Theodore Moskovitz, Heishiro Kanagawa, Maneesh Sahani [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5769-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5769-Supplemental.pdf)
> <p>Models that employ latent variables to capture structure in observed data lie at the heart of many current unsupervised learning algorithms, but exact maximum-likelihood learning for powerful and flexible latent-variable models is almost always intractable. Thus, state-of-the-art approaches either abandon the maximum-likelihood framework entirely, or else rely on a variety of variational approximations to the posterior distribution over the latents. Here, we propose an alternative approach that we call amortised learning. Rather than computing an approximation to the posterior over latents, we use a wake-sleep Monte-Carlo strategy to learn a function that directly estimates the maximum-likelihood parameter updates. Amortised learning is possible whenever samples of latents and observations can be simulated from the generative model, treating the model as a ``black box''. We demonstrate its effectiveness on a wide range of complex models, including those with latents that are discrete or supported on non-Euclidean spaces. </p> 
### 931.[Fair Generative Modeling via Weak Supervision](https://proceedings.icml.cc/book/4171.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5778-Paper.pdf)
  Kristy Choi, Aditya Grover, Trisha Singh, Rui Shu, Stefano Ermon [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5778-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5778-Supplemental.pdf)
> <p>Real-world datasets are often biased with respect to key demographic factors such as race and gender. Due to the latent nature of the underlying factors, detecting and mitigating bias is especially challenging for unsupervised machine learning. We present a weakly supervised algorithm for overcoming dataset bias for deep generative models. Our approach requires access to an additional small, unlabeled but unbiased dataset as the supervision signal, thus sidestepping the need for explicit labels on the underlying bias factors. Using this supplementary dataset, we detect the bias in existing datasets via a density ratio technique and learn generative models which efficiently achieve the twin goals of: 1) data efficiency by using training examples from both biased and unbiased datasets for learning, 2) unbiased data generation at test time. Empirically, we demonstrate the efficacy of our approach which reduces bias w.r.t. latent factors by 37.2% on average over baselines for comparable image generation using generative adversarial networks.</p> 
### 932.[Multi-Step Greedy Reinforcement Learning Algorithms](https://proceedings.icml.cc/book/4172.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5786-Paper.pdf)
  Manan Tomar, Yonathan Efroni, Mohammad Ghavamzadeh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5786-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5786-Supplemental.pdf)
> Multi-step greedy policies have been extensively used in model-based Reinforcement Learning (RL), both when a model of the environment is available (e.g.,~in the game of Go) and when it is learned. In this paper, we explore the benefits of multi-step greedy policies in model-free RL when employed using the multi-step Dynamic Programming algorithms: $\kappa$-Policy Iteration ($\kappa$-PI) and $\kappa$-Value Iteration ($\kappa$-VI). These methods iteratively compute the next policy ($\kappa$-PI) and value function ($\kappa$-VI) by solving a surrogate decision problem with a shaped reward and a smaller discount factor. We derive model-free RL algorithms based on $\kappa$-PI and $\kappa$-VI in which the surrogate decision problem is solved by DQN and TRPO. We call the resulting algorithms $\kappa$-PI-DQN, $\kappa$-VI-DQN, $\kappa$-PI-TRPO, and $\kappa$-VI-TRPO and evaluate them on Atari and MuJoCo benchmarks. Our results indicate that for the right range of $\kappa$, our algorithms outperform DQN and TRPO. Moreover, we identify the importance of a hyper-parameter that controls the extent to which the surrogate decision problem is solved, and show how to set this parameter. Finally, we establish that $\kappa$-PI-TRPO coincides with the popular GAE algorithm. 
### 933.[Linear Mode Connectivity and the Lottery Ticket Hypothesis](https://proceedings.icml.cc/book/4173.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5787-Paper.pdf)
  Jonathan Frankle, Gintare Karolina Dziugaite, Daniel Roy, Michael Carbin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5787-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5787-Supplemental.pdf)
> <p>We introduce "instability analysis," which assesses whether a neural network optimizes to the same, linearly connected minimum under different samples of SGD noise. We find that standard vision models become stable in this way early in training. From then on, the outcome of optimization is determined to within a linearly connected region.</p>  <p>We use instability to study iterative magnitude pruning (IMP), the procedure used by work on the lottery ticket hypothesis to identify subnetworks that could have trained to full accuracy from initialization. We find that these subnetworks only reach full accuracy when they are stable, which either occurs at initialization for small-scale settings (MNIST) or early in training for large-scale settings (Resnet-50 and Inception-v3 on ImageNet).</p> 
### 934.[Superpolynomial Lower Bounds for Learning One-Layer Neural Networks using Gradient Descent](https://proceedings.icml.cc/book/4174.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5791-Paper.pdf)
  Surbhi Goel, Aravind Gollakota, Zhihan Jin, Sushrut Karmalkar, Adam Klivans [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5791-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5791-Supplemental.zip)
> <p>We give the first superpolynomial lower bounds for learning one-layer neural networks with respect to the Gaussian distribution for a broad class of algorithms.  In the regression setting, we prove that gradient descent run on any classifier with respect to square loss will fail to achieve small test error in polynomial time.  Prior work held only for gradient descent run with small batch sizes and sufficiently smooth classifiers. For classification, we give a stronger result, namely that any statistical query (SQ) algorithm will fail to achieve small test error in polynomial time.  Our lower bounds hold for commonly used activations such as ReLU and sigmoid.  The core of our result relies on a novel construction of a simple family of neural networks that are exactly orthogonal with respect to all spherically symmetric distributions.</p> 
### 935.[Learnable Group Transform For Time-Series](https://proceedings.icml.cc/book/4175.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5795-Paper.pdf)
  Romain Cosentino, Behnaam Aazhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5795-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5795-Supplemental.pdf)
> <p>We propose a novel approach to filter bank learning for time-series by considering spectral decompositions of signals defined as a Group Transform. This framework allows us to generalize classical time-frequency transformations such as the Wavelet Transform, and  to efficiently learn the representation of signals. While the creation of the wavelet transform filter-bank relies on affine transformations of a mother filter, our approach allows for non-linear transformations. The transformations induced by such maps enable us to span a larger class of signal representations, from wavelet to chirplet-like filters. We propose a parameterization of such a non-linear map such that its sampling can be optimized for a specific task and signal. The Learnable Group Transform can be cast into a Deep Neural Network. The experiments on diverse time-series datasets demonstrate the expressivity of this framework, which competes with state-of-the-art performances.</p> 
### 936.[Optimistic bounds for multi-output learning](https://proceedings.icml.cc/book/4176.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5808-Paper.pdf)
  Henry Reeve, Ata Kaban [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5808-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5808-Supplemental.pdf)
> <p>We investigate the challenge of multi-output learning, where the goal is to learn a vector-valued function based on a supervised data set. This includes a range of important problems in Machine Learning including multi-target regression, multi-class classification and multi-label classification. We begin our analysis by introducing the self-bounding Lipschitz condition for multi-output loss functions, which interpolates continuously between a classical Lipschitz condition and a multi-dimensional analogue of a smoothness condition. We then show that the self-bounding Lipschitz condition gives rise to optimistic bounds for multi-output learning, which are minimax optimal up to logarithmic factors. The proof exploits local Rademacher complexity combined with a powerful minoration inequality due to Srebro, Sridharan and Tewari.  As an application we derive a state-of-the-art generalization bound for multi-class gradient boosting. </p> 
### 937.[Detecting Out-of-Distribution Examples with Gram Matrices](https://proceedings.icml.cc/book/4177.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5813-Paper.pdf)
  Chandramouli Shama Sastry, Sageev Oore [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5813-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5813-Supplemental.pdf)
> <p>When presented with Out-of-Distribution (OOD) examples, deep neural networks yield confident, incorrect predictions. Detecting OOD examples is challenging, and the potential risks are high. In this paper, we propose to detect OOD examples by identifying inconsistencies between activity patterns and predicted class. We find that characterizing activity patterns by Gram matrices and identifying anomalies in Gram matrix values can yield high OOD detection rates. We identify anomalies in the Gram matrices by simply comparing each value with its respective range observed over the training data. Unlike many approaches, this can be used with any pre-trained softmax classifier and neither requires access to OOD data for fine-tuning hyperparameters, nor does it require OOD access for inferring parameters. We empirically demonstrate applicability across a variety of architectures and vision datasets and, for the important and surprisingly hard task of detecting far out-of-distribution examples, it generally performs better than or equal to state-of-the-art OOD detection methods (including those that do assume access to OOD examples).</p> 
### 938.[On Variational Learning of Controllable Representations for Text without Supervision](https://proceedings.icml.cc/book/4178.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5816-Paper.pdf)
  Peng Xu, Jackie Chi Kit Cheung, Yanshuai Cao [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5816-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5816-Supplemental.pdf)
> <p>The variational autoencoder (VAE) can learn the manifold of natural images on certain datasets, as evidenced by meaningful interpolating or extrapolating in the continuous latent space. However, on discrete data such as text, it is unclear if unsupervised learning can discover similar latent space that allows controllable manipulation. In this work, we find that sequence VAEs trained on text fail to properly decode when the latent codes are manipulated, because the modified codes often land in holes or vacant regions in the aggregated posterior latent space, where the decoding network fails to generalize. Both as a validation of the explanation and as a fix to the problem, we propose to constrain the posterior mean to a learned probability simplex, and performs manipulation within this simplex. Our proposed method mitigates the latent vacancy problem and achieves the first success in unsupervised learning of controllable representations for text. Empirically, our method outperforms unsupervised baselines and strong supervised approaches on text style transfer. On automatic evaluation metrics used in text style transfer, even with the decoding network trained from scratch, our method achieves comparable results with state-of-the-art supervised approaches leveraging large-scale pre-trained models for generation. Furthermore, it is capable of performing more flexible fine-grained control over text generation than existing methods.</p> 
### 939.[Model-Based Reinforcement Learning with Value-Targeted Regression](https://proceedings.icml.cc/book/4179.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5817-Paper.pdf)
  Zeyu Jia, Lin Yang, Csaba Szepesvari, Mengdi Wang, Alex Ayoub [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5817-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5817-Supplemental.pdf)
> Reinforcement learning (RL) applies to control problems with large state and action spaces, hence it is natural to consider RL with a parametric model. In this paper we focus on finite-horizon episodic RL where the transition model admits a nonlinear parametrization $P_{\theta}$, a special case of which is the linear parameterization: $P_{\theta} = \sum_{i=1}^{d} (\theta)_{i}P_{i}$.  We propose an upper confidence model-based RL algorithm with value-targeted model parameter estimation. The algorithm updates the estimate of $\theta$ by solving a nonlinear regression problem using the latest value estimate as the target. We demonstrate the efficiency of our algorithm by proving its expected regret bound which, in the special case of linear parameterization takes the form $\tilde{\mathcal{O}}(d\sqrt{H^{3}T})$, where $H, T, d$ are the horizon, total number of steps and dimension of $\theta$. This regret bound is independent of the total number of states or actions, and is close to a lower bound $\Omega(\sqrt{HdT})$. In the general nonlinear case, we handle the regret analysis by using the concept of Eluder dimension proposed by \citet{RuVR14}.
### 940.[Two Routes to Scalable Credit Assignment without Weight Symmetry](https://proceedings.icml.cc/book/4180.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5826-Paper.pdf)
  Daniel Kunin, Aran Nayebi, Javier Sagastuy-Brena, Surya Ganguli, Jonathan Bloom, Daniel Yamins [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5826-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5826-Supplemental.pdf)
> <p>The neural plausibility of backpropagation has long been disputed, primarily for its use of non-local weight transport --- the biologically dubious requirement that one neuron instantaneously measure the synaptic weights of another. Until recently, attempts to create local learning rules that avoid weight transport have typically failed in the large-scale learning scenarios where backpropagation shines, e.g. ImageNet categorization with deep convolutional networks. Here, we investigate a recently proposed local learning rule that yields competitive performance with backpropagation and find that it is highly sensitive to metaparameter choices, requiring laborious tuning that does not transfer across network architecture. Our analysis indicates the underlying mathematical reason for this instability, allowing us to identify a more robust local learning rule that better transfers without metaparameter tuning. Nonetheless, we find a performance and stability gap between this local rule and backpropagation that widens with increasing model depth. We then investigate several non-local learning rules that relax the need for instantaneous weight transport into a more biologically-plausible "weight estimation" process, showing that these rules match state-of-the-art performance on deep networks and operate effectively in the presence of noisy updates. Taken together, our results suggest two routes towards the discovery of neural implementations for credit assignment without weight symmetry: further improvement of local rules so that they perform consistently across architectures and the identification of biological implementations for non-local learning mechanisms.</p> 
### 941.[ Predicting deliberative outcomes](https://proceedings.icml.cc/book/4181.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5832-Paper.pdf)
  Vikas Garg, Tommi Jaakkola [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5832-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5832-Supplemental.pdf)
> <p>We extend structured prediction to deliberative outcomes. Specifically, we learn parameterized games that can map any inputs to equilibria as the outcomes. Standard structured prediction models rely heavily on global scoring functions and are therefore unable to model individual player preferences or how they respond to others asymmetrically. Our games take as input, e.g., UN resolution to be voted on, and map such contexts to initial strategies, player utilities, and interactions. Players are then thought to repeatedly update their strategies in response to weighted aggregates of other players' choices towards maximizing their individual utilities. The output from the game is a sample from the resulting (near) equilibrium mixed strategy profile. We characterize conditions under which players converge to an equilibrium in such games and when the game parameters can be provably recovered from observations. Empirically, we demonstrate on two real voting datasets that our games can recover interpretable strategic interactions, and predict strategies for players in new settings. </p> 
### 942.[Black-box Certification and Learning under Adversarial Perturbations](https://proceedings.icml.cc/book/4182.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5833-Paper.pdf)
  Hassan Ashtiani, Vinayak Pathak, Ruth Urner [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5833-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5833-Supplemental.pdf)
> <p>We formally study the problem of classification under adversarial perturbations, both from the learner's perspective, and from the viewpoint of a third-party who aims at certifying the robustness of a given black-box classifier.  We further introduce and study a new setting of black-box certification under limited query budget. We analyze this for various classes of predictors and types of perturbation.  We also consider the viewpoint of a black-box adversary that aims at finding adversarial examples, showing that the existence of an adversary with polynomial query complexity implies the existence of a robust learner with small sample complexity.</p> 
### 943.[When deep denoising meets iterative phase retrieval](https://proceedings.icml.cc/book/4183.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5838-Paper.pdf)
  Yaotian Wang, Xiaohang Sun, Jason Fleischer [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5838-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5838-Supplemental.pdf)
> <p>Recovering a signal from its Fourier intensity underlies many important applications, including lensless imaging and imaging through scattering media. Conventional algorithms for retrieving the phase suffer when noise is present but display global convergence when given clean data. Neural networks have been used to improve algorithm robustness, but efforts to date are sensitive to initial conditions and give inconsistent performance. Here, we combine iterative methods from phase retrieval with image statistics from deep denoisers, via regularization-by-denoising. The resulting methods inherit the advantages of each approach and outperform other noise-robust phase retrieval algorithms. Our work paves the way for hybrid imaging methods that integrate machine-learned constraints in conventional algorithms.</p> 
### 944.[The Neural Tangent Kernel in High Dimensions: Triple Descent and a Multi-Scale Theory of Generalization](https://proceedings.icml.cc/book/4184.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5840-Paper.pdf)
  Ben Adlam, Jeffrey Pennington [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5840-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5840-Supplemental.pdf)
> <p>Modern deep learning models employ considerably more parameters than required to fit the training data. Whereas conventional statistical wisdom suggests such models should drastically overfit, in practice these models generalize remarkably well. An emerging paradigm for describing this unexpected behavior is in terms of a double descent curve, in which increasing a model's capacity causes its test error to first decrease, then increase to a maximum near the interpolation threshold, and then decrease again in the overparameterized regime. Recent efforts to explain this phenomenon theoretically have focused on simple settings, such as linear regression or kernel regression with unstructured random features, which we argue are too coarse to reveal important nuances of actual neural networks. We provide a precise high-dimensional asymptotic analysis of generalization under kernel regression with the Neural Tangent Kernel, which characterizes the behavior of wide neural networks optimized with gradient descent. Our results reveal that the test error has nonmonotonic behavior deep in the overparameterized regime and can even exhibit additional peaks and descents when the number of parameters scales quadratic with the dataset size.</p> 
### 945.[A Sequential Self Teaching Approach for Improving Generalization in Sound Event Recognition](https://proceedings.icml.cc/book/4185.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5853-Paper.pdf)
  Anurag Kumar, Vamsi Krishna Ithapu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5853-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5853-Supplemental.pdf)
> <p>An important problem in machine auditory perception is to recognize and detect sound events. In this paper, we propose a sequential self-teaching approach to learn sounds. Our main proposition is that it is harder to learn sounds in adverse situations such as from weakly labeled or noisy labeled data and in these situations a single stage of learning is not sufficient. Our proposal is a sequential stage-wise learning process that improves generalization capabilities of a given modeling system. We justify this via technical results. On Audioset, the largest sound events dataset, our sequential learning approach can lead to up to 9% improvement in performance. A comprehensive evaluation also shows that the model leads to improved transferability of knowledge from previously trained models, thereby leading to improved generalization capabilities on transfer learning tasks as well.</p> 
### 946.[On the Global Convergence Rates of Softmax Policy Gradient Methods](https://proceedings.icml.cc/book/4186.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5857-Paper.pdf)
  Jincheng Mei, Chenjun Xiao, Csaba Szepesvari, Dale Schuurmans [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5857-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5857-Supplemental.pdf)
> We make three contributions toward better understanding policy gradient methods. First, we show that with the true gradient, policy gradient with a softmax parametrization converges at a $O(1/t)$ rate, with constants depending on the problem and initialization. This result significantly improves recent asymptotic convergence results.  The analysis relies on two findings: that the softmax policy gradient satisfies a \L{}ojasiewicz inequality, and the minimum probability of an optimal action during optimization can be bounded in terms of its initial value. Second, we analyze entropy regularized policy gradient and show that in the one state (bandit) case it enjoys a linear convergence rate $O(e^{-t})$,  while for general MDPs we prove that it converges at a $O(1/t)$ rate. This result resolves an open question in the recent literature. A key insight is that the entropy regularized gradient update behaves similarly to the contraction operator in value learning, with contraction factor depending on current policy. Finally, combining the above two results and additional lower bound results, we explain how entropy regularization improves policy optimization, even with the true gradient, from the perspective of convergence rate.  These results provide a theoretical understanding of the impact of entropy and corroborate existing empirical studies.
### 947.[Source Separation with Deep Generative Priors](https://proceedings.icml.cc/book/4187.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5859-Paper.pdf)
  Vivek Jayaram, John Thickstun [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5859-Metadata.json)
> <p>Despite substantial progress in signal source separation, results for richly structured data continue to contain perceptible artifacts. In contrast, recent deep generative models can produce authentic samples in a variety of domains that are indistinguishable from samples of the data distribution. This paper introduces a Bayesian approach to source separation that uses deep generative models as priors over the components of a mixture of sources, and Langevin dynamics to sample from the posterior distribution of sources given a mixture. This decouples the source separation problem from generative modeling, enabling us to directly use cutting-edge generative models as priors. The method achieves state-of-the-art performance for MNIST digit separation. We introduce new methodology for evaluating separation quality on richer datasets, providing quantitative evaluation and qualitative discussion of results for CIFAR-10 image separation.</p> 
### 948.[Non-Autoregressive Neural Text-to-Speech](https://proceedings.icml.cc/book/4188.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5861-Paper.pdf)
  Kainan Peng, Wei Ping, Zhao Song, Kexin Zhao [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5861-Metadata.json)
> <p>In this work, we propose ParaNet, a non-autoregressive seq2seq model that converts text to spectrogram. It is fully convolutional and brings 46.7 times speed-up over its autoregressive counterpart at synthesis, while obtaining reasonably good speech quality.  ParaNet also produces stable alignment between text and speech on the challenging test sentences by iteratively improving the attention in a layer-by-layer manner.  Furthermore, we build the parallel text-to-speech system by applying various parallel neural vocoders, which can synthesize speech from text through a single feed-forward pass.  We also explore a novel approach to train the IAF-based vocoder from scratch, which avoids the need for distillation from a separately trained WaveNet.</p> 
### 949.[Amortized Population Gibbs Samplers with Neural Sufficient Statistics](https://proceedings.icml.cc/book/4189.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5881-Paper.pdf)
  Hao Wu, Heiko Zimmermann, Eli Sennesh, Tuan Anh Le, Jan-Willem van de Meent [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5881-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5881-Supplemental.pdf)
> <p>Amortized variational methods have proven difficult to scale to structured problems, such as inferring positions of multiple objects from video images. We develop amortized population Gibbs (APG) samplers, a class of scalable methods that frame structured variational inference as adaptive importance sampling. APG samplers construct high-dimensional proposals by iterating over updates to lower-dimensional blocks of variables. We train each conditional proposal by minimizing the inclusive KL divergence with respect to the conditional posterior. To appropriately account for the size of the input data, we develop a new parameterization in terms of neural sufficient statistics. Experiments show that APG samplers can be used to train highly-structured deep generative models in an unsupervised manner, and achieve substantial improvements in inference accuracy relative to standard autoencoding variational methods.</p> 
### 950.[Neural Network Control Policy Verification With Persistent Adversarial Perturbation](https://proceedings.icml.cc/book/4190.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5885-Paper.pdf)
  Yuh-Shyang Wang, Tsui-Wei Weng, Luca Daniel [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5885-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5885-Supplemental.pdf)
> <p>Deep neural networks are known to be fragile to small adversarial perturbations. This issue becomes more critical when a neural network is interconnected with a physical system in a closed loop. In this paper, we show how to combine recent works on static neural network certification tools with robust control theory to certify a neural network policy in a control loop. We give a sufficient condition and an algorithm to ensure that the closed loop state and control constraints are satisfied when the persistent adversarial perturbation is linf norm bounded. Our method is based on finding a positively invariant set of the closed loop dynamical system, and thus we do not require the continuity of the neural network policy. Along with the verification result, we also develop an effective attack strategy for neural network control systems that outperforms exhaustive Monte-Carlo search significantly. We show that our certification algorithm works well on learned models and achieves 5 times better result than the traditional Lipschitz-based method to certify the robustness of a neural network policy on multiple control problems.</p> 
### 951.[Circuit-Based Intrinsic Methods to Detect Overfitting](https://proceedings.icml.cc/book/4191.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5901-Paper.pdf)
  Satrajit Chatterjee, Alan Mishchenko [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5901-Metadata.json)
> <p>The focus of this paper is on intrinsic methods to detect overfitting. These rely only on the model and the training data, as opposed to traditional extrinsic methods that rely on performance on a test set or on bounds from model complexity. We propose a family of intrinsic methods called Counterfactual Simulation (CFS) which analyze the flow of training examples through the model by identifying and perturbing rare patterns. By applying CFS to logic circuits we get a method that has no hyper-parameters and works uniformly across different types of models such as neural networks, random forests and lookup tables. Experimentally, CFS can separate models with different levels of overfit using only their logic circuit representations without any access to the high level structure. By comparing lookup tables, neural networks, and random forests using CFS, we get insight into why neural networks generalize. In particular, we find that stochastic gradient descent in neural nets does not lead to “brute force" memorization, but finds common patterns (whether we train with actual or randomized labels), and neural networks are not unlike forests in this regard. Finally, we identify a limitation with our proposal that makes it unsuitable in an adversarial setting, but points the way to future work on robust intrinsic methods.</p> 
### 952.[Inter-domain Deep Gaussian Processes with RKHS Fourier Features](https://proceedings.icml.cc/book/4192.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5904-Paper.pdf)
  Tim Rudner, Dino Sejdinovic, Yarin Gal [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5904-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5904-Supplemental.pdf)
> <p>Inter-domain Gaussian processes (GPs) allow for high flexibility and low computational cost when performing approximate inference in GP models. They are particularly suitable for modeling data exhibiting global function behavior but are limited to stationary covariance functions and thus fail to model non-stationary data effectively. We propose Inter-domain Deep Gaussian Processes with RKHS Fourier Features, an extension of shallow inter-domain GPs that combines the advantages of inter-domain and deep Gaussian processes (DGPs) and demonstrate how to leverage existing approximate inference approaches to perform simple and scalable approximate inference on Inter-domain Deep Gaussian Processes. We assess the performance of our method on a wide range of prediction problems and demonstrate that it outperforms inter-domain GPs and DGPs on challenging large-scale and high-dimensional real-world datasets exhibiting both global behavior as well as a high-degree of non-stationarity.</p> 
### 953.[Estimating Q(s,s&#x27;) with Deterministic Dynamics Gradients](https://proceedings.icml.cc/book/4193.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5905-Paper.pdf)
  Ashley Edwards, Himanshu Sahni, Rosanne Liu, Jane Hung, Ankit Jain, Rui Wang, Adrien Ecoffet, Thomas Miconi, Charles Isbell, Jason Yosinski [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5905-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5905-Supplemental.pdf)
> In this paper, we introduce a novel form of a value function, $Q(s, s&#x27;)$, that expresses the utility of transitioning from a state $s$ to a neighboring state $s&#x27;$ and then acting optimally thereafter. In order to derive an optimal policy, we develop a novel forward dynamics model that learns to make next-state predictions that maximize $Q(s,s&#x27;)$. This formulation decouples actions from values while still learning off-policy. We highlight the benefits of this approach in terms of value function transfer, learning within redundant action spaces, and learning off-policy from state observations generated by sub-optimal or completely random policies.
### 954.[On conditional versus marginal bias in multi-armed bandits](https://proceedings.icml.cc/book/4194.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5908-Paper.pdf)
  Jaehyeok Shin, Aaditya Ramdas, Alessandro Rinaldo [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5908-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5908-Supplemental.zip)
> <p>The bias of the sample means of the arms in multi-armed bandits is an important issue in adaptive data analysis that has recently received considerable attention in the literature. Existing results relate in precise ways the sign and magnitude of the bias to various sources of data adaptivity, but do not apply to the conditional inference setting in which the sample means are computed only if some specific conditions are satisfied. In this paper, we characterize the sign of the conditional bias of monotone functions of the rewards, including the sample mean. Our results hold for arbitrary conditioning events and leverage natural monotonicity properties of the data collection policy. We further demonstrate, through several examples from sequential testing and best arm identification, that the sign of the conditional and unconditional bias of the sample mean of an arm can be different, depending on the conditioning event. Our analysis offers new and interesting perspectives on the subtleties of assessing the bias in data adaptive settings.</p> 
### 955.[Implicit competitive regularization in GANs](https://proceedings.icml.cc/book/4195.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5910-Paper.pdf)
  Florian Schaefer, Hongkai Zheng, Anima Anandkumar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5910-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5910-Supplemental.pdf)
> <p>To improve the stability of GAN training we need to understand why they can produce realistic samples. Presently, this is attributed to properties of the divergence obtained under an optimal discriminator. This argument has a fundamental flaw:\ If we do not impose regularity of the discriminator, it can exploit visually imperceptible errors of the generator to always achieve the maximal generator loss. In practice, gradient penalties are used to regularize the discriminator. However, this needs a metric on the space of images that captures visual similarity.  Such a metric is not known, which explains the limited success of gradient penalties in stabilizing GANs.\ We argue that the performance of GANs is instead due to the implicit competitive regularization (ICR) arising from the simultaneous optimization of generator and discriminator. ICR promotes solutions that \emph{look real} to the discriminator and thus leverages its inductive biases to generate realistic images. We show that opponent-aware modelling of generator and discriminator, as present in competitive gradient descent (CGD), can significantly strengthen ICR and thus stabilize GAN training without explicit regularization. In our experiments, we use an existing implementation of WGAN-GP and show that by training it with CGD we can improve the inception score (IS) on CIFAR10 for a wide range of scenarios, without any hyperparameter tuning. The highest IS is obtained by combining CGD with the WGAN-loss, without any explicit regularization.</p> 
### 956.[Graph-based, Self-Supervised Program Repair from Diagnostic Feedback](https://proceedings.icml.cc/book/4196.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5912-Paper.pdf)
  Michihiro Yasunaga, Percy Liang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5912-Metadata.json)
> <p>We consider the problem of learning to repair programs from diagnostic feedback (e.g., compiler error messages). Program repair is challenging for two reasons: First, it requires reasoning and tracking symbols across source code and diagnostic feedback. Second, labeled datasets available for program repair are relatively small. In this work, we propose novel solutions to these two challenges. First, we introduce a program-feedback graph, which connects symbols relevant to program repair in source code and diagnostic feedback, and then apply a graph neural network on top to model the reasoning process. Second, we present a self-supervised learning paradigm for program repair that leverages unlabeled programs available online to create a large amount of extra program repair examples, which we use to pre-train our models. We evaluate our proposed approach on two applications: correcting introductory programming assignments (DeepFix dataset) and correcting the outputs of program synthesis (SPoC dataset). Our final system, DrRepair, significantly outperforms prior work, achieving 68.2\% full repair rate on DeepFix (+22.9\% over the prior best), and 48.4\% synthesis success rate on SPoC (+3.7\% over the prior best).</p> 
### 957.[Interpretable Off-Policy Evaluation in Reinforcement Learning by Highlighting Influential Transitions](https://proceedings.icml.cc/book/4197.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5919-Paper.pdf)
  Omer Gottesman, Joseph Futoma, Yao Liu, Sonali Parbhoo, Leo Celi, Emma Brunskill, Finale Doshi-Velez [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5919-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5919-Supplemental.pdf)
> <p>Off-policy evaluation in reinforcement learning offers the chance of using observational data to improve future outcomes in domains such as healthcare and education, but safe deployment in high stakes settings requires ways of assessing its validity. Traditional measures such as confidence intervals may be insufficient due to noise, limited data and confounding. In this paper we develop a method that could serve as a hybrid human-AI system, to enable human experts to analyze the validity of policy evaluation estimates. This is accomplished by highlighting observations in the data whose removal will have a large effect on the OPE estimate, and formulating a set of rules for choosing which ones to present to domain experts for validation. We develop methods to compute exactly the influence functions for fitted Q-evaluation with two different function classes: kernel-based and linear least squares. Experiments on medical simulations and real-world intensive care unit data demonstrate that our method can be used to identify limitations in the evaluation process and make evaluation more robust.</p> 
### 958.[Communication-Efficient Federated Learning with Sketching](https://proceedings.icml.cc/book/4198.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5927-Paper.pdf)
  Daniel Rothchild, Ashwinee Panda, Enayat Ullah, Nikita Ivkin, Vladimir Braverman, Joseph Gonzalez, Ion Stoica, Raman Arora [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5927-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5927-Supplemental.pdf)
> <p>Existing approaches to federated learning suffer from a communication bottleneck as well as convergence issues due to sparse client participation. In this paper we introduce a novel algorithm, called FedSketchedSGD, to overcome these challenges. FedSketchedSGD compresses model updates using a Count Sketch, and then takes advantage of the mergeability of sketches to combine model updates from many workers. A key insight in the design of FedSketchedSGD is that, because the Count Sketch is linear, momentum and error accumulation can both be carried out within the sketch. This allows the algorithm to move momentum and error accumulation from clients to the central aggregator, overcoming the challenges of sparse client participation while still achieving high compression rates. We prove that FedSketchedSGD has favorable convergence guarantees, and we demonstrate its empirical effectiveness by training two residual networks and a transformer model.</p> 
### 959.[Learning Fair Policies in Multi-Objective (Deep) Reinforcement Learning with Average and Discounted Rewards](https://proceedings.icml.cc/book/4199.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5937-Paper.pdf)
  Umer Siddique, Paul Weng, Matthieu Zimmer [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5937-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5937-Supplemental.pdf)
> <p>As the operations of autonomous systems generally affect simultaneously several users, it is crucial that their designs account for fairness considerations. In contrast to standard (deep) reinforcement learning (RL), we investigate the problem of learning a policy that treats its users equitably. In this paper, we formulate this novel RL problem, in which an objective function (generalized Gini index of utility vectors), which encodes a notion of fairness that we formally define, is optimized. For this problem, we provide a theoretical discussion where we examine the case of discounted rewards and that of average rewards. During this analysis, we notably derive a new result in the standard RL setting, which is of independent interest: it states a novel bound on the approximation error with respect to the optimal average reward of that of a policy optimal for the discounted reward. Since learning with discounted rewards is generally easier, this discussion further justifies finding a fair policy for the average reward by learning a fair policy for the discounted reward. Thus, we describe how several classic deep RL algorithms can be adapted to our fair optimization problem. Finally, we validate our approach with extensive experiments in three different domains.</p> 
### 960.[Robust Black Box Explanations Under Distribution Shift](https://proceedings.icml.cc/book/4200.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5945-Paper.pdf)
  Himabindu Lakkaraju, Nino Arsov, Osbert Bastani [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5945-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5945-Supplemental.pdf)
> <p>As machine learning black boxes are increasingly being deployed in real-world applications, there has been a growing interest in developing post hoc explanations that summarize the behaviors of these black box models. However, existing algorithms for generating such explanations have been shown to lack robustness with respect to shifts in the underlying data distribution. In this paper, we propose a novel framework for generating robust explanations of black box models based on adversarial training. In particular, our framework optimizes a minimax objective that aims to construct the highest fidelity explanation with respect to the worst-case over a set of distribution shifts. We instantiate this algorithm for explanations in the form of linear models and decision sets by devising the required optimization procedures. To the best of our knowledge, this work makes the first attempt at generating post hoc explanations that are robust to a general class of distribution shifts that are of practical interest. Experimental evaluation with real-world and synthetic datasets demonstrates that our approach substantially improves the robustness of explanations without sacrificing their fidelity on the original data distribution.</p> 
### 961.[Distributed Online Optimization over a Heterogeneous Network](https://proceedings.icml.cc/book/4201.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5948-Paper.pdf)
  Nima Eshraghi, Ben Liang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5948-Metadata.json)
> <p>In distributed online optimization over a computing network with heterogeneous nodes, slow nodes can adversely affect the progress of fast nodes, leading to drastic slowdown of the overall convergence process. To address this issue, we consider a new algorithm termed Distributed Any-Batch Mirror Descent (DABMD), which is based on distributed Mirror Descent but uses a fixed per-round computing time to limit the waiting by fast nodes to receive information updates from slow nodes. DABMD is characterized by varying minibatch sizes across nodes. It is applicable to a broader range of problems compared with existing distributed online optimization methods such as those based on dual averaging, and it accommodates time-varying network topology. We study two versions of DABMD, depending on whether the computing nodes average their primal variables via single or multiple consensus iterations. We show that both versions provide strong theoretical performance guarantee, by deriving upperbounds on their expected dynamic regret, which capture the variability in minibatch sizes. Our experimental results show substantial reduction in cost and acceleration in convergence compared with the known best alternative.</p> 
### 962.[ECLIPSE: An Extreme-Scale Linear Program Solver for Web-Applications](https://proceedings.icml.cc/book/4202.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5950-Paper.pdf)
  Kinjal Basu, Amol Ghoting, Rahul Mazumder, Yao Pan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5950-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5950-Supplemental.zip)
> Key problems arising in web applications (with millions of users and thousands of items) can be formulated as Linear Programs (LP) involving billions to trillions of decision variables and constraints. Despite the appeal of LP formulations, solving problems at these scales is well beyond the capabilities of existing LP solvers. Often ad-hoc decomposition rules are used to approximately solve these LPs, which have limited optimality guarantees and lead to sub-optimal performance in practice. In this work, we propose a distributed solver that solves a perturbation of the LP problems at scale. We propose a gradient-based algorithm on the smooth dual of the perturbed LP with computational guarantees. The main workhorses of our algorithm are distributed matrix-vector multiplications (with load balancing) and efficient projection operations on distributed machines. Experiments on real-world data show that our proposed LP solver, ECLIPSE, can solve problems with $10^{12}$ decision variables -- well beyond the capabilities of current solvers.
### 963.[CURL: Contrastive Unsupervised Representation Learning for Reinforcement Learning](https://proceedings.icml.cc/book/4203.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5951-Paper.pdf)
  Michael Laskin, Pieter Abbeel, Aravind Srinivas [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5951-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5951-Supplemental.pdf)
> <p>Reinforcement Learning for control tasks where the agent learns from raw high dimensional pixels has proven to be difficult and sample-inefficient.  Operating on high-dimensional observational input poses a challenging credit assignment problem, which hinders the agent’s ability to learn optimal policies quickly. One promising approach to improve the sample efficiency of image-based RL algorithms is to learn low-dimensional representations from the raw input using unsupervised learning. To that end, we propose a new model: Contrastive Unsupervised Representation Learning for Reinforcement Learning (CURL). CURL extracts high level features from raw pixels using a contrastive learning objective and performs off-policy control on top of the extracted features. CURL achieves state-of-the-art performance and is the first image based algorithm across both model-free and model-based settings to nearly match the sample-efficiency and performance of state-based features on five out of the six DeepMind control benchmarks.</p> 
### 964.[Confidence-Aware Learning for Deep Neural Networks](https://proceedings.icml.cc/book/4204.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5957-Paper.pdf)
  Sangheum Hwang, Jooyoung Moon, Jihyo Kim, Younghak Shin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5957-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5957-Supplemental.pdf)
> <p>Despite the power of deep neural networks for a wide range of tasks, an overconfident prediction issue has limited their practical use in many safety-critical applications. Many recent works have been proposed to mitigate this issue, but most of them require either additional computational costs in training and/or inference phases or customized architectures to output confidence estimates separately. In this paper, we propose a method of training deep neural networks with a novel loss function, named Correctness Ranking Loss, which regularizes class probabilities explicitly to be better confidence estimates in terms of ordinal ranking according to confidence. The proposed method is easy to implement and can be applied to the existing architectures without any modification. Also, it has almost the same computational costs for training as conventional deep classifiers and outputs reliable predictions by a single inference. Extensive experimental results on classification benchmark datasets indicate that the proposed method helps networks to produce well-ranked confidence estimates. We also demonstrate that it is effective for the tasks closely related to confidence estimation, out-of-distribution detection and active learning.</p> 
### 965.[Online Bayesian Moment Matching based SAT Solver Heuristics](https://proceedings.icml.cc/book/4205.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5964-Paper.pdf)
  Haonan Duan, Saeed Nejati, George Trimponias, Pascal Poupart, Vijay Ganesh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5964-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5964-Supplemental.pdf)
> <p>In this paper, we present a Bayesian Moment Matching (BMM) based method aimed at solving the initialization problem in Boolean SAT solvers.  The initialization problem can be stated as follows: given a SAT formula φ, compute an initial order over the variables of φ and values/polarity for these variables such that the runtime of SAT solvers on input φ is minimized. At the start of a solver run, our BMM-based methods compute a posterior probability distribution for an assign- ment to the variables of the input formula after analyzing its clauses. This probability distribution is then used by the solver to initialize its search.  We perform extensive experiments to evaluate the efficacy of our BMM-based heuristic against 4 other initialization methods (random, survey propagation, Jeroslow-Wang, and default) in state-of-the-art solvers, MapleCOMSPS and MapleLCMDistChronotBT over the SAT competition 2018 application benchmark, as well as the best-known solvers in the cryptographic category, namely, CryptoMiniSAT, Glucose and MapleSAT.  On the cryptographic benchmark, BMM-based solvers out-perform all other initialization methods. Further, the BMM-based MapleCOMSPS significantly out-perform the same solver using all other initialization methods by 12 additional instances solved and better average runtime, over the SAT 2018 competition benchmark.</p>  <p>We performed extensive experiments to evaluate the efficacy of our BMM-based heuristics on SAT competition 2018 application and hard cryptographic benchmarks. We implemented our heuristics in state-of-the-art solvers (MapleCOMSPS and MapleLCMDistChronotBT for SAT competition 2018 application benchmarks) and CryptoMiniSAT, Glucose and MapleSAT (in the context of cryptographic benchmarks), against 4 other initialization methods. Our solvers out-perform the baselines by solving 12 more instances from the SAT competition 2018 application benchmark and are %40 faster on average in solving hard cryptographic instances.</p> 
### 966.[Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search](https://proceedings.icml.cc/book/4206.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5966-Paper.pdf)
  Binghong Chen, Chengtao Li, Hanjun Dai, Le Song [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5966-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5966-Supplemental.pdf)
> <p>Retrosynthetic planning is a critical task in organic chemistry which identifies a series of reactions that can lead to the synthesis of a target product.  The vast number of possible chemical transformations makes the size of the search space very big, and retrosynthetic planning is challenging even for experienced chemists. However, existing methods either require expensive return estimation by rollout with high variance, or optimize for search speed rather than the quality.  In this paper, we propose Retro<em>, a neural-based A</em>-like algorithm that finds high-quality synthetic routes efficiently. It maintains the search as an AND-OR tree, and learns a neural search bias with off-policy data. Then guided by this neural network, it performs best first search efficiently during new planning episode. Experiments on  benchmark USPTO datasets show that, our proposed method outperforms existing state-of-the-art with respect to both the success rate and solution quality, while being more efficient at the same time.</p> 
### 967.[FedBoost: A Communication-Efficient Algorithm for Federated Learning](https://proceedings.icml.cc/book/4207.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5967-Paper.pdf)
  Jenny Hamer, Mehryar Mohri, Ananda Theertha Suresh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5967-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5967-Supplemental.pdf)
> <p>Communication cost is often a bottleneck in federated learning and other client-based distributed learning scenarios. To overcome this, several gradient compression and model compression algorithms have been proposed. In this work, we propose an alternative approach whereby an ensemble of pre-trained base predictors is trained via federated learning. This method allows for training a model which may otherwise surpass the communication bandwidth and storage capacity of the clients to be learned with on-device data through federated learning. Motivated by language modeling, we prove the optimality of ensemble methods for density estimation for standard empirical risk minimization and agnostic risk minimization. We provide communication-efficient ensemble algorithms for federated learning, where per-round communication cost is independent of the size of the ensemble. Furthermore, unlike works on gradient compression, our proposed approach reduces the communication cost of both server-to-client and client-to-server communication.</p> 
### 968.[Sharp Composition Bounds for Gaussian Differential Privacy via Edgeworth Expansion](https://proceedings.icml.cc/book/4208.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/5996-Paper.pdf)
  Qinqing Zheng, Jinshuo Dong, Qi Long, Weijie Su [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/5996-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/5996-Supplemental.pdf)
> Datasets containing sensitive information are often sequentially analyzed by many algorithms and, accordingly, a fundamental question in differential privacy is concerned with how the overall privacy bound degrades under composition. To address this question, we introduce a family of analytical and sharp privacy bounds under composition using the Edgeworth expansion in the framework of the recently proposed $f$-differential privacy. In short, whereas the existing composition theorem, for example, relies on the central limit theorem, our new privacy bounds under composition gain improved tightness by leveraging the refined approximation accuracy of the Edgeworth expansion. Our approach is easy to implement and computationally efficient for any number of compositions. The superiority of these new bounds is confirmed by an asymptotic error analysis and an application to quantifying the overall privacy guarantees of noisy stochastic gradient descent used in training private deep neural networks.
### 969.[Fast and Three-rious: Speeding Up Weak Supervision with Triplet Methods](https://proceedings.icml.cc/book/4210.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6012-Paper.pdf)
  Dan Fu, Mayee Chen, Frederic Sala, Sarah Hooper, Kayvon  Fatahalian, Christopher Re [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6012-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/6012-Supplemental.pdf)
> <p>Weak supervision is a popular method for building machine learning models without relying on ground truth annotations. Instead, it generates probabilistic training labels by estimating the accuracies of multiple noisy labeling sources (e.g., heuristics, crowd workers). Existing approaches use latent variable estimation to model the noisy sources, but these methods can be computationally expensive, scaling superlinearly in the data. In this work, we show that, for a class of latent variable models highly applicable to weak supervision, we can find a closed-form solution to model parameters, obviating the need for iterative solutions like stochastic gradient descent (SGD). We use this insight to build FlyingSquid, a weak supervision framework that runs orders of magnitude faster than previous weak supervision approaches and requires fewer assumptions. In particular, we prove bounds on generalization error without assuming that the latent variable model can exactly parameterize the underlying data distribution. Empirically, we validate FlyingSquid on benchmark weak supervision datasets and find that it achieves the same or higher quality compared to previous approaches without the need to tune an SGD procedure, recovers model parameters 170 times faster on average, and enables new video analysis and online learning applications.</p> 
### 970.[Spectral Frank-Wolfe Algorithm: Strict Complementarity and Linear Convergence](https://proceedings.icml.cc/book/4211.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6015-Paper.pdf)
  Lijun Ding, Yingjie Fei, Qiantong Xu, Chengrun Yang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6015-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/6015-Supplemental.pdf)
> <p>We develop a novel variant of the classical Frank-Wolfe algorithm, which we call spectral Frank-Wolfe, for convex optimization over a spectrahedron. The spectral Frank-Wolfe algorithm has a novel ingredient: it computes a few eigenvectors of the gradient and solves a small-scale subproblem in each iteration. Such a procedure overcomes the slow convergence of the classical Frank-Wolfe algorithm due to ignoring eigenvalue coalescence. We demonstrate that strict complementarity of the optimization problem is key to proving linear convergence of various algorithms, such as the spectral Frank-Wolfe algorithm as well as the projected gradient method and its accelerated version. We showcase that the strict complementarity is equivalent to the eigengap assumption on the gradient at the optimal solution considered in the literature. As a byproduct of this observation, we also develop a generalized block Frank-Wolfe algorithm and prove its linear convergence.</p> 
### 971.[Deep Molecular Programming: A Natural Implementation of Binary-Weight ReLU Neural Networks](https://proceedings.icml.cc/book/4212.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6017-Paper.pdf)
  Marko Vasic, Cameron Chalk, Sarfraz Khurshid, David Soloveichik [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6017-Metadata.json)
> <p>Embedding computation in molecular contexts incompatible with traditional electronics is expected to have wide ranging impact in synthetic biology, medicine, nanofabrication and other fields. A key remaining challenge lies in developing programming paradigms for molecular computation that are well-aligned with the underlying chemical hardware and do not attempt to shoehorn ill-fitting electronics paradigms. We discover a surprisingly tight connection between a popular class of neural networks (Binary-weight ReLU aka BinaryConnect) and a class of coupled chemical reactions that are absolutely robust to reaction rates. The robustness of rate-independent chemical computation makes it a promising target for bioengineering implementation. We show how a BinaryConnect neural network trained in silico using well-founded deep learning optimization techniques, can be compiled to an equivalent chemical reaction network, providing a novel molecular programming paradigm. We illustrate such translation on widely used IRIS and MNIST datasets. Our work sets the stage for rich knowledge transfer between neural network and molecular programming communities.</p> 
### 972.[Generative Pretraining From Pixels](https://proceedings.icml.cc/book/4213.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6022-Paper.pdf)
  Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6022-Metadata.json)
> <p>Inspired by progress in unsupervised representation learning for natural language, we examine whether similar models can learn useful representations for images. We train a sequence Transformer to auto-regressively predict pixels, without incorporating knowledge of the 2D input structure. Despite training on low-resolution ImageNet without labels, we find that a GPT-2 scale model learns strong image representations as measured by linear probing, fine-tuning, and low-data classification. On CIFAR-10, we achieve 96.3% accuracy with a linear probe, outperforming a supervised Wide ResNet, and 99.0% accuracy with full fine-tuning, matching the top supervised pre-trained models. We are also competitive with self-supervised benchmarks on ImageNet when substituting pixels for a VQVAE encoding, achieving 69.0% top-1 accuracy on a linear probe of our features.</p> 
### 973.[Inferring DQN structure for high-dimensional continuous control](https://proceedings.icml.cc/book/4214.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6024-Paper.pdf)
  Andrey Sakryukin, Chedy Raissi, Mohan Kankanhalli [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6024-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/6024-Supplemental.zip)
> <p>Despite recent advancements in the field of Deep Reinforcement Learning, Deep Q-network (DQN) models still show lackluster performance on problems with high-dimensional action spaces. The problem is even more pronounced for cases with high-dimensional continuous action spaces due to a combinatorial increase in the number of the outputs.  Recent works approach the problem by dividing the network into multiple parallel or sequential (action) modules responsible for different discretized actions.  However, there are drawbacks to both the parallel and the sequential approaches. Parallel module architectures lack coordination between action modules, leading to extra complexity in the task, while a sequential structure can result in the vanishing gradients problem and exploding parameter space.  In this work, we show that the compositional structure of the action modules has a significant impact on model performance. We propose a novel approach to infer the network structure for DQN models operating with high-dimensional continuous actions. Our method is based on the uncertainty estimation techniques introduced in the paper. Our approach achieves state-of-the-art performance on MuJoCo environments with high-dimensional continuous action spaces. Furthermore, we demonstrate the improvement of the introduced approach on a realistic AAA sailing simulator game.</p> 
### 974.[Subspace Fitting Meets Regression: The Effects of Supervision and  Orthonormality Constraints on Double Descent of Generalization Errors](https://proceedings.icml.cc/book/4215.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6043-Paper.pdf)
  Yehuda Dar, Paul Mayer, Lorenzo Luzi, Richard Baraniuk [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6043-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/6043-Supplemental.pdf)
> <p>We study the linear subspace fitting problem in the overparameterized setting, where the estimated subspace can perfectly interpolate the training examples. Our scope includes the least-squares solutions to subspace fitting tasks with varying levels of supervision in the training data (i.e., the proportion of input-output examples of the desired low-dimensional mapping) and orthonormality of the vectors defining the learned operator. This flexible family of problems connects standard, unsupervised subspace fitting that enforces strict orthonormality with a corresponding regression task that is fully supervised and does not constrain the linear operator structure. This class of problems is defined over a supervision-orthonormality plane, where each coordinate induces a problem instance with a unique pair of supervision level and softness of orthonormality constraints. We explore this plane and show that the generalization errors of the corresponding subspace fitting problems follow double descent trends as the settings become more supervised and less orthonormally constrained. </p> 
### 975.[Learning Selection Strategies in Buchberger’s Algorithm](https://proceedings.icml.cc/book/4216.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6058-Paper.pdf)
  Dylan Peifer, Michael Stillman, Daniel Halpern-Leistner [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6058-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/6058-Supplemental.pdf)
> <p>Studying the set of exact solutions of a system of polynomial equations largely depends on a single iterative algorithm, known as Buchberger’s algorithm. Optimized versions of this algorithm are crucial for many computer algebra systems (e.g., Mathematica, Maple, Sage). We introduce a new approach to Buchberger’s algorithm that uses reinforcement learning agents to perform S-pair selection, a key step in the algorithm. We then study how the difficulty of the problem depends on the choices of domain and distribution of polynomials, about which little is known. Finally, we train a policy model using proximal policy optimization (PPO) to learn S-pair selection strategies for random systems of binomial equations. In certain domains, the trained model outperforms state-of-the-art selection heuristics both in number of iterations of the algorithm and total number of polynomial additions performed. These results provide a proof-of-concept that recent developments in machine learning have the potential to improve performance of algorithms in symbolic computation.</p> 
### 976.[Estimating the Error of Randomized Newton Methods: A Bootstrap Approach](https://proceedings.icml.cc/book/4217.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6067-Paper.pdf)
  Miles Lopes, Jessie X.T. Chen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6067-Metadata.json)
> <p>Randomized Newton methods have recently become the focus of intense research activity in large-scale and distributed optimization. Generally, these methods are based on a "computation-accuracy trade-off", which allows the user to gain scalability in exchange for error in the solution. However, the user does not know how much error is created by the randomization, which can be detrimental in two ways: On one hand, the user may try to manage the unknown error with theoretical worst-case error bounds, but this approach is impractical when the bounds involve unknown constants, and it typically leads to excessive computation. On the other hand, the user may select tuning parameters or stopping criteria in a heuristic manner, but this is generally unreliable. Motivated by these difficulties, we develop a bootstrap method for directly estimating the unknown error, which avoids excessive computation and offers greater reliability. Also, we provide non-asymptotic theoretical guarantees to show that the error estimates are valid for several error metrics and algorithms (including GIANT and Newton Sketch). Lastly, we show that the proposed method adds relatively little cost to existing randomized Newton methods, and that it performs well in a range of experimental conditions.</p> 
### 977.[Spectral Subsampling MCMC for Stationary Time Series](https://proceedings.icml.cc/book/4218.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6077-Paper.pdf)
  Robert Salomone, Matias Quiroz, Robert kohn, Mattias Villani, Minh-Ngoc Tran [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6077-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/6077-Supplemental.zip)
> <p>Bayesian inference using Markov Chain Monte Carlo (MCMC) on large datasets has developed rapidly in recent years. However, the underlying methods are generally limited to relatively simple settings where the data have specific forms of independence. We propose a novel technique for speeding up MCMC for time series data by efficient data subsampling in the frequency domain. For several challenging time series models, we demonstrate a speedup of up to two orders of magnitude while incurring negligible bias compared to MCMC on the full dataset. We also propose alternative control variates for variance reduction based on data grouping and coreset constructions.</p> 
### 978.[Progressive Identification of True Labels for Partial-Label Learning](https://proceedings.icml.cc/book/4219.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6080-Paper.pdf)
  Jiaqi Lv, Miao Xu, LEI FENG, Gang Niu, Xin Geng, Masashi Sugiyama [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6080-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/6080-Supplemental.pdf)
> <p>Partial-label learning is one of the important weakly supervised learning problems, where each training example is equipped with a set of candidate labels that contains the true label. Most existing methods elaborately designed learning objectives as constrained optimizations that must be solved in specific manners, making their computational complexity a bottleneck for scaling up to big data. The goal of this paper is to propose a novel framework of partial-label learning without implicit assumptions on the model or optimization algorithm. More specifically, we propose a general estimator of the classification risk, theoretically analyze the classifier-consistency, and establish an estimation error bound. We then explore a progressive identification method for approximately minimizing the proposed risk estimator, where the update of the model and identification of true labels can be conducted in a seamless manner. The resulting algorithm is model-independent and loss-independent, and compatible with stochastic optimization. Thorough experiments demonstrate it sets the new state of the art.</p> 
### 979.[R2-B2: Recursive Reasoning-Based Bayesian Optimization for No-Regret Learning in Games](https://proceedings.icml.cc/book/4220.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6082-Paper.pdf)
  Zhongxiang Dai, Yizhou Chen, Bryan Kian Hsiang Low, Patrick Jaillet , Teck-Hua Ho [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6082-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/6082-Supplemental.pdf)
> <p>This paper presents a recursive reasoning formalism of Bayesian optimization (BO) to model the reasoning process in the interactions between boundedly rational, self-interested agents with unknown, complex, and costly-to-evaluate payoff functions in repeated games, which we call Recursive Reasoning-Based BO (R2-B2). Our R2-B2 algorithm is general in that it does not constrain the relationship among the payoff functions of different agents and can thus be applied to various types of games such as constant-sum, general-sum, and common-payoff games. We prove that by reasoning at level 2 or more and at one level higher than the other agents, our R2-B2 agent can achieve faster asymptotic convergence to no regret than that without utilizing recursive reasoning. We also propose a computationally cheaper variant of R2-B2 called R2-B2-Lite at the expense of a weaker convergence guarantee. The performance and generality of our R2-B2 algorithm are empirically demonstrated using synthetic games, adversarial machine learning, and multi-agent reinforcement learning.</p> 
### 980.[Graph Homomorphism Convolution](https://proceedings.icml.cc/book/4221.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6084-Paper.pdf)
  Hoang Nguyen, Takanori Maehara [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6084-Metadata.json)
> In this paper, we study the graph classification problem from the graph homomorphism perspective. We consider the homomorphisms from $F$ to $G$, where $G$ is a graph of interest (e.g. molecules or social networks) and $F$ belongs to some family of graphs (e.g. paths or non-isomorphic trees). We proved that graph homomorphism numbers provide a natural universally invariant embedding maps which can be used for graph classifications. We also discovered that the graph homomorphism method unifies connectivity preserving methods. In practice, by observing that graph classification datasets often have bounded treewidths, we show that our method is not only competitive in classification accuracy but also run much faster than other state-of-the-art. Finally, based on our theoretical analysis, we propose the Graph Homomorphism Convolution module which has promising performance in the graph classification task.
### 981.[Conditional Augmentation for Generative Modeling](https://proceedings.icml.cc/book/4222.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6095-Paper.pdf)
  Heewoo Jun, Rewon Child, Mark Chen, John Schulman, Aditya Ramesh, Alec Radford, Ilya Sutskever [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6095-Metadata.json)
> <p>We present conditional augmentation (CondAugment), a simple and powerful method of regularizing generative models. Core to our approach is applying augmentation functions to data and then conditioning the generative model on the specific function used. Unlike typical data augmentation, CondAugment allows usage of functions which modify the target density, enabling aggressive augmentations more commonly seen in supervised and self-supervised learning. We demonstrate this is a more effective regularizer than standard methods, and use it to train a 150M parameter autoregressive model on CIFAR-10 to 2.56 bits per dim (relative to the state-of-the-art 2.80). Samples from this model attain FID 12.75 and IS 8.40, outperforming the majority of GANs. We further demonstrate the technique is broadly applicable across model architectures, objectives, and problem domains.</p> 
### 982.[PDO-eConvs: Partial Differential Operator Based Equivariant Convolutions](https://proceedings.icml.cc/book/4223.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6096-Paper.pdf)
  Zhengyang Shen, Lingshen He, Zhouchen Lin, Jinwen Ma [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6096-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/6096-Supplemental.pdf)
> <p>Recent research has shown that incorporating equivariance into neural network architectures is very helpful, and there have been some works investigating the equivariance of networks under group actions. However, as digital images and feature maps are on the discrete meshgrid, corresponding equivariance-preserving transformation groups are very limited.  In this work, we deal with this issue from the connection between convolutions and partial differential operators (PDOs). In theory, assuming inputs to be smooth, we transform PDOs and propose a system which is equivariant to a much more general continuous group, the n-dimension Euclidean group. In implementation, we discretize the system using the numerical schemes of PDOs, deriving approximately equivariant convolutions (PDO-eConvs). Theoretically, the approximation error of PDO-eConvs is of the quadratic order. It is the first time that the error analysis is provided when the equivariance is approximate. Extensive experiments on rotated MNIST and natural image classification show that PDO-eConvs perform competitively yet use parameters much more efficiently. Particularly, compared with Wide ResNets, our methods result in comparable results using only 12.6% parameters.</p> 
### 983.[Abstraction Mechanisms Predict Generalization in Deep Neural Networks](https://proceedings.icml.cc/book/4224.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6109-Paper.pdf)
  Alex Gain, Hava Siegelmann [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6109-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/6109-Supplemental.pdf)
> <p>A longstanding problem for Deep Neural Networks (DNNs) is understanding their puzzling ability to generalize well. We approach this problem through the unconventional angle of \textit{cognitive abstraction mechanisms}, drawing inspiration from recent neuroscience work, allowing us to define the Cognitive Neural Activation metric (CNA) for DNNs, which is the correlation between information complexity (entropy) of given input and the concentration of higher activation values in deeper layers of the network. The CNA is highly predictive of generalization ability, outperforming norm-and-margin-based generalization metrics on an extensive evaluation of over 100 dataset-and-network-architecture combinations, especially in cases where additive noise is present and/or training labels are corrupted. These strong empirical results show the usefulness of CNA as a generalization metric, and encourage further research on the connection between information complexity and representations in the deeper layers of networks in order to better understand the generalization capabilities of DNNs.</p> 
### 984.[Revisiting Fundamentals of Experience Replay](https://proceedings.icml.cc/book/4225.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6110-Paper.pdf)
  William Fedus, Prajit Ramachandran, Rishabh Agarwal, Yoshua Bengio, Hugo Larochelle, Mark Rowland, Will Dabney [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6110-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/6110-Supplemental.pdf)
> <p>Experience replay is central to off-policy algorithms in deep reinforcement learning (RL), but there remain significant gaps in our understanding. We therefore present a systematic and extensive analysis of experience replay in Q-learning methods, focusing on two fundamental properties: the replay capacity and the ratio of learning updates to experience collected (replay ratio). Our additive and ablative studies upend conventional wisdom around experience replay - greater capacity is found to substantially increase the performance of certain algorithms, while leaving others unaffected. Counter-intuitively we show that theoretically ungrounded, uncorrected n-step returns are uniquely beneficial while other techniques confer limited benefit for sifting through larger memory. Separately by directly controlling the replay ratio we contextualize previous observations in the literature and empirically measure the importance across three deep RL algorithms. Finally, we conclude by testing a set of hypotheses on the nature of these performance benefits.</p> 
### 985.[Go Wide, Then Narrow: Efficient Training of Deep Thin Networks](https://proceedings.icml.cc/book/4226.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6116-Paper.pdf)
  Denny Zhou, Mao Ye, Chen Chen, Mingxing Tan, Tianjian Meng, Xiaodan Song, Quoc Le, Qiang Liu, Dale Schuurmans [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6116-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/6116-Supplemental.pdf)
> <p>We propose an efficient algorithm to train  a very deep and thin network with theoretic guarantee. Our method is motivated by model compression, and consists of three stages. In the first stage, we widen the deep thin network and train it until convergence. In the second stage, we use this well trained deep wide network to warm up or initialize the original deep thin network. In the last stage, we train this well initialized deep thin network until convergence. The key ingredient of our method is  its second stage, in which the thin network is gradually warmed up by imitating the intermediate outputs of the wide network from bottom to top. We establish theoretical guarantee using mean field analysis. We show that our method is provably more efficient than directly training a deep thin network from scratch. We also conduct empirical evaluations on image classification and language modeling. By training with our approach, ResNet50 can outperform  ResNet101 which is normally trained as in the literature, and BERT<em>BASE can be comparable with BERT</em>LARGE. </p> 
### 986.[Meta-learning for Mixed Linear Regression](https://proceedings.icml.cc/book/4227.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6124-Paper.pdf)
  Weihao Kong, Raghav Somani, Zhao Song, Sham Kakade, Sewoong Oh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6124-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/6124-Supplemental.zip)
> In modern supervised learning, there are a large number of tasks, but many of them are associated with only a small amount of labelled data. These include data from medical image processing and robotic interaction. Even though each individual task cannot be meaningfully trained in isolation, one seeks to meta-learn across the tasks from past experiences by exploiting some similarities. We study a fundamental question of interest: When can abundant tasks with small data compensate for lack of tasks with big data? We focus on a canonical scenario where each task is drawn from a mixture of $k$ linear regressions, and identify sufficient conditions for such a graceful exchange to hold; there is little loss in sample complexity even when we only have access to small data tasks. To this end, we introduce a novel spectral approach and show that we can efficiently utilize small data tasks with the help of $\tilde\Omega(k^{3/2})$ medium data tasks each with  $\tilde\Omega(k^{1/2})$ examples.
### 987.[Efficiently Learning Adversarially Robust Halfspaces with Noise](https://proceedings.icml.cc/book/4228.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6130-Paper.pdf)
  Omar Montasser, Surbhi Goel, Ilias Diakonikolas, Nati Srebro [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6130-Metadata.json)
> We study the problem of learning adversarially robust halfspaces in the distribution-independent setting. We give the first computationally efficient algorithm for this problem in the realizable setting and in the presence of random label noise with respect to any $\ell_p$-perturbation (and, more generally, perturbations with respect to any norm). 
### 988.[Bayesian Graph Neural Networks with Adaptive Connection Sampling](https://proceedings.icml.cc/book/4229.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6133-Paper.pdf)
  Arman Hasanzadeh, Ehsan Hajiramezanali, Shahin Boluki, Nick Duffield, Mingyuan Zhou, Krishna Narayanan, Xiaoning Qian [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6133-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/6133-Supplemental.pdf)
> <p>We propose a unified framework for adaptive connection sampling in graph neural  networks (GNNs) that generalizes existing stochastic regularization methods for  training GNNs. The proposed framework not only alleviates over-smoothing and  over-fitting tendencies of deep GNNs, but also enables learning with uncertainty in graph analytic tasks with GNNs. Instead of using fixed sampling rates or hand-tuning themas model hyperparameters in existing stochastic regularization methods, our adaptive connection sampling can be trained jointly with GNN model parameters in both global and local fashions. GNN training with adaptive connection sampling is shown to be mathematically equivalent to an efficient approximation of training BayesianGNNs. Experimental results with ablation studies on benchmark datasets validate that adaptively learning the sampling rate given graph training data is the key to boost the performance of GNNs in semi-supervised node classification, less prone to over-smoothing and over-fitting with more robust prediction.</p> 
### 989.[On the Theoretical Properties of the Network Jackknife](https://proceedings.icml.cc/book/4230.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6137-Paper.pdf)
  Qiaohui Lin, Robert Lunde, Purnamrita Sarkar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6137-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/6137-Supplemental.pdf)
> <p>We study the properties of a leave-node-out jackknife procedure for network data.  Under the sparse graphon model, we prove an Efron-Stein-type inequality, showing that the network jackknife leads to conservative estimates of the variance (in expectation) for any network functional that is invariant to node permutation.  For a general class of count functionals, we also establish consistency of the network jackknife.  We complement our theoretical analysis with a range of simulated and real-data examples and show that the network jackknife offers competitive performance in cases where other resampling methods are known to be valid. In fact, for several network statistics, we see that the jackknife provides more accurate inferences compared to related methods such as subsampling.</p> 
### 990.[Thompson Sampling via Local Uncertainty](https://proceedings.icml.cc/book/4231.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/6144-Paper.pdf)
  Zhendong Wang, Mingyuan Zhou [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/6144-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/6144-Supplemental.pdf)
> <p>Thompson sampling is an efficient algorithm for sequential decision making, which exploits the posterior uncertainty to address the exploration-exploitation dilemma. There has been significant recent interest in integrating  Bayesian neural networks into Thompson sampling. Most of these methods rely on global variable uncertainty for exploration. In this paper, we propose a new probabilistic modeling framework for Thompson sampling, where local latent variable uncertainty is used to sample the mean reward. Variational inference is used to approximate the posterior of the local variable, and semi-implicit structure is further introduced to enhance its expressiveness. Our experimental results on eight  contextual bandits benchmark datasets show that Thompson sampling guided by local uncertainty achieves state-of-the-art performance while having low computational complexity.</p> 
