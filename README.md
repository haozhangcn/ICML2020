# ICML2020
ICML2020 papers with abstract

### 1.Reverse-engineering deep ReLU networks
  David Rolnick, Konrad Kording [link](https://proceedings.icml.cc/book/3241.pdf) [Bibtex](https://proceedings.icml.cc/book/3241.pdf/static/paper_files/icml/2020/1-Bibtex.bib) [Metadata](https://proceedings.icml.cc/book/3241.pdf/static/paper_files/icml/2020/1-Metadata.json) [Paper](https://proceedings.icml.cc/book/3241.pdf/static/paper_files/icml/2020/1-Paper.pdf) [Supplemental](https://proceedings.icml.cc/book/3241.pdf/static/paper_files/icml/2020/1-Supplemental.zip)
> It has been widely assumed that a neural network cannot be recovered from its outputs, as the  network depends on its parameters in a highly nonlinear way. Here, we prove that in fact it is often possible to identify the architecture, weights, and biases of an unknown deep ReLU network by observing only its output. Every ReLU network defines a piecewise linear function, where the boundaries between linear regions correspond to inputs for which some neuron in the network switches between inactive and active ReLU states. By dissecting the set of region boundaries into components associated with particular neurons, we show both theoretically and empirically that it is possible to recover the weights of neurons and their arrangement within the network, up to isomorphism.
### 2My Fair Bandit: Distributed Learning of Max-Min Fairness with Multi-player Bandits
  Ilai Bistritz, Tavor Baharav, Amir Leshem, Nicholas Bambos [link](https://proceedings.icml.cc/book/3242.pdf) [Bibtex](https://proceedings.icml.cc/book/3242.pdf/static/paper_files/icml/2020/11-Bibtex.bib) [Metadata](https://proceedings.icml.cc/book/3242.pdf/static/paper_files/icml/2020/11-Metadata.json) [Paper](https://proceedings.icml.cc/book/3242.pdf/static/paper_files/icml/2020/11-Paper.pdf)
> Consider N cooperative but non-communicating players where each plays one out of M arms for T turns. Players have different utilities for each arm, representable as an NxM matrix. However, these utilities are unknown to the players. In each turn players receive noisy observations of their utility for their selected arm. However, if any other players selected the same arm that turn, they will all receive zero utility due to the conflict. No other communication or coordination between the players is possible. Our goal is to design a distributed algorithm that learns the matching between players and arms that achieves max-min fairness while minimizing the regret. We present an algorithm and prove that it is regret optimal up to a log(log T) factor. This is the first max-min fairness multi-player bandit algorithm with (near) order optimal regret. 
### 3.Scalable Differentiable Physics for Learning and Control
  Yi-Ling Qiao, Junbang Liang, Vladlen Koltun, Ming Lin [link](https://proceedings.icml.cc/book/3243.pdf) [Bibtex](https://proceedings.icml.cc/book/3243.pdf/static/paper_files/icml/2020/15-Bibtex.bib) [Metadata](https://proceedings.icml.cc/book/3243.pdf/static/paper_files/icml/2020/15-Metadata.json) [Paper](https://proceedings.icml.cc/book/3243.pdf/static/paper_files/icml/2020/15-Paper.pdf) [Supplemental](https://proceedings.icml.cc/book/3243.pdf/static/paper_files/icml/2020/15-Supplemental.pdf)
> Differentiable physics is a powerful approach to learning and control problems that involve physical objects and environments. While notable progress has been made, the capabilities of differentiable physics solvers remain limited. We develop a scalable framework for differentiable physics that can support a large number of objects and their interactions. To accommodate objects with arbitrary geometry and topology, we adopt meshes as our representation and leverage the sparsity of contacts for scalable differentiable collision handling. Collisions are resolved in localized regions to minimize the number of optimization variables even when the number of simulated objects is high. We further accelerate implicit differentiation of optimization with nonlinear constraints. Experiments demonstrate that the presented framework requires up to two orders of magnitude less memory and computation in comparison to recent particle-based methods. We further validate the approach on inverse problems and control scenarios, where it outperforms derivative-free and model-free baselines by at least an order of magnitude.
### 4.Generalization to New Actions in Reinforcement Learning
  Ayush Jain, Andrew Szot, Joseph Lim [link](https://proceedings.icml.cc/book/3244.pdf) [Bibtex](https://proceedings.icml.cc/book/3244.pdf/static/paper_files/icml/2020/29-Bibtex.bib) [Metadata](https://proceedings.icml.cc/book/3244.pdf/static/paper_files/icml/2020/29-Metadata.json) [Paper](https://proceedings.icml.cc/book/3244.pdf/static/paper_files/icml/2020/29-Paper.pdf) [Supplemental](https://proceedings.icml.cc/book/3244.pdf/static/paper_files/icml/2020/29-Supplemental.pdf)
> A fundamental trait of intelligence is the ability to achieve goals in the face of novel circumstances. However, standard reinforcement learning typically assumes a fixed set of actions to choose from. Completing tasks with a new action space then requires time-consuming retraining. The ability to seamlessly utilize novel actions is crucial for adaptable agents. We take a step in this direction by introducing the problem of learning to generalize decision-making to unseen actions, based on action information acquired separately from the task. To approach this problem, we propose a two-stage framework where the agent first infers action representations from acquired action observations and then learns to use these in reinforcement learning with added generalization objectives. We demonstrate that our framework enables zero-shot generalization to new actions in sequential decision-making tasks, such as selecting unseen tools to solve physical reasoning puzzles and stacking towers with novel 3D shapes.
### 5.Randomized Block-Diagonal Preconditioning for Parallel Learning
  Celestine Mendler-DÃ¼nner, Aurelien Lucchi [ :link:	](https://proceedings.icml.cc/book/3245.pdf) [Bibtex](https://proceedings.icml.cc/book/3245.pdf/static/paper_files/icml/2020/53-Bibtex.bib) [Metadata](https://proceedings.icml.cc/book/3245.pdf/static/paper_files/icml/2020/53-Metadata.json) [Paper](https://proceedings.icml.cc/book/3245.pdf/static/paper_files/icml/2020/53-Paper.pdf) [Supplemental](https://proceedings.icml.cc/book/3245.pdf/static/paper_files/icml/2020/53-Supplemental.pdf)
> We study preconditioned gradient-based optimization methods where the preconditioning matrix has block-diagonal form. Such a structural constraint comes with the advantage that the update computation can be parallelized across multiple independent tasks. Our main contribution is to demonstrate that the convergence of these methods can significantly be improved by a randomization technique which corresponds to repartitioning coordinates across tasks during the optimization procedure. We provide a theoretical analysis that accurately characterizes the expected convergence gains of repartitioning and validate our findings empirically on various traditional machine learning tasks. From an implementation perspective, block-separable models are well suited for parallelization and, when shared memory is available, randomization can be implemented on top of existing methods very efficiently to improve convergence.
### 6.Stochastic Flows and Geometric Optimization on the Orthogonal Group
  Krzysztof Choromanski, David Cheikhi, Jared Davis, Valerii Likhosherstov, Achille Nazaret, Achraf Bahamou, Xingyou Song, Mrugank Akarte, Jack Parker-Holder, Jacob Bergquist, YUAN GAO, Aldo Pacchiano, Tamas Sarlos, Adrian Weller, Vikas Sindhwani [link](https://proceedings.icml.cc/book/3246.pdf) [Bibtex](https://proceedings.icml.cc/book/3246.pdf/static/paper_files/icml/2020/57-Bibtex.bib) [Metadata](https://proceedings.icml.cc/book/3246.pdf/static/paper_files/icml/2020/57-Metadata.json) [Paper](https://proceedings.icml.cc/book/3246.pdf/static/paper_files/icml/2020/57-Paper.pdf) [Supplemental](https://proceedings.icml.cc/book/3246.pdf/static/paper_files/icml/2020/57-Supplemental.pdf)
> We present a new class of stochastic, geometrically-driven optimization algorithms on the orthogonal group O(d) and naturally reductive homogeneous manifolds obtained from the action of the rotation group SO(d). We theoretically and experimentally demonstrate that our methods can be applied in various fields of machine learning including deep, convolutional and recurrent neural networks, reinforcement learning, normalizing flows and metric learning. We show an intriguing connection between efficient stochastic optimization on the orthogonal group and graph theory (e.g. matching problem, partition functions over graphs, graph-coloring). We leverage the theory of Lie groups and provide theoretical results for the designed class of algorithms. We demonstrate broad applicability of our methods by showing strong performance on the seemingly unrelated tasks of learning world models to obtain stable policies for the most difficult Humanoid agent from OpenAI Gym and improving convolutional neural networks.
### 7.PackIt: A Virtual Environment for Geometric Planning
  Ankit Goyal, Jia Deng [link](https://proceedings.icml.cc/book/3247.pdf) [Bibtex](https://proceedings.icml.cc/book/3247.pdf/static/paper_files/icml/2020/62-Bibtex.bib) [Metadata](https://proceedings.icml.cc/book/3247.pdf/static/paper_files/icml/2020/62-Metadata.json) [Paper](https://proceedings.icml.cc/book/3247.pdf/static/paper_files/icml/2020/62-Paper.pdf) [Supplemental](https://proceedings.icml.cc/book/3247.pdf/static/paper_files/icml/2020/62-Supplemental.pdf)
> The ability to jointly understand the geometry of objects and plan actions for manipulating them is crucial for intelligent agents. We refer to this ability as geometric planning. Recently, many interactive environments have been proposed to evaluate intelligent agents on various skills, however, none of them cater to the needs of geometric planning. We present PackIt, a virtual environment to evaluate and potentially learn the ability to do geometric planning. In this environment, an agent needs to take a sequence of actions to pack a set of objects into a box with limited space. We also construct a set of challenging packing tasks using an evolutionary algorithm. Further, we study various baselines for the task that include model-free learning-based and heuristic-based methods, as well as search-based optimization methods that assume access to the model of the environment.

