# ICML2020-1
ICML2020 papers with abstract [:link:](https://proceedings.icml.cc/book/2020)

### 1.[Reverse-engineering deep ReLU networks](https://proceedings.icml.cc/book/3241.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1-Paper.pdf)
  David Rolnick, Konrad Kording [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1-Supplemental.zip)
> <p>It has been widely assumed that a neural network cannot be recovered from its outputs, as the  network depends on its parameters in a highly nonlinear way. Here, we prove that in fact it is often possible to identify the architecture, weights, and biases of an unknown deep ReLU network by observing only its output. Every ReLU network defines a piecewise linear function, where the boundaries between linear regions correspond to inputs for which some neuron in the network switches between inactive and active ReLU states. By dissecting the set of region boundaries into components associated with particular neurons, we show both theoretically and empirically that it is possible to recover the weights of neurons and their arrangement within the network, up to isomorphism.</p> 
### 2.My Fair Bandit: Distributed Learning of Max-Min Fairness with Multi-player Bandits [:chains:](https://proceedings.icml.cc/book/3242.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/11-Paper.pdf)
  Ilai Bistritz, Tavor Baharav, Amir Leshem, Nicholas Bambos [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/11-Metadata.json)
> <p>Consider N cooperative but non-communicating players where each plays one out of M arms for T turns. Players have different utilities for each arm, representable as an NxM matrix. However, these utilities are unknown to the players. In each turn players receive noisy observations of their utility for their selected arm. However, if any other players selected the same arm that turn, they will all receive zero utility due to the conflict. No other communication or coordination between the players is possible. Our goal is to design a distributed algorithm that learns the matching between players and arms that achieves max-min fairness while minimizing the regret. We present an algorithm and prove that it is regret optimal up to a log(log T) factor. This is the first max-min fairness multi-player bandit algorithm with (near) order optimal regret. </p> 
### 3.[Scalable Differentiable Physics for Learning and Control](https://proceedings.icml.cc/book/3243.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/15-Paper.pdf)
  Yi-Ling Qiao, Junbang Liang, Vladlen Koltun, Ming Lin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/15-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/15-Supplemental.pdf)
> <p>Differentiable physics is a powerful approach to learning and control problems that involve physical objects and environments. While notable progress has been made, the capabilities of differentiable physics solvers remain limited. We develop a scalable framework for differentiable physics that can support a large number of objects and their interactions. To accommodate objects with arbitrary geometry and topology, we adopt meshes as our representation and leverage the sparsity of contacts for scalable differentiable collision handling. Collisions are resolved in localized regions to minimize the number of optimization variables even when the number of simulated objects is high. We further accelerate implicit differentiation of optimization with nonlinear constraints. Experiments demonstrate that the presented framework requires up to two orders of magnitude less memory and computation in comparison to recent particle-based methods. We further validate the approach on inverse problems and control scenarios, where it outperforms derivative-free and model-free baselines by at least an order of magnitude.</p> 
### 4.[Generalization to New Actions in Reinforcement Learning](https://proceedings.icml.cc/book/3244.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/29-Paper.pdf)
  Ayush Jain, Andrew Szot, Joseph Lim [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/29-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/29-Supplemental.pdf)
> <p>A fundamental trait of intelligence is the ability to achieve goals in the face of novel circumstances. However, standard reinforcement learning typically assumes a fixed set of actions to choose from. Completing tasks with a new action space then requires time-consuming retraining. The ability to seamlessly utilize novel actions is crucial for adaptable agents. We take a step in this direction by introducing the problem of learning to generalize decision-making to unseen actions, based on action information acquired separately from the task. To approach this problem, we propose a two-stage framework where the agent first infers action representations from acquired action observations and then learns to use these in reinforcement learning with added generalization objectives. We demonstrate that our framework enables zero-shot generalization to new actions in sequential decision-making tasks, such as selecting unseen tools to solve physical reasoning puzzles and stacking towers with novel 3D shapes.</p> 
### 5.[Randomized Block-Diagonal Preconditioning for Parallel Learning](https://proceedings.icml.cc/book/3245.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/53-Paper.pdf)
  Celestine Mendler-DÃ¼nner, Aurelien Lucchi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/53-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/53-Supplemental.pdf)
> <p>We study preconditioned gradient-based optimization methods where the preconditioning matrix has block-diagonal form. Such a structural constraint comes with the advantage that the update computation can be parallelized across multiple independent tasks. Our main contribution is to demonstrate that the convergence of these methods can significantly be improved by a randomization technique which corresponds to repartitioning coordinates across tasks during the optimization procedure. We provide a theoretical analysis that accurately characterizes the expected convergence gains of repartitioning and validate our findings empirically on various traditional machine learning tasks. From an implementation perspective, block-separable models are well suited for parallelization and, when shared memory is available, randomization can be implemented on top of existing methods very efficiently to improve convergence.</p> 
### 6.[Stochastic Flows and Geometric Optimization on the Orthogonal Group](https://proceedings.icml.cc/book/3246.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/57-Paper.pdf)
  Krzysztof Choromanski, David Cheikhi, Jared Davis, Valerii Likhosherstov, Achille Nazaret, Achraf Bahamou, Xingyou Song, Mrugank Akarte, Jack Parker-Holder, Jacob Bergquist, YUAN GAO, Aldo Pacchiano, Tamas Sarlos, Adrian Weller, Vikas Sindhwani [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/57-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/57-Supplemental.pdf)
> <p>We present a new class of stochastic, geometrically-driven optimization algorithms on the orthogonal group O(d) and naturally reductive homogeneous manifolds obtained from the action of the rotation group SO(d). We theoretically and experimentally demonstrate that our methods can be applied in various fields of machine learning including deep, convolutional and recurrent neural networks, reinforcement learning, normalizing flows and metric learning. We show an intriguing connection between efficient stochastic optimization on the orthogonal group and graph theory (e.g. matching problem, partition functions over graphs, graph-coloring). We leverage the theory of Lie groups and provide theoretical results for the designed class of algorithms. We demonstrate broad applicability of our methods by showing strong performance on the seemingly unrelated tasks of learning world models to obtain stable policies for the most difficult Humanoid agent from OpenAI Gym and improving convolutional neural networks.</p> 
### 7.[PackIt: A Virtual Environment for Geometric Planning](https://proceedings.icml.cc/book/3247.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/62-Paper.pdf)
  Ankit Goyal, Jia Deng [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/62-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/62-Supplemental.pdf)
> <p>The ability to jointly understand the geometry of objects and plan actions for manipulating them is crucial for intelligent agents. We refer to this ability as geometric planning. Recently, many interactive environments have been proposed to evaluate intelligent agents on various skills, however, none of them cater to the needs of geometric planning. We present PackIt, a virtual environment to evaluate and potentially learn the ability to do geometric planning. In this environment, an agent needs to take a sequence of actions to pack a set of objects into a box with limited space. We also construct a set of challenging packing tasks using an evolutionary algorithm. Further, we study various baselines for the task that include model-free learning-based and heuristic-based methods, as well as search-based optimization methods that assume access to the model of the environment.</p> 
### 8.[Soft Threshold Weight Reparameterization for Learnable Sparsity](https://proceedings.icml.cc/book/3248.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/67-Paper.pdf)
  Aditya Kusupati, Vivek Ramanujan, Raghav Somani, Mitchell Wortsman, Prateek Jain, Sham Kakade, Ali Farhadi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/67-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/67-Supplemental.pdf)
> <p>Sparsity in Deep Neural Networks (DNNs) is studied extensively with the focus of maximizing prediction accuracy given an overall parameter budget. Existing methods rely on uniform or heuristic non-uniform sparsity budgets which have sub-optimal layer-wise parameter allocation resulting in a) lower prediction accuracy or b) higher inference cost (FLOPs). This work proposes Soft Threshold Reparameterization (STR), a novel use of the soft-threshold operator on DNN weights. STR smoothly induces sparsity while learning pruning thresholds thereby obtaining a non-uniform sparsity budget. Our method achieves state-of-the-art accuracy for unstructured sparsity in CNNs (ResNet50 and MobileNetV1 on ImageNet-1K), and, additionally, learns non-uniform budgets that empirically reduce the FLOPs by up to 50%. Notably, STR boosts the accuracy over existing results by up to 10% in the ultra sparse (99%) regime and can also be used to induce low-rank (structured sparsity) in RNNs. In short, STR is a simple mechanism which learns effective sparsity budgets that contrast with popular heuristics. Code, pretrained models and sparsity budgets are at https://github.com/RAIVNLab/STR.</p> 
### 9.[Stochastic Latent Residual Video Prediction](https://proceedings.icml.cc/book/3249.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/78-Paper.pdf)
  Jean-Yves Franceschi, Edouard Delasalles, Mickael Chen, Sylvain Lamprier, Patrick Gallinari [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/78-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/78-Supplemental.zip)
> <p>Designing video prediction models that account for the inherent uncertainty of the future is challenging. Most works in the literature are based on stochastic image-autoregressive recurrent networks, which raises several performance and applicability issues. An alternative is to use fully latent temporal models which untie frame synthesis and temporal dynamics. However, no such model for stochastic video prediction has been proposed in the literature yet, due to design and training difficulties. In this paper, we overcome these difficulties by introducing a novel stochastic temporal model whose dynamics are governed in a latent space by a residual update rule. This first-order scheme is motivated by discretization schemes of differential equations. It naturally models video dynamics as it allows our simpler, more interpretable, latent model to outperform prior state-of-the-art methods on challenging datasets.</p> 
### 10.[Fractional Underdamped Langevin Dynamics: Retargeting SGD with Momentum under Heavy-Tailed Gradient Noise](https://proceedings.icml.cc/book/3250.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/86-Paper.pdf)
  Umut Simsekli, Lingjiong Zhu, Yee Whye Teh, Mert Gurbuzbalaban [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/86-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/86-Supplemental.pdf)
> <p>Stochastic gradient descent with momentum (SGDm) is one of the most popular optimization algorithms in deep learning. While there is a rich theory of SGDm for convex problems, the theory is considerably less developed in the context of deep learning where the  problem is non-convex and the gradient noise might exhibit a heavy-tailed behavior, as empirically observed in recent studies. In this study, we consider a \emph{continuous-time} variant of SGDm, known as the underdamped Langevin dynamics (ULD), and investigate its asymptotic properties under heavy-tailed perturbations. Supported by recent studies from statistical physics, we argue both theoretically and empirically that the heavy-tails of such perturbations can result in a bias even when the step-size is small, in the sense that \emph{the optima of stationary distribution} of the dynamics might not match \emph{the optima of the cost function to be optimized}. As a remedy, we develop a novel framework, which we coin as \emph{fractional} ULD (FULD), and prove that FULD targets the so-called Gibbs distribution, whose optima exactly match the optima of the original cost. We observe that the Euler discretizatin of FULD has noteworthy algorithmic similarities with \emph{natural gradient} methods and \emph{gradient clipping}, bringing a new perspective on understanding their role in deep learning. We support our theory with experiments conducted on a synthetic model and neural networks.</p> 
### 11.[Context Aware Local Differential Privacy](https://proceedings.icml.cc/book/3251.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/111-Paper.pdf)
  Jayadev Acharya, Keith Bonawitz, Peter Kairouz, Daniel  Ramage, Ziteng Sun [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/111-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/111-Supplemental.pdf)
> <p>Local differential privacy (LDP) is a strong notion of privacy that often leads to a significant drop in utility. The original definition of LDP assumes that all the elements in the data domain are equally sensitive. However, in many real-life applications, some elements are more sensitive than others. We propose a context-aware framework for LDP that allows the privacy level to vary across the data domain, enabling system designers to place privacy constraints where they matter without paying the cost where they do not. For binary data domains, we provide a universally optimal privatization scheme and highlight its connections to Warnerâs randomized response and Mangatâs improved response. Motivated by geo-location and web search applications, for k-ary data domains, we consider two special cases of context-aware LDP: block-structured LDP and high-low LDP. We study minimax discrete distribution estimation under both cases and provide communication-efficient, sample-optimal schemes, and information-theoretic lower bounds. We show, using worst-case analyses and experiments on Gowallaâs 3.6 million check-ins to 43,750 locations, that context-aware LDP achieves a far better accuracy under the same number of samples.</p> 
### 12.[Privately Learning Markov Random Fields](https://proceedings.icml.cc/book/3252.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/112-Paper.pdf)
  Gautam Kamath, Janardhan Kulkarni, Steven Wu, Huanyu Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/112-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/112-Supplemental.pdf)
> <p>We consider the problem of learning Markov Random Fields (including   the prototypical example, the Ising model) under the constraint of   differential privacy.  Our learning goals include both   \emph{structure learning}, where we try to estimate the underlying   graph structure of the model, as well as the harder goal of   \emph{parameter learning}, in which we additionally estimate the   parameter on each edge.  We provide algorithms and lower bounds for   both problems under a variety of privacy constraints --   namely pure, concentrated, and approximate differential privacy.   While non-privately, both learning goals enjoy roughly the same   complexity, we show that this is not the case under differential   privacy.  In particular, only structure learning under approximate   differential privacy maintains the non-private logarithmic   dependence on the dimensionality of the data, while a change in   either the learning goal or the privacy notion would necessitate a   polynomial dependence. As a result, we show that the privacy     constraint imposes a strong separation between these two learning     problems in the high-dimensional data regime.</p> 
### 13.[A Mean Field Analysis Of Deep ResNet And Beyond: Towards  Provably Optimization Via Overparameterization From Depth](https://proceedings.icml.cc/book/3253.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/115-Paper.pdf)
  Yiping Lu, Chao Ma, Yulong Lu, Jianfeng Lu, Lexing Ying [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/115-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/115-Supplemental.pdf)
> <p>Training deep neural networks with stochastic gradient descent (SGD) can often achieve zero training loss on real-world tasks although the optimization landscape is known to be highly non-convex. To understand the success of SGD for training deep neural networks, this work presents a mean-field analysis of deep residual networks, based on a line of works which interpret the continuum limit of the deep residual network as an ordinary differential equation as the the network capacity tends to infinity. Specifically, we propose a \textbf{new continuum limit} of deep residual networks, which enjoys a good landscape in the sense that \textbf{every local minimizer is global}.  This characterization enables us to derive the first global convergence result for multilayer neural networks in the mean-field regime. Furthermore, our proof does not rely on the convexity of the loss landscape, but instead, an assumption on the global minimizer should achieve zero loss which can be achieved when the model shares a universal approximation property. Key to our result is the observation that a deep residual network resembles a shallow network ensemble~\cite{veit2016residual}, \emph{i.e.} a two-layer network. We bound the difference between the shallow network and our ResNet model via the adjoint sensitivity method, which enables us to transfer previous mean-field analysis of two-layer networks to deep networks. Furthermore, we propose several novel training schemes based on our new continuous model, among which one new training procedure introduces the operation of switching the order of the residual blocks and results in strong empirical performance on benchmark datasets. </p> 
### 14.Provable Smoothness Guarantees for Black-Box Variational Inference [:chains:](https://proceedings.icml.cc/book/3254.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/120-Paper.pdf)
  Justin Domke [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/120-Metadata.json)
> <p>Black-box variational inference tries to approximate a complex target distribution through a gradient-based optimization of the parameters of a simpler distribution. Provable convergence guarantees require structural properties of the objective. This paper shows that for location-scale family approximations, if the target is M-Lipschitz smooth, then so is the âenergyâ part of the variational objective. The key proof idea is to describe gradients in a certain inner-product space, thus permitting the use of Besselâs inequality. This result gives bounds on the location of the optimal parameters, and is a key ingredient for convergence guarantees.</p> 
### 15.[Enhancing Simple Models by Exploiting What They Already Know](https://proceedings.icml.cc/book/3255.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/126-Paper.pdf)
  Amit Dhurandhar, Karthikeyan Shanmugam, Ronny Luss [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/126-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/126-Supplemental.pdf)
> <p>There has been recent interest in improving performance of simple models for multiple reasons such as interpretability, robust learning from small data, deployment in memory constrained settings as well as environmental considerations. In this paper, we propose a novel method SRatio that can utilize information from high performing complex models (viz. deep neural networks, boosted trees, random forests) to reweight a training dataset for a potentially low performing simple model of much lower complexity such as a decision tree or a shallow network enhancing its performance. Our method also leverages the per sample hardness estimate of the simple model which is not the case with the prior works which primarily consider the complex model's confidences/predictions and is thus conceptually novel. Moreover, we generalize and formalize the concept of attaching probes to intermediate layers of a neural network to other commonly used classifiers and incorporate this into our method. The benefit of these contributions is witnessed in the experiments where on 6 UCI datasets and CIFAR-10 we outperform competitors in a majority (16 out of 27) of the cases and tie for best performance in the remaining cases. In fact, in a couple of cases, we even approach the complex model's performance. We also conduct further experiments to validate assertions and intuitively understand why our method works. Theoretically, we motivate our approach by showing that the weighted loss minimized by simple models using our weighting upper bounds the loss of the complex model.</p> 
### 16.[Fiduciary Bandits](https://proceedings.icml.cc/book/3256.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/127-Paper.pdf)
  Gal Bahar, Omer Ben-Porat, Kevin Leyton-Brown, Moshe Tennenholtz [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/127-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/127-Supplemental.pdf)
> <p>Recommendation systems often face exploration-exploitation tradeoffs: the system can only learn about the desirability of new options by recommending them to some user. Such systems can thus be modeled as multi-armed bandit settings; however, users are self-interested and cannot be made to follow recommendations. We ask whether exploration can nevertheless be performed in a way that scrupulously respects agents' interests---i.e., by a system that acts as a \emph{fiduciary}.  More formally, we introduce a  model  in  which  a recommendation system faces an exploration-exploitation tradeoff under the constraint that it can never recommend any action that it knows  yields lower reward in expectation than an agent would achieve if it acted alone. Our main contribution is a positive result: an asymptotically optimal, incentive compatible, and \emph{ex-ante} individually rational recommendation algorithm.</p> 
### 17.[Training Deep Energy-Based Models with f-Divergence Minimization](https://proceedings.icml.cc/book/3257.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/130-Paper.pdf)
  Lantao Yu, Yang Song, Jiaming Song, Stefano Ermon [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/130-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/130-Supplemental.pdf)
> <p>Deep energy-based models (EBMs) are very flexible in distribution parametrization but computationally challenging because of the intractable partition function. They are typically trained via maximum likelihood, using contrastive divergence to approximate the gradient of the KL divergence between data and model distribution. While KL divergence has many desirable properties, other f-divergences have shown advantages in training implicit density generative models such as generative adversarial networks. In this paper, we propose a general variational framework termed f-EBM to train EBMs using any desired f-divergence. We introduce a corresponding optimization algorithm and prove its local convergence property with non-linear dynamical systems theory. Experimental results demonstrate the superiority of f-EBM over contrastive divergence, as well as the benefits of training EBMs using f-divergences other than KL.</p> 
### 18.[Progressive Graph Learning for Open-Set Domain Adaptation](https://proceedings.icml.cc/book/3258.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/136-Paper.pdf)
  Yadan Luo, Zijian Wang, Zi Huang, Mahsa Baktashmotlagh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/136-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/136-Supplemental.pdf)
> <p>Domain shift is a fundamental problem in visual recognition which typically arises when the source and target data follow different distributions. The existing domain adaptation approaches which tackle this problem work in the "closed-set" setting with the assumption that the source and the target data share exactly the same classes of objects. In this paper, we tackle a more realistic problem of the "open-set" domain shift where the target data contains additional classes that were not present in the source data. More specifically, we introduce an end-to-end Progressive Graph Learning (PGL) framework where a graph neural network with episodic training is integrated to suppress underlying conditional shift and adversarial learning is adopted to close the gap between the source and target distributions. Compared to the existing open-set adaptation approaches, our approach guarantees to achieve a tighter upper bound of the target error. Extensive experiments on three standard open-set benchmarks evidence that our approach significantly outperforms the state-of-the-arts in open-set domain adaptation.</p> 
### 19.[Learning De-biased Representations with Biased Representations](https://proceedings.icml.cc/book/3259.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/138-Paper.pdf)
  Hyojin Bahng, SANGHYUK CHUN, Sangdoo Yun, Jaegul Choo, Seong Joon Oh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/138-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/138-Supplemental.pdf)
> <p>Many machine learning algorithms are trained and evaluated by splitting data from a single source into training and test sets. While such focus on \textit{in-distribution} learning scenarios has led interesting advances, it has not been able to tell if models are relying on dataset biases as shortcuts for successful prediction (e.g., using snow cues for recognising snowmobiles). Such biased models fail to generalise when the bias shifts to a different class. The \textit{cross-bias generalisation} problem has been addressed by de-biasing training data through augmentation or re-sampling, which are often prohibitive due to the data collection cost (e.g., collecting images of a snowmobile on a desert) and the difficulty of quantifying or expressing biases in the first place. In this work, we propose a novel framework to train a de-biased representation by encouraging it to be \textit{different} from a set of representations that are biased by design. This tactic is feasible in many scenarios where it is much easier to define a set of biased representations than to define and quantify bias. Our experiments and analyses show that our method discourages models from taking bias shortcuts, resulting in improved generalisation.</p> 
### 20.[Generalized Neural Policies for Relational MDPs](https://proceedings.icml.cc/book/3260.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/140-Paper.pdf)
  Sankalp Garg, Aniket Bajpai, Mausam  [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/140-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/140-Supplemental.pdf)
> <p>A Relational Markov Decision Process (RMDP) is a first-order representation to express all instances of a single probabilistic planning domain with possibly unbounded number of objects.  Early work in RMDPs outputs generalized (instance-independent) first-order policies or value functions as a means to solve all instances of a domain at once. Unfortunately, this line of work met with limited success due to inherent limitations of the representation space used in such policies or value functions. Can neural models provide the missing link by easily representing more complex generalized policies, thus making them effective on all instances of a given domain?</p>  <p>We present the first neural approach for solving RMDPs, expressed in the probabilistic planning language of RDDL. Our solution first converts an RDDL instance into a ground DBN. We then extract a graph structure from the DBN. We train a relational neural model that computes an embedding for each node in the graph and also scores each ground action as a function over the first-order action variable and object embeddings on which the action is applied. In essence, this represents a neural generalized policy for the whole domain. Given a new test problem of the same domain, we can compute all node embeddings using trained parameters and score each ground action to choose the best action using a single forward pass without any retraining. Our experiments on nine RDDL domains from IPPC demonstrate that neural generalized policies are significantly better than random and sometimes even more effective than training a state-of-the-art deep reactive policy from scratch.</p> 
### 21.[Feature-map-level Online Adversarial Knowledge Distillation](https://proceedings.icml.cc/book/3261.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/143-Paper.pdf)
  Inseop Chung, SeongUk Park, Kim Jangho, NOJUN KWAK [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/143-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/143-Supplemental.pdf)
> <p>Feature maps contain rich information about image intensity and spatial correlation. However, previous online knowledge distillation methods only utilize the class probabilities. Thus in this paper, we propose an online knowledge distillation method that transfers not only the knowledge of the class probabilities but also that of the feature map using the adversarial training framework. We train multiple networks simultaneously by employing discriminators to distinguish the feature map distributions of different networks. Each network has its corresponding discriminator which discriminates the feature map from its own as fake while classifying that of the other network as real. By training a network to fool the corresponding discriminator, it can learn the other networkâs feature map distribution. We show that our method performs better than the conventional direct alignment method such as L1 and is more suitable for online distillation. Also, we propose a novel cyclic learning scheme for training more than two networks together. We have applied our method to various network architectures on the classification task and discovered a significant improvement of performance especially in the case of training a pair of a small network and a large one.</p> 
### 22.[DRWR: A Differentiable Renderer without Rendering for Unsupervised 3D Structure Learning from Silhouette Images](https://proceedings.icml.cc/book/3262.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/145-Paper.pdf)
  Zhizhong Han, Chao Chen, Yu-Shen Liu, Matthias Zwicker [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/145-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/145-Supplemental.pdf)
> <p>Differentiable renderers have been used successfully for unsupervised 3D structure learning from 2D images because they can bridge the gap between 3D and 2D. To optimize 3D shape parameters, current renderers rely on pixel-wise losses between rendered images of 3D reconstructions and ground truth images from corresponding viewpoints. Hence they require interpolation of the recovered 3D structure at each pixel, visibility handling, and optionally evaluating a shading model. In contrast, here we propose a Differentiable Renderer Without Rendering (DRWR) that omits these steps. DRWR only relies on a simple but effective loss that evaluates how well the projections of reconstructed 3D point clouds cover the ground truth object silhouette. Specifically, DRWR employs a smooth silhouette loss to pull the projection of each individual 3D point inside the object silhouette, and a structure-aware repulsion loss to push each pair of projections that fall inside the silhouette far away from each other. Although we omit surface interpolation, visibility handling, and shading, our results demonstrate that DRWR achieves state-of-the-art accuracies under widely used benchmarks, outperforming previous methods both qualitatively and quantitatively. In addition, our training times are significantly lower due to the simplicity of DRWR.</p> 
### 23.Towards Accurate Post-training Network Quantization via Bit-Split and Stitching [:chains:](https://proceedings.icml.cc/book/3263.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/147-Paper.pdf)
  Peisong Wang, Qiang Chen, Xiangyu He, Jian Cheng [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/147-Metadata.json)
> <p>Network quantization is essential for deploying deep models to IoT devices due to the high efficiency, no matter on special hardware like TPU or general hardware like CPU and GPU. Most existing quantization approaches rely on retraining to retain accuracy, which is referred to as quantization-aware training. However, this quantization scheme assumes the access to the training data, which is not always the case. Moreover, retraining is a tedious and time-consuming procedure, which hinders the application of quantization to a wider range of tasks. Post-training quantization, on the other hand, does not have these problems. However, it has only been shown effective for 8-bit quantization due to the simple optimization strategy. In this paper, we propose a Bit-Split and Stitching framework for lower-bit post-training quantization with minimal accuracy degradation. The proposed framework are validated on a variety of computer vision tasks, including image classification, object detection, instance segmentation, with various network architectures.</p> 
### 24.[Hybrid Stochastic-Deterministic Minibatch Proximal Gradient: Less-Than-Single-Pass Optimization with Nearly Optimal Generalization](https://proceedings.icml.cc/book/3264.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/150-Paper.pdf)
  Pan Zhou, Xiao-Tong Yuan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/150-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/150-Supplemental.pdf)
> Stochastic variance-reduced gradient (SVRG) algorithms have been shown to work favorably in solving large-scale learning problems. Despite the remarkable success, the stochastic gradient complexity of SVRG-type algorithms usually scales linearly with data size and thus could still be expensive for huge data. To address this deficiency, we propose a hybrid stochastic-deterministic minibatch proximal gradient (HSDMPG) algorithm for strongly-convex problems that enjoys provably improved data-size-independent complexity guarantees. More precisely, for quadratic loss $F(\wm)$ of $n$ components, we prove that HSDMPG can attain an $\epsilon$-optimization-error  $E[F(\theta)-F(\theta^*)] \leq \epsilon$ within $\mathcal{O}\Big(\!\frac{\kappa^{1.5}}{\epsilon^{0.25}}\!  \log^{\!1.5}\!\!\big(\frac{1}{\epsilon}\big) \wedge   \Big(\!\kappa \sqrt{n}  \log^2\!\!\big(\frac{1}{\epsilon}\big) \!+\! \frac{\kappa^3}{n^{1.5}\epsilon} \!\Big)\!\Big)$ stochastic gradient evaluations, where $\kappa$ is condition number. For generic strongly convex loss functions, we prove a nearly identical complexity bound though at the cost of slightly increased logarithmic factors. For large-scale learning problems, our complexity bounds are superior to those of the prior state-of-the-art SVRG algorithms with or without dependence on data size. Particularly, in the case of $\epsilon\!=\!\mathcal{O}\big(1/\sqrt{n}\big)$ which is at the order of intrinsic excess error bound of a learning model and thus sufficient for generalization,  the stochastic gradient complexity bounds of HSDMPG~for quadratic and generic loss functions are respectively $\mathcal{O} (n^{0.875}\log^{1.5}(n))$ and $\mathcal{O} (n^{0.875}\log^{2.25}(n))$, which to our best knowledge, for the first time achieve optimal generalization in less than a single pass over data. Extensive numerical results demonstrate the computational advantages of our algorithm over the prior ones.
### 25.[Reserve Pricing in Repeated Second-Price Auctions with Strategic Bidders](https://proceedings.icml.cc/book/3265.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/151-Paper.pdf)
  Alexey Drutsa [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/151-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/151-Supplemental.pdf)
> We study revenue optimization learning algorithms for repeated second-price auctions with reserve where a seller interacts with multiple strategic bidders each of which holds a fixed private valuation for a good and seeks to maximize his expected future cumulative discounted surplus.	 We propose a novel algorithm that  has strategic regret upper bound of $O(\log\log T)$ for worst-case valuations. This pricing is based on our novel transformation that upgrades an algorithm designed for the setup with a single buyer to the multi-buyer case.  We provide theoretical guarantees on the ability of a transformed algorithm to  learn the valuation of a strategic buyer, which has uncertainty about  the future due to the presence of rivals.
### 26.[On Gradient Descent Ascent for Nonconvex-Concave Minimax Problems](https://proceedings.icml.cc/book/3266.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/179-Paper.pdf)
  Tianyi Lin, Chi Jin, Michael Jordan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/179-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/179-Supplemental.pdf)
> We consider nonconvex-concave minimax problems, $\min_{\mathbf{x}} \max_{\mathbf{y} \in \mathcal{Y}} f(\mathbf{x}, \mathbf{y})$, where $f$ is nonconvex in $\mathbf{x}$ but concave in $\mathbf{y}$ and $\mathcal{Y}$ is a convex and bounded set. One of the most popular algorithms for solving this problem is the celebrated gradient descent ascent (GDA) algorithm, which has been widely used in machine learning, control theory and economics. Despite the extensive convergence results for the convex-concave setting, GDA with equal stepsize can converge to limit cycles or even diverge in a general setting. In this paper, we present the complexity results on two-time-scale GDA for solving nonconvex-concave minimax problems, showing that the algorithm can find a stationary point of the function $\Phi(\cdot) := \max_{\mathbf{y} \in \mathcal{Y}} f(\cdot, \mathbf{y})$ efficiently. To the best our knowledge, this is the first nonasymptotic analysis for two-time-scale GDA in this setting, shedding light on its superior practical performance in training generative adversarial networks (GANs) and other real applications. 
### 27.Training Binary Neural Networks through Learning with Noisy Supervision [:chains:](https://proceedings.icml.cc/book/3267.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/181-Paper.pdf)
  Kai Han, Yunhe Wang, Yixing Xu, Chunjing Xu, Enhua Wu, Chang Xu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/181-Metadata.json)
> <p>This paper formalizes the binarization operations over neural networks from a learning perspective. In contrast to classical hand crafted rules (\eg hard thresholding) to binarize full-precision neurons, we propose to learn a mapping from full-precision neurons to the target binary ones. Each individual weight entry will not be binarized independently. Instead, they are taken as a whole to accomplish the binarization, just as they work together in generating convolution features. To help the training of the binarization mapping, the full-precision neurons after taking sign operations is regarded as some auxiliary supervision signal, which is noisy but still has valuable guidance.  An unbiased estimator is therefore introduced to mitigate the influence of the supervision noise. Experimental results on benchmark datasets indicate that the proposed binarization technique attains consistent improvements over baselines.</p> 
### 28.[Stochastic Frank-Wolfe for Constrained Finite-Sum Minimization](https://proceedings.icml.cc/book/3268.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/186-Paper.pdf)
  Geoffrey Negiar, Gideon Dresdner, Alicia Yi-Ting Tsai, Laurent El Ghaoui, Francesco Locatello, Fabian Pedregosa [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/186-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/186-Supplemental.pdf)
> We propose a novel Stochastic Frank-Wolfe ($\equiv$ Conditional Gradient) algorithm with fixed batch size tailored to the constrained optimization of a finite sum of smooth objectives. We make use of a primal-dual interpretation of the Frank-Wolfe algorithm.   Recent work to design stochastic variants of the Frank-Wolfe algorithm fall into two categories: algorithms with increasing batch size, and algorithms with constant batch size. The former have faster convergence rates but are impractical; the latter are practical but slower. Our method combines the advantages of both: it converges for any constant batch size, and has faster theoretical worst case rates than previous fixed batch size algorithms. Our experiments also show faster empirical convergence than previous fixed batch methods for several tasks.   Finally, we construct a stochastic estimator of the Frank-Wolfe gap. It allows us to bound the true Frank-Wolfe gap, which is a primal-dual gap in the convex case and a measure of stationarity in general.  Our gap estimator can therefore be used as a practical stopping criterion in all cases.
### 29.Do We Really Need to Access the Source Data? Source Hypothesis Transfer for Unsupervised Domain Adaptation [:chains:](https://proceedings.icml.cc/book/3269.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/194-Paper.pdf)
  Jian Liang, Dapeng Hu, Jiashi Feng [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/194-Metadata.json)
> <p>Unsupervised domain adaptation (UDA) aims to leverage the knowledge learned from a labeled source dataset to solve similar tasks in a new unlabeled domain. Prior UDA methods typically require to access the source data when learning to adapt the model, making them risky and inefficient for decentralized private data. In this work we tackle a novel setting where only a trained source model is available and investigate how we can effectively utilize such a model without source data to solve UDA problems. To this end, we propose a simple yet generic representation learning framework, named \emph{Source HypOthesis Transfer} (SHOT). Specifically, SHOT freezes the classifier module (hypothesis) of the source model and learns the target-specific feature extraction module by exploiting both information maximization and self-supervised pseudo-labeling to implicitly align representations from the target domains to the source hypothesis. In this way, the learned target model can directly predict the labels of target data. We further investigate several techniques to refine the network architecture to parameterize the source model for better transfer performance. To verify its versatility, we evaluate SHOT in a variety of adaptation cases including closed-set, partial-set, and open-set domain adaptation. Experiments indicate that SHOT yields state-of-the-art results among multiple domain adaptation benchmarks.</p> 
### 30.[Acceleration through spectral density estimation](https://proceedings.icml.cc/book/3270.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/195-Paper.pdf)
  Fabian Pedregosa, Damien Scieur [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/195-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/195-Supplemental.pdf)
> <p>We develop a framework for designing optimal optimization methods in terms of their average-case runtime. This yields a new class of methods that achieve acceleration through a model of the Hessian's expected spectral density. We develop explicit algorithms for the uniform, Marchenko-Pastur and exponential distribution. These methods are momentum-based gradient algorithms whose hyper-parameters can be estimated cheaply using only the norm and the trace of the Hessian, in stark contrast with classical accelerated methods like Nesterov acceleration and Polyak momentum that require knowledge of the Hessian's largest and smallest singular value. Empirical results on quadratic, logistic regression and neural network show the proposed methods always match and in many cases significantly improve upon classical accelerated methods.</p> 
### 31.[Graph Structure of Neural Networks](https://proceedings.icml.cc/book/3271.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/201-Paper.pdf)
  Jiaxuan You, Kaiming He, Jure Leskovec, Saining Xie [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/201-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/201-Supplemental.pdf)
> <p>Neural networks are often represented as graphs of connections between the neurons. However, despite their wide use there is currently no understanding of the relationship between the graph structure of a neural network and its predictive performance. Here we systematically investigate this relationship, via developing a novel graph-based representation of neural networks called relational graph, where computation is specified by rounds of message exchange along the graph structure. Using our novel framework we show that (1) there is a âsweet spotâ, where relational graphs within certain range of average path length and clustering coefficient lead to neural networks with significant improvements in predictive performance; (2) perhaps even more surprisingly, we find that these sweet spots tend to highly correlate across different architectures and datasets; and, (3) we show that discovering top-performing relational graphs only requires a few epochs of training. Overall, our results suggest promising avenues for designing and understanding neural networks with graph representations.</p> 
### 32.[Optimal Continual Learning has Perfect Memory and is NP-hard](https://proceedings.icml.cc/book/3272.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/204-Paper.pdf)
  Jeremias Knoblauch, Hisham Husain, Tom Diethe [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/204-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/204-Supplemental.pdf)
> <p>Continual Learning (CL) algorithms incrementally learn a predictor or representation across multiple sequentially observed tasks. Designing CL algorithms that perform reliably and avoid so-called catastrophic forgetting has proven a persistent challenge. The current paper develops a theoretical approach that explains why. In particular, we derive the computational properties which CL algorithms would have to possess in order to avoid catastrophic forgetting. Our main finding is that such optimal CL algorithms generally solve an NP-hard problem and will require perfect memory to do so. The findings are of theoretical interest, but also explain the excellent performance of CL algorithms using experience replay, episodic memory and core sets relative to regularization-based approaches.</p> 
### 33.[Clinician-in-the-Loop Decision Making: Reinforcement Learning with Near-Optimal Set-Valued Policies](https://proceedings.icml.cc/book/3273.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/205-Paper.pdf)
  Shengpu Tang, Aditya Modi, Michael Sjoding, Jenna Wiens [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/205-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/205-Supplemental.pdf)
> <p>Standard reinforcement learning aims to find an optimal policy that identifies the best action for each state. However, in healthcare settings, many actions may be near-equivalent with respect to the reward (e.g., survival). We consider an alternative objective -- learning set-valued policies to capture near-equivalent actions that lead to similar cumulative rewards. We propose a model-free, off-policy algorithm based on temporal difference learning and a near-greedy action selection heuristic. We analyze the theoretical properties of the proposed algorithm, providing optimality guarantees and demonstrate our approach on simulated environments and a real clinical task. Empirically, the proposed algorithm exhibits reasonably good convergence properties and discovers meaningful near-equivalent actions. Our work provides theoretical, as well as practical, foundations for clinician-in-the-loop decision making, in which clinicians/patients can incorporate additional knowledge (e.g., side effects and patient preference) to distinguish among near-equivalent actions. </p> 
### 34.[Computational and Statistical Tradeoffs in Inferring Combinatorial Structures of Ising Model](https://proceedings.icml.cc/book/3274.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/208-Paper.pdf)
  Ying Jin, Zhaoran Wang, Junwei Lu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/208-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/208-Supplemental.pdf)
> <p>We study the computational and statistical tradeoffs in inferring combinatorial structures of high dimensional simple zero-field ferromagnetic Ising model. Under the framework of oracle computational model where an algorithm interacts with an oracle that discourses a randomized version of truth, we characterize the computational lower bounds of learning combinatorial structures in polynomial time, under which no algorithms within polynomial-time can distinguish between graphs with and without certain structures. This hardness of learning with limited computational budget is shown to be characterized by a novel quantity called vertex overlap ratio. Such quantity is universally valid for many specific graph structures including cliques and nearest neighbors. On the other side, we attain the optimal rates for testing these structures against empty graph by proposing the quadratic testing statistics to match the lower bounds. We also investigate the relationship between computational bounds and information-theoretic bounds for such problems, and found gaps between the two boundaries in inferring some particular structures, especially for those with dense edges.</p> 
### 35.[On the Number of Linear Regions of Convolutional Neural Networks](https://proceedings.icml.cc/book/3275.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/228-Paper.pdf)
  Huan Xiong, Lei Huang, Mengyang Yu, Li Liu, Fan Zhu, Ling Shao [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/228-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/228-Supplemental.zip)
> <p>One fundamental problem in deep learning is understanding the outstanding performance of deep Neural Networks (NNs) in practice. One explanation for the superiority of NNs is that they can realize a large class of complicated functions, i.e., they have powerful expressivity. The expressivity of a ReLU NN can be quantified by the maximal number of linear regions it can separate its input space into. In this paper, we provide several mathematical results needed for studying the linear regions of CNNs, and use them to derive the maximal and average numbers of linear regions for one-layer ReLU CNNs. Furthermore, we obtain upper and lower bounds for the number of linear regions of multi-layer ReLU CNNs. Our results suggest that deeper CNNs have more powerful expressivity than their shallow counterparts, while CNNs have more expressivity than fully-connected NNs per parameter. </p> 
### 36.[Deep Streaming Label Learning](https://proceedings.icml.cc/book/3276.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/230-Paper.pdf)
  Zhen Wang, Liu Liu, Dacheng Tao [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/230-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/230-Supplemental.pdf)
> <p>In multi-label learning, each instance can be associated with multiple and non-exclusive labels. Previous studies assume that all the labels in the learning process are fixed and static; however, they ignore the fact that the labels will emerge continuously in changing environments. In order to fill in these research gaps, we propose a novel deep neural network (DNN) based framework, Deep Streaming Label Learning (DSLL), to classify instances with newly emerged labels effectively. DSLL can explore and incorporate the knowledge from past labels and historical models to understand and develop emerging new labels. DSLL consists of three components: 1) a streaming label mapping to extract deep relationships between new labels and past labels with a novel label-correlation aware loss; 2) a streaming feature distillation propagating feature-level knowledge from the historical model to a new model; 3) a senior student network to model new labels with the help of knowledge learned from the past. Theoretically, we prove that DSLL admits tight generalization error bounds for new labels in the DNN framework. Experimentally, extensive empirical results show that the proposed method performs significantly better than the existing state-of-the-art multi-label learning methods to handle the continually emerging new labels.</p> 
### 37.[From Importance Sampling to Doubly Robust Policy Gradient](https://proceedings.icml.cc/book/3277.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/236-Paper.pdf)
  Jiawei Huang, Nan Jiang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/236-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/236-Supplemental.pdf)
> <p>We show that on-policy policy gradient (PG) and its variance reduction variants can be derived by taking finite-difference of function evaluations supplied by estimators from the importance sampling (IS) family for off-policy evaluation (OPE). Starting from the doubly robust (DR) estimator (Jiang &amp; Li, 2016), we provide a simple derivation of a very general and flexible form of PG, which subsumes the state-of-the-art variance reduction technique (Cheng et al., 2019) as its special case and immediately hints at further variance reduction opportunities overlooked by existing literature. We analyze the variance of the new DR-PG estimator, compare it to existing methods as well as the Cramer-Rao lower bound of policy gradient, and empirically show its effectiveness.</p> 
### 38.Loss Function Search for Face Recognition [:chains:](https://proceedings.icml.cc/book/3278.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/245-Paper.pdf)
  Xiaobo Wang, Shuo Wang, Shifeng Zhang, Cheng Chi, Tao Mei [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/245-Metadata.json)
> <p>In face recognition, designing margin-based (\textit{e.g.}, angular, additive, additive angular margins) softmax loss functions plays an important role to learn discriminative features. However, these hand-crafted heuristic methods may be sub-optimal because they require much effort to explore the large design space. Recently, an AutoML for loss function search method AM-LFS has been derived, which leverages reinforcement learning to search loss functions during the training process. But its search space is complex and unstable that hindering its superiority. In this paper, we first analyze that the key to enhance the feature discrimination is actually \textbf{how to reduce the softmax probability}. We then design a unified formulation for the current margin-based softmax losses. Accordingly, we define a novel search space and develop a reward-guided search method to automatically obtain the best candidate. Experimental results on a variety of face recognition benchmarks have demonstrated the effectiveness of our method over the state-of-the-art alternatives.</p> 
### 39.[Breaking the Curse of Space Explosion: Towards Efficient NAS with Curriculum Search](https://proceedings.icml.cc/book/3279.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/248-Paper.pdf)
  Yong Guo, Yaofo Chen, Yin Zheng, Peilin Zhao, Jian Chen, Junzhou Huang, Mingkui Tan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/248-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/248-Supplemental.pdf)
> <p>Neural architecture search (NAS) has become an important approach to automatically find effective architectures. To cover all possible good architectures, we need to search in an extremely large search space with billions of candidate architectures. More critically, given a large search space, we may face a very challenging issue of space explosion. However, due to the limitation of computational resources, we can only sample a very small proportion of the architectures, which provides insufficient information for the training. As a result, existing methods may often produce suboptimal architectures. To alleviate this issue, we propose a curriculum search method that starts from a small search space and gradually incorporates the learned knowledge to guide the search in a large space. With the proposed search strategy, our Curriculum Neural Architecture Search (CNAS) method significantly improves the search efficiency and finds better architectures than existing NAS methods. Extensive experiments on CIFAR-10 and ImageNet demonstrate the effectiveness of the proposed method.</p> 
### 40.[Automatic Reparameterisation of Probabilistic Programs](https://proceedings.icml.cc/book/3280.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/271-Paper.pdf)
  Maria Gorinova, Dave Moore, Matthew Hoffman [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/271-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/271-Supplemental.pdf)
> <p>Probabilistic programming has emerged as a powerful paradigm in statistics, applied science, and machine learning: by decoupling modelling from inference, it promises to allow modellers to directly reason about the processes generating data. However, the performance of inference algorithms can be dramatically affected by the parameterisation used to express a model, requiring users to transform their programs in non-intuitive ways. We argue for automating these transformations, and demonstrate that mechanisms available in recent modelling frameworks can implement non-centring and related reparameterisations. This enables new inference algorithms, and we propose two: a simple approach using interleaved sampling and a novel variational formulation that searches over a continuous space of parameterisations. We show that these approaches enable robust inference across a range of models, and can yield more efficient samplers than the best fixed parameterisation.</p> 
### 41.Kernel Methods for Cooperative Multi-Agent Learning with Delays [:chains:](https://proceedings.icml.cc/book/3281.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/281-Paper.pdf)
  Abhimanyu Dubey, Alex `Sandy&#x27; Pentland [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/281-Metadata.json)
> <p>Cooperative multi-agent decision making involves a group of agents collectively solving individual learning problems, while communicating over a (sparse) network with delays. In this paper, we consider the kernelised contextual bandit problem, where the reward obtained by an agent is an arbitrary linear function of the contexts' images in the related reproducing kernel Hilbert space (RKHS), and a group of agents must cooperate to collectively solve their unique decision problems. We propose Coop-KernelUCB that provides near-optimal bounds on the per-agent regret in this setting, and is both computationally and communicatively efficient. For special cases of the cooperative problem, we also provide variants of Coop-KernelUCB that provides optimal per-agent regret. In addition, our algorithm generalizes several existing results in the multi-agent bandit setting. Finally, on a series of both synthetic and real-world multi-agent network benchmarks, our algorithm significantly outperforms existing clustering or consensus-based algorithms, even in the linear setting.</p> 
### 42.[Robust Multi-Agent Decision-Making with Heavy-Tailed Payoffs](https://proceedings.icml.cc/book/3282.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/282-Paper.pdf)
  Abhimanyu Dubey, Alex `Sandy&#x27; Pentland [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/282-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/282-Supplemental.pdf)
> <p>We study the heavy-tailed stochastic bandit problem in the cooperative multiagent setting, where a group of agents interact with a common bandit problem, while communicating on a network with delays. Existing algorithms for the stochastic bandit in this setting utilize confidence intervals arising from an averaging-based communication protocol known as~\textit{running consensus}, that does not lend itself to robust estimation for heavy-tailed settings. We propose \textsc{MP-UCB}, a decentralized multi-agent algorithm for the cooperative stochastic bandit that incorporates robust estimation with a message-passing protocol. We prove optimal regret bounds for \textsc{MP-UCB} for several problem settings, and also demonstrate its superiority to existing methods. Furthermore, we establish the first lower bounds for the cooperative bandit problem, in addition to providing efficient algorithms for robust bandit estimation of location.</p> 
### 43.Learning the Valuations of a $k$-demand Agent [:chains:](https://proceedings.icml.cc/book/3283.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/285-Paper.pdf)
  Hanrui Zhang, Vincent Conitzer [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/285-Metadata.json)
> We study problems where a learner aims to learn the valuations of an agent by observing which goods he buys under varying price vectors.  More specifically, we consider the case of a $k$-demand agent, whose valuation over the goods is additive when receiving up to $k$ goods, but who has no interest in receiving more than $k$ goods.  We settle the query complexity for the active-learning (preference elicitation) version, where the learner chooses the prices to post, by giving a {\em biased binary search} algorithm, generalizing the classical binary search procedure. We complement our query complexity upper bounds by lower bounds that match up to lower-order terms.  We also study the passive-learning version in which the learner does not control the prices, and instead they are sampled from some distribution.  We show that in the PAC model for passive learning, any {\em empirical risk minimizer} has a sample complexity that is optimal up to a factor of $\widetilde{O}(k)$.
### 44.[Rigging the Lottery: Making All Tickets Winners](https://proceedings.icml.cc/book/3284.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/287-Paper.pdf)
  Utku Evci, Trevor Gale, Jacob Menick, Pablo Samuel Castro, Erich Elsen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/287-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/287-Supplemental.pdf)
> <p>Compared to dense networks, sparse neural networks are shown to be more parameter efficient, more compute efficient and have been used to decrease wall clock inference times.  There is a large body of work on training dense networks to yield sparse networks for inference, but this limits the size of the largest trainable sparse model to that of the largest trainable dense model. In this paper we introduce a method to train sparse neural networks with a fixed parameter count and a fixed computational cost throughout training, without sacrificing accuracy relative to existing dense-to-sparse training methods. Our method updates the topology of the sparse network during training by using parameter magnitudes and infrequent gradient calculations.  We show that this approach requires fewer floating-point operations (FLOPs) to achieve a given level of accuracy compared to prior techniques. We demonstrate state-of-the-art sparse training results on a variety of networks and datasets, including ResNet-50, MobileNets on Imagenet-2012, and RNNs on WikiText-103. Finally, we provide some insights into why allowing the topology to change during the optimization can overcome local minima encountered when the topology remains static.</p> 
### 45.[Active Learning on Attributed Graphs via Graph   Cognizant Logistic Regression and Preemptive Query Generation](https://proceedings.icml.cc/book/3285.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/321-Paper.pdf)
  Florence Regol, Soumyasundar Pal, Yingxue Zhang, Mark Coates [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/321-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/321-Supplemental.pdf)
> <p>Node classification in attributed graphs is an important task in multiple practical settings, but it can often be difficult or expensive to obtain labels. Active learning can improve the achieved classification performance for a given budget on the number of queried labels. The best existing methods are based on graph neural networks, but they often perform poorly unless a sizeable validation set of labelled nodes is available in order to choose good hyperparameters. We propose a novel graph-based active learning algorithm for the task of node classification in attributed graphs. Our algorithm uses graph cognizant logistic regression, equivalent to a linearized graph-convolutional neural network (GCNN), for the prediction phase and maximizes the expected error reduction in the query phase. To reduce the delayexperienced by a labeller interacting with the system, we derive a preemptive querying system that calculates a new query during the labelling process. To address the setting where learning starts with almost no labelled data, we also develop a hybrid algorithm that performs adaptive model averaging of label propagation and linearized GCNN inference. We conduct experiments on four public benchmark datasets, demonstrating a significant improvement over state-of-the-art approaches. We illustrate the practical value of the method by applying it to a private commercial dataset that is used for the task of identifying faulty links in a microwave link network.</p> 
### 46.[Performative Prediction](https://proceedings.icml.cc/book/3286.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/325-Paper.pdf)
  Juan Perdomo, Tijana Zrnic, Celestine Mendler-DÃ¼nner, University of California Moritz Hardt [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/325-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/325-Supplemental.zip)
> <p>When predictions support decisions they may influence the outcome they aim to predict. We call such predictions performative; the prediction influences the target. Performativity is a well-studied phenomenon in policy-making that has so far been neglected in supervised learning. When ignored, performativity surfaces as undesirable distribution shift, routinely addressed with retraining.</p>  <p>We develop a risk minimization framework for performative prediction bringing together concepts from statistics, game theory, and causality. A conceptual novelty is an equilibrium notion we call performative stability. Performative stability implies that the predictions are calibrated not against past outcomes, but against the future outcomes that manifest from acting on the prediction. Our main results are necessary and sufficient conditions for the convergence of retraining to a performatively stable point of nearly minimal loss.</p>  <p>In full generality, performative prediction strictly subsumes the setting known as strategic classification. We thus also give the first sufficient conditions for retraining to overcome strategic feedback effects.</p> 
### 47.[On Layer Normalization in the Transformer Architecture](https://proceedings.icml.cc/book/3287.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/328-Paper.pdf)
  Ruibin Xiong, Yunchang Yang, Di He, Kai Zheng, Shuxin Zheng, Chen Xing, Huishuai Zhang, Yanyan Lan, Liwei Wang, Tie-Yan Liu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/328-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/328-Supplemental.pdf)
> <p>The Transformer is widely used in natural language processing tasks. To train a Transformer however, one usually needs a carefully designed learning rate warm-up stage, which is shown to be crucial to the final performance but will slow down the optimization and bring more hyper-parameter tunings. In this paper, we first study theoretically why the learning rate warm-up stage is essential and show that the location of layer normalization matters. Specifically, we prove with mean field theory that at initialization, for the original-designed Post-LN Transformer, which places the layer normalization between the residual blocks, the expected gradients of the parameters near the output layer are large. Therefore, using a large learning rate on those gradients makes the training unstable. The warm-up stage is practically helpful for avoiding this problem. On the other hand, our theory also shows that if the layer normalization is put inside the residual blocks (recently proposed as Pre-LN Transformer), the gradients are well-behaved at initialization. This motivates us to remove the warm-up stage for the training of Pre-LN Transformers. We show in our experiments that Pre-LN Transformers without the warm-up stage can reach comparable results with baselines while requiring significantly less training time and hyper-parameter tuning on a wide range of applications.</p> 
### 48.The many Shapley values for model explanation [:chains:](https://proceedings.icml.cc/book/3288.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/334-Paper.pdf)
  Mukund Sundararajan, Amir Najmi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/334-Metadata.json)
> <p>The Shapley value has become a popular method to attribute the prediction of a machine-learning model on an input to its base features. The use of the Shapley value is justified by citing ~\cite{Shapley53} showing that it is the \emph{unique} method that satisfies certain good properties (\emph{axioms}). </p>  <p>There are, however, a multiplicity of ways in which the Shapley value is operationalized in the attribution problem. These differ in how they reference the model, the training data, and the explanation context. These give very different results, rendering the uniqueness result meaningless. Furthermore, we find that previously proposed approaches can produce counterintuitive attributions in theory and in practice---for instance, they can assign non-zero attributions to features that are not even referenced by the model. </p>  <p>In this paper, we use the axiomatic approach to study the differences between some of the many operationalizations of the Shapley value for attribution, and propose a technique called Baseline Shapley (BShap) that is backed by a proper uniqueness result. We also contrast BShap with Integrated Gradients, another extension of Shapley value to the continuous setting.</p> 
### 49.[Linear Convergence of Randomized Primal-Dual Coordinate Method for Large-scale Linear Constrained Convex Programming](https://proceedings.icml.cc/book/3289.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/339-Paper.pdf)
  Daoli Zhu, Lei Zhao [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/339-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/339-Supplemental.pdf)
> <p>Linear constrained convex programming (LCCP) has many practical applications, including support vector machine (SVM) and machine learning portfolio (MLP) problems. We propose the randomized primal-dual coordinate (RPDC) method, a randomized coordinate extension of the first-order primal-dual method by Cohen and Zhu, 1984 and Zhao and Zhu, 2019, to solve LCCP. We randomly choose a block of variables based on the uniform distribution and apply linearization and a Bregman-like function (core function) to the selected block to obtain simple parallel primal-dual decomposition for LCCP. We establish almost surely convergence and expected O(1/t) convergence rate. Under global strong metric subregularity, we establish the linear convergence of RPDC. Both SVM and MLP problems satisfy the global strong metric subregularity condition under some reasonable conditions. Finally, we discuss the implementation details of RPDC and present numerical experiments on SVM and MLP problems to verify the linear convergence.</p> 
### 50.[New Oracle-Efficient Algorithms for Private Synthetic Data Release](https://proceedings.icml.cc/book/3290.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/352-Paper.pdf)
  Giuseppe Vietri, Steven Wu, Mark Bun, Thomas Steinke, Grace Tian [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/352-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/352-Supplemental.pdf)
> We present three new algorithms for constructing differentially   private synthetic data---a sanitized version of a sensitive dataset   that approximately preserves the answers to a large collection of   statistical queries. All three algorithms are   \emph{oracle-efficient} in the sense that they are computationally   efficient when given access to an optimization oracle. Such an oracle can   be implemented using many existing (non-private)   optimization tools such as sophisticated integer program solvers. While the   accuracy of the synthetic data is contingent on the oracle&#x27;s   optimization performance, the algorithms satisfy differential   privacy even in the worst case. For all three algorithms, we provide   theoretical guarantees for both accuracy and privacy. Through   empirical evaluation, we demonstrate that our methods scale well   with both the dimensionality of the data and the number of queries. In the high privacy   regime (corresponding to low privacy loss $\eps$), our algorithms achieve better accuracy than state-of-the-art techniques, including the High-Dimensional Matrix Mechanism (McKenna et al.~VLDB 2018). 
### 51.[Oracle Efficient Private Non-Convex Optimization](https://proceedings.icml.cc/book/3291.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/354-Paper.pdf)
  Seth Neel, Aaron Roth, Giuseppe Vietri, Steven Wu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/354-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/354-Supplemental.pdf)
> <p>One of the most effective algorithms for differentially private learning and optimization is \emph{objective perturbation}. This technique augments a given optimization problem (e.g. deriving from an ERM problem) with a random linear term, and then exactly solves it. However, to date, analyses of this approach crucially rely on the convexity and smoothness of the objective function. We give two algorithms that extend this approach substantially. The first algorithm requires nothing except boundedness of the loss function, and operates over a discrete domain. Its privacy and accuracy guarantees hold even without assuming convexity. We are able to extend traditional analyses of objective perturbation by introducing a novel <code>normalization</code> step into the algorithm, which provides enough stability to be differentially private even without second-order conditions. The second algorithm operates over a continuous domain and requires only that the loss function be bounded and Lipschitz in its continuous parameter. Its privacy analysis does not even require convexity. Its accuracy analysis does require convexity, but does not require second order conditions like smoothness. We complement our theoretical results with an empirical evaluation of the non-convex case, in which we use an integer program solver as our optimization oracle. We find that for the problem of learning linear classifiers, directly optimizing for 0/1 loss using our approach can out-perform the more standard approach of privately optimizing a convex-surrogate loss function on the Adult dataset.</p> 
### 52.Universal Asymptotic Optimality of Polyak Momentum [:chains:](https://proceedings.icml.cc/book/3292.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/360-Paper.pdf)
  Damien Scieur, Fabian Pedregosa [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/360-Metadata.json)
> <p>We consider the average-case runtime analysis of algorithms for minimizing quadratic objectives. In this setting, and contrary to the more classical worst-case analysis, non-asymptotic convergence rates and optimal algorithms depend on the full spectrum of the Hessian through its expected spectral distribution.  Under mild assumptions, we show that these optimal methods converge asymptotically towards Polyak momentum \emph{independently} of the expected spectral density. This makes Polyak momentum universally (i.e., independent of the spectral distribution) asymptotically average-case optimal.</p> 
### 53.[Adversarial Robustness via Runtime Masking and Cleansing](https://proceedings.icml.cc/book/3293.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/377-Paper.pdf)
  Yi-Hsuan Wu, Chia-Hung Yuan, Shan-Hung (Brandon) Wu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/377-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/377-Supplemental.pdf)
> <p>Deep neural networks are shown to be vulnerable to adversarial attacks. This motivates robust learning techniques, such as the adversarial training, whose goal is to learn a network that is robust against adversarial attacks.  However, the sample complexity of robust learning can be significantly larger than that of âstandardâ learning. In this paper, we propose improving the adversarial robustness of a network by leveraging the potentially large test data seen at runtime. We devise a new defense method, called runtime masking and cleansing (RMC), that adapts the network at runtime before making a prediction to dynamically mask network gradients and cleanse the model of the non-robust features inevitably learned during the training process due to the size limit of the training set. We conduct experiments on real-world datasets and the results demonstrate the effectiveness of RMC empirically.</p> 
### 54.[Implicit Euler Skip Connections: Enhancing Adversarial Robustness via Numerical Stability](https://proceedings.icml.cc/book/3294.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/381-Paper.pdf)
  Mingjie Li, Lingshen He, Zhouchen Lin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/381-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/381-Supplemental.pdf)
> <p>Deep neural networks have achieved great success in various areas. However, recent works have found that neural networks are vulnerable to adversarial attacks, which leads to a hot topic nowadays. Although many approaches have been proposed to enhance the robustness of neural networks, few of them explored robust architectures for neural networks. On this account, we try to address such an issue from the perspective of dynamic system in this work. By viewing ResNet as an explicit Euler discretization of an ordinary differential equation (ODE), for the first time, we find that the adversarial robustness of ResNet is connected to the numerical stability of the corresponding dynamic system. Namely, more stable numerical schemes may correspond to more robust deep networks. Furthermore, inspired by the implicit Euler method for solving numerical ODE problems, we propose Implicit Euler skip connections (IE-Skips) by modifying the original skip connection in ResNet or its variants. Then we theoretically prove its advantages under the adversarial attack. Experimental results show that our ResNet with IE-Skips can largely improve the robustness and the generalization ability under adversarial attacks when compared with the vanilla ResNet of the same parameter size.</p> 
### 55.[Best Arm Identification for Cascading Bandits in the Fixed Confidence Setting](https://proceedings.icml.cc/book/3295.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/393-Paper.pdf)
  Zixin Zhong, Wang Chi Cheung, Vincent Tan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/393-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/393-Supplemental.zip)
> <p>We design and analyze CascadeBAI, an algorithm for finding the best set of K items, also called an arm, within the framework of cascading bandits. An upper bound on the time complexity of CascadeBAI is derived by overcoming a crucial analytical challenge, namely, that of probabilistically estimating the amount of available feedback at each step. To do so, we define a new class of random variables (r.v.'s) which we term as left-sided sub-Gaussian r.v.'s; these are r.v.'s whose cumulant generating functions (CGFs) can be bounded by a quadratic only for non-positive arguments of the CGFs. This enables the application of a sufficiently tight Bernstein-type concentration inequality. We show, through the derivation of a lower bound on the time complexity, that the performance of CascadeBAI is optimal in some practical regimes. Finally, extensive numerical simulations corroborate the efficacy of CascadeBAI as well as the tightness of our upper bound on its time complexity.</p> 
### 56.[Robustness to Programmable String Transformations via Augmented Abstract Training](https://proceedings.icml.cc/book/3296.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/398-Paper.pdf)
  Yuhao Zhang, Aws Albarghouthi, Loris D&#x27;Antoni [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/398-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/398-Supplemental.zip)
> <p>Deep neural networks for natural language processing tasks are vulnerable to adversarial input perturbations. Existing works have proposed to improve the robustness against specific adversarial input perturbations (e.g., token substitutions), but do not consider general perturbations such as token insertions, token deletions, token swaps, etc. To fill this gap, we present a technique to train models that are robust to user-defined string transformations. Our technique combines data augmentation---to detect worst-case transformed inputs---and verifiable training using abstract interpretation---to further increase the robustness of the model on the worst-case transformed inputs. We use our technique to train models on the AG and SST2 datasets and show that the resulting models are robust to combinations of user-defined transformations mimicking spelling mistakes and other meaning-preserving transformations.</p> 
### 57.[The Complexity of Finding Stationary Points with Stochastic Gradient Descent](https://proceedings.icml.cc/book/3297.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/413-Paper.pdf)
  Yoel Drori, Ohad Shamir [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/413-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/413-Supplemental.pdf)
> We study the iteration complexity of stochastic gradient descent (SGD) for minimizing the gradient norm of smooth, possibly nonconvex functions. We provide several results, implying that the classical $\mathcal{O}(\epsilon^{-4})$ upper bound (for making the average gradient norm less than $\epsilon$) cannot be improved upon, unless a combination of additional assumptions is made. Notably, this holds even if we limit ourselves to convex quadratic functions. We also show that for nonconvex functions, the feasibility of minimizing gradients with SGD is surprisingly sensitive to the choice of optimality criteria.
### 58.[Sample Complexity Bounds for 1-bit Compressive Sensing and Binary Stable Embeddings with Generative Priors](https://proceedings.icml.cc/book/3298.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/423-Paper.pdf)
  Zhaoqiang Liu, Selwyn Gomes, Avtansh Tiwari, Jonathan Scarlett [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/423-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/423-Supplemental.pdf)
> The goal of standard 1-bit compressive sensing is to accurately recover an unknown sparse vector from binary-valued measurements, each indicating the sign of a linear function of the vector.  Motivated by recent advances in compressive sensing with generative models, where a generative modeling assumption replaces the usual sparsity assumption, we study the problem of 1-bit compressive sensing with generative models. We first consider noiseless 1-bit measurements, and provide sample complexity bounds for approximate recovery under i.i.d.~Gaussian measurements and a Lipschitz continuous generative prior, as well as a near-matching algorithm-independent lower bound. Moreover, we demonstrate that the Binary $\epsilon$-Stable Embedding property, which characterizes the robustness of the reconstruction to measurement errors and noise, also holds for 1-bit compressive sensing with Lipschitz continuous generative models with sufficiently many Gaussian measurements.  In addition, we apply our results to neural network generative models, and provide a proof-of-concept numerical experiment demonstrating significant improvements over sparsity-based approaches.
### 59.[Class-Weighted Classification: Trade-offs and Robust Approaches](https://proceedings.icml.cc/book/3299.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/434-Paper.pdf)
  Ziyu Xu, Chen Dan, Justin Khim, Pradeep Ravikumar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/434-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/434-Supplemental.pdf)
> <p>We consider imbalanced classification, the problem in which a label may have low marginal probability relative to other labels, by weighting losses according to the correct class.  First, we examine the convergence rates of the expected excess weighted risk of plug-in classifiers where the weighting for the plug-in classifier and the risk may be different. This leads to irreducible errors that do not converge to the weighted Bayes risk, which motivates our consideration of robust risks. We define a robust risk that minimizes risk over a set of weightings and show excess risk bounds for this problem.  Finally, we show that particular choices of the weighting set leads to a special instance of conditional value at risk (CVaR) from stochastic programming, which we call label conditional value at risk (LCVaR). Additionally, we generalize this weighting to derive a new robust risk problem that we call label heterogeneous conditional value at risk (LHCVaR). Finally, we empirically demonstrate the efficacy of LCVaR and LHCVaR on improving class conditional risks.</p> 
### 60.Neural Architecture Search in a Proxy Validation Loss Landscape [:chains:](https://proceedings.icml.cc/book/3300.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/439-Paper.pdf)
  Yanxi Li, Minjing Dong, Yunhe Wang, Chang Xu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/439-Metadata.json)
> <p>This paper searches for the optimal neural architecture  by minimizing a proxy of validation loss. Existing neural architecture search (NAS) methods used to discover the optimal neural architecture that best fits the validation examples given the up-to-date network weights. However, back propagation with a number of validation examples could be time consuming, especially when it needs to be repeated many times in NAS. Though these  intermediate validation results are invaluable, they would be wasted if we cannot use them to predict the future from the past. In this paper, we propose to approximate the validation loss landscape by learning a mapping from neural architectures to their corresponding validate losses. The optimal neural architecture thus can be easily identified as the minimum of this proxy validation loss landscape. A novel sampling strategy is further developed for an efficient approximation of the loss landscape. Theoretical analysis indicates that our sampling strategy can reach a lower error rate and a lower label complexity compared with a uniform sampling. Experimental results on benchmarks demonstrate that the architecture searched by the proposed algorithm can achieve a satisfactory accuracy with less time cost.</p> 
### 61.[Almost Tune-Free Variance Reduction](https://proceedings.icml.cc/book/3301.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/453-Paper.pdf)
  Bingcong Li, Lingda Wang, Georgios B. Giannakis [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/453-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/453-Supplemental.pdf)
> <p>The variance reduction class of algorithms including the representative ones, SVRG and SARAH, have well documented merits for empirical risk minimization problems. However, they require grid search to tune parameters (step size and the number of iterations per inner loop) for optimal performance. This work introduces <code>almost tune-free' SVRG and SARAH schemes equipped with i) Barzilai-Borwein (BB) step sizes; ii) averaging; and, iii) the inner loop length adjusted to the BB step sizes. In particular, SVRG, SARAH, and their BB variants are first reexamined through an</code>estimate sequence' lens to enable new averaging methods that tighten their convergence rates theoretically, and improve their performance empirically when the step size or the inner loop length is chosen large. Then a simple yet effective means to adjust the number of iterations per inner loop is developed to enhance the merits of the proposed averaging schemes and BB step sizes. Numerical tests corroborate the proposed methods.</p> 
### 62.[Uniform Convergence of Rank-weighted Learning ](https://proceedings.icml.cc/book/3302.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/454-Paper.pdf)
  Liu Leqi, Justin Khim, Adarsh Prasad, Pradeep Ravikumar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/454-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/454-Supplemental.pdf)
> <p>The decision-theoretic foundations of classical machine learning models have largely focused on estimating model parameters that minimize the expectation of a given loss function. However, as machine learning models are deployed in varied contexts, such as in high-stakes decision-making and societal settings, it is clear that these models are not just evaluated by their average performances. In this work, we study a novel notion of L-Risk based on the classical idea of rank-weighted learning. These L-Risks, induced by rank-dependent weighting functions with bounded variation, is a unification of popular risk measures such as conditional value-at-risk and those defined by cumulative prospect theory. We give uniform convergence bounds of this broad class of risk measures and study their consequences on a logistic regression example.</p> 
### 63.Non-autoregressive Translation with Disentangled Context Transformer [:chains:](https://proceedings.icml.cc/book/3303.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/477-Paper.pdf)
  Jungo Kasai, James Cross, Marjan Ghazvininejad, Jiatao Gu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/477-Metadata.json)
> <p>State-of-the-art neural machine translation models generate a translation from left to right and every step is conditioned on the previously generated tokens. The sequential nature of this generation process causes fundamental latency in inference since we cannot generate multiple tokens in each sentence in parallel. We propose an attention-masking based model, called Disentangled Context (DisCo) transformer, that simultaneously generates all tokens given different contexts. The DisCo transformer is trained to predict every output token given an arbitrary subset of the other reference tokens. We also develop the parallel easy-first inference algorithm, which iteratively refines every token in parallel and reduces the number of required iterations. Our extensive experiments on 7 translation directions with varying data sizes demonstrate that our model achieves competitive, if not better, performance compared to the state of the art in non-autoregressive machine translation while significantly reducing decoding time on average. </p> 
### 64.More Information Supervised Probabilistic Deep Face Embedding Learning [:chains:](https://proceedings.icml.cc/book/3304.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/478-Paper.pdf)
  Ying Huang, Shangfeng Qiu, Wenwei Zhang, Xianghui Luo, Jinzhuo Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/478-Metadata.json)
> <p>Researches using margin based comparison loss demonstrate the effectiveness of penalizing the distance between face feature and their corresponding class centers. Despite their popularity and excellent performance, they do not explicitly encourage the generic embedding learning for an open set recognition problem. In this paper, we analyse margin based softmax loss in probability view. With this perspective, we propose two general principles: 1) monotonically decreasing and 2) margin probability penalty, for designing new margin loss functions. Unlike methods optimized with single comparison metric, we provide a new perspective to treat open set face recognition as a problem of information transmission.  And the generalization capability for face embedding is gained with more clean information. An auto-encoder architecture called Linear-Auto-TS-Encoder(LATSE) is proposed to corroborate this finding. Extensive experiments on several benchmarks demonstrate that LATSE help face embedding to gain more generalization capability and it boost the single model performance with open training dataset to more than 99% on MegaFace test.</p> 
### 65.Reinforcement Learning for Non-Stationary Markov Decision Processes: The Blessing of (More) Optimism [:chains:](https://proceedings.icml.cc/book/3305.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/488-Paper.pdf)
  Wang Chi Cheung, David Simchi-Levi, Ruihao Zhu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/488-Metadata.json)
> <p>We consider un-discounted reinforcement learning (RL) in  Markov decision processes (MDPs) under drifting non-stationarity, \ie, both the reward and state transition distributions are allowed to evolve over time, as long as their respective total variations, quantified by suitable metrics, do not exceed certain \emph{variation budgets}. We first develop the Sliding Window Upper-Confidence bound for Reinforcement Learning with Confidence Widening (\texttt{SWUCRL2-CW}) algorithm, and establish its dynamic regret bound when the variation budgets are known. In addition, we propose the Bandit-over-Reinforcement Learning (\texttt{BORL}) algorithm to adaptively tune the \sw~to achieve the same dynamic regret bound, but  in a \emph{parameter-free} manner, \ie, without knowing the variation budgets. Notably, learning drifting MDPs via conventional optimistic exploration presents a unique challenge absent in existing (non-stationary) bandit learning settings. We overcome the challenge by a novel confidence widening technique that incorporates additional optimism.</p> 
### 66.[Improved Sleeping Bandits with Stochastic Action Sets and Adversarial Rewards](https://proceedings.icml.cc/book/3306.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/490-Paper.pdf)
  Aadirupa Saha, Pierre Gaillard, Michal Valko [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/490-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/490-Supplemental.pdf)
> In this paper, we consider the problem of sleeping bandits with stochastic action sets and adversarial rewards. In this setting, in contrast to most work in bandits, the actions may not be available at all times. For instance, some products might be out of stock in item recommendation. The best existing efficient (i.e., polynomial-time) algorithms for this problem only guarantee a $O(T^{2/3})$ upper-bound on the regret. Yet, inefficient algorithms based on EXP4 can achieve $O(\sqrt{T})$.  In this paper, we provide a new computationally efficient algorithm inspired by EXP3 satisfying a regret of order  $O(\sqrt{T})$ when the availabilities of each action $i \in \cA$ are independent. We then study the most general version of the problem where at each round available sets are generated from some unknown arbitrary distribution (i.e., without the independence assumption) and propose an efficient algorithm with $O(\sqrt {2^K T})$ regret guarantee. Our theoretical results are corroborated with experimental evaluations.
### 67.[From PAC to Instance-Optimal Sample Complexity in the Plackett-Luce Model](https://proceedings.icml.cc/book/3307.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/491-Paper.pdf)
  Aadirupa Saha, Aditya Gopalan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/491-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/491-Supplemental.pdf)
> We consider PAC learning a good item from $k$-subsetwise feedback sampled from a Plackett-Luce probability model, with instance-dependent sample complexity performance. In the setting where subsets of a fixed size can be tested and top-ranked feedback is made available to the learner, we give an optimal instance-dependent algorithm with a  sample complexity bound for PAC best arm identification algorithm of  $O\bigg(\frac{\Theta_{[k]}}{k}\sum_{i = 2}^n\max\Big(1,\frac{1}{\Delta_i^2}\Big) \ln\frac{k}{\delta}\Big(\ln \frac{1}{\Delta_i}\Big)\bigg)$, $\Delta_i$ being the Plackett-Luce parameter gap between the best and the $i^{th}$ best item, and $\Theta_{[k]}$ is the sum of the Plackett-Luce parameters for top-$k$ items. The algorithm is based on a wrapper around a PAC winner-finding algorithm with weaker performance guarantees to adapt to the hardness of the input instance. The sample complexity is also shown to be multiplicatively better depending on the length of rank-ordered feedback available in each subset-wise play. We show optimality of our algorithms with matching sample complexity lower bounds. We next address the winner-finding problem in Plackett-Luce models in the fixed-budget setting with instance dependent upper and lower bounds on the misidentification probability, of $\Omega\left(\exp(-2 \tilde \Delta Q) \right)$ for a given budget $Q$, where $\tilde \Delta$ is an explicit instance-dependent problem complexity parameter. Numerical performance results are also reported for the algorithms. 
### 68.Reliable Fidelity and Diversity Metrics for Generative Models [:chains:](https://proceedings.icml.cc/book/3308.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/503-Paper.pdf)
  Muhammad Ferjad Naeem, Seong Joon Oh, Yunjey Choi, Youngjung Uh, Jaejun Yoo [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/503-Metadata.json)
> <p>Devising indicative evaluation metrics for the image generation task remains an open problem. The most widely used metric for measuring the similarity between real and generated images has been the Frechet Inception Distance (FID) score. Since it does not differentiate the fidelity and diversity aspects of the generated images, recent papers have introduced variants of precision and recall metrics to diagnose those properties separately. In this paper, we show that even the latest version of the precision and recall metrics are not reliable yet. For example, they fail to detect the match between two identical distributions, they are not robust against outliers, and the evaluation hyperparameters are selected arbitrarily. We propose density and coverage metrics that solve the above issues. We analytically and experimentally show that density and coverage provide more interpretable and reliable signals for practitioners than the existing metrics.</p> 
### 69.Learning Factorized Weight Matrix for Joint Image Filtering [:chains:](https://proceedings.icml.cc/book/3309.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/506-Paper.pdf)
  Xiangyu Xu, Yongrui Ma, Wenxiu Sun [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/506-Metadata.json)
> <p>Joint image filtering is a fundamental problem in computer vision with applications in many different areas. Most existing algorithms solve this problem with a weighted averaging process to aggregate input pixels. However, the weight matrix of this process is often empirically designed and not robust to complex input. In this work, we propose to learn the weight matrix for joint image filtering. This is a challenging problem, as directly learning a large weight matrix is computationally intractable. To address this issue, we introduce the correlation of deep features to approximate the aggregation weights. However, this strategy only uses inner product for the weight matrix estimation, which limits the performance of the proposed algorithm. Therefore, we further propose to learn a nonlinear function to predict sparse residuals of the feature correlation matrix. Note that the proposed method essentially factorizes the weight matrix into a low-rank and a sparse matrix and then learn both of them simultaneously with deep neural networks. Extensive experiments show that the proposed algorithm compares favorably against the state-of-the-art approaches on a wide variety of joint image filtering tasks.</p> 
### 70.[Likelihood-free MCMC with Amortized Approximate Ratio Estimators](https://proceedings.icml.cc/book/3310.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/518-Paper.pdf)
  Joeri Hermans, Volodimir Begy, Gilles Louppe [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/518-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/518-Supplemental.pdf)
> <p>Posterior inference with an intractable likelihood is becoming an increasingly common task in scientific domains which rely on sophisticated computer simulations. Typically, these forward models do not admit tractable densities forcing practitioners to rely on approximations. This work introduces a novel approach to address the intractability of the likelihood and the marginal model. We achieve this by learning a flexible amortized estimator which approximates the likelihood-to-evidence ratio. We demonstrate that the learned ratio estimator can be embedded in \textsc{mcmc} samplers to approximate likelihood-ratios between consecutive states in the Markov chain, allowing us to draw samples from the intractable posterior. Techniques are presented to improve the numerical stability and to measure the quality of an approximation. The accuracy of our approach is demonstrated on a variety of benchmarks against well-established techniques. Scientific applications in physics show its applicability.</p> 
### 71.[Attacks Which Do Not Kill Training Make Adversarial Learning Stronger](https://proceedings.icml.cc/book/3311.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/520-Paper.pdf)
  Jingfeng Zhang, Xilie Xu, Bo Han, Gang Niu, Lizhen Cui, Masashi Sugiyama, Mohan Kankanhalli [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/520-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/520-Supplemental.pdf)
> <p>Adversarial training based on the minimax formulation is necessary for obtaining adversarial robustness of trained models. However, it is conservative or even pessimistic so that it sometimes hurts the natural generalization. In this paper, we raise a fundamental question---do we have to trade off natural generalization for adversarial robustness? We argue that adversarial training is to employ confident adversarial data for updating the current model. We propose a novel approach of friendly adversarial training (FAT): rather than employing most adversarial data maximizing the loss, we search for least adversarial (i.e., friendly adversarial) data minimizing the loss, among the adversarial data that are confidently misclassified. Our novel formulation is easy to implement by just stopping the most-adversarial data searching algorithms such as PGD (projected gradient descent) early, which we call early-stopped PGD. Theoretically, FAT is justified by an upper bound of the adversarial risk. Empirically, early-stopped PGD allows us to answer the earlier question negatively---adversarial robustness can indeed be achieved without compromising the natural generalization.</p> 
### 72.[GradientDICE: Rethinking Generalized Offline Estimation of Stationary Values](https://proceedings.icml.cc/book/3312.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/522-Paper.pdf)
  Shangtong Zhang, Bo Liu, Shimon Whiteson [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/522-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/522-Supplemental.pdf)
> <p>We present GradientDICE for estimating the density ratio between the state distribution of the target policy and the sampling distribution in off-policy reinforcement learning. GradientDICE fixes several problems of GenDICE (Zhang et al., 2020), the current state-of-the-art for estimating such density ratios.  Namely, the optimization problem in GenDICE is not a convex-concave saddle-point problem once nonlinearity in optimization variable parameterization is introduced to ensure positivity,  so primal-dual algorithms are not guaranteed to find the desired solution.  However, such nonlinearity is essential to ensure the consistency of GenDICE even with a tabular representation. This is a fundamental contradiction, resulting from GenDICE's original formulation of the optimization problem. In GradientDICE, we optimize a different objective from GenDICE by using the Perron-Frobenius theorem and eliminating GenDICE's use of divergence, such that nonlinearity in parameterization is not necessary for GradientDICE,  which is provably convergent under linear function approximation.</p> 
### 73.[Provably Convergent Two-Timescale Off-Policy Actor-Critic with Function Approximation](https://proceedings.icml.cc/book/3313.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/523-Paper.pdf)
  Shangtong Zhang, Bo Liu, Hengshuai Yao, Shimon Whiteson [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/523-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/523-Supplemental.pdf)
> <p>We present the first provably convergent two-timescale off-policy actor-critic algorithm (COF-PAC) with function approximation. Key to COF-PAC is the introduction of a new critic, the emphasis critic,  which is trained via Gradient Emphasis Learning (GEM),  a novel combination of the key ideas of Gradient Temporal Difference Learning and Emphatic Temporal Difference Learning. With the help of the emphasis critic and the canonical value function critic,  we show convergence for COF-PAC, where the critics are linear and the actor can be nonlinear. </p> 
### 74.[Adversarial Attacks on Probabilistic Autoregressive Forecasting Models](https://proceedings.icml.cc/book/3314.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/526-Paper.pdf)
  RaphaÃ«l Dang-Nhu, Gagandeep Singh, Pavol Bielik, Martin Vechev [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/526-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/526-Supplemental.pdf)
> <p>We develop an effective generation of adversarial attacks on neural models that output a sequence of probability distributions rather than a sequence of single values. This setting includes the recently proposed deep probabilistic autoregressive forecasting models that estimate the probability distribution of a time series given its past and achieve state-of-the-art results in a diverse set of application domains. The key technical challenge we address is how to effectively differentiate through the Monte-Carlo estimation of statistics of the output sequence joint distribution. Additionally, we extend prior work on probabilistic forecasting to the Bayesian setting which allows conditioning on future observations, instead of only on past observations. We demonstrate that our approach can successfully generate attacks with small input perturbations in two challenging tasks where robust decision making is crucial -- stock market trading and prediction of electricity consumption.</p> 
### 75.Informative Dropout for Robust Representation Learning: A Shape-bias Perspective [:chains:](https://proceedings.icml.cc/book/3315.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/528-Paper.pdf)
  Baifeng Shi, Dinghuai Zhang, Qi Dai, Jingdong Wang, Zhanxing Zhu, Yadong Mu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/528-Metadata.json)
> <p>Convolutional Neural Networks (CNNs) are known to rely more on local texture rather than global shape when making decisions. Recent work also indicates a close relationship between CNN's texture-bias and its robustness against distribution shift, adversarial perturbation, random corruption, etc. In this work, we attempt at improving various kinds of robustness universally by alleviating CNN's texture bias. Specifically, with inspiration from human visual system, we propose a light-weight model-agnostic method, namely Informative Dropout (InfoDrop), to improve interpretability and reduce texture bias. Through extensive experiments, we observe enhanced robustness in various tasks (domain generalization, few-shot classification, robustness against random corruptions and adversarial robustness). Moreover, we show that as a local algorithm, InfoDrop can further improve performance when incorporated with other algorithms for global structure modeling (e.g. Non-Local blocks). To the best of our knowledge, this work is the first attempt to improve different kinds of robustness in a unified model, shedding new light on relationship between shape-bias and robustness, also on new approaches to trustworthy machine learning algorithms.</p> 
### 76.[Graph Convolutional Network for Recommendation with Low-pass Collaborative Filters](https://proceedings.icml.cc/book/3316.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/530-Paper.pdf)
  Wenhui Yu, Zheng Qin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/530-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/530-Supplemental.pdf)
> <p>Graph Convolutional Neural Network (GCN) is widely used in graph data learning tasks such as recommendation. When facing to a large graph, the graph convolution is very computational expensive thus is simplified in all existing GCNs, while is seriously impaired due to the oversimplification. To address this gap, we leverage the original graph convolution in GCN and propose a Low-pass Collaborative Filter (LCF) to make it applicable to the large graph. LCF is designed to remove the noise in observed data, and it also reduces the complexity of graph convolution without hurting its ability. Experiments show that LCF improves the effectiveness and efficiency of graph convolution and our GCN outperforms existing GCNs significantly.</p> 
### 77.[SoftSort: A Differantiable Continuous Relaxation of the argsort Operator](https://proceedings.icml.cc/book/3317.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/535-Paper.pdf)
  Sebastian Prillo, Julian Eisenschlos [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/535-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/535-Supplemental.pdf)
> <p>Sorting is an important procedure in computer science. However, the argsort operator - which takes as input a vector and returns its sorting per-mutation - has a discrete image and thus zero gradients almost everywhere. This prohibits end-to-end, gradient-based learning of models that rely on the argsort operator. A natural way to overcome this problem is to replace the argsort operator with a continuous relaxation. Recent work has shown a number of ways to do this. However, the relaxations proposed so far are computationally complex. In this work we propose a simple continuous relaxation for the argsort operator. Unlike previous works, our relaxation is straight-forward: it can be implemented in three lines of code, achieves state-of-the-art performance, is easy to reason about mathematically - substantially simplifying proofs - and is up to six times faster than competing approaches. We open-source the code to reproduce all of the experiments</p> 
### 78.[Too Relaxed to Be Fair](https://proceedings.icml.cc/book/3318.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/544-Paper.pdf)
  Michael Lohaus, MichaÃ«l Perrot, Ulrike von Luxburg [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/544-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/544-Supplemental.pdf)
> <p>We address the problem of classification under fairness constraints. Given a notion of fairness, the goal is to learn a classifier that is not discriminatory against a group of individuals. In the literature, this problem is often formulated as a constrained optimization problem and solved using relaxations of the fairness constraints. We show that many existing relaxations are unsatisfactory: even if a model satisfies the relaxed constraint, it can be surprisingly unfair. We propose a principled framework to solve this problem. This new approach uses a strongly convex formulation and comes with theoretical guarantees on the fairness of its solution. In practice, we show that this method gives promising results on real data.</p> 
### 79.[Lorentz Group Equivariant Neural Network for Particle Physics](https://proceedings.icml.cc/book/3319.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/561-Paper.pdf)
  Alexander Bogatskiy, Brandon Anderson, Jan Offermann, Marwah Roussi, David Miller, Risi Kondor [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/561-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/561-Supplemental.pdf)
> <p>We present a neural network architecture that is fully equivariant with respect to transformations under the Lorentz group, a fundamental symmetry of space and time in physics. The architecture is based on the theory of the finite-dimensional representations of the Lorentz group and the equivariant nonlinearity involves the tensor product. For classification tasks in particle physics, we show that such an equivariant architecture leads to drastically simpler models that have relatively few learnable parameters and are much more physically interpretable than leading approaches that use CNNs and point cloud approaches. The performance of the network is tested on a public classification dataset [https://zenodo.org/record/2603256] for tagging top quark decays given energy-momenta of jet constituents produced in proton-proton collisions.</p> 
### 80.[One-shot Distributed Ridge Regression in High Dimensions](https://proceedings.icml.cc/book/3320.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/566-Paper.pdf)
  Yue Sheng, Edgar Dobriban [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/566-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/566-Supplemental.pdf)
> <p>To scale up data analysis, distributed and parallel computing approaches are increasingly needed. Here we study a fundamental problem in this area: How to do ridge regression in a distributed computing environment? We study one-shot methods constructing weighted combinations of ridge regression estimators computed on each machine. By analyzing the mean squared error in a high dimensional model where each predictor has a small effect, we discover several new phenomena including that the efficiency depends strongly on the signal strength, but does not degrade with many workers, the risk decouples over machines, and the unexpected consequence that the optimal weights do not sum to unity. We also propose a new optimally weighted one-shot ridge regression algorithm. Our results are supported by simulations and real data analysis.</p> 
### 81.[Streaming k-Submodular Maximization under Noise subject to Size Constraint](https://proceedings.icml.cc/book/3321.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/571-Paper.pdf)
  Lan N. Nguyen, My T. Thai [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/571-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/571-Supplemental.pdf)
> <p>Maximizing on k-submodular functions subject to size constraint has received extensive attention recently. In this paper, we investigate a more realistic scenario of this problem that (1) obtaining exact evaluation of an objective function is impractical, instead, its noisy version is acquired; and (2) algorithms are required to take only one single pass over dataset, producing solutions in a timely manner. We propose two novel streaming algorithms, namely DStream and RStream, with their theoretical performance guarantees. We further demonstrate the efficiency of our algorithms in two application, showing that our algorithms can return comparative results to state-of-the-art non-streaming methods while using a much fewer number of queries.</p> 
### 82.[Variational Imitation Learning with Diverse-quality Demonstrations](https://proceedings.icml.cc/book/3322.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/577-Paper.pdf)
  Voot Tangkaratt, Bo Han, Mohammad Emtiyaz Khan, Masashi Sugiyama [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/577-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/577-Supplemental.pdf)
> <p>Learning from demonstrations can be challenging when the quality of demonstrations is diverse, and even more so when the quality is unknown and there is no additional information to estimate the quality. We propose a new method for imitation learning in such scenarios. We show that simple quality-estimation approaches might fail due to compounding error, and fix this issue by jointly estimating both the quality and reward using a variational approach. Our method is easy to implement within reinforcement-learning frameworks and also achieves state-of-the-art performance on continuous-control benchmarks.Our work enables scalable and data-efficient imitation learning under more realistic settings than before.</p> 
### 83.[Task Understanding from Confusing Multi-task Data](https://proceedings.icml.cc/book/3323.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/578-Paper.pdf)
  Xin Su, Yizhou Jiang, Shangqi Guo, Feng Chen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/578-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/578-Supplemental.zip)
> <p>Beyond machine learning's success in the specific tasks, research for learning multiple tasks simultaneously is referred to as multi-task learning. However, existing multi-task learning needs manual definition of tasks and manual task annotation. A crucial problem for advanced intelligence is how to understand the human task concept using basic input-output pairs. Without task definition, samples from multiple tasks are mixed together and result in a confusing mapping challenge. We propose Confusing Supervised Learning (CSL) that takes these confusing samples and extracts task concepts by differentiating between these samples. We theoretically proved the feasibility of the CSL framework and designed an iterative algorithm to distinguish between tasks. The experiments demonstrate that our CSL methods could achieve a human-like task understanding without task labeling in multi-function regression problems and multi-task recognition problems.</p> 
### 84.[Cost-effective Interactive Attention Learning with Neural Attention Process](https://proceedings.icml.cc/book/3324.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/579-Paper.pdf)
  Jay Heo, Junhyeon Park, Hyewon Jeong, Kwang Joon Kim, Juho Lee, Eunho Yang, Sung Ju Hwang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/579-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/579-Supplemental.pdf)
> <p>We propose a novel interactive learning framework which we refer to as Interactive Attention Learning (IAL), in which the human supervisors interactively manipulate the allocated attentions, to correct the model's behavior by updating the attention-generating network. However, such a model is prone to overfitting due to scarcity of human annotations, and requires costly retraining. Moreover, it is almost infeasible for the human annotators to examine attentions on tons of instances and features. We tackle these challenges by proposing a sample-efficient attention mechanism and a cost-effective reranking algorithm for instances and features. First, we propose Neural Attention Process (NAP), which is an attention generator that can update its behavior by incorporating new attention-level supervisions without any retraining. Secondly, we propose an algorithm which prioritizes the instances and the features by their negative impacts, such that the model can yield large improvements with minimal human feedback. We validate IAL on various time-series datasets from multiple domains (healthcare, real-estate, and computer vision) on which it significantly outperforms baselines with conventional attention mechanisms, or without cost-effective reranking, with substantially less retraining and human-model interaction cost.</p> 
### 85.[Channel Equilibrium Networks for Learning Deep Representation](https://proceedings.icml.cc/book/3325.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/590-Paper.pdf)
  Wenqi Shao, Shitao Tang, Xingang Pan, Ping Tan, Xiaogang Wang, Ping Luo [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/590-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/590-Supplemental.pdf)
> <p>Convolutional Neural Networks (CNNs) are typically constructed by stacking multiple building blocks, each of which contains a normalization layer such as batch normalization (BN) and a rectified linear function such as ReLU.  However, this work shows that the combination of normalization and rectified linear function leads to inhibited channels, which have small magnitude and contribute little to the learned feature representation, impeding the generalization ability of CNNs. Unlike prior arts that simply removed the inhibited channels, we propose to ``wake them up'' during training by designing a novel neural building block, termed Channel Equilibrium (CE) block, which enables channels at the same layer to contribute equally to the learned representation. We show that CE is able to prevent inhibited channels both empirically and theoretically. CE has several appealing benefits. (1) It can be integrated into many advanced CNN architectures such as ResNet and MobileNet, outperforming their original networks. (2) CE has an interesting connection with the Nash Equilibrium, a well-known solution of a non-cooperative game. (3) Extensive experiments show that CE achieves state-of-the-art performance on various challenging benchmarks such as ImageNet and COCO. </p> 
### 86.[Optimal Non-parametric Learning in Repeated Contextual Auctions with  Strategic Buyer](https://proceedings.icml.cc/book/3326.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/602-Paper.pdf)
  Alexey Drutsa [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/602-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/602-Supplemental.pdf)
> We study learning algorithms that optimize revenue in repeated contextual posted-price auctions where a seller interacts with a single strategic buyer that seeks to maximize his cumulative discounted surplus. The buyer&#x27;s valuation of a good is a fixed private function of a $d$-dimensional context (feature) vector that describes the good being sold. In contrast to existing studies on repeated contextual auctions with strategic buyer, in our work, the seller is not assumed to know the parametric model that underlies this valuation function. We introduce a novel non-parametric learning algorithm that is horizon-independent and has tight strategic regret upper bound of $\Theta(T^{d/(d+1)})$. We also non-trivially generalize several value-localization techniques of non-contextual repeated auctions  to make them effective in  the considered contextual non-parametric learning of the buyer valuation function. 
### 87.[Topological Autoencoders](https://proceedings.icml.cc/book/3327.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/613-Paper.pdf)
  Michael Moor, Max Horn, Bastian Rieck, Karsten Borgwardt [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/613-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/613-Supplemental.pdf)
> <p>We propose a novel approach for preserving topological structures of the input space in latent representations of autoencoders. Using persistent homology, a technique from topological data analysis, we calculate topological signatures of both the input and latent space to derive a topological loss term.  Under weak theoretical assumptions, we construct this loss in a differentiable manner, such that the encoding learns to retain multi-scale connectivity information.  We show that our approach is theoretically well-founded and that it exhibits favourable latent representations on a synthetic manifold as well as on real-world image data sets, while preserving low reconstruction errors.</p> 
### 88.[An Accelerated DFO Algorithm for Finite-sum Convex Functions](https://proceedings.icml.cc/book/3328.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/623-Paper.pdf)
  Yuwen Chen, Antonio Orvieto, Aurelien Lucchi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/623-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/623-Supplemental.pdf)
> <p>Derivative-free optimization (DFO) has recently gained a lot of momentum in machine learning, spawning interest in the community to design faster methods for problems where gradients are not accessible. While some attention has been given to the concept of acceleration in the DFO literature, there exists no algorithm with a provably accelerated rate of convergence for objective functions with a finite-sum structure. Stochastic algorithms that use acceleration in such a setting are prone to instabilities, making it difficult to reach convergence. In this work, we exploit the finite-sum structure of the objective to design a variance-reduced DFO algorithm that probably yields an accelerated rate of convergence. We prove rates of convergence for both smooth convex and strongly-convex finite-sum objective functions. Finally, we validate our theoretical results empirically on several datasets.</p> 
### 89.[The Shapley Taylor Interaction Index](https://proceedings.icml.cc/book/3329.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/625-Paper.pdf)
  Mukund Sundararajan, Kedar Dhamdhere, Ashish Agarwal [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/625-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/625-Supplemental.zip)
> The attribution problem, that is the problem of attributing a model&#x27;s prediction to its base features, is well-studied. We extend the notion of attribution to also apply to feature interactions.  The Shapley value is a commonly used method to attribute a model&#x27;s prediction to its base features. We propose a generalization of the Shapley value called Shapley-Taylor index that attributes the model&#x27;s prediction to interactions of subsets of features up to some size $k$. The method is analogous to how the truncated Taylor Series decomposes the function value at a certain point using its  derivatives at a different point. In fact, we show that the Shapley Taylor index is equal to the Taylor Series of the multilinear extension of the set-theoretic behavior of the model.     We axiomatize this method using the standard Shapley axioms---linearity, dummy, symmetry and efficiency---and an additional axiom that we call the interaction distribution axiom. This new axiom explicitly characterizes how interactions are distributed for a class of functions that model pure interaction.   We contrast the Shapley-Taylor index against the previously proposed Shapley Interaction index from the cooperative game theory literature. We also apply the Shapley Taylor index to three models and identify interesting qualitative insights.
### 90.[Privately detecting changes in unknown distributions](https://proceedings.icml.cc/book/3330.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/632-Paper.pdf)
  Rachel Cummings, Sara Krehbiel, Yuliia Lut, Wanrong Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/632-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/632-Supplemental.pdf)
> <p>The change-point detection problem seeks to identify distributional changes in streams of data. Increasingly, tools for change-point detection are applied in settings where data may be highly sensitive and formal privacy guarantees are required, such as identifying disease outbreaks based on hospital records, or IoT devices detecting activity within a home. Differential privacy has emerged as a powerful technique for enabling data analysis while preventing information leakage about individuals. Much of the prior work on change-point detection---including the only private algorithms for this problem---requires complete knowledge of the pre-change and post-change distributions. However, this assumption is not realistic for many practical applications of interest. This work develops differentially private algorithms for solving the change-point problem when the data distributions are unknown. Additionally, the data may be sampled from distributions that change smoothly over time, rather than fixed pre-change and post-change distributions.  We apply our algorithms to detect changes in the linear trends of such data streams. We also provide experimental results to empirically validate the performance of our algorithms.</p> 
### 91.[CAUSE: Learning Granger Causality from Event Sequences using Attribution Methods](https://proceedings.icml.cc/book/3331.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/637-Paper.pdf)
  Wei Zhang, Thomas  Panum, Somesh Jha, Prasad Chalasani, David Page [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/637-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/637-Supplemental.pdf)
> <p>We study the problem of learning Granger causality between event types from asynchronous, interdependent, multi-type event sequences. Existing work suffers from either limited model flexibility or poor model explainability and thus fails to uncover Granger causality across a wide variety of event sequences with diverse event interdependency. To address these weaknesses, we propose CAUSE (Causality from AttribUtions on Sequence of Events), a novel framework for the studied task. The key idea of CAUSE is to first implicitly capture the underlying event interdependency by fitting a neural point process, and then extract from the process a Granger causality statistic using an axiomatic attribution method. Across multiple datasets riddled with diverse event interdependency, we demonstrate that CAUSE achieves superior performance on correctly inferring the inter-type Granger causality over a range of state-of-the-art methods.</p> 
### 92.[Efficient Continuous Pareto Exploration in Multi-Task Learning](https://proceedings.icml.cc/book/3332.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/640-Paper.pdf)
  Pingchuan Ma, Tao Du, Wojciech Matusik [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/640-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/640-Supplemental.pdf)
> <p>Tasks in multi-task learning often correlate, conflict, or even compete with each other. As a result, a single solution that is optimal for all tasks rarely exists. Recent papers introduced the concept of Pareto optimality to this field and directly cast multi-task learning as multi-objective optimization problems, but solutions returned by existing methods are typically finite, sparse, and discrete. We present a novel, efficient method that generates locally continuous Pareto sets and Pareto fronts, which opens up the possibility of continuous analysis of Pareto optimal solutions in machine learning problems. We scale up a recent theoretical result in multi-objective optimization to modern machine learning problems by proposing a sample-based sparse linear system, for which standard Hessian-free solvers in machine learning can be applied. We compare our method to the state-of-the-art algorithms and demonstrate its usage of analyzing local Pareto sets on various multi-task classification problems. The experimental results confirm that our algorithm reveals the primary directions in local Pareto sets for trade-off balancing, finds more solutions with different trade-offs efficiently, and scales well to tasks with millions of parameters.</p> 
### 93.WaveFlow: A Compact Flow-based Model for Raw Audio [:chains:](https://proceedings.icml.cc/book/3333.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/647-Paper.pdf)
  Wei Ping, Kainan Peng, Kexin Zhao, Zhao Song [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/647-Metadata.json)
> <p>In this work, we propose WaveFlow, a small-footprint generative flow for raw audio, which is directly trained with maximum likelihood. It handles the long-range structure of 1-D waveform with a dilated 2-D convolutional architecture, while modeling the local variations using expressive autoregressive functions. WaveFlow provides a unified view of likelihood-based models for 1-D data, including WaveNet and WaveGlow as special cases. It generates high-fidelity speech as WaveNet, while synthesizing several orders of magnitude faster as it only requires a few sequential steps to generate very long waveforms with hundreds of thousands of time-steps. Furthermore, it can significantly reduce the likelihood gap that has existed between autoregressive models and flow-based models for efficient synthesis. Finally, our small-footprint WaveFlow has only 5.91M parameters, which is 15Ã smaller than WaveGlow. It can generate 22.05 kHz high-fidelity audio 42.6Ã faster than real-time (at a rate of 939.3 kHz) on a V100 GPU without engineered inference kernels.</p> 
### 94.[Multi-Agent Determinantal Q-Learning](https://proceedings.icml.cc/book/3334.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/651-Paper.pdf)
  Yaodong Yang, Ying Wen, Jun Wang, Liheng Chen, Kun Shao, David Mguni, Weinan Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/651-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/651-Supplemental.pdf)
> <p>Centralized training with decentralized execution has become an important paradigm in multi-agent learning. Though practical, current methods rely on restrictive assumptions to decompose the centralized  value function across agents for execution. In this paper, we eliminate this restriction by proposing multi-agent determinantal Q-learning. Our method is established on Q-DPP, a novel extension of determinantal point process (DPP) to multi-agent setting. Q-DPP promotes agents to acquire diverse behavioral models; this allows  a natural factorization of the joint Q-functions with no need for \emph{a priori} structural constraints on the value function or special network architectures. We demonstrate that Q-DPP generalizes major solutions including VDN, QMIX, and QTRAN on decentralizable cooperative tasks. To efficiently draw samples  from Q-DPP, we develop a linear-time sampler with theoretical approximation guarantee. Our sampler also benefits exploration by  coordinating agents to cover orthogonal directions in the state space during training. We evaluate our algorithm on multiple cooperative benchmarks; its effectiveness has been demonstrated when compared with the state-of-the-art. </p> 
### 95.[Revisiting Spatial Invariance with Low-Rank Local Connectivity](https://proceedings.icml.cc/book/3335.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/652-Paper.pdf)
  Gamaleldin Elsayed, Prajit Ramachandran, Jon Shlens, Simon Kornblith [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/652-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/652-Supplemental.pdf)
> <p>Convolutional neural networks are among the most successful architectures in deep learning. This success is at least partially attributable to the efficacy of spatial invariance as an inductive bias. Locally connected layers, which differ from convolutional layers only in their lack of spatial invariance, usually perform poorly in practice. However, these observations still leave open the possibility that some degree of relaxation of spatial invariance may yield a better inductive bias than either convolution or local connectivity. To test this hypothesis, we design a method to relax the spatial invariance of a network layer in a controlled manner. In particular, we create a \textit{low-rank} locally connected layer, where the kernel applied at each position is constructed as a linear combination of basis kernels with spatially varying combining weights. By varying the number of basis kernels, we can control the degree of relaxation of spatial invariance. In our experiments, we find that relaxing spatial invariance improves classification accuracy over both convolution and locally connected layers across MNIST, CIFAR-10, and CelebA datasets. These results suggest that spatial invariance may be an overly restrictive prior.</p> 
### 96.[Minimax Weight and Q-Function Learning for Off-Policy Evaluation](https://proceedings.icml.cc/book/3336.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/658-Paper.pdf)
  Masatoshi Uehara, Jiawei Huang, Nan Jiang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/658-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/658-Supplemental.zip)
> <p>We provide theoretical investigations into off-policy evaluation in reinforcement learning using function approximators for (marginalized) importance weights and value functions. Our contributions include: (1) A new estimator, MWL, that directly estimates importance ratios over the state-action distributions, removing the reliance on knowledge of the behavior policy as in prior work  (Liu et.al, 2018), (2) Another new estimator, MQL, obtained by swapping the roles of importance weights and value-functions in MWL. MQL has an intuitive interpretation of minimizing average Bellman errors and can be combined with MWL in a doubly robust manner, (3) Several additional results that offer further insights, including the sample complexities of MWL and MQL, their asymptotic optimality in the tabular setting, how the learned importance weights depend the choice of the discriminator class, and how our methods provide a unified view of some old and new algorithms in RL.</p> 
### 97.[Tensor denoising and completion based on ordinal observations](https://proceedings.icml.cc/book/3337.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/663-Paper.pdf)
  Chanwoo Lee, Miaoyan Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/663-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/663-Supplemental.pdf)
> <p>Higher-order tensors arise frequently in applications such as neuroimaging, recommendation system, and social network analysis. We consider the problem of low-rank tensor estimation from possibly incomplete, ordinal-valued observations. Two related problems are studied, one on tensor denoising and another on tensor completion. We propose a multi-linear cumulative link model, develop a rank-constrained M-estimator, and obtain theoretical accuracy guarantees. Our mean squared error bound enjoys a faster convergence rate than previous results, and we show that the proposed estimator is minimax optimal under the class of low-rank models. Furthermore, the procedure developed serves as an efficient completion method which guarantees consistent recovery of an order-K (d,...,d)-dimensional low-rank tensor using only O(Kd) noisy, quantized observations. We demonstrate the outperformance of our approach over previous methods on the tasks of clustering and collaborative filtering. </p> 
### 98.[Learning Human Objectives by Evaluating Hypothetical Behavior](https://proceedings.icml.cc/book/3338.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/664-Paper.pdf)
  Siddharth Reddy, Anca Dragan, Sergey Levine, Shane Legg, Jan Leike [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/664-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/664-Supplemental.pdf)
> <p>We seek to align agent behavior with a user's objectives in a reinforcement learning setting with unknown dynamics, an unknown reward function, and unknown unsafe states. The user knows the rewards and unsafe states, but querying the user is expensive. We propose an algorithm that safely and efficiently learns a model of the user's reward function by posing 'what if?' questions about hypothetical agent behavior. We start with a generative model of initial states and a forward dynamics model trained on off-policy data. Our method uses these models to synthesize hypothetical behaviors, asks the user to label the behaviors with rewards, and trains a neural network to predict the rewards. The key idea is to actively synthesize the hypothetical behaviors from scratch by maximizing tractable proxies for the value of information, without interacting with the environment. We call this method reward query synthesis via trajectory optimization (ReQueST). We evaluate ReQueST with simulated users on a state-based 2D navigation task and the image-based Car Racing video game. The results show that ReQueST significantly outperforms prior methods in learning reward models that transfer to new environments with different initial state distributions. Moreover, ReQueST safely trains the reward model to detect unsafe states, and corrects reward hacking before deploying the agent.</p> 
### 99.[Counterfactual Cross-Validation: Stable Model Selection Procedure for Causal Inference Models](https://proceedings.icml.cc/book/3339.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/676-Paper.pdf)
  Yuta Saito, Shota Yasui [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/676-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/676-Supplemental.pdf)
> <p>We study the model selection problem in \textit{conditional average treatment effect} (CATE) prediction. Unlike previous works on this topic, we focus on preserving the rank order of the performance of candidate CATE predictors to enable accurate and stable model selection. To this end, we analyze the model performance ranking problem and formulate guidelines to obtain a better evaluation metric. We then propose a novel metric that can identify the ranking of the performance of CATE predictors with high confidence. Empirical evaluations demonstrate that our metric outperforms existing metrics in both model selection and hyperparameter tuning tasks.</p> 
### 100.[Learning Efficient Multi-agent Communication: An Information Bottleneck Approach](https://proceedings.icml.cc/book/3340.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/695-Paper.pdf)
  Rundong Wang, Xu He, Runsheng Yu, Wei Qiu, Bo An, Zinovi Rabinovich [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/695-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/695-Supplemental.zip)
> <p>We consider the problem of the limited-bandwidth communication for multi-agent reinforcement learning, where agents cooperate with the assistance of a communication protocol and a scheduler. The protocol and scheduler jointly determine which agent is communicating what message and to whom. Under the limited bandwidth constraint, a communication protocol is required to generate informative messages. Meanwhile, an unnecessary communication connection should not be established because it occupies limited resources in vain. In this paper, we develop an Informative Multi-Agent Communication (IMAC) method to learn efficient communication protocols as well as scheduling. First, from the perspective of communication theory, we prove that the limited bandwidth constraint requires low-entropy messages throughout the transmission. Then inspired by the information bottleneck principle, we learn a valuable and compact communication protocol and a weight-based scheduler. To demonstrate the efficiency of our method, we conduct extensive experiments in various cooperative and competitive multi-agent tasks with different numbers of agents and different bandwidths. We show that IMAC converges faster and leads to efficient communication among agents under the limited bandwidth as compared to many baseline methods.</p> 
### 101.MoNet3D: Towards Accurate Monocular 3D Object Localization in Real Time [:chains:](https://proceedings.icml.cc/book/3341.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/696-Paper.pdf)
  XICHUAN ZHOU, YiCong Peng, Chunqiao Long, Fengbo Ren, Cong Shi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/696-Metadata.json)
> <p>Monocular multi-object detection and localization in 3D space has been proven to be a challenging task. The MoNet3D algorithm is a novel and effective framework that can predict the 3D position of each object in a monocular image, and draw a 3D bounding box on each object. The MoNet3D method incorporates the prior knowledge of spatial geometric correlation of neighboring objects into the deep neural network training process, in order to improve the accuracy of 3D object localization. Experiments over the KITTI data set show that the accuracy of predicting the depth and horizontal coordinate of the object in 3D space can reach 96.25% and 94.74%,  respectively. Meanwhile, the method can realize the real-time image processing capability of 27.85 FPS. Our demo and code will be published on GitHub when the paper is accepted.</p> 
### 102.[SIGUA: Forgetting May Make Learning with Noisy Labels More Robust](https://proceedings.icml.cc/book/3342.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/705-Paper.pdf)
  Bo Han, Gang Niu, Xingrui Yu, QUANMING YAO, Miao Xu, Ivor Tsang, Masashi Sugiyama [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/705-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/705-Supplemental.pdf)
> <p>Given data with noisy labels, over-parameterized deep networks can gradually memorize the data, and fit everything in the end. Although equipped with corrections for noisy labels, many learning methods in this area still suffer overfitting due to undesired memorization. In this paper, to relieve this issue, we propose stochastic integrated gradient underweighted ascent (SIGUA): in a mini-batch, we adopt gradient descent on good data as usual, and learning-rate-reduced gradient ascent} on bad data; the proposal is a versatile approach where data goodness or badness is w.r.t. desired or undesired memorization given a base learning method. Technically, SIGUA pulls optimization back for generalization when their goals conflict with each other; philosophically, SIGUA shows forgetting undesired memorization can reinforce desired memorization. Experiments demonstrate that SIGUA successfully robustifies two typical base learning methods, so that their performance is often significantly improved.</p> 
### 103.[Multinomial Logit Bandit with Low Switching Cost](https://proceedings.icml.cc/book/3343.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/707-Paper.pdf)
  Kefan Dong, Yingkai Li, Qin Zhang, Yuan Zhou [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/707-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/707-Supplemental.pdf)
> We study multinomial logit bandit with limited adaptivity, where the algorithms change their exploration actions as infrequently as possible when achieving almost optimal minimax regret. We propose two measures of adaptivity: the assortment switching cost and the more fine-grained item switching cost. We present an anytime algorithm (AT-DUCB) with $O(N \log T)$ assortment switches, almost matching the lower bound $\Omega(\frac{N \log T}{ \log \log T})$. In the fixed-horizon setting, our algorithm FH-DUCB incurs $O(N \log \log T)$ assortment switches, matching the asymptotic lower bound. We also present the ESUCB algorithm with item switching cost $O(N \log^2 T)$.
### 104.Deep Reasoning Networks for Unsupervised Pattern De-mixing with Constraint Reasoning [:chains:](https://proceedings.icml.cc/book/3344.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/717-Paper.pdf)
  Di Chen, Yiwei Bai, Wenting Zhao, Sebastian Ament, John Gregoire, Carla Gomes [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/717-Metadata.json)
> <p>We introduce Deep Reasoning Networks (DRNets), an end-to-end framework that combines deep learning with constraint reasoning for solving pattern de-mixing problems, typically in an unsupervised or very-weakly-supervised setting. DRNets exploit problem structure and prior knowledge by tightly combining constraint reasoning with stochastic-gradient-based neural network optimization. Our motivating task is from materials discovery and concerns inferring crystal structures of materials from X-ray diffraction data (Crystal-Structure-Phase-Mapping). Given the complexity of its underlying scientific domain, we start by introducing DRNets on an analogous but much simpler task: de-mixing overlapping hand-written Sudokus (Multi-MNIST-Sudoku). On Multi-MNIST-Sudoku, DRNets almost perfectly recovered the mixed Sudokus' digits, with 100\% digit accuracy, outperforming the supervised state-of-the-art MNIST de-mixing models. On Crystal-Structure-Phase-Mapping, DRNets significantly outperform the state of the art and experts' capabilities, recovering more precise and physically meaningful crystal structures.</p> 
### 105.[Uncertainty-Aware Lookahead Factor Models for Improved Quantitative Investing](https://proceedings.icml.cc/book/3345.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/721-Paper.pdf)
  Lakshay Chauhan, John Alberg, Zachary Lipton [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/721-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/721-Supplemental.pdf)
> <p>On a periodic basis, publicly traded companies are required to report fundamentals: financial data such as revenue, earnings, debt, etc., providing insight into the companyâs financial health. Quantitative finance research has identified several factorsâcomputed features of the reported dataâthat have been demonstrated in retrospective analysis to outperform market averages. In this paper, we first show through simulation that if we could (clairvoyantly) select stocks using factors calculated on future fundamentals (via oracle), then our portfolios would far outperform a standard factor approach.  Motivated by this analysis, we train MLP and LSTM neural networks to forecast future fundamentals based on a trailing window of five years. We propose lookahead factor models to act upon these predictions,  plugging the predicted future fundamentals into traditional factors. Finally, we incorporate uncertainty estimates from both neural heteroscedastic regression and a dropout-based heuristic, demonstrating gains from adjusting our portfolios to avert risk.  In a retrospective analysis using an industry-grade stock portfolio simulator (backtester), we show simultaneous improvement in annualized return and Sharpe ratio (a common measure of risk-adjusted returns).  Specifically, the simulated annualized return for the uncertainty-aware model is 17.7% (vs 14.0% for a standard factor model) and the Sharpe ratio is 0.84 (vs 0.52).</p> 
### 106.[On the Unreasonable Effectiveness of the Greedy Algorithm: Greedy Adapts to Sharpness](https://proceedings.icml.cc/book/3346.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/722-Paper.pdf)
  Sebastian Pokutta, Mohit Singh, Alfredo Torrico [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/722-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/722-Supplemental.pdf)
> <p>Submodular maximization has been widely studied over the past decades, mostly because of its numerous applications in real-world problems. It is well known that the standard greedy algorithm guarantees a worst-case approximation factor of 1 â 1/e when maximizing a monotone submodular function under a cardinality constraint. However, empirical studies show that its performance is substantially better in practice. This raises a natural question of explaining this improved performance of the greedy algorithm. In this work, we define sharpness for submodular functions as a candidate explanation for this phenomenon. The sharpness criterion is inspired by the concept of strong convexity in convex optimization. We show that the greedy algorithm provably performs better as the sharpness of the submodular function increases. This improvement ties closely to the faster convergence rates of the first order methods for strongly convex functions. Finally, we perform a computational study to empirically support our theoretical results and show that sharpness explains the greedy performance better than other justifications in the literature.</p> 
### 107.[Stronger and Faster Wasserstein Adversarial Attacks](https://proceedings.icml.cc/book/3347.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/724-Paper.pdf)
  Kaiwen Wu, Allen Wang, Yaoliang Yu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/724-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/724-Supplemental.pdf)
> Deep models, while being extremely flexible and accurate, are surprisingly vulnerable to ``small, imperceptible&#x27;&#x27; perturbations known as adversarial attacks. While the majority of existing attacks focuses on measuring perturbations under the $\ell_p$ metric, Wasserstein distance, which takes geometry in pixel space into account, has long known to be a better metric for measuring image quality and has recently risen as a compelling alternative to the $\ell_p$ metric in adversarial attacks. However, constructing an effective attack under the Wasserstein metric is computationally much more challenging and calls for better optimization algorithms. We address this gap in two ways: (a) we develop an exact yet efficient projection operator to enable a stronger projected gradient attack; (b) we show for the first time that conditional gradient method equipped with a suitable linear minimization oracle works extremely fast under Wasserstein constraints. Our algorithms not only converge faster but also generate much stronger attacks. For instance, we decrease the accuracy of a residual network on CIFAR-10 to less than $30\%$ within a Wasserstein perturbation ball of radius $0.005$, in contrast to $65.2\%$ using the  previous state-of-the-art attack based on approximate projection.
### 108.[Optimizing Multiagent Cooperation via Policy Evolution and Shared Experiences](https://proceedings.icml.cc/book/3348.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/730-Paper.pdf)
  Somdeb Majumdar, Shauharda Khadka, Santiago Miret, Stephen Mcaleer, Kagan Tumer [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/730-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/730-Supplemental.pdf)
> <p>Many cooperative multiagent reinforcement learning environments provide agents with a sparse team-based reward, as well as a dense agent-specific reward that incentivizes learning basic skills. Training policies solely on the team-based reward is often difficult due to its sparsity. Also, relying solely on the agent-specific reward is sub-optimal because it usually does not capture the team coordination objective. A common approach is to use reward shaping to construct a proxy reward by combining the individual rewards. However, this requires manual tuning for each environment. We introduce Multiagent Evolutionary Reinforcement Learning (MERL), a split-level training platform that handles the two objectives separately through two optimization processes. An evolutionary algorithm maximizes the sparse team-based objective through neuroevolution on a population of teams. Concurrently, a gradient-based optimizer trains policies to only maximize the dense agent-specific rewards. The gradient-based policies are periodically added to the evolutionary population as a way of information transfer between the two optimization processes. This enables the evolutionary algorithm to use skills learned via the agent-specific rewards toward optimizing the global objective. Results demonstrate that MERL significantly outperforms state-of-the-art methods, such as MADDPG, on a number of difficult coordination benchmarks.</p> 
### 109.Why Are Learned Indexes So Effective? [:chains:](https://proceedings.icml.cc/book/3349.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/737-Paper.pdf)
  Paolo Ferragina, Fabrizio Lillo, Giorgio Vinciguerra [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/737-Metadata.json)
> <p>A recent trend in algorithm design consists of augmenting classic data structures with machine learning models, which are better suited to reveal and exploit patterns and trends in the input data so to achieve outstanding practical improvements in space occupancy and time efficiency. <br /> This is especially known in the context of indexing data structures where, despite few attempts in evaluating their asymptotic efficiency, theoretical results are yet missing in showing that learned indexes are provably better than classic indexes, such as B+ trees and their variants. In this paper, we present the first mathematically-grounded answer to this open problem. We obtain this result by discovering and exploiting a link between the original problem and a mean exit time problem over a proper stochastic process which, we show, is related to the space and time occupancy of those learned indexes. Our general result is then specialised to five well-known distributions: Uniform, Lognormal, Pareto, Exponential, and Gamma; and it is corroborated in precision and robustness by a large set of experiments.</p> 
### 110.Fast OSCAR and OWL with Safe Screening Rules [:chains:](https://proceedings.icml.cc/book/3350.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/738-Paper.pdf)
  Runxue Bao, Bin Gu, Heng Huang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/738-Metadata.json)
> Ordered Weight $L_{1}$-Norms (OWL) is a new family of regularizers for high-dimensional sparse regression. However, due to the non-separable penalty, existing algorithms are either invalid or inefficient when either the size of the feature or sample is large. To address this challenge, we propose the first safe screening rule for the OWL regularized regression, which effectively avoids the updates of the parameters whose coefficients must be zeros. Moreover, we prove the proposed screening rule can be safely applied to the standard proximal gradient methods. More importantly, our screening rule can also be safely applied to stochastic proximal gradient methods in large-scale learning, which is the first safe screening rule in the stochastic setting. Experimental results on a variety of datasets show that the screening rule leads to a significant computation gain without any loss of accuracy, compared to exiting competitive algorithms.  
### 111.[Which Tasks Should Be Learned Together in Multi-task Learning?](https://proceedings.icml.cc/book/3351.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/758-Paper.pdf)
  Trevor Standley, Amir Zamir, Dawn Chen, Leonidas Guibas, Jitendra Malik, Silvio Savarese [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/758-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/758-Supplemental.zip)
> <p>Many computer vision applications require solving multiple tasks in real-time. A neural network can be trained to solve multiple tasks simultaneously using 'multi-task learning'. This saves computation at inference time as only a single network needs to be evaluated. Unfortunately, this often leads to inferior overall performance as task objectives compete, which consequently poses the question: which tasks should and should not be learned together in one network when employing multi-task learning? We systematically study task cooperation and competition and propose a framework for assigning tasks to a few neural networks such that cooperating tasks are computed by the same neural network, while competing tasks are computed by different networks. Our framework offers a time-accuracy trade-off and can produce better accuracy using less inference time than not only a single large multi-task neural network but also many single-task networks.</p> 
### 112.[Inertial Block Proximal Methods for Non-Convex Non-Smooth Optimization](https://proceedings.icml.cc/book/3352.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/766-Paper.pdf)
  Hien Le, Nicolas Gillis, Panagiotis Patrinos [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/766-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/766-Supplemental.pdf)
> <p>We propose inertial versions of block coordinate descent methods for solving non-convex non-smooth composite optimization problems. Our methods possess three main advantages compared to current state-of-the-art accelerated first-order methods: (1) they allow using two different extrapolation points to evaluate the gradients and to add the inertial force (we will empirically show that it is more efficient than using a single extrapolation point), (2) they allow to randomly select the block of variables to update, and (3) they do not require a restarting step. We prove the subsequential convergence of the generated sequence under mild assumptions, prove the global convergence under some additional assumptions, and provide convergence rates. We deploy the proposed methods to solve non-negative matrix factorization (NMF) and show that they compete favorably with the state-of-the-art NMF algorithms. Additional experiments on non-negative approximate canonical polyadic decomposition, also known as nonnegative tensor factorization, are also provided.  </p> 
### 113.[Adversarial Neural Pruning with Latent Vulnerability Suppression](https://proceedings.icml.cc/book/3353.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/770-Paper.pdf)
  Divyam Madaan, Jinwoo Shin, Sung Ju Hwang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/770-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/770-Supplemental.pdf)
> <p>Despite the remarkable performance of deep neural networks on various computer vision tasks, they are known to be highly susceptible to adversarial perturbations, which makes it challenging to deploy them in real-world safety-critical applications. In this paper, we conjecture that the leading cause of this adversarial vulnerability is the distortion in the latent feature space, and provide methods to suppress them effectively. Explicitly, we define \textbf{vulnerability} for each latent feature and then propose a new loss for adversarial learning, \textbf{Vulnerability Suppression (VS)} loss, that aims to minimize the feature-level vulnerability during training. We further propose a Bayesian framework to prune features with high vulnerability to reduce both vulnerability and loss on adversarial samples. We validate our \textbf{Adversarial Neural Pruning (ANP)} method on multiple benchmark datasets, on which it not only obtains state-of-the-art adversarial robustness but also improves the performance on clean examples, using only a fraction of the parameters used by the full network. Further qualitative analysis suggests that the improvements come from the suppression of feature-level vulnerability.</p> 
### 114.[Lifted Disjoint Paths with Application in Multiple Object Tracking](https://proceedings.icml.cc/book/3354.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/771-Paper.pdf)
  Andrea Hornakova, Roberto Henschel, Bodo Rosenhahn, Paul Swoboda [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/771-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/771-Supplemental.pdf)
> <p>We present an extension to the disjoint paths problem in which additional lifted edges are introduced to provide path connectivity priors. We call the resulting optimization problem the lifted disjoint paths problem. We show that this problem is NP-hard by reduction from multicommodity flow and 3-SAT. To enable practical global optimization, we propose several classes of linear inequalities that produce a high-quality LP-relaxation. Additionally, we propose efficient cutting plane algorithms for separating the proposed linear inequalities. The lifted disjoint path problem is a natural model for multiple object tracking and allows an elegant mathematical formulation for long-range temporal interactions. Lifted edges help to prevent id switches and to re-identify persons. Our lifted disjoint paths tracker leads on all three main benchmarks of the MOT challenge, improving significantly over state-of-the-art.</p> 
### 115.[Being Bayesian, Even Just a Bit, Fixes Overconfidence in ReLU Networks](https://proceedings.icml.cc/book/3355.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/780-Paper.pdf)
  Agustinus Kristiadi, Matthias Hein, Philipp Hennig [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/780-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/780-Supplemental.pdf)
> <p>The point estimates of ReLU classification networks---arguably the most widely used neural network architecture---have been shown to yield arbitrarily high confidence far away from the training data. This architecture, in conjunction with a maximum a posteriori estimation scheme, is thus not calibrated nor robust. Approximate Bayesian inference has been empirically demonstrated to improve predictive uncertainty in neural networks, although the theoretical analysis of such Bayesian approximations is limited. We theoretically analyze approximate Gaussian posterior distributions on the weights of ReLU networks and show that they fix the overconfidence problem. Furthermore, we show that even a simplistic, thus cheap, Bayesian approximation, also fixes these issues. This indicates that a sufficient condition for a calibrated uncertainty on a ReLU network is ``to be a bit Bayesian''. These theoretical results validate the usage of last-layer Bayesian approximation and motivate a range of a fidelity-cost trade-off. We further validate these findings empirically via various standard experiments using common deep ReLU networks and Laplace approximations.</p> 
### 116.[SCAFFOLD: Stochastic Controlled Averaging for Federated Learning](https://proceedings.icml.cc/book/3356.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/788-Paper.pdf)
  Sai Praneeth Reddy Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Jakkam Reddi, Sebastian Stich, Ananda Theertha Suresh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/788-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/788-Supplemental.pdf)
> <p>Federated learning is a key scenario in modern large-scale machine learning where the data remains distributed over a large number of clients and the task is to learn a centralized model without transmitting the client data. The standard optimization algorithm used in this setting is Federated Averaging (FedAvg) due to its low communication cost. We obtain a tight characterization of the convergence of FedAvg and prove that heterogeneity (non-iid-ness) in the client's data results in a `drift' in the local updates resulting in poor performance.</p>  <p>As a solution, we propose a new algorithm (SCAFFOLD) which uses control variates (variance reduction) to correct for the `client drift'. We prove that SCAFFOLD requires significantly fewer communication rounds and is not affected by data heterogeneity or client sampling. Further, we show that (for quadratics) SCAFFOLD can take advantage of similarity in the client's data yielding even faster convergence. The latter is the first result to quantify the usefulness of local-steps in distributed optimization.</p> 
### 117.[Statistically Preconditioned Accelerated Gradient Method for Distributed Optimization](https://proceedings.icml.cc/book/3357.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/803-Paper.pdf)
  Hadrien Hendrikx, Lin Xiao, Sebastien Bubeck, Francis Bach, Laurent MassouliÃ© [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/803-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/803-Supplemental.zip)
> <p>We consider the setting of distributed empirical risk minimization where multiple machines compute the gradients in parallel and a centralized server updates the model parameters. In order to reduce the number of communications required to reach a given accuracy, we propose a preconditioned accelerated gradient method where the preconditioning is done by solving a local optimization problem over a subsampled dataset at the server. The convergence rate of the method depends on the square root of the relative condition number between the global and local loss functions. We estimate the relative condition number for linear prediction models by studying uniform concentration of the Hessians over a bounded domain, which allows us to derive improved convergence rates for existing preconditioned gradient methods and our accelerated method. Experiments on real-world datasets illustrate the benefits of acceleration in the ill-conditioned regime.</p> 
### 118.Pretrained Generalized Autoregressive Model with Adaptive Probabilistic Label Cluster for Extreme Multi-label Text Classification [:chains:](https://proceedings.icml.cc/book/3358.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/807-Paper.pdf)
  Hui Ye, Zhiyu Chen, Da-Han Wang, Brian Davison [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/807-Metadata.json)
> <p>Extreme multi-label text classification (XMTC) is a task for tagging a given text with the most relevant labels from an extremely large label set. We propose a novel deep learning method called APLC-XLNet.   Our approach fine-tunes  the  recently  released  generalized  autoregressive  pretraining model (XLNet) to learn the dense representation for the input text.   We propose the Adaptive Probabilistic Label Cluster (APLC) to approximate the cross entropy loss by exploiting the  unbalanced  label  distribution  to  form  clusters that explicitly reduce the computational time. Our experiments, carried out on five benchmark datasets, show that our approach significantly outperforms existing state-of-the-art methods. The code of our method will be released publicly at GitHub.</p> 
### 119.[Frequentist Uncertainty in Recurrent Neural Networks via Blockwise Influence Functions](https://proceedings.icml.cc/book/3359.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/817-Paper.pdf)
  Ahmed Alaa, Mihaela van der Schaar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/817-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/817-Supplemental.pdf)
> <p>Recurrent neural networks (RNNs) are instrumental in modelling sequential and time-series data. Yet, when using RNNs to inform decision-making, predictions by themselves are not sufficient â we also need estimates of predictive uncertainty. Existing approaches for uncertainty quantification in RNNs are based predominantly on Bayesian methods; these are computationally prohibitive, and require major alterations to the RNN architecture and training. Capitalizing on ideas from classical jackknife resampling, we develop a frequentist alternative that: (a) is computationally efficient, (b) does not interfere with model training or compromise its accuracy, (c) applies to any RNN architecture, and (d) provides theoretical coverage guarantees on the estimated uncertainty intervals. Our method derives predictive uncertainty from the variability of the (jackknife) sampling distribution of the RNN outputs, which is estimated by repeatedly deleting "blocks" of (temporally-correlated) training data, and collecting the predictions of the RNN re-trained on the remaining data. To avoid computationally expensive re-training, we utilize influence functions to estimate the effect of removing training data blocks on the learned RNN parameters. Using data from a critical care medical setting, we demonstrate the utility of uncertainty quantification in sequential decision-making.</p> 
### 120.[Disentangling Trainability and Generalization in Deep Neural Networks](https://proceedings.icml.cc/book/3360.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/827-Paper.pdf)
  Lechao Xiao, Jeffrey Pennington, Samuel Schoenholz [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/827-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/827-Supplemental.pdf)
> <p>A longstanding goal in the theory of deep learn-ing is to characterize the conditions under whicha given neural network architecture will be train-able, and if so, how well it might generalize tounseen data. In this work, we provide such a char-acterization in the limit of very wide and verydeep networks, for which the analysis simplifiesconsiderably.  For wide networks, the trajectoryunder gradient descent is governed by the NeuralTangent Kernel (NTK), and for deep networks,the NTK itself maintains only weak data depen-dence.  By analyzing the spectrum of the NTK,we formulate necessary conditions for trainabilityand generalization across a range of architectures,including Fully Connected Networks (FCNs) andConvolutional  Neural  Networks  (CNNs).   Weidentify large regions of hyperparameter spacefor which networks can memorize the training setbut completely fail to generalize.  We find thatCNNs without global average pooling behave al-most identically to FCNs,  but that CNNs withpooling have markedly different and often bettergeneralization performance. A thorough empiri-cal investigation of these theoretical results showsexcellent agreement on real datasets.</p> 
### 121.[Moniqua: Modulo Quantized Communication in Decentralized SGD](https://proceedings.icml.cc/book/3361.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/831-Paper.pdf)
  Yucheng Lu, Christopher De Sa [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/831-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/831-Supplemental.pdf)
> Running Stochastic Gradient Descent (SGD) in a decentralized fashion has shown promising results. In this paper we propose Moniqua, a technique that allows decentralized SGD to use quantized communication. We prove in theory that Moniqua communicates a provably bounded number of bits per iteration, while converging at the same asymptotic rate as the original algorithm does with full-precision communication. Moniqua improves upon prior works in that it (1) requires zero additional memory, (2) works with 1-bit quantization, and (3) is applicable to a variety of decentralized algorithms. We demonstrate empirically that Moniqua converges faster with respect to wall clock time than other quantized decentralized algorithms.  We also show that Moniqua is robust to very low bit-budgets, allowing  $1$-bit-per-parameter communication without compromising validation accuracy when training ResNet20 and ResNet110 on CIFAR10.
### 122.[Expectation Maximization with Bias-Corrected Calibration is Hard-To-Beat at Label Shift Adaptation](https://proceedings.icml.cc/book/3362.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/835-Paper.pdf)
  Amr Mohamed Alexandari, Anshul Kundaje, Avanti Shrikumar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/835-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/835-Supplemental.pdf)
> <p>Label shift refers to the phenomenon where the prior class probability p(y) changes between the training and test distributions, while the conditional probability p(x|y) stays fixed. Label shift arises in settings like medical diagnosis, where a classifier trained to predict disease given symptoms must be adapted to scenarios where the baseline prevalence of the disease is different. Given estimates of p(y|x) from a predictive model, Saerens et al. proposed an efficient EM algorithm to correct for label shift that does not require model retraining. A limiting assumption of this algorithm is that p(y|x) is calibrated, which is not true of modern neural networks. Recently, Black Box Shift Learning (BBSL) and Regularized Learning under Label Shifts (RLLS) have emerged as state-of-the-art techniques to cope with label shift when a classifier does not output calibrated probabilities. However, both BBSL and RLLS require model retraining with importance weights, which poses challenges in practice, and neither has been benchmarked against EM. We show that by combining EM with a type of calibration we call bias-corrected calibration, we outperform both BBSL and RLLS across diverse datasets and distribution shifts. We further show that the EM objective is concave and bounded, and introduce a theoretically principled strategy for estimating source-domain priors that improves robustness to poor calibration. This work demonstrates that EM with appropriate calibration is a formidable and efficient baseline that future work in label shift adaptation should be compared with.</p>  <p>Colab notebooks reproducing experiments are available at (anonymized link): https://github.com/blindauth/labelshiftexperiments</p> 
### 123.Expert Learning through Generalized Inverse Multiobjective Optimization: Models, Insights and Algorithms [:chains:](https://proceedings.icml.cc/book/3363.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/842-Paper.pdf)
  Chaosheng Dong, Bo Zeng [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/842-Metadata.json)
> We study a new unsupervised learning task of inferring objective functions or constraints of a multiobjective decision making model, based on a set of observed decisions. Specifically, we formulate such a learning problem as an inverse multiobjective optimization problem (IMOP) and propose its first sophisticated model with statistical guarantees. Then, we some fundamental connections between IMOP, K-means clustering and manifold learning. More precisely, we prove that every K-means clustering problem can be transformed equivalently into an IMOP, and every IMOP can be conversely interpreted as a constrained K-means clustering problem. In addition, we show that the Pareto optimal set is a piecewise continuous manifold with an intrinsic dimension of $ p-1 $ (where $ p $ is the number of objectives) under suitable conditions. Hence, IMOP can also be interpreted as a manifold learning problem. Leveraging these critical insights and connections, we propose two algorithms to solve IMOP through manifold learning and clustering. Numerical results confirm the effectiveness of our model and the computational efficacy of algorithms.
### 124.[Random Matrix Theory Proves that Deep Learning Representations of GAN-data Behave as Gaussian Mixtures](https://proceedings.icml.cc/book/3364.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/858-Paper.pdf)
  Mohamed El Amine Seddik, Cosme Louart, Mohamed Tamaazousti, Romain  COUILLET [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/858-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/858-Supplemental.pdf)
> This paper shows that deep learning (DL) representations of data produced by generative adversarial nets (GANs) are random vectors which fall within the class of so-called \textit{concentrated} random vectors. Further exploiting the fact that Gram matrices, of the type $G = X^\intercal X$ with $X=[x_1,\ldots,x_n]\in \mathbb{R}^{p\times n}$ and $x_i$ independent concentrated random vectors from a mixture model, behave asymptotically (as $n,p\to \infty$) as if the $x_i$ were drawn from a Gaussian mixture, suggests that DL representations of GAN-data can be fully described by their first two statistical moments for a wide range of standard classifiers. Our theoretical findings are validated by generating images with the BigGAN model and across different popular deep representation networks.
### 125.Optimizing Data Usage via Differentiable Rewards [:chains:](https://proceedings.icml.cc/book/3365.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/860-Paper.pdf)
  Xinyi Wang, Hieu Pham, Paul Michel, Antonios  Anastasopoulos, Jaime Carbonell, Graham Neubig [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/860-Metadata.json)
> <p>To acquire a new skill, humans learn better and faster if a tutor, based on their current knowledge level, informs them of how much attention they should pay to particular content or practice problems. Similarly, a machine learning model could potentially be trained better with a scorer that ``adapts'' to its current learning state and estimates the importance of each training data instance. Training such an adaptive scorer efficiently is a challenging problem; in order to precisely quantify the effect of a data instance at a given time during the training, it is typically necessary to first complete the entire training process. To efficiently optimize data usage, we propose a reinforcement learning approach called Differentiable Data Selection (DDS). In DDS, we formulate a scorer network as a learnable function of the training data, which can be efficiently  updated along with the main model being trained. Specifically, DDS updates the scorer with an intuitive reward signal: it should up-weigh the data that has a similar gradient with a dev set upon which we would finally like to perform well. Without significant computing overhead, DDS delivers strong and consistent improvements over several strong baselines on two very different tasks of machine translation and image classification.</p> 
### 126.Optimistic Policy Optimization with Bandit Feedback [:chains:](https://proceedings.icml.cc/book/3366.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/875-Paper.pdf)
  Lior Shani, Yonathan Efroni, Aviv Rosenberg, Shie Mannor [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/875-Metadata.json)
> Policy optimization methods are one of the most widely used classes of Reinforcement Learning (RL) algorithms. Yet, so far, such methods have been mostly analyzed from an optimization perspective, without addressing the problem of exploration, or by making strong assumptions on the interaction with the environment.  In this paper we consider model-based RL in the tabular finite-horizon MDP setting with unknown transitions and bandit feedback. For this setting, we propose an optimistic trust region policy optimization (TRPO) algorithm for which we establish $\tilde O(\sqrt{S^2 A H^4 K})$ regret for stochastic rewards. Furthermore, we prove $\tilde O( \sqrt{ S^2 A H^4 }  K^{2/3} ) $ regret for adversarial rewards. Interestingly, this result matches previous bounds derived for the bandit feedback case, yet with known transitions. To the best of our knowledge, the two results are the first sub-linear regret bounds obtained for policy optimization algorithms with unknown transitions and bandit feedback.
### 127.Maximum-and-Concatenation Networks [:chains:](https://proceedings.icml.cc/book/3367.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/876-Paper.pdf)
  Xingyu Xie, Hao Kong, Jianlong Wu, Wayne Zhang, Guangcan Liu, Zhouchen Lin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/876-Metadata.json)
> While successful in many fields, deep neural networks (DNNs) still suffer from some open problems such as bad local minima and unsatisfactory generalization performance. Despite the progresses achieved during the past several years, those difficulties have not been overcome completely and are still preventing DNNs from being more successful. In this work, we propose a novel architecture called Maximum-and-Concatenation Networks (MCN) to try eliminating bad local minima and improving generalization ability as well. MCN is a multi-layer network concatenated by a linear part and the maximum of two piecewise smooth functions, and it can approximate a wide range of functions used in practice. Remarkably, we prove that MCN has a very nice property; that is, \emph{every local minimum of an $(l+1)$-layer MCN can be better than, at least as good as, the global minima of the network consisting of its first $l$ layers}. In other words, via increasing the network depth, MCN can autonomously improve the goodness of its local minima. What is more, \emph{it is easy to plug MCN into an existing deep model to make it also have this property}. Finally, under mild conditions, we show that MCN can approximate certain continuous functions arbitrarily well with \emph{high efficiency}; that is, the covering number of MCN is much smaller than most existing DNNs such as deep ReLU. Based on this, we further provide a tight generalization bound to guarantee the inference ability of MCN when dealing with testing samples. Experiments on the CIFAR datasets confirm the effectiveness of MCN.
### 128.[Learning Adversarial Markov Decision Processes with Bandit Feedback and Unknown Transition](https://proceedings.icml.cc/book/3368.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/879-Paper.pdf)
  Chi Jin, Tiancheng Jin, Haipeng Luo, Suvrit Sra, Tiancheng Yu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/879-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/879-Supplemental.pdf)
> <p>We consider the task of learning in episodic finite-horizon Markov decision processes with an unknown transition function, bandit feedback, and adversarial losses. We propose an efficient algorithm that achieves  O(âL|X|AT ) regret with high probability, where L is the horizon, |X| the number of states, |A| the number of actions, and T the number of episodes. To our knowledge, our algorithm is the first to ensure O(âT) regret in this challenging setting; in fact, it achieves the same regret as (Rosenberg &amp; Mansour, 2019a) who consider the easier setting with full-information. Our key contributions are two-fold: a tighter confidence set for the transition function; and an optimistic loss estimator that is inversely weighted by an "upper occupancy bound". </p> 
### 129.[Kernelized Stein Discrepancy Tests of Goodness-of-fit  for Time-to-Event Data](https://proceedings.icml.cc/book/3369.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/880-Paper.pdf)
  Wenkai Xu, Tamara Fernandez, Nicolas Rivera, Arthur Gretton [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/880-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/880-Supplemental.pdf)
> <p>Survival Analysis and Reliability Theory are concerned with the analysis of time-to-event data, in which observations correspond to waiting times until an event of interest, such as death from a particular disease or failure of a component in a mechanical system. This type of data is unique due to the presence of censoring, a type of missing data that occurs when we do not observe the actual time of the event of interest but instead we have access to an approximation for it given by random interval in which the observation is known to belong.</p>  <p>Most traditional methods are not designed to deal with censoring, and thus we need to adapt them to censored time-to-event data. In this paper, we focus on non-parametric Goodness-of-Fit testing procedures based on combining the Stein's method and kernelized discrepancies. While for uncensored data, there is a natural way of implementing a kernelized Stein discrepancy test, for censored data there are several options, each of them with different advantages and disadvantages. In this paper we propose a collection of kernelized Stein discrepancy tests for time-to-event data, and we study each of them theoretically and empirically. Our experimental results show that our proposed methods perform better than existing tests, including previous tests based on a kernelized maximum mean discrepancy.</p> 
### 130.[Efficient Intervention Design for Causal Discovery with Latents](https://proceedings.icml.cc/book/3370.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/884-Paper.pdf)
  Raghavendra Addanki, Shiva Kasiviswanathan, Andrew McGregor, Cameron Musco [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/884-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/884-Supplemental.pdf)
> <p>We consider recovering a causal graph in presence of latent variables, where we seek to minimize the cost of interventions used in the recovery process. We consider two intervention cost models: (1) a linear cost model where the cost of an intervention on a subset of variables has a linear form, and (2) an identity cost model where the cost of an intervention is the same, regardless of what variables it is on, i.e., the goal is just to minimize the number of interventions. Under the linear cost model, we give an algorithm to identify the ancestral relations of the underlying causal graph, achieving within a 2-factor of the optimal intervention cost. This approximation factor can be improved to 1+eps for any eps &gt; 0, under some mild restrictions. Under the identity cost model, we bound the number of interventions needed to recover the entire causal graph, including the latent variables, using a parameterization of the causal graph  through a special type of colliders. In particular, we introduce the notion of p-colliders, that are colliders between pair of nodes arising from a specific type of conditioning in the causal graph, and provide an upper bound on the number of interventions as a function of the maximum number of p-colliders between any two nodes in the causal graph.</p> 
### 131.Certified Data Removal from Machine Learning Models [:chains:](https://proceedings.icml.cc/book/3371.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/894-Paper.pdf)
  Chuan Guo, Tom Goldstein, Awni Hannun, Laurens van der Maaten [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/894-Metadata.json)
> <p>Good data stewardship requires removal of data at the request of the data's owner. This raises the question if and how a trained machine-learning model, which implicitly stores information about its training data, should be affected by such a removal request. Is it possible to ``remove'' data from a machine-learning model? We study this problem by defining certified removal: a very strong theoretical guarantee that a model from which data is removed cannot be distinguished from a model that never observed the data to begin with. We develop a certified-removal mechanism for linear classifiers and empirically study learning settings in which this mechanism is practical.</p> 
### 132.One Size Fits All: Can We Train One Denoiser for All Noise Levels? [:chains:](https://proceedings.icml.cc/book/3372.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/895-Paper.pdf)
  Abhiram Gnanasambandam, Stanley Chan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/895-Metadata.json)
> <p>When using deep neural networks for estimating signals such as denoising images, it is generally preferred to train one network and apply it to all noise levels. The de facto training protocol to achieve this goal is to train the network with noisy samples whose noise levels are uniformly distributed across the range of interest. However, why should we allocate the samples uniformly? Can we have more training samples that are less noisy, and fewer samples that are more noisy? What is the optimal distribution? How do we obtain such optimal distribution? The goal of this paper is to address these questions. In particular, we show that the sampling problem can be formulated as a minimax risk optimization. We show that, although the neural networks are non-convex, the minimax problem itself is convex. We derive a dual ascent algorithm to determine the optimal distribution of which the convergence is guaranteed. We show that the framework is general not only to denoising but any trainable estimators where there is a range of uncertainty conditions. We demonstrate applications in image denoising, low-light reconstruction, and super-resolution.</p> 
### 133.GNN-FiLM: Graph Neural Networks with Feature-wise Linear Modulation [:chains:](https://proceedings.icml.cc/book/3373.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/904-Paper.pdf)
  Marc Brockschmidt [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/904-Metadata.json)
> <p>This paper presents a new Graph Neural Network (GNN) type using feature-wise linear modulation (FiLM). Many standard GNN variants propagate information along the edges of a graph by computing messages based only on the representation of the source of each edge. In GNN-FiLM, the representation of the target node of an edge is used to compute a transformation that can be applied to all incoming messages, allowing feature-wise modulation of the passed information.</p>  <p>Different GNN architectures are compared in extensive experiments on three tasks from the literature, using re-implementations of many baseline methods. Hyperparameters for all methods were found using extensive search, yielding somewhat surprising results: differences between state of the art models are much smaller than reported in the literature and well-known simple baselines that are often not compared to perform better than recently proposed GNN variants. Nonetheless, GNN-FiLM outperforms these methods on a regression task on molecular graphs and performs competitively on other tasks.</p> 
### 134.[Sparse Gaussian Processes with Spherical Harmonic Features](https://proceedings.icml.cc/book/3374.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/906-Paper.pdf)
  Vincent Dutordoir, Nicolas Durrande, James Hensman [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/906-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/906-Supplemental.pdf)
> <p>We introduce a new class of interdomain variational Gaussian processes (GP) where data is mapped onto the unit hypersphere in order to use spherical harmonic representations. Our inference scheme is comparable to variational Fourier features, but it does not suffer from the curse of dimensionality, and leads to diagonal covariance matrices between inducing variables. This enables a speed-up in inference, because it bypasses the need to invert large covariance matrices. Our experiments show that our model is able to fit a regression model for a dataset with 6 million entries two orders of magnitude faster compared to standard sparse GPs, while retaining state of the art accuracy. We also demonstrate competitive performance on classification with non-conjugate likelihoods.</p> 
### 135.[Asynchronous Coagent Networks](https://proceedings.icml.cc/book/3375.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/910-Paper.pdf)
  James Kostas, Chris Nota, Philip Thomas [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/910-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/910-Supplemental.pdf)
> <p>Coagent policy gradient algorithms (CPGAs) are reinforcement learning algorithms for training a class of stochastic neural networks called coagent networks. In this work, we prove that CPGAs converge to locally optimal policies. Additionally, we extend prior theory to encompass asynchronous and recurrent coagent networks. These extensions facilitate the straightforward design and analysis of hierarchical reinforcement learning algorithms like the option-critic, and eliminate the need for complex derivations of customized learning rules for these algorithms.</p> 
### 136.[Adaptive Checkpoint Adjoint Method for Gradient Estimation in Neural ODE](https://proceedings.icml.cc/book/3376.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/917-Paper.pdf)
  Juntang Zhuang, Nicha Dvornek, Xiaoxiao Li, Sekhar Tatikonda, Xenophon Papademetris, James Duncan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/917-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/917-Supplemental.zip)
> <p>The empirical performance of neural ordinary differential equations (NODEs) is significantly inferior to discrete-layer models on benchmark tasks (e.g. image classification). We demonstrate an explanation is the inaccuracy of existing gradient estimation methods: the adjoint method has numerical errors in reverse-mode integration; the naive method suffers from a redundantly deep computation graph. We propose the Adaptive Checkpoint Adjoint (ACA) method: ACA applies a trajectory checkpoint strategy which records the forward- mode trajectory as the reverse-mode trajectory to guarantee accuracy; ACA deletes redundant components for shallow computation graphs; and ACA supports adaptive solvers. On image classification tasks, compared with the adjoint and naive method, ACA achieves half the error rate in half the training time; NODE trained with ACA outperforms ResNet in both accuracy and test-retest reliability. On time-series modeling, ACA outperforms competing methods. Furthermore, NODE with ACA can incorporate physical knowledge to achieve better accuracy.</p> 
### 137.[Understanding the Curse of Horizon in Off-Policy Evaluation via Conditional Importance Sampling](https://proceedings.icml.cc/book/3377.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/924-Paper.pdf)
  Yao Liu, Pierre-Luc Bacon, Emma Brunskill [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/924-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/924-Supplemental.pdf)
> Off-policy policy estimators that use importance sampling (IS) can suffer from high variance in long-horizon domains, and there has been particular excitement over new IS methods that leverage the structure of Markov decision processes. We analyze the variance of the most popular approaches through the viewpoint of conditional Monte Carlo. Surprisingly, we find that in finite horizon MDPs there is no strict variance reduction of per-decision importance sampling or stationary importance sampling, comparing with vanilla importance sampling. We then provide sufficient conditions under which the per-decision or stationary estimators will provably reduce the variance over importance sampling with finite horizons. For the asymptotic (in terms of horizon $T$) case, we develop upper and lower bounds on the variance of those estimators which yields sufficient conditions under which there exists an exponential v.s. polynomial gap between the variance of importance sampling and that of the per-decision or stationary estimators. These results help advance our understanding of if and when new types of IS estimators will improve the accuracy of off-policy estimation.
### 138.[Taylor Expansion Policy Optimization](https://proceedings.icml.cc/book/3378.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/941-Paper.pdf)
  Yunhao Tang, Michal Valko, Remi Munos [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/941-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/941-Supplemental.pdf)
> <p>In this work, we investigate the application of Taylor expansions in reinforcement learning. In particular, we propose Taylor Expansion Policy Optimization, a policy optimization formalism that generalizes prior work as a first-order special case. We also show that Taylor expansions intimately relate to off-policy evaluation. Finally, we show that this new formulation entails modifications which  improve the performance of several state-of-the-art distributed algorithms.</p> 
### 139.[Reinforcement Learning for Integer Programming: Learning to Cut](https://proceedings.icml.cc/book/3379.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/943-Paper.pdf)
  Yunhao Tang, Shipra Agrawal, Yuri Faenza [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/943-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/943-Supplemental.pdf)
> <p>Integer programming is a general optimization framework with a wide variety of applications, e.g., in scheduling, production planning, and graph optimization. As Integer Programs (IPs) model many provably hard to solve problems, modern IP solvers rely on heuristics. These heuristics are often human-designed, and tuned over time using experience and data.  The goal of this work is to show that the performance of those solvers can be greatly enhanced using reinforcement learning (RL). In particular, we investigate a specific methodology for solving IPs, known as the Cutting Plane Method.  This method is employed as a subroutine by all modern IP solvers. We present a deep RL formulation, network architecture, and algorithms for intelligent adaptive selection of cutting planes (aka cuts). Across a wide range of IP tasks, we show that our trained RL agent significantly outperforms human-designed heuristics, and effectively generalizes to larger instances and across IP problem classes. The trained agent is also demonstrated to benefit the popular downstream application of cutting plane methods in Branch-and-Cut algorithm, which is the backbone of state-of-the-art commercial IP solvers.</p> 
### 140.[Safe Reinforcement Learning in Constrained Markov Decision Processes](https://proceedings.icml.cc/book/3380.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/951-Paper.pdf)
  Akifumi Wachi, Yanan Sui [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/951-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/951-Supplemental.pdf)
> <p>Safe reinforcement learning has been a promising approach for optimizing the policy of an agent that operates in safety-critical applications. In this paper, we propose an algorithm, SNO-MDP, that explores and optimizes Markov decision processes under unknown safety constraints. Specifically, we take a step-wise approach for optimizing safety and cumulative reward.  In our method, the agent first learns safety constraints by expanding the safe region, and then optimizes the cumulative reward in the certified safe region. We provide theoretical guarantees on both the satisfaction of the safety constraint and the near-optimality of the cumulative reward under proper regularity assumptions. In our experiments, we demonstrate the effectiveness of SNO-MDP through two experiments: one uses a synthetic data in a new, openly-available environment named GP-Safety-Gym, and the other simulates Mars surface exploration by using real observation data.</p> 
### 141.[Layered Sampling for Robust Optimization Problems](https://proceedings.icml.cc/book/3381.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/953-Paper.pdf)
  Hu Ding, Zixiu Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/953-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/953-Supplemental.pdf)
> In real world,  our datasets often contain outliers. Moreover, the outliers can seriously affect the final machine learning result. Most existing algorithms for handling outliers take high time complexities ({\em e.g.} quadratic or cubic complexity). {\em Coreset} is a popular approach for compressing data so as to speed up the optimization algorithms. However, the current coreset methods cannot be easily extended to handle the case with outliers. In this paper, we propose a new variant of coreset technique,  {\em layered sampling}, to deal with two fundamental robust optimization problems: {\em $k$-median/means clustering with outliers} and {\em linear regression with outliers}. This new coreset method is in particular suitable to speed up the iterative algorithms (which often improve the solution within a local range) for those robust optimization problems. Moreover, our method is easy to be implemented in practice. We expect that our framework of layered sampling will be applicable to  other robust optimization problems.
### 142.[Learning to Encode Position for Transformer with Continuous Dynamical Model](https://proceedings.icml.cc/book/3382.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/955-Paper.pdf)
  Xuanqing Liu, Hsiang-Fu Yu, Inderjit Dhillon, Cho-Jui Hsieh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/955-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/955-Supplemental.pdf)
> <p>We introduce a new way of learning to encode position information for non-recurrent models, such as Transformer models. Unlike RNN and LSTM, which contain inductive bias by loading the input tokens sequentially, non-recurrent models are less sensitive to position. The main reason is that position information among input units is not encoded inherently, i.e., they are permutation equivalent, this problem justifies why all of the existing models are accompanied by position encoding/embedding layer at the input. However, this solution has clear limitations: the sinusoidal position encoding is not flexible enough as it is manually designed and does not contain any learnable parameters, whereas the position embedding restricts the maximum length of input sequences. It is thus desirable to design a new position layer that contains learnable parameters to adjust to different datasets and different architectures. At the same time, we would also like it to extrapolate in accordance with the variable length of inputs. In our proposed solution, we borrow from the recent Neural ODE approach, which may be viewed as a versatile continuous version of a ResNet. This model is capable of modeling many kinds of dynamical systems. We model the evolution of encoded results along position index by such a dynamical system, thereby overcoming the above limitations of existing methods. We evaluate our new position layers on a variety of neural machine translation and language understanding tasks, the experimental results show consistent improvements over the baselines.</p> 
### 143.[Do RNN and LSTM have Long Memory?](https://proceedings.icml.cc/book/3383.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/956-Paper.pdf)
  Jingyu Zhao, Feiqing Huang, Jia Lv, Yanjie Duan, Zhen Qin, Guodong Li, Guangjian Tian [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/956-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/956-Supplemental.pdf)
> <p>The LSTM network was proposed to overcome the difficulty in learning long-term dependence, and has made significant advancements in applications. With its success and drawbacks in mind, we raise the question - do RNN and LSTM have long memory? We answer it partially by proving that RNN and LSTM do not have long memory from a time series perspective. Since the term "long memory" is still not well-defined for a network, we propose a new definition for long memory network. To verify our theory, we make minimal modifications to RNN and LSTM and convert them to long memory networks, and illustrate their superiority in modeling long-term dependence of various datasets.</p> 
### 144.[Training Linear Neural Networks: Non-Local Convergence and Complexity Results](https://proceedings.icml.cc/book/3384.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/967-Paper.pdf)
  Armin Eftekhari [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/967-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/967-Supplemental.pdf)
> <p>Linear networks provide valuable insight into the workings of neural networks in general.</p>  <p>In this paper, we improve the state of the art in (Bah et al., 2019) by identifying conditions under which gradient flow successfully trains a linear network, in spite of the non-strict saddle points present in the optimization landscape.</p>  <p>We also improve the state of the art for computational complexity of training linear networks in (Arora et al., 2018a) by establishing non-local linear convergence rates for gradient flow.</p>  <p>Crucially, these new results are not in the lazy training regime, cautioned against in (Chizat et al., 2019; Yehudai &amp; Shamir, 2019).</p>  <p>Our results require the network to have a layer with one neuron, which corresponds to the popular spiked covariance model in statistics, and subsumes the important case of networks with a scalar output. Extending these results to all linear networks remains an open problem.</p> 
### 145.[On Validation and Planning of An Optimal Decision Rule with Application in Healthcare Studies](https://proceedings.icml.cc/book/3385.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/968-Paper.pdf)
  Hengrui Cai, Wenbin Lu, Rui Song [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/968-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/968-Supplemental.zip)
> <p>In the current era of personalized recommendation, one major interest is to develop an optimal individualized decision rule that assigns individuals with the best treatment option according to their covariates. Estimation of optimal decision rules (ODR) has been extensively investigated recently, however, at present, no testing procedure is proposed to verify whether these ODRs are significantly better than the naive decision rule that always assigning individuals to a fixed treatment option. In this paper, we propose a testing procedure for detecting the existence of an ODR that is better than the naive decision rule under the randomized trials. We construct the proposed test based on the difference of estimated value functions using the augmented inverse probability weighted method. The asymptotic distributions of the proposed test statistic under the null and local alternative hypotheses are established. Based on the established asymptotic distributions, we further develop a sample size calculation formula for testing the existence of an ODR in designing A/B tests. Extensive simulations and a real data application to a schizophrenia clinical trial data are conducted to demonstrate the empirical validity of the proposed methods.</p> 
### 146.Graph Optimal Transport for Cross-Domain Alignment [:chains:](https://proceedings.icml.cc/book/3386.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/971-Paper.pdf)
  Liqun Chen, Zhe Gan, Yu Cheng, Linjie Li, Lawrence Carin, Jingjing Liu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/971-Metadata.json)
> <p>Cross-domain alignment between two sets of entities (e.g., objects in an image, words in a sentence) is fundamental to both computer vision and natural language processing. Existing methods mainly focus on designing advanced attention mechanisms to simulate soft alignment, where no training signals are provided to explicitly encourage alignment. Plus, the learned attention matrices are often dense and difficult to interpret. We propose Graph Optimal Transport (GOT), a principled framework that builds upon recent advances in Optimal Transport (OT). In GOT, cross-domain alignment is formulated as a graph matching problem, by representing entities as a dynamically-constructed graph. Two types of OT distances are considered: (i) Wasserstein distance (WD) for node (entity) matching; and (ii) Gromov-Wasserstein distance (GWD) for edge (structure) matching. Both WD and GWD can be incorporated into existing neural network models, effectively acting as a drop-in regularizer. <br /> The inferred transport plan also yields sparse and self-normalized alignment, enhancing the interpretability of the learned model. Experiments show consistent outperformance of GOT over baselines across a wide range of tasks, including image-text retrieval, visual question answering, image captioning, machine translation, and text summarization. </p> 
### 147.Approximation Capabilities of Neural ODEs and Invertible Residual Networks [:chains:](https://proceedings.icml.cc/book/3387.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/979-Paper.pdf)
  Han Zhang, Xi Gao, Jacob Unterman, Tomasz Arodz [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/979-Metadata.json)
> Recent interest in invertible models and normalizing flows has resulted in new architectures that ensure invertibility of the network model. Neural ODEs and i-ResNets are two recent techniques for constructing models that are invertible, but it is unclear if they can be used to approximate any continuous invertible mapping. Here, we show that out of the box, both of these architectures are limited in their approximation capabilities. We then show how to overcome this limitation: we prove that any homeomorphism on a $p$-dimensional Euclidean space can be approximated by a Neural ODE or an i-ResNet operating on a $2p$-dimensional Euclidean space. We conclude by showing that capping a Neural ODE or an i-ResNet with a single linear layer is sufficient to turn the model into a universal approximator for non-invertible continuous functions.
### 148.[Refined bounds for algorithm configuration: The knife-edge of dual class approximability](https://proceedings.icml.cc/book/3388.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/984-Paper.pdf)
  Nina Balcan, Tuomas Sandholm, Ellen Vitercik [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/984-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/984-Supplemental.pdf)
> <p>Automating algorithm configuration is growing increasingly necessary as algorithms come with more and more tunable parameters. It is common to tune parameters using machine learning, optimizing algorithmic performance (runtime or solution quality, for example) using a training set of problem instances from the specific domain at hand. We investigate a fundamental question about these techniques: how large should the training set be to ensure that a parameterâs average empirical performance over the training set is close to its expected, future performance? We answer this question for algorithm configuration problems that exhibit a widely-applicable structure: the algorithm's performance as a function of its parameters can be approximated by a âsimpleâ function. We show that if this approximation holds under the Lâ-norm, we can provide strong sample complexity bounds, but if the approximation holds only under the Lp-norm for p &lt; â, it is not possible to provide meaningful sample complexity bounds in the worst case. We empirically evaluate our bounds in the context of integer programming, obtaining sample complexity bounds that are up to 700 times smaller than the previously best-known bounds.</p> 
### 149.[Teaching with Limited Information on the Learner&#x27;s Behaviour](https://proceedings.icml.cc/book/3389.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/991-Paper.pdf)
  Ferdinando Cicalese, Francisco Sergio de Freitas Filho, Eduardo Laber, Marco Molinaro [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/991-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/991-Supplemental.pdf)
> Machine Teaching studies how efficiently a Teacher  can guide a Learner to a target hypothesis. We focus on the model of Machine Teaching with a black box learner introduced in [Dasgupta et al., ICML 2019], where the teaching is done  interactively   without having any knowledge of the Learner&#x27;s   algorithm and  class of hypotheses, apart from the fact that it contains the target hypothesis $h^*$.   We first refine some existing results for this   model and,  then, we study new variants of it. Motivated  by the realistic possibility that  $h^*$ is not available to the learner, we consider the case where the teacher can only aim at having the learner converge to a best available approximation of $h^*$. We also consider weaker black box learners, where, in each round, the choice of the consistent hypothesis returned to the Teacher is not adversarial, and in particular, we show that better provable bounds can be obtained for a type of Learner  that moves to the next  hypothesis smoothly, preferring hypotheses that are  close  to the current one; and for another type of Learner that can provide to the Teacher hypotheses chosen at random among those consistent with the examples received so far.   Finally, we present an empirical evaluation of  our basic interactive teacher on real datasets. 
### 150.[Interpretations are Useful: Penalizing Explanations to Align Neural Networks with Prior Knowledge](https://proceedings.icml.cc/book/3390.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/992-Paper.pdf)
  Laura Rieger, Chandan Singh, William Murdoch, Bin Yu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/992-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/992-Supplemental.pdf)
> <p>For an explanation of a deep learning model to be effective, it must provide both insight into a model and suggest a corresponding action in order to achieve some objective. Too often, the litany of proposed explainable deep learning methods stop at the first step, providing practitioners with insight into a model, but no way to act on it. In this paper, we propose contextual decomposition explanation penalization (CDEP), a method which enables practitioners to leverage existing explanation methods to increase the predictive accuracy of a deep learning model. In particular, when shown that a model has incorrectly assigned importance to some features, CDEP enables practitioners to correct these errors by inserting domain knowledge into the model  via explanations. We demonstrate the ability of CDEP to increase performance on an array of toy and real datasets.</p> 
### 151.[DeltaGrad: Rapid retraining of machine learning models](https://proceedings.icml.cc/book/3391.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1003-Paper.pdf)
  Yinjun Wu, Edgar Dobriban, Susan Davidson [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1003-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1003-Supplemental.pdf)
> <p>Machine learning models are not static and may need to be retrained on slightly different datasets, for instance, with the addition or deletion of a set of datapoints. This has many applications, including privacy, robustness, bias reduction, and uncertainty quantification. However, it is expensive to retrain models from scratch. To address this problem, we propose the DeltaGrad algorithm for rapidly retraining machine learning models based on information cached during the training phase. We provide both theoretical and empirical support for the effectiveness of DeltaGrad, and show that it compares favorably to the state of the art.</p> 
### 152.[The Cost-free Nature of Optimally Tuning Tikhonov Regularizers and Other Ordered Smoothers](https://proceedings.icml.cc/book/3392.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1015-Paper.pdf)
  Pierre Bellec, Dana Yang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1015-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1015-Supplemental.zip)
> We consider the problem of selecting the best estimator among a family of Tikhonov regularized estimators, or, alternatively, to select a linear combination of these regularizers that is as good as the best regularizer in the family. Our theory reveals that if the Tikhonov regularizers share the same penalty matrix with different tuning parameters, a convex procedure based on $Q$-aggregation achieves the mean square error of the best estimator, up to a small error term no larger than $C\sigma^2$, where $\sigma^2$ is the noise level and $C&gt;0$ is an absolute constant. Remarkably, the error term does not depend on the penalty matrix or the number of estimators as long as they share the same penalty matrix, i.e., it applies to any grid of tuning parameters, no matter how large the cardinality of the grid is. This reveals the surprising &quot;cost-free&quot; nature of optimally tuning Tikhonov regularizers, in striking contrast with the existing literature on aggregation of estimators where one typically has to pay a cost of $\sigma^2\log(M)$ where $M$ is the number of estimators in the family. The result holds, more generally, for any family of ordered linear smoothers. This encompasses Ridge regression as well as Principal Component Regression. The result is extended to the problem of tuning Tikhonov regularizers with different penalty matrices.
### 153.[Approximation Guarantees of Local Search Algorithms via Localizability of Set Functions](https://proceedings.icml.cc/book/3393.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1027-Paper.pdf)
  Kaito Fujii [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1027-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1027-Supplemental.pdf)
> <p>This paper proposes a new framework for providing approximation guarantees of local search algorithms. Local search is a basic algorithm design technique and is widely used for various combinatorial optimization problems. To analyze local search algorithms for set function maximization, we propose a new notion called \textit{localizability} of set functions, which measures how effective local improvement is. Moreover, we provide approximation guarantees of standard local search algorithms under various combinatorial constraints in terms of localizability. The main application of our framework is sparse optimization, for which we show that restricted strong concavity and restricted smoothness of the objective function imply localizability, and further develop accelerated versions of local search algorithms. We conduct experiments in sparse regression and structure learning of graphical models to confirm the practical efficiency of the proposed local search algorithms.</p> 
### 154.[Fine-Grained Analysis of Stability and Generalization for Stochastic Gradient Descent](https://proceedings.icml.cc/book/3394.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1028-Paper.pdf)
  Yunwen Lei, Yiming Ying [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1028-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1028-Supplemental.pdf)
> <p>Recently there are a considerable amount of work devoted to the study of the algorithm stability and  generalization for stochastic gradient descent (SGD). However, the existing stability analysis requires to impose restrictive assumptions on the boundedness of gradients, strong smoothness and convexity of loss functions. In this paper, we provide a fine-grained analysis of stability and generalization for SGD by substantially relaxing these assumptions. Firstly, we establish stability and generalization for SGD by removing the existing bounded gradient assumptions. The key idea is the introduction of a new stability measure called  on-average model stability, for which we develop novel bounds controlled by the risks of SGD iterates. This yields  generalization bounds depending on the behavior of the best model, and leads to the first-ever-known fast bounds in the low-noise setting using stability approach. Secondly, the smoothness assumption is relaxed by considering loss functions with Holder continuous gradients for which we show that optimal bounds are still achieved by balancing computation and stability. Finally, we study learning problems with (strongly) convex objectives but non-convex loss functions, and provide applications where the existing stability bounds fail.</p> 
### 155.[Online Dense Subgraph Discovery via Blurred-Graph Feedback](https://proceedings.icml.cc/book/3395.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1029-Paper.pdf)
  Yuko Kuroki, Atsushi Miyauchi, Junya Honda, Masashi Sugiyama [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1029-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1029-Supplemental.pdf)
> <p>\emph{Dense subgraph discovery} aims to find a dense component in edge-weighted graphs. This is a fundamental graph-mining task with a variety of applications and thus has received much attention recently. Although most existing methods assume that each individual edge weight is easily obtained, such an assumption is not necessarily valid in practice. In this paper, we introduce a novel learning problem for dense subgraph discovery in which a learner queries edge subsets rather than only single edges and observes a noisy sum of edge weights in a queried subset. For this problem, we first propose a polynomial-time algorithm that obtains a nearly-optimal solution with high probability. Moreover, to deal with large-sized graphs, we design a more scalable algorithm with a theoretical guarantee. Computational experiments using real-world graphs demonstrate the effectiveness of our algorithms.</p> 
### 156.[LazyIter: A Fast Algorithm for Counting Markov Equivalent DAGs and Designing Experiments](https://proceedings.icml.cc/book/3396.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1030-Paper.pdf)
  Ali AhmadiTeshnizi, Saber Salehkaleybar, Negar Kiyavash [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1030-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1030-Supplemental.pdf)
> The causal relationships among a set of random variables are commonly represented by a Directed Acyclic Graph (DAG), where there is a directed edge from variable $X$ to variable $Y$ if $X$ is a direct cause of $Y$. From the purely observational data, the true causal graph can be identified up to a Markov Equivalence Class (MEC), which is a set of DAGs with the same conditional independencies between the variables. The size of an MEC is a measure of complexity for recovering the true causal graph by performing interventions. We propose a method for efficient iteration over possible MECs given intervention results. We utilize the proposed method for computing MEC sizes and experiment design in active and passive learning settings. Compared to previous work for computing the size of MEC, our proposed algorithm reduces the time complexity by a factor of $O(n)$ for sparse graphs where $n$ is the number of variables in the system. Additionally, integrating our approach with dynamic programming, we design an optimal algorithm for passive experiment design. Experimental results show that our proposed algorithms for both computing the size of MEC and experiment design outperform the state of the art. 
### 157.[Perceptual Generative Autoencoders](https://proceedings.icml.cc/book/3397.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1042-Paper.pdf)
  Zijun Zhang, Ruixiang ZHANG, Zongpeng Li, Yoshua Bengio, Liam Paull [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1042-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1042-Supplemental.pdf)
> <p>Modern generative models are usually designed to match target distributions directly in the data space, where the intrinsic dimension of data can be much lower than the ambient dimension. We argue that this discrepancy may contribute to the difficulties in training generative models. We therefore propose to map both the generated and target distributions to the latent space using the encoder of a standard autoencoder, and train the generator (or decoder) to match the target distribution in the latent space. Specifically, we enforce the consistency in both the data space and the latent space with theoretically justified data and latent reconstruction losses. The resulting generative model, which we call a perceptual generative autoencoder (PGA), is then trained with a maximum likelihood or variational autoencoder (VAE) objective. With maximum likelihood, PGAs generalize the idea of reversible generative models to unrestricted neural network architectures and arbitrary number of latent dimensions. When combined with VAEs, PGAs substantially improve over the baseline VAEs in terms of sample quality. Compared to other autoencoder-based generative models using simple priors, PGAs achieve state-of-the-art FID scores on CIFAR-10 and CelebA.</p> 
### 158.[Towards Understanding the Regularization of Adversarial Robustness on Neural Networks](https://proceedings.icml.cc/book/3398.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1057-Paper.pdf)
  Yuxin Wen, Shuai Li, Kui Jia [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1057-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1057-Supplemental.pdf)
> <p>The problem of adversarial examples has shown that modern Neural Network (NN) models could be rather fragile. Among the most promising techniques to solve the problem, one is to require the model to be epsilon-adversarially robust (AR); that is, to require the model not to change predicted labels when any given input examples are perturbed within a certain range. However, it is observed that such methods would lead to standard performance degradation, i.e., the degradation on natural examples. In this work, we study the degradation through the regularization perspective. We identify quantities from generalization analysis of NNs; with the identified quantities we empirically find that AR is achieved by regularizing/biasing NNs towards less confident solutions by making the changes in the feature space (induced by changes in the instance space) of most layers smoother uniformly in all directions; so to a certain extent, it prevents sudden change in prediction w.r.t. perturbations. However, the end result of such smoothing concentrates samples around decision boundaries, resulting in less confident solutions, and leads to worse standard performance. Our studies suggest that one might consider ways that build AR into NNs in a gentler way to avoid the problematic regularization.</p> 
### 159.[Stochastic Gradient and Langevin Processes](https://proceedings.icml.cc/book/3399.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1074-Paper.pdf)
  Xiang Cheng, Dong Yin, Peter Bartlett, Michael Jordan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1074-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1074-Supplemental.pdf)
> <p>We prove quantitative convergence rates at which discrete Langevin-like processes converge to the invariant distribution of a related stochastic differential equation. We study the setup where the additive noise can be non-Gaussian and state-dependent and the potential function can be non-convex. We show that the key properties of these processes depend on the potential function and the second moment of the additive noise. We apply our theoretical findings to studying the convergence of Stochastic Gradient Descent (SGD) for non-convex problems and corroborate them with experiments using SGD to train deep neural networks on the CIFAR-10 dataset.</p> 
### 160.[ROMA: Multi-Agent Reinforcement Learning with Emergent Roles](https://proceedings.icml.cc/book/3400.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1080-Paper.pdf)
  Tonghan Wang, Heng Dong, Victor Lesser, Chongjie Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1080-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1080-Supplemental.pdf)
> <p>The role concept provides a useful tool to design and understand complex multi-agent systems, which allows agents with a similar role to share similar behaviors. However, existing role-based methods use prior domain knowledge and predefine role structures and behaviors. In contrast, multi-agent reinforcement learning (MARL) provides flexibility and adaptability, but less efficiency in complex tasks. In this paper, we synergize these two paradigms and propose a role-oriented MARL framework (ROMA). In this framework, roles are emergent, and agents with similar roles tend to share their learning to be specialized on certain sub-tasks. To this end, we construct a stochastic role embedding space by introducing two novel regularizers and conditioning individual policies on roles. Experiments show that our method can learn dynamic, versatile, identifiable, and specialized roles, which help our method push forward the state of the art on the StarCraft II micromanagement benchmark. Demonstrative videos are available at https://sites.google.com/view/romarl/.</p> 
### 161.[Minimax Pareto Fairness: A Multi Objective Perspective](https://proceedings.icml.cc/book/3401.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1084-Paper.pdf)
  Martin Bertran, Natalia Martinez, Guillermo Sapiro [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1084-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1084-Supplemental.pdf)
> <p>In this work we formulate and formally characterize group fairness as a multi-objective optimization problem, where each sensitive group risk is a separate objective. We propose a fairness criterion where a classifier achieves minimax risk and is Pareto-efficient w.r.t. all groups, avoiding unnecessary harm, and can lead to the best zero-gap model if policy dictates so. We provide a simple optimization algorithm compatible with deep neural networks to satisfy these constraints. Since our method does not require test-time access to sensitive attributes, it can be applied to reduce worst-case classification errors between outcomes in unbalanced classification problems. We test the proposed methodology on real case-studies of predicting income, ICU patient mortality, skin lesions classification, and assessing credit risk, demonstrating how our framework compares favorably to other approaches.</p> 
### 162.Online Pricing with Offline Data: Phase Transition and Inverse Square Law [:chains:](https://proceedings.icml.cc/book/3402.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1090-Paper.pdf)
  Jinzhi Bu, David Simchi-Levi, Yunzong Xu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1090-Metadata.json)
> <p>This paper investigates the impact of pre-existing offline data on online learning, in the context of dynamic pricing. We study a single-product dynamic pricing problem over a selling horizon of T periods. The demand in each period is determined by the price of the product according to a linear demand model with unknown parameters. We assume that the seller already has some pre-existing offline data before the start of the selling horizon. The seller wants to utilize both the pre-existing offline data and the sequential online data to minimize the regret of the online learning process. We characterize the joint effect of the size, location and dispersion of the offline data on the optimal regret of the online learning process. Our results reveal surprising transformations of the optimal regret rate with respect to the size of the offline data, which we refer to as phase transitions. In addition, our results demonstrate that the location and dispersion of the offline data also have an intrinsic effect on the optimal regret, and we quantify this effect via the inverse-square law.</p> 
### 163.[Explicit Gradient Learning for Black-Box Optimization](https://proceedings.icml.cc/book/3403.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1091-Paper.pdf)
  Elad Sarafian, Mor Sinay, yoram louzoun, Noa Agmon, Sarit Kraus [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1091-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1091-Supplemental.zip)
> <p>Black-Box Optimization (BBO) methods can find optimal policies for systems that interact with complex environments with no analytical representation. As such, they are of interest in many Artificial Intelligence (AI) domains. Yet classical BBO methods fall short in high-dimensional non-convex problems. They are thus often overlooked in real-world AI tasks. Here we present a BBO method, termed Explicit Gradient Learning (EGL), that is designed to optimize high-dimensional ill-behaved functions. We derive EGL by finding weak spots in methods that fit the objective function with a parametric Neural Network (NN) model and obtain the gradient signal by calculating the parametric gradient. Instead of fitting the function, EGL trains a NN to estimate the objective gradient directly. We prove the convergence of EGL to a stationary point and its robustness in the optimization of integrable functions. We evaluate EGL and achieve state-of-the-art results in two challenging problems: (1) the COCO test suite against an assortment of standard BBO methods; and (2) in a high-dimensional non-convex image generation task.</p> 
### 164.[Optimization and Analysis of the pAp@k Metric for Recommender Systems](https://proceedings.icml.cc/book/3404.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1095-Paper.pdf)
  Gaurush Hiranandani, Warut Vijitbenjaronk, Sanmi Koyejo, Prateek Jain [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1095-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1095-Supplemental.pdf)
> <p>Modern recommendation and notification systems must be robust to data imbalance, limitations on the number of recommendations/notifications, and heterogeneous engagement profiles across users. The pAp@k metric, which combines the partial-AUC and the precision@k metrics, was recently proposed to evaluate such recommendation systems and has been used in real-world deployments. Conceptually, pAp@k measures the probability of correctly ranking a top-ranked positive instance over top-ranked negative instances. Due to the combinatorial aspect surfaced by top-ranked points, little is known about the characteristics and optimization methods of pAp@k. In this paper, we analyze the learning-theoretic properties of pAp@k and propose novel surrogates that are consistent under certain data regularity conditions. We then provide gradient descent based algorithms to optimize the surrogates directly. Our analysis and experimental evaluation suggest that pAp@k indeed exhibits a certain dual behavior with respect to partial-AUC and precision@k. Moreover, the proposed methods outperform all the baselines in various applications. Taken together, our results motivate the use of pAp@k for large-scale recommender systems.</p> 
### 165.[When Explanations Lie: Why Many Modified BP Attributions Fail](https://proceedings.icml.cc/book/3405.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1105-Paper.pdf)
  Leon Sixt, Maximilian Granz, Tim Landgraf [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1105-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1105-Supplemental.pdf)
> <p>Attribution methods aim to explain a neural network's prediction by highlighting the most relevant image areas. A popular approach is to backpropagate (BP) a custom relevance score using modified rules, rather than the gradient. We analyze an extensive set of modified BP methods: Deep Taylor Decomposition, Layer-wise Relevance Propagation (LRP), Excitation BP, PatternAttribution, DeepLIFT, Deconv, RectGrad, and Guided BP. We find empirically that the explanations of all mentioned methods, except for DeepLIFT, are independent of the parameters of later layers. We provide theoretical insights for this surprising behavior and also analyze why DeepLIFT does not suffer from this limitation. Empirically, we measure how information of later layers is ignored by using our new metric, cosine similarity convergence (CSC). The paper provides a framework to assess the faithfulness of new and existing modified BP methods theoretically and empirically.</p> 
### 166.[Naive Exploration is Optimal for Online LQR](https://proceedings.icml.cc/book/3406.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1107-Paper.pdf)
  Max Simchowitz, Dylan Foster [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1107-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1107-Supplemental.pdf)
> We consider the problem of online adaptive control of the linear quadratic regulator, where the true system parameters are unknown. We prove new upper and lower bounds demonstrating that the optimal regret scales as $\widetilde{\Theta}({\sqrt{d_{\mathbf{u}}^2 d_{\mathbf{x}} T}})$, where $T$ is the number of time steps, $d_{\mathbf{u}}$ is the dimension of the input space, and $d_{\mathbf{x}}$ is the dimension of the system state.  Notably, our lower bounds rule out the possibility of a $\mathrm{poly}(\log{}T)$-regret algorithm, which has been conjectured due to the apparent strong convexity of the problem. Our upper bounds are attained by a simple variant of \emph{certainty equivalence control}, where the learner selects control inputs according to  the optimal controller for their estimate of the system while injecting exploratory random noise (Mania et al. 2019).  Central to our upper and lower bounds is a new approach for controlling perturbations of Riccati equations, which we call the \emph{self-bounding ODE method}. The approach enables regret upper bounds which hold for \emph{any stabilizable instance}, require no foreknowledge of the system except for a single stabilizing controller, and scale with natural control-theoretic quantities.  
### 167.[Learning Structured Latent Factors from Dependent Data:A Generative Model Framework from Information-Theoretic Perspective](https://proceedings.icml.cc/book/3407.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1111-Paper.pdf)
  Ruixiang ZHANG, Katsuhiko Ishiguro, Masanori Koyama [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1111-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1111-Supplemental.pdf)
> <p>Learning controllable and generalizable representation of multivariate data with desired structural properties remains a fundamental problem in machine learning. In this paper, we present a novel framework for learning generative models with various underlying structures in the latent space. We represent the inductive bias in the form of mask variables to model the dependency structure in the graphical model and extend the theory of multivariate information bottleneck to enforce it. Our model provides a principled approach to learn a set of semantically meaningful latent factors that reflect various types of desired structures like capturing correlation or encoding invariance, while also offering the flexibility to automatically estimate the dependency structure from data. We show that our framework unifies many existing generative models and can be applied to a variety of tasks including multi-modal data modeling, algorithmic fairness, and invariant risk minimization.</p> 
### 168.[Implicit Generative Modeling for Efficient Exploration](https://proceedings.icml.cc/book/3408.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1113-Paper.pdf)
  Neale Ratzlaff, Qinxun Bai, Fuxin Li, Wei Xu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1113-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1113-Supplemental.pdf)
> <p>Efficient exploration remains a challenging problem in reinforcement learning, especially for those tasks where rewards from environments are sparse.  In this work, we introduce an exploration approach based on a novel implicit generative modeling algorithm to estimate a Bayesian uncertainty of the agent's belief of the environment dynamics. Each random draw from our generative model is a neural network that instantiates the dynamic function, hence multiple draws would approximate the posterior, and the variance in the predictions based on this posterior is used as an intrinsic reward for exploration. We design a training algorithm for our generative model based on the amortized Stein Variational Gradient Descent. In experiments, we demonstrate the effectiveness of this exploration algorithm in both pure exploration tasks and a downstream task, comparing with state-of-the-art intrinsic reward-based exploration approaches, including two recent approaches based on an ensemble of dynamic models. In challenging exploration tasks, our implicit generative model consistently outperforms competing approaches regarding data efficiency in exploration.</p> 
### 169.[Prediction-Guided Multi-Objective Reinforcement Learning for Continuous Robot Control](https://proceedings.icml.cc/book/3409.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1114-Paper.pdf)
  Jie Xu, Yunsheng Tian, Pingchuan Ma, Daniela Rus, Shinjiro Sueda, Wojciech Matusik [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1114-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1114-Supplemental.zip)
> <p>Many real-world control problems involve conflicting objectives where we desire a dense and high-quality set of control policies that are optimal for different objective preferences (called Pareto-optimal). While extensive research in multi-objective reinforcement learning (MORL) has been conducted to tackle such problems, multi-objective optimization for complex continuous robot control is still under-explored. In this work, we propose an efficient evolutionary learning algorithm to find the Pareto set approximation for continuous robot control problems, by extending a state-of-the-art RL algorithm and presenting a novel prediction model to guide the learning process. In addition to efficiently discovering the individual policies on the Pareto front, we construct a continuous set of Pareto-optimal solutions by Pareto analysis and interpolation. Furthermore, we design six multi-objective RL environments with continuous action space, which is the first benchmark platform to evaluate MORL algorithms on various robot control problems. We test the previous methods on the proposed benchmark problems, and the experiments show that our approach is able to find a much denser and higher-quality set of Pareto policies than the existing algorithms.</p> 
### 170.[Goodness-of-Fit Tests for Inhomogeneous Random Graphs](https://proceedings.icml.cc/book/3410.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1119-Paper.pdf)
  Soham Dan, Bhaswar B. Bhattacharya [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1119-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1119-Supplemental.pdf)
> Hypothesis testing of random networks is an emerging area of modern research, especially in the high-dimensional regime, where the  number of samples is smaller or comparable to the size of the graph.  In this paper we consider the goodness-of-fit testing problem for large inhomogeneous random (IER) graphs, where given a (known) reference symmetric matrix $Q \in [0, 1]^{n \times n}$ and $m$ independent samples from an IER graph given by an unknown  symmetric matrix $P \in [0, 1]^{n \times n}$, the goal is to test the hypothesis $P=Q$ versus $||P-Q|| \geq \varepsilon$, where $||\cdot||$ is some specified norm on symmetric matrices. Building on recent related work on two-sample testing for IER graphs, we derive the optimal minimax sample complexities for the goodness-of-fit problem in various natural norms, such as the Frobenius norm and the operator norm. We also propose practical implementations of natural test statistics, using their asymptotic distributions and through the parametric bootstrap. We compare the performances of the different tests in simulations, and show that the proposed  tests outperform the baseline tests across various natural random graphs models.
### 171.[Few-shot Domain Adaptation by Causal Mechanism Transfer](https://proceedings.icml.cc/book/3411.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1121-Paper.pdf)
  Takeshi Teshima, Issei Sato, Masashi Sugiyama [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1121-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1121-Supplemental.pdf)
> <p>We study few-shot supervised domain adaptation (DA) for regression problems, where only a few labeled target domain data and many labeled source domain data are available. Many of the current DA methods base their transfer assumptions on either parametrized distribution shift or apparent distribution similarities, e.g., identical conditionals or small distributional discrepancies. However, these assumptions may preclude the possibility of adaptation from intricately shifted and apparently very different distributions. To overcome this problem, we propose mechanism transfer, a meta-distributional scenario in which a data generating mechanism is invariant among domains. This transfer assumption can accommodate nonparametric shifts resulting in apparently different distributions while providing a solid statistical basis for DA. We take the structural equations in causal modeling as an example and propose a novel DA method, which is shown to be useful both theoretically and experimentally. Our method can be seen as the first attempt to fully leverage the invariance of structural causal models for DA.</p> 
### 172.[Adaptive Adversarial Multi-task Representation Learning](https://proceedings.icml.cc/book/3412.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1125-Paper.pdf)
  YUREN MAO, Weiwei Liu, Xuemin Lin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1125-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1125-Supplemental.zip)
> <p>Adversarial Multi-task Representation Learning (AMTRL) methods are able to boost the performance of Multi-task Representation Learning (MTRL) models. However, the theoretical mechanism behind AMTRL is less investigated. To fill this gap, we study the generalization error bound of AMTRL through the lens of Lagrangian duality . Based on the duality, we proposed an novel adaptive AMTRL algorithm which improves the performance of original AMTRL methods. The extensive experiments back up our theoretical analysis and validate the superiority of our proposed algorithm.</p> 
### 173.[Streaming Submodular Maximization under a k-Set System Constraint](https://proceedings.icml.cc/book/3413.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1126-Paper.pdf)
  Ran Haba, Ehsan Kazemi, Moran Feldman, Amin Karbasi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1126-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1126-Supplemental.pdf)
> In this paper, we propose a novel framework that converts streaming algorithms for monotone submodular maximization into streaming algorithms for non-monotone submodular maximization. This reduction readily leads to the currently tightest deterministic approximation ratio for submodular maximization subject to a $k$-matchoid constraint. Moreover, we propose the first streaming algorithms for monotone submodular maximization subject to $k$-extendible and $k$-system constraints. Together with our proposed reduction, we obtain $O(k\log k)$ and $O(k^2\log k)$ approximation ratio for submodular maximization subject to the above constraints, respectively. We extensively evaluate the empirical performance of our algorithm against the existing work in a series of experiments including finding the maximum independent set in randomly generated graphs, maximizing linear functions over social networks, movie recommendation, Yelp location summarization, and Twitter data summarization.
### 174.[A Generic First-Order Algorithmic Framework for Bi-Level Programming Beyond Lower-Level Singleton](https://proceedings.icml.cc/book/3414.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1129-Paper.pdf)
  Risheng Liu, Pan Mu, Xiaoming Yuan, Shangzhi Zeng, Jin Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1129-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1129-Supplemental.pdf)
> <p>Recently, gradient-based methods have been developed for Bi-Level Programmings (BLPs) in learning and vision fields. The successes of these methods heavily rely on the simplification that for each fixed upper-level variable, the lower-level solution is a singleton (i.e., Lower-Level Singleton, LLS). However, LLS is usually too restrictive to be satisfied in real-world complex scenarios. This paper first presents a counter-example to illustrate the invalidation of those existing gradient-based bi-level schemes in the absence of the LLS condition. To address this critical issue, a new method, named Bi-level Descent Aggregation (BDA) is proposed, aiming to broaden the application horizon of first-order schemes for BLPs. In particular, by investigating BLPs from the view point of optimistic bi-level, BDA establishes a generic algorithmic framework. In our strategy, the aggregation of hierarchical objective information helps to produce flexible bi-level iteration schemes. Our theoretical investigations prove the strict convergence of BDA for general BLPs without the LLS condition. We also show that BDA is indeed compatible to a verify of particular first-order computation modules. Additionally, as an interesting byproduct, we improve those conventional first-order bi-level schemes under the LLS simplification. Particularly, we establish their convergences with weaker assumptions. Extensive experiments justify our theoretical results and demonstrate the superiority of the proposed BDA for different tasks, including hyper-parameter optimization and meta learning.</p> 
### 175.[Optimal approximation for unconstrained non-submodular minimization](https://proceedings.icml.cc/book/3415.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1143-Paper.pdf)
  Marwa El Halabi, Stefanie Jegelka [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1143-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1143-Supplemental.pdf)
> <p>Submodular function minimization is well studied, and existing algorithms solve it exactly or up to arbitrary accuracy. However, in many applications, such as structured sparse learning, and batch Bayesian optimization, the objective function is not exactly submodular, but close. In this case, no theoretical guarantees exist. Indeed, submodular minimization algorithms rely on intricate connections between submodularity and convexity. We show how these relations can be extended to obtain approximation guarantees for minimizing non-submodular functions, characterized by how close the function is to submodular. We also extend this result to noisy function evaluations. Our approximation results are the first for minimizing non-submodular functions, and are optimal, as established by our matching lower bound.</p> 
### 176.Generating Programmatic Referring Expressions via Program Synthesis [:chains:](https://proceedings.icml.cc/book/3416.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1158-Paper.pdf)
  Jiani Huang, Calvin Smith, Osbert Bastani, Rishabh Singh, Aws Albarghouthi, Mayur Naik [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1158-Metadata.json)
> <p>Incorporating symbolic reasoning into machine learning algorithms is a promising approach to improve performance on learning tasks that require logical reasoning. We study the problem of generating a programmatic variant of referring expressions that we call referring relational programs. In particular, given a symbolic representation of an image and a target object in that image, the goal is to generate a relational program that uniquely identifies the target object in terms of its attributes and its relations to other objects in the image. We propose a neurosymbolic program synthesis algorithm that combines a policy neural network with enumerative search to generate such relational programs. The policy neural network employs a program interpreter that provides immediate feedback on the consequences of the decisions made by the policy, and also takes into account the uncertainty in the symbolic representation of the image. We evaluate our algorithm on challenging benchmarks based on the CLEVR dataset, and demonstrate that our approach significantly outperforms several baselines.</p> 
### 177.[Nearly Linear Row Sampling Algorithm for Quantile Regression](https://proceedings.icml.cc/book/3417.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1160-Paper.pdf)
  Yi Li, Ruosong Wang, Lin Yang, Hanrui Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1160-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1160-Supplemental.zip)
> We give a row sampling algorithm for the quantile loss function with sample complexity nearly linear in the dimensionality of the data, improving upon the previous best algorithm whose sampling complexity has at least cubic dependence on the dimensionality. Based upon our row sampling algorithm, we give the fastest known algorithm for quantile regression and a graph sparsification algorithm for balanced directed graphs. Our main technical contribution is to show that Lewis weights sampling, which has been used in row sampling algorithms for $\ell_p$ norms, can also be applied in row sampling algorithms for a variety of loss functions. We complement our theoretical results by experiments to demonstrate the practicality of our approach. 
### 178.[On Leveraging Pretrained GANs for Generation with Limited Data](https://proceedings.icml.cc/book/3418.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1164-Paper.pdf)
  Miaoyun Zhao, Yulai Cong, Lawrence Carin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1164-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1164-Supplemental.pdf)
> <p>Recent work has shown generative adversarial networks (GANs) can generate highly realistic images, that are often indistinguishable (by humans) from real images. Most images so generated are not contained in the training dataset, suggesting potential for augmenting training sets with GAN-generated data. While this scenario is of particular relevance when there are limited data available, there is still the issue of training the GAN itself based on that limited data. To facilitate this, we leverage existing GAN models pretrained on large-scale datasets (like ImageNet) to introduce additional knowledge (which may not exist within the limited data), following the concept of transfer learning. Demonstrated by natural-image generation, we reveal that low-level filters (those close to observations) of both the generator and discriminator of pretrained GANs can be transferred to facilitate generation in a perceptually-distinct target domain with limited training data. To further adapt the transferred filters to the target domain, we propose adaptive filter modulation (AdaFM). An extensive set of experiments is presented to demonstrate the effectiveness of the proposed techniques on generation with limited data.</p> 
### 179.[More Data Can Expand The Generalization Gap Between Adversarially Robust and Standard Models](https://proceedings.icml.cc/book/3419.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1172-Paper.pdf)
  Lin Chen, Yifei Min, Mingrui Zhang, Amin Karbasi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1172-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1172-Supplemental.zip)
> Despite remarkable success in practice, modern machine learning models have been found to be susceptible to adversarial attacks that make human-imperceptible perturbations to the data, but result in serious and potentially dangerous prediction errors. To address this issue, practitioners often use adversarial training to learn models that are robust against such attacks at the cost of higher generalization error on unperturbed test sets. The conventional wisdom is that more training data should shrink the gap between the generalization error of adversarially-trained models and standard models. However, we study the training of robust classifiers for both Gaussian and Bernoulli models under $\ell_\infty$ attacks, and we prove that more data may actually increase this gap. Furthermore, our theoretical results identify if and when additional data will finally begin to shrink the gap. Lastly, we experimentally demonstrate that our results also hold for linear regression models, which may indicate that this phenomenon occurs more broadly.
### 180.[Double Reinforcement Learning for Efficient and Robust Off-Policy Evaluation](https://proceedings.icml.cc/book/3420.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1173-Paper.pdf)
  Nathan Kallus, Masatoshi Uehara [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1173-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1173-Supplemental.zip)
> Off-policy evaluation (OPE) in reinforcement learning allows one to evaluate novel decision policies without needing to conduct exploration, which is often costly or otherwise infeasible. We consider for the first time the semiparametric efficiency limits of OPE in Markov decision processes (MDPs), where actions, rewards, and states are memoryless. We show existing OPE estimators may fail to be efficient in this setting. We develop a new estimator based on cross-fold estimation of $q$-functions and marginalized density ratios, which we term double reinforcement learning (DRL). We show that DRL is efficient when both components are estimated at fourth-root rates and is also doubly robust when only one component is consistent. We investigate these properties empirically and demonstrate the performance benefits due to harnessing memorylessness.
### 181.[Statistically Efficient Off-Policy Policy Gradients](https://proceedings.icml.cc/book/3421.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1176-Paper.pdf)
  Nathan Kallus, Masatoshi Uehara [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1176-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1176-Supplemental.zip)
> <p>Policy gradient methods in reinforcement learning update policy parameters by taking steps in the direction of an estimated gradient of policy value. In this paper, we consider the efficient estimation of policy gradients from off-policy data, where the estimation is particularly non-trivial. We derive the asymptotic lower bound on the feasible mean-squared error in both Markov and non-Markov decision processes and show that existing estimators fail to achieve it in general settings. We propose a meta-algorithm that achieves the lower bound without any parametric assumptions and exhibits a unique 4-way double robustness property. We discuss how to estimate nuisances that the algorithm relies on. Finally, we establish guarantees at the rate at which we approach a stationary point when we take steps in the direction of our new estimated policy gradient.</p> 
### 182.Self-PU: Self Boosted and Calibrated Positive-Unlabeled Training [:chains:](https://proceedings.icml.cc/book/3422.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1182-Paper.pdf)
  Xuxi Chen, Wuyang Chen, Tianlong Chen, Ye Yuan, Chen Gong, Kewei Chen, Zhangyang Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1182-Metadata.json)
> <p>Many real-world applications have to tackle the Positive-Unlabeled (PU) learning problem, i.e., learning binary classifiers from a large amount of unlabeled data and a few labeled positive examples. While current state-of-the-art methods employ importance reweighting to design various biased or unbiased risk estimators, they completely ignored the learning capability of the model itself, which could provide reliable supervision. This motivates us to propose a novel Self-PU learning framework, which seamlessly integrates PU learning and self-training. Self-PU highlights three ``self''-oriented building blocks: a self-paced training algorithm that adaptively discovers and augments confident positive/negative examples as the training proceeds; a self-reweighted, instance-aware loss; and a self-distillation scheme that introduces teacher-students learning as an effective regularization for PU learning. We demonstrate the state-of-the-art performance of Self-PU on common PU learning benchmarks (MNIST and CIFAR10), which compare favorably against the latest competitors. Moreover, we study a real-world application of PU learning, i.e., classifying brain images of Alzheimer's Disease. Self-PU obtains significantly improved results on the renowned Alzheimer's Disease Neuroimaging Initiative (ADNI) database over existing methods.</p> 
### 183.[When Does Self-Supervision Help Graph Convolutional Networks?](https://proceedings.icml.cc/book/3423.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1185-Paper.pdf)
  Yuning You, Tianlong Chen, Zhangyang Wang, Yang Shen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1185-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1185-Supplemental.pdf)
> <p>Self-supervision as an emerging learning technique has been employed to train convolutional neural networks (CNNs) for more transferrable, generalizable, and robust representation learning of image data.  Its introduction to graph convolutional networks (GCNs) operating on graph data is however rarely explored.  In this study, we report the first systematic exploration and assessment of incorporating self-supervision into  GCNs.  We first elaborate three mechanisms to incorporate self-supervision into GCNs, analyze the limitations of pretraining &amp; finetuning and self-training, and proceed to focus on multi-task learning. Moreover, we design three novel self-supervised learning tasks for GCNs with both theoretical rationales and numerical comparisons.  Lastly, we further integrate multi-task self-supervision into graph adversarial training. Our results show that, with properly designed task forms and incorporation mechanisms, self-supervision benefits GCNs in gaining more generalizability and robustness. </p> 
### 184.[On Differentially Private Stochastic Convex Optimization  with Heavy-tailed Data](https://proceedings.icml.cc/book/3424.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1190-Paper.pdf)
  Di Wang, Hanshen Xiao, Srinivas Devadas, Jinhui Xu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1190-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1190-Supplemental.zip)
> In this paper, we consider the problem of designing  Differentially Private (DP) algorithms for Stochastic Convex Optimization (SCO) on heavy-tailed data. The irregularity of such data violates some key  assumptions used in almost all existing DP-SCO and DP-ERM methods, resulting in failure to provide the DP guarantees. To better understand this type of challenges, we provide in this paper a comprehensive study of DP-SCO under various settings. First, we consider the case where the loss function is strongly convex and smooth. For this case, we propose a method based on the sample-and-aggregate framework, which has an excess population risk of  $\tilde{O}(\frac{d^3}{n\epsilon^4})$ (after omitting other factors), where $n$ is the sample size and $d$ is the dimensionality of the data. Then, we show that with some additional assumptions on the loss functions, it is possible to reduce the  \textit{expected} excess population risk to $\tilde{O}(\frac{ d^2}{ n\epsilon^2 })$. To lift these additional conditions, we also    provide a gradient smoothing and trimming based scheme to achieve  excess population risks of    $\tilde{O}(\frac{ d^2}{n\epsilon^2})$ and $\tilde{O}(\frac{d^\frac{2}{3}}{(n\epsilon^2)^\frac{1}{3}})$ for strongly convex and general convex loss functions, respectively, \textit{with high probability}. Experiments on both synthetic and real-world datasets suggest that our algorithms can effectively deal with the challenges caused by data irregularity. 
### 185.[Variance Reduced Coordinate Descent with Acceleration: New Method With a Surprising Application to Finite-Sum Problems](https://proceedings.icml.cc/book/3425.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1205-Paper.pdf)
  Filip Hanzely, Dmitry Kovalev, Peter Richtarik [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1205-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1205-Supplemental.zip)
> <p>We propose an accelerated version of stochastic variance reduced coordinate descent -- ASVRCD. As other variance reduced coordinate descent methods such as SEGA or SVRCD, our method can deal with problems that include a non-separable and non-smooth regularizer, while accessing a random block of partial derivatives in each iteration only. However, ASVRCD incorporates Nesterov's momentum, which offers favorable iteration complexity guarantees over both  SEGA and SVRCD. As a by-product of our theory, we show that a variant of Katyusha (Allen-Zhu, 2017) is a specific case of ASVRCD, recovering the optimal oracle complexity for the finite sum objective.</p> 
### 186.[Stochastic Subspace Cubic Newton Method](https://proceedings.icml.cc/book/3426.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1206-Paper.pdf)
  Filip Hanzely, Nikita Doikov, Yurii Nesterov, Peter Richtarik [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1206-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1206-Supplemental.zip)
> In this paper, we propose a new randomized second-order optimization algorithm---Stochastic Subspace Cubic Newton (SSCN)---for minimizing a high dimensional convex function $f$. Our method can be seen both as a {\em stochastic} extension of the cubically-regularized Newton method of Nesterov and Polyak (2006), and a {\em second-order} enhancement of stochastic subspace descent of Kozak et al. (2019). We prove that as we vary the minibatch size, the global convergence rate of SSCN interpolates between the rate of stochastic coordinate descent (CD) and the rate of cubic regularized Newton, thus giving new insights into the connection between first and second-order methods. Remarkably, the local convergence rate of SSCN matches the rate of stochastic subspace descent applied to the problem of minimizing the quadratic function $\frac12 (x-x^*)^\top \nabla^2f(x^*)(x-x^*)$, where $x^*$ is the minimizer of $f$, and hence depends on the properties of $f$ at the optimum only. Our numerical experiments show that SSCN outperforms non-accelerated first-order CD algorithms while being competitive to their accelerated variants.
### 187.[Ready Policy One: World Building Through Active Learning](https://proceedings.icml.cc/book/3427.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1214-Paper.pdf)
  Philip Ball, Jack Parker-Holder, Aldo Pacchiano, Krzysztof Choromanski, Stephen Roberts [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1214-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1214-Supplemental.pdf)
> <p>Model-Based Reinforcement Learning (MBRL) offers a promising direction for sample efficient learning, often achieving state of the art results for continuous control tasks. However many existing MBRL methods rely on combining greedy policies with exploration heuristics, and even those which utilize principled exploration bonuses construct dual objectives in an ad hoc fashion. In this paper we introduce Ready Policy One (RP1), a framework that views MBRL as an active learning problem, where we aim to improve the world model in the fewest samples possible. RP1 achieves this by utilizing a hybrid objective function, which crucially adapts during optimization, allowing the algorithm to trade off reward v.s. exploration at different stages of learning. In addition, we introduce a principled mechanism to terminate sample collection once we have a rich enough trajectory batch to improve the model. We rigorously evaluate our method on a variety of continuous control tasks, and demonstrate statistically significant gains over existing approaches.</p> 
### 188.[Structural Language Models of Code](https://proceedings.icml.cc/book/3428.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1218-Paper.pdf)
  Uri Alon, Roy Sadaka, Omer Levy, Eran Yahav [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1218-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1218-Supplemental.pdf)
> <p>We address the problem of any-code completion - generating a missing piece of source code in a given program without any restriction on the vocabulary or structure. We introduce a new approach to any-code completion that leverages the strict syntax of programming languages to model a code snippet as a tree - structural language modeling (SLM). SLM estimates the probability of the program's abstract syntax tree (AST) by decomposing it into a product of conditional probabilities over its nodes. We present a neural model that computes these conditional probabilities by considering all AST paths leading to a target node. Unlike previous techniques that have severely restricted the kinds of expressions that can be generated in this task, our approach can generate arbitrary code in any programming language. Our model significantly outperforms both seq2seq and a variety of structured approaches in generating Java and C# code. Our code, data, and trained models are available at http://github.com/tech-srl/slm-code-generation/. An online demo is available at http://AnyCodeGen.org.</p> 
### 189.[PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization](https://proceedings.icml.cc/book/3429.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1219-Paper.pdf)
  Jingqing Zhang, Yao Zhao, Mohammad Saleh, Peter Liu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1219-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1219-Supplemental.pdf)
> <p>Recent work pre-training Transformers with self-supervised objectives on large text corpora has shown great success when fine-tuned on downstream NLP tasks including text summarization. However, pre-training objectives tailored for abstractive text summarization have not been explored. Furthermore there is a lack of systematic evaluation across diverse domains. In this work, we propose pre-training large Transformer-based encoder-decoder models on massive text corpora with a new self-supervised objective. In PEGASUS, important sentences are removed/masked from an input document and are generated together as one output sequence from the remaining sentences, similar to an extractive summary. We evaluated our best PEGASUS model on 12 downstream summarization tasks spanning news, science, stories, instructions, emails, patents, and legislative bills. Experiments demonstrate it achieves state-of-the-art performance on all 12 downstream datasets measured by ROUGE scores. Our model also shows surprising performance on low-resource summarization, surpassing previous  state-of-the-art results on 6 datasets with only 1000 examples. Finally we validated our results using human evaluation and show that our model summaries achieve  human performance on multiple datasets.</p> 
### 190.[Aggregation of Multiple Knockoffs](https://proceedings.icml.cc/book/3430.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1222-Paper.pdf)
  Tuan-Binh Nguyen, Jerome-Alexis Chevalier, Thirion Bertrand, Sylvain Arlot [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1222-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1222-Supplemental.pdf)
> <p>We develop an extension of the knockoff inference procedure, introduced by Barber &amp; Candes (2015). This new method, called Aggregation of Multiple Knockoffs (AKO), addresses the instability inherent to the random nature of knockoff-based inference. Specifically, AKO improves both the stability and power compared with the original knockoff algorithm while still maintaining guarantees for false discovery rate control. We provide a new inference procedure, prove its core properties, and demonstrate its benefits in a set of experiments on synthetic and real datasets.</p> 
### 191.[Off-Policy Actor-Critic with Shared Experience Replay](https://proceedings.icml.cc/book/3431.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1228-Paper.pdf)
  Simon Schmitt, Matteo Hessel, Karen Simonyan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1228-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1228-Supplemental.pdf)
> <p>We investigate the combination of actor-critic reinforcement learning algorithms with a uniform large-scale experience replay and propose solutions for two ensuing challenges: (a) efficient actor-critic learning with experience replay (b) the stability of off-policy learning where agents learn from other agents behaviour. </p>  <p>To this end we analyze the bias-variance tradeoffs in V-trace, a form of importance sampling for actor-critic methods. Based on our analysis, we then argue for mixing experience sampled from replay with on-policy experience, and propose a new trust region scheme that scales effectively to data distributions where V-trace becomes unstable.</p>  <p>We provide extensive empirical validation of the proposed solutions on DMLab-30. We further show the benefits of this setup in two training regimes for Atari: (1) a single agent is trained up until 200M environment frames per game (2) a population of agents is trained up until 200M environment frames each and may share experience. While (1) is a standard regime, (2) reflects the use case of concurrently executed hyper-parameter sweeps. We demonstrate state-of-the-art data efficiency among model-free agents in both regimes.</p> 
### 192.[Graph-based Nearest Neighbor Search: From Practice to Theory](https://proceedings.icml.cc/book/3432.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1229-Paper.pdf)
  Liudmila Prokhorenkova, Aleksandr Shekhovtsov [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1229-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1229-Supplemental.pdf)
> <p>Graph-based approaches are empirically shown to be very successful for the nearest neighbor search (NNS). However, there has been very little research on their theoretical guarantees. In this work, we fill this gap and rigorously analyze the performance of graph-based NNS algorithms, specifically focusing on the low-dimensional (d &lt;&lt; log n) regime. In addition to the basic greedy algorithm on the nearest neighbor graph, we also analyze the most successful heuristics commonly used in practice: speeding up via adding shortcut edges and improving accuracy via maintaining a dynamic list of candidates. We believe that our theoretical results supported by experimental analysis are an important step towards understanding the limits and benefits of graph-based NNS algorithms.</p> 
### 193.Policy Teaching via Environment Poisoning: Training-time Adversarial Attacks against Reinforcement Learning [:chains:](https://proceedings.icml.cc/book/3433.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1231-Paper.pdf)
  Amin Rakhsha, Goran Radanovic, Rati Devidze, Jerry Zhu, Adish Singla [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1231-Metadata.json)
> <p>We study a security threat to reinforcement learning where an attacker poisons the learning environment to force the agent into executing a target policy chosen by the attacker. As a victim, we consider RL agents whose objective is to find a policy that maximizes average reward in undiscounted infinite-horizon problem settings. The attacker can manipulate the rewards or the transition dynamics in the learning environment at training-time and is interested in doing so in a stealthy manner. We propose an optimization framework for finding an \emph{optimal stealthy attack} for different measures of attack cost. We provide sufficient technical conditions under which the attack is feasible and provide lower/upper bounds on the attack cost. We instantiate our attacks in two settings: (i) an \emph{offline} setting where the agent is doing planning in the poisoned environment, and (ii) an \emph{online} setting where the agent is learning a policy using a regret-minimization framework with poisoned feedback. Our results show that the attacker can easily succeed in teaching any target policy to the victim under mild conditions and highlight a significant security threat to reinforcement learning agents in practice.</p> 
### 194.[Semismooth Newton Algorithm for Efficient Projections onto $\ell_{1, \infty}$-norm Ball](https://proceedings.icml.cc/book/3434.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1238-Paper.pdf)
  Dejun Chu, Changshui Zhang, Shiliang Sun, Qing Tao [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1238-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1238-Supplemental.pdf)
> Structured sparsity-inducing $\ell_{1, \infty}$-norm, as a generalization of the classical $\ell_1$-norm, plays an important role in jointly sparse models which select or remove simultaneously all the variables forming a group. However, its resulting problem is more difficult to solve than the conventional $\ell_1$-norm constrained problem. In this paper, we propose an efficient algorithm for Euclidean projection onto $\ell_{1, \infty}$-norm ball. We tackle the projection problem via semismooth Newton algorithm to solve the system of semismooth equations. Meanwhile, exploiting the structure of Jacobian matrix via LU decomposition yields an equivalent algorithm which is proved to terminate after a finite number  of iterations. Empirical studies demonstrate that our proposed algorithm outperforms the existing state-of-the-art solver and is promising for the optimization of learning problems with $\ell_{1, \infty}$-norm ball constraint.
### 195.[Influenza Forecasting Framework based on Gaussian Processes](https://proceedings.icml.cc/book/3435.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1239-Paper.pdf)
  Christoph Zimmer, Reza Yaesoubi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1239-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1239-Supplemental.zip)
> <p>The seasonal epidemic of influenza costs thousands of lives each year in the US. While influenza epidemics occur every year, timing and size of the epidemic vary strongly from season to season. This complicates the public health efforts to adequately respond to such epidemics. Forecasting techniques to predict the development of seasonal epidemics such as influenza, are of great help to public health decision making. Therefore, the US Center for Disease Control and Prevention (CDC) has initiated a yearly challenge to forecast influenza-like illness. Here, we propose a new framework based on Gaussian process (GP) for seasonal epidemics forecasting and demonstrate its capability on the CDC reference data on influenza like illness: our framework leads to accurate forecasts with small but reliable uncertainty estimation. We compare our framework to several state of the art benchmarks and show competitive performance. We, therefore, believe that our GP based framework for seasonal epidemics forecasting will play a key role for future influenza forecasting and, lead to further research in the area.</p> 
### 196.[Unique Properties of Wide Minima in Deep Networks](https://proceedings.icml.cc/book/3436.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1243-Paper.pdf)
  Rotem Mulayoff, Tomer Michaeli [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1243-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1243-Supplemental.pdf)
> <p>It is well known that (stochastic) gradient descent has an implicit bias towards wide minima. In deep neural network training, this mechanism serves to screen out minima. However, the precise effect that this has on the trained network is not yet fully understood. In this paper, we characterize the wide minima in linear neural networks trained with a quadratic loss. First, we show that linear ResNets with zero initialization necessarily converge to the widest of all minima. We then prove that these minima correspond to nearly balanced networks whereby the gain from the input to any intermediate representation does not change drastically from one layer to the next. Finally, we show that consecutive layers in wide minima solutions are coupled. That is, one of the left singular vectors of each weight matrix, equals one of the right singular vectors of the next matrix. This forms a distinct path from input to output, that, as we show, is dedicated to the signal that experiences the largest gain end-to-end. Experiments indicate that these properties are characteristic of both linear and nonlinear models trained in practice.</p> 
### 197.[Does the Markov Decision Process Fit the Data: Testing for the Markov Property in Sequential Decision Making](https://proceedings.icml.cc/book/3437.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1244-Paper.pdf)
  Chengchun Shi, Runzhe Wan, Rui Song, Wenbin Lu, Ling Leng [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1244-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1244-Supplemental.pdf)
> <p>The Markov assumption (MA) is fundamental to the empirical validity of reinforcement learning. In this paper, we propose a novel Forward-Backward Learning procedure to test MA in sequential decision making. The proposed test does not assume any parametric form on the joint distribution of the observed data and plays an important role for identifying the optimal policy in high-order Markov decision processes and partially observable MDPs. We apply our test to both synthetic datasets and a real data example from mobile health studies to illustrate its usefulness.</p> 
### 198.[LTF: A Label Transformation Framework for Correcting Label Shift](https://proceedings.icml.cc/book/3438.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1262-Paper.pdf)
  Jiaxian Guo, Mingming Gong, Tongliang Liu, Kun Zhang, Dacheng Tao [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1262-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1262-Supplemental.pdf)
> Distribution shift is a major obstacle to the deployment of current deep learning models on real-world problems. Let $Y$ be the class label and $X$ the features. We focus on one type of distribution shift, \textit{ label shift}, where the label marginal distribution $P_Y$ changes but the conditional distribution $P_{X|Y}$ does not. Most existing methods estimate the density ratio between the source- and target-domain label distributions by density matching. However, these methods are either computationally infeasible for large-scale data or restricted to shift correction for discrete labels. In this paper, we propose an end-to-end Label Transformation Framework (LTF) for correcting label shift, which implicitly models the shift of $P_Y$ and the conditional distribution $P_{X|Y}$ using neural networks. Thanks to the flexibility of deep networks, our framework can handle continuous, discrete, and even multi-dimensional labels in a unified way and is scalable to large data. Moreover, for high dimensional $X$, such as images, we find that the redundant information in $X$ severely degrades the estimation accuracy. To remedy this issue, we propose to match the distribution implied by our generative model and the target-domain distribution in a low-dimensional feature space that discards information irrelevant to $Y$. Both theoretical and empirical studies demonstrate the superiority of our method over previous approaches.  
### 199.[Divide, Conquer, and Combine: a New Inference Strategy for Probabilistic Programs with Stochastic Support](https://proceedings.icml.cc/book/3439.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1272-Paper.pdf)
  Yuan Zhou, Hongseok Yang, Yee Whye Teh, Tom Rainforth [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1272-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1272-Supplemental.pdf)
> <p>Universal probabilistic programming systems (PPSs) provide a powerful framework for specifying rich and complex probabilistic models. They further attempt to automate the process of drawing inferences from these models, but doing this successfully is severely hampered by the wide range of non-standard models they can express. As a result, although one can specify complex models in a universal PPS, the provided inference engines often fall far short of what is required. In particular, we show they produce surprisingly unsatisfactory performance for models where the support may vary between executions, often doing no better than importance sampling from the prior. To address this, we introduce a new inference framework: Divide, Conquer, and Combine, which remains efficient for such models, and show how it can be implemented as an automated and general-purpose PPS inference engine. We empirically demonstrate substantial performance improvements over existing approaches on two examples.</p> 
### 200.Duality in RKHSs with Infinite Dimensional Outputs: Application to Robust Losses [:chains:](https://proceedings.icml.cc/book/3440.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1279-Paper.pdf)
  Pierre Laforgue, Alex Lambert, Luc Brogat-Motte, Florence d&#x27;Alche-Buc [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1279-Metadata.json)
> <p>Operator-Valued Kernels (OVKs) and associated vector-valued Reproducing Kernel Hilbert Spaces provide an elegant way to extend scalar kernel methods when the output space is a Hilbert space. Although primarily used in finite dimension for problems like multi-task regression, the ability of this framework to deal with infinite dimensional output spaces unlocks many more applications, such as functional regression, structured output prediction, and structured data representation. However, these sophisticated schemes crucially rely on the kernel trick in the output space, so that most of previous works have focused on the square norm loss function, completely neglecting robustness issues that may arise in such surrogate problems. To overcome this limitation, this paper develops a duality approach that allows to solve OVK machines for a wide range of loss functions. The infinite dimensional Lagrange multipliers are handled through a Double Representer Theorem, and algorithms for \epsilon-insensitive losses and the Huber loss are thoroughly detailed. Robustness benefits are emphasized by a theoretical stability analysis, as well as empirical improvements on structured data applications.</p> 
### 201.[Causal Effect Estimation and Optimal Dose Suggestions in Mobile Health](https://proceedings.icml.cc/book/3441.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1297-Paper.pdf)
  Liangyu Zhu, Wenbin Lu, Rui Song [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1297-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1297-Supplemental.pdf)
> <p>In this article, we propose novel structural nested models to estimate causal effects of continuous treatments based on mobile health data. To find the treatment regime which optimizes the short-term outcomes for the patients, we define the weighted lag K advantage. The optimal treatment regime is then defined to be the one which maximizes this advantage. This method imposes minimal assumptions on the data generating process. Statistical inference can also be provided for the estimated parameters. Simulation studies and an application to the Ohio type 1 diabetes dataset show that our method could provide meaningful insights for dose suggestions with mobile health data. </p> 
### 202.Towards Understanding the Dynamics of the First-Order Adversaries [:chains:](https://proceedings.icml.cc/book/3442.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1310-Paper.pdf)
  Zhun Deng, Hangfeng He, Jiaoyang Huang, Weijie Su [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1310-Metadata.json)
> <p>An acknowledged weakness of neural networks is their vulnerability to adversarial perturbations to the inputs. To improve the robustness of these models, one of the most popular defense mechanisms is to alternatively maximize the loss over the constrained perturbations (or called adversaries) on the inputs using projected gradient ascent and minimize over weights. In this paper, we analyze the dynamics of the maximization step towards understanding the experimentally observed effectiveness of this defense mechanism. Specifically, we investigate the landscape of the adversaries for a two-layer neural network with a quadratic loss. Our main result proves that projected gradient ascent finds a local maximum of this non-concave problem in a polynomial number of iterations with high probability.  To our knowledge, this is the first work that provides a convergence analysis of the first-order adversaries. Moreover, our analysis demonstrates that, in the initial phase of adversarial training, the scale of the inputs matters in the sense that a smaller input scale leads to faster convergence of adversarial training and a ``more regular'' landscape. Finally, we show that these theoretical findings are in excellent agreement with a series of experiments.</p> 
### 203.Interpreting Robust Optimization via Adversarial Influence Functions [:chains:](https://proceedings.icml.cc/book/3443.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1313-Paper.pdf)
  Zhun Deng, Cynthia Dwork, Jialiang Wang, Linjun Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1313-Metadata.json)
> <p>Robust optimization has been widely used in nowadays data science, especially in adversarial training. However, little research has been done to quantify how robust optimization changes the optimizers and the prediction losses comparing to standard training.  In this paper, inspired by the influence function in robust statistics, we introduce the Adversarial Influence Function (AIF) as a tool to investigate the solution produced by robust optimization. The proposed AIF enjoys a closed-form and can be calculated efficiently. To illustrate the usage of AIF, we apply it to study model sensitivity -- a quantity defined to capture the change of prediction losses on the natural data after implementing robust optimization. We use AIF to analyze how model complexity and randomized smoothing affect the model sensitivity with respect to specific models.  We further derive AIF for kernel regressions, with a particular application to neural tangent kernels, and experimentally demonstrate the effectiveness of the proposed AIF. Lastly, the theories of AIF will be extended to distributional robust optimization.</p> 
### 204.[Multilinear Latent Conditioning for Generating Unseen Attribute Combinations](https://proceedings.icml.cc/book/3444.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1314-Paper.pdf)
  Markos Georgopoulos, Grigorios Chrysos, Yannis Panagakis, Maja Pantic [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1314-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1314-Supplemental.pdf)
> <p>Empirical studies have shown that deep generative models demonstrate inductive bias. Although this bias is crucial in problems with high dimensional data, like images, generative models lack the generalization ability that occurs naturally in human perception. For example, humans can visualize a woman smiling after only seeing a smiling man. On the contrary, the standard conditional variational auto-encoder (cVAE) is unable to generate unseen attribute combinations. To this end, we extend the cVAE by introducing a multilinear latent conditioning framework. We implement two variants of our model and demonstrate their efficacy on MNIST, Fashion-MNIST and CelebA. Altogether, we design a novel conditioning framework that can be used with any architecture to synthesize unseen attribute combinations.</p> 
### 205.[No-Regret Exploration in Goal-Oriented Reinforcement Learning](https://proceedings.icml.cc/book/3445.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1315-Paper.pdf)
  Jean Tarbouriech, Evrard Garcelon, Michal Valko, Matteo Pirotta, Alessandro Lazaric [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1315-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1315-Supplemental.pdf)
> Many popular reinforcement learning problems (e.g., navigation in a maze, some Atari games, mountain car) are instances of the episodic setting under its stochastic shortest path (SSP) formulation, where an agent has to achieve a goal state while minimizing the cumulative cost. Despite the popularity of this setting, the exploration-exploitation dilemma has been sparsely studied in general SSP problems, with most of the theoretical literature focusing on different problems (i.e., fixed-horizon and infinite-horizon) or making the restrictive loop-free SSP assumption (i.e., no state can be visited twice during an episode). In this paper, we study the general SSP problem with no assumption on its dynamics (some policies may actually never reach the goal). We introduce UC-SSP, the first no-regret algorithm in this setting, and prove a regret bound scaling as $\widetilde{\mathcal{O}}( D S \sqrt{ A D K})$ after $K$ episodes for any unknown SSP with $S$ states, $A$ actions, positive costs and SSP-diameter $D$, defined as the smallest expected hitting time from any starting state to the goal. We achieve this result by crafting a novel stopping rule, such that UC-SSP may interrupt the current policy if it is taking too long to achieve the goal and switch to alternative policies that are designed to rapidly terminate the episode.
### 206.OPtions as REsponses: Grounding behavioural hierarchies in multi-agent reinforcement learning [:chains:](https://proceedings.icml.cc/book/3446.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1319-Paper.pdf)
  Alexander Vezhnevets, Yuhuai Wu, Maria Eckstein, RÃ©mi Leblond, Joel Z Leibo [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1319-Metadata.json)
> <p>This paper investigates generalisation in multi-agent games, where the generality of the agent can be evaluated by playing against opponents it hasn't seen during training. We propose two new games with concealed information and complex, non-transitive reward structure (think rock-paper-scissors). It turns out that most current deep reinforcement learning methods fail to efficiently explore the strategy space, thus learning policies that generalise poorly to unseen opponents. We then propose a novel hierarchical agent architecture, where the hierarchy is grounded in the game-theoretic structure of the game -- the top level chooses strategic responses to opponents, while the low level implements them into policy over primitive actions. This grounding facilitates credit assignment across the levels of hierarchy. Our experiments show that the proposed hierarchical agent is capable of generalisation to unseen opponents, while conventional baselines fail to generalise whatsoever.</p> 
### 207.[Feature Noise Induces Loss Discrepancy Across Groups](https://proceedings.icml.cc/book/3447.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1320-Paper.pdf)
  Fereshte Khani, Percy Liang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1320-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1320-Supplemental.pdf)
> <p>It has been observed that the performance of standard learning procedures differs widely across groups. Recent studies usually attribute this loss discrepancy to an information deficiency for one group (e.g., one group has less data). In this work, we point to a more subtle source of loss discrepancy---feature noise. Our main result is that even when there is no information deficiency specific to one group (e.g., both groups have infinite data), adding the same amount of feature noise to all individuals leads to loss discrepancy. For linear regression, we characterize this loss discrepancy in terms of the amount of noise and difference between moments of the two groups. We then study the time it takes for an estimator to adapt to a shift in the population that makes the groups have the same mean. We finally validate our results on three real-world datasets.</p> 
### 208.[Reinforcement Learning for Molecular Design Guided by Quantum Mechanics](https://proceedings.icml.cc/book/3448.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1323-Paper.pdf)
  Gregor Simm, Robert Pinsler, Jose Miguel Hernandez-Lobato [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1323-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1323-Supplemental.pdf)
> <p>Automating molecular design using deep reinforcement learning (RL) holds the promise of accelerating the discovery of new chemical compounds. A limitation of existing approaches is that they work with molecular graphs and thus ignore the location of atoms in space, which restricts them to (1) generating single organic molecules and (2) heuristic reward functions. To address this, we present a novel RL formulation for molecular design in 3D space, thereby extending the class of molecules that can be built. Our reward function is directly based on fundamental physical properties such as the energy, which we approximate via fast quantum-chemical calculations. To enable progress towards designing molecules in 3D space, we introduce MolGym, an RL environment comprising several molecular design tasks alongside with baselines. In our experiments, we show that our agent can efficiently learn to solve these tasks from scratch by working in a translation and rotation invariant state-action space.</p> 
### 209.Small-GAN: Speeding up GAN Training using Core-Sets  [:chains:](https://proceedings.icml.cc/book/3449.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1324-Paper.pdf)
  Samrath Sinha, Han Zhang, Anirudh Goyal, Yoshua Bengio, Hugo Larochelle, Augustus Odena [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1324-Metadata.json)
> <p>Recent work suggests that Generative Adversarial Networks (GANs) benefit disproportionately from large mini-batch sizes. This finding is interesting but also discouraging -- large batch sizes are slow and expensive to emulate on conventional hardware. Thus, it would be nice if there were some trick by which we could generate batches that were effectively big though small in practice. In this work, we propose such a trick, inspired by the use of Coreset-selection in active learning. When training a GAN, we draw a large batch of samples from the prior and then compress that batch using Coreset-selection. To create effectively large batches of real images, we create a cached dataset of Inception activations of each training image, randomly project them down to a smaller dimension, and then use Coreset-selection on those projected embeddings at training time. We conduct experiments showing that this technique substantially reduces training time and memory usage for modern GAN variants, that it reduces the fraction of dropped modes in a synthetic dataset, and that it helps us use GANs to reach a new state of the art in anomaly detection.</p> 
### 210.[Conditional gradient methods for stochastically constrained convex minimization](https://proceedings.icml.cc/book/3450.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1343-Paper.pdf)
  Maria-Luiza Vladarean, Ahmet Alacaoglu, Ya-Ping Hsieh, Volkan Cevher [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1343-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1343-Supplemental.zip)
> <p>We propose two novel conditional gradient-based methods for solving structured stochastic convex optimization problems with a large number of linear constraints. Instances of this template naturally arise from SDP-relaxations of combinatorial problems, which involve a number of constraints that is polynomial in the problem dimension. The most important feature of our framework is that only a subset of the constraints is processed at each iteration, thus gaining a computational advantage over prior works that require full passes. Our algorithms rely on variance reduction and smoothing used in conjunction with conditional gradient steps, and are accompanied by rigorous convergence guarantees. Preliminary numerical experiments are provided for illustrating the practical performance of the methods.</p> 
### 211.[Undirected Graphical Models as Approximate Posteriors](https://proceedings.icml.cc/book/3451.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1354-Paper.pdf)
  Arash Vahdat, Evgeny Andriyash, William Macready [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1354-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1354-Supplemental.pdf)
> <p>The representation of the approximate posterior is a critical aspect of effective variational autoencoders (VAEs). Poor choices for the approximate posterior have a detrimental impact on the generative performance of VAEs due to the mismatch with the true posterior. We extend the class of posterior models that may be learned by using undirected graphical models. We develop an efficient method to train undirected approximate posteriors by showing that the gradient of the training objective with respect to the parameters of the undirected posterior can be computed by backpropagation through Markov chain Monte Carlo updates. We apply these gradient estimators for training discrete VAEs with Boltzmann machines as approximate posteriors and demonstrate that undirected models outperform previous results obtained using directed graphical models.</p> 
### 212.Dynamics of Deep Neural Networks and  Neural Tangent Hierarchy [:chains:](https://proceedings.icml.cc/book/3452.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1356-Paper.pdf)
  Jiaoyang Huang, Horng-Tzer Yau [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1356-Metadata.json)
> <p>The evolution of a deep neural network trained by the gradient descent can be described by its neural tangent kernel (NTK) as introduced in \cite{jacot2018neural}, where it was proven that in the infinite width limit the NTK converges to an explicit limiting kernel and it stays constant during training. The NTK was also implicit in some other recent papers \cite{du2018gradient1,du2018gradient2,arora2019fine}. In the overparametrization regime, a fully-trained deep neural network is indeed equivalent to the kernel regression predictor using the limiting NTK. And the gradient descent achieves zero training loss for a deep overparameterized neural network. However, it was observed in \cite{arora2019exact} that there is a performance gap between the kernel regression using the limiting NTK and the deep neural networks. This performance gap  is likely to  originate   from the change of the NTK along training due to the finite width effect. The change of the NTK along the  training is central to describe the generalization features of deep neural networks. </p>  <p>In the current paper, we study the dynamic of the NTK for finite width deep fully-connected neural networks. We derive an  infinite hierarchy of ordinary differential equations, the neural tangent hierarchy (NTH) which captures the gradient descent  dynamic of the deep neural network. Moreover, under certain conditions  on the neural network width and the data set dimension,  we prove  that the truncated hierarchy of NTH approximates the dynamic of the NTK up to arbitrary precision. This description makes it possible to directly study the change of the NTK for deep neural networks, and sheds light on the observation that deep neural networks outperform kernel regressions using the corresponding limiting NTK. </p> 
### 213.[Measuring Non-Expert Comprehension of Machine Learning Fairness Metrics](https://proceedings.icml.cc/book/3453.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1357-Paper.pdf)
  Debjani Saha, Candice Schumann, Duncan McElfresh, John Dickerson, Michelle Mazurek, Michael Tschantz [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1357-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1357-Supplemental.pdf)
> <p>Bias in machine learning has manifested injustice in several areas, such as medicine, hiring, and criminal justice. In response, computer scientists have developed myriad definitions of fairness to correct this bias in fielded algorithms. While some definitions are based on established legal and ethical norms, others are largely mathematical. It is unclear whether the general public agrees with these fairness definitions, and perhaps more importantly, whether they understand these definitions.  We take initial steps toward bridging this gap between ML researchers and the public, by addressing the question: does a lay audience understand a basic definition of ML fairness? We develop a metric to measure comprehension of three such definitions--demographic parity, equal opportunity, and equalized odds. We evaluate this metric using an online survey, and investigate the relationship between comprehension and sentiment, demographics, and the definition itself.</p> 
### 214.[Encoding Musical Style with Transformer Autoencoders](https://proceedings.icml.cc/book/3454.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1363-Paper.pdf)
  Kristy Choi, Curtis Hawthorne, Ian Simon, Monica  Dinculescu, Jesse Engel [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1363-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1363-Supplemental.pdf)
> <p>We consider the problem of learning high-level controls over the global structure of sequence generation, particularly in the context of symbolic music generation with complex language models. In this work, we present the Transformer autoencoder, which aggregates encodings of the input data across time to obtain a global representation of style from a given performance. We show it is possible to combine this global representation with other temporally distributed embeddings, enabling improved control over the separate aspects of performance style and melody. Empirically, we demonstrate the effectiveness of our method on a variety of music generation tasks on the MAESTRO dataset and an internal dataset with 10,000+ hours of piano performances, where we achieve improvements in terms of log-likelihood and mean listening scores as compared to relevant baselines.</p> 
### 215.[Min-Max Optimization without Gradients: Convergence and Applications to Black-Box Evasion and Poisoning Attacks](https://proceedings.icml.cc/book/3455.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1365-Paper.pdf)
  Sijia Liu, Songtao Lu, Xiangyi Chen, Yao Feng, Kaidi Xu, Abdullah Al-Dujaili, Mingyi Hong, Una-May O&#x27;Reilly [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1365-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1365-Supplemental.pdf)
> <p>In this paper, we study the problem of constrained min-max optimization in a black-box setting, where the desired optimizer cannot access the gradients of the objective function but may query its values. We present a principled optimization framework, integrating a zeroth-order (ZO) gradient estimator with an alternating projected stochastic gradient descent-ascent method, where the former only requires a small number of function queries and the later needs just one-step descent/ascent update. We show that the proposed framework, referred to as ZO-Min-Max, has a sub-linear convergence rate under mild conditions and scales gracefully with problem size. We also explore a promising connection between black-box min-max optimization and black-box evasion and poisoning attacks in adversarial machine learning (ML). Our empirical evaluations on these use cases demonstrate the effectiveness of our approach and its scalability to dimensions that prohibit using recent black-box solvers.</p> 
### 216.[ConQUR: Mitigating Delusional Bias in Deep Q-Learning ](https://proceedings.icml.cc/book/3456.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1373-Paper.pdf)
  DiJia Su, Jayden Ooi, Tyler Lu, Dale Schuurmans, Craig Boutilier [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1373-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1373-Supplemental.pdf)
> <p>Delusional bias is a fundamental source of error in approximate Q-learning. To date, the only techniques that explicitly address delusion require comprehensive search using tabular value estimates. In this paper, we develop efficient methods to mitigate delusional bias by training Q-approximators with labels that are "consistent" with the underlying greedy policy class. We introduce a simple penalization scheme that encourages Q-labels used across training batches to remain (jointly) consistent with the expressible policy class. We also propose a search framework that allows multiple Q-approximators to be generated and tracked, thus mitigating the effect of premature (implicit) policy commitments. Experimental results demonstrate that these methods can improve the performance of Q-learning in a variety of Atari games, sometimes dramatically.</p> 
### 217.[Self-Modulating Nonparametric Event-Tensor Factorization](https://proceedings.icml.cc/book/3457.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1382-Paper.pdf)
  Zheng Wang, Xinqi Chu, Shandian Zhe [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1382-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1382-Supplemental.pdf)
> <p>Tensor factorization is a fundamental framework to analyze high-order interactions in data. Despite the success of the existing methods, the valuable temporal information are severely underused. The timestamps of the interactions are either ignored or discretized into crude steps. The recent work although formulates event-tensors to keep the timestamps in factorization and can capture mutual excitation effects among the interaction events, it overlooks another important type of temporal influence, inhibition. In addition, it uses a local window to exclude all the long-term dependencies. To overcome these limitations, we propose a self-modulating nonparametric Bayesian factorization model. We use the latent factors to construct mutually governed, general random point processes, which can capture various short-term/long-term, excitation/inhibition effects, so as to encode the complex temporal dependencies into factor representations.  In addition, our model couples with a latent Gaussian process to estimate and fuse nonlinear yet static relationships between the entities. For efficient inference, we derive a fully decomposed model evidence lower bound to dispense with the huge kernel matrix and costly summations inside the rate and log rate functions. We then develop an efficient stochastic optimization algorithm. We show the advantage of our method in four real-world applications. </p> 
### 218.[Extreme Multi-label Classification from Aggregated Labels](https://proceedings.icml.cc/book/3458.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1388-Paper.pdf)
  Yanyao Shen, Hsiang-Fu Yu, Sujay Sanghavi, Inderjit Dhillon [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1388-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1388-Supplemental.pdf)
> <p>Extreme multi-label classification (XMC) is the problem of finding the relevant labels for an input, from a very large universe of possible labels. We consider XMC in the setting where labels are available only for groups of samples - but not for individual ones. Current XMC approaches are not built for such multi-instance multi-label (MIML) training data, and MIML approaches do not scale to XMC sizes. We develop a new and scalable algorithm to impute individual-sample labels from the group labels; this can be paired with any existing XMC method to solve the aggregated label problem. We characterize the statistical properties of our algorithm under mild assumptions, and provide a new end-to-end framework for MIML as an extension. Experiments on both aggregated label XMC and MIML tasks show the advantages over existing approaches.</p> 
### 219.[Full Law Identification In Graphical Models Of Missing Data: Completeness Results](https://proceedings.icml.cc/book/3459.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1396-Paper.pdf)
  Razieh Nabi, Rohit Bhattacharya, Ilya Shpitser [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1396-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1396-Supplemental.pdf)
> <p>Missing data has the potential to affect analyses conducted in all fields of scientific study, including healthcare, economics, and the social sciences. Several approaches to unbiased inference in the presence of non-ignorable missingness rely on the specification of the target distribution and its missingness process as a probability distribution that factorizes with respect to a directed acyclic graph. In this paper, we address the longstanding question of the characterization of models that are identifiable within this class of missing data distributions. We provide the first completeness result in this field of study -- necessary and sufficient graphical conditions under which, the full data distribution can be recovered from the observed data distribution. We then simultaneously address issues that may arise due to the presence of both missing data and unmeasured confounding, by extending these graphical conditions and proofs of completeness, to settings where some variables are not just missing, but completely unobserved.</p> 
### 220.[Self-Attentive Associative Memory](https://proceedings.icml.cc/book/3460.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1397-Paper.pdf)
  Hung Le, Truyen Tran, Svetha Venkatesh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1397-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1397-Supplemental.pdf)
> <p>Heretofore, neural networks with external memory are restricted to single memory with lossy representations of memory interactions. A rich representation of relationships between memory pieces urges a high-order and segregated relational memory. In this paper, we propose to separate the storage of individual experiences (item memory) and their occurring relationships (relational memory). The idea is implemented through a novel Self-attentive Associative Memory (SAM) operator. Found upon outer product, SAM forms a set of associative memories that represent the hypothetical high-order relationships between arbitrary pairs of memory elements, through which a relational memory is constructed from an item memory. The two memories are wired into a single sequential model capable of both memorization and relational reasoning. We achieve competitive results with our proposed two-memory model in a diversity of machine learning tasks, from challenging synthetic problems to practical testbeds such as geometry, graph, reinforcement learning, and question answering. </p> 
### 221.Imputer: Sequence Modelling via Imputation and Dynamic Programming [:chains:](https://proceedings.icml.cc/book/3461.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1410-Paper.pdf)
  William Chan, Chitwan Saharia, Geoffrey Hinton, Mohammad Norouzi, Navdeep Jaitly [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1410-Metadata.json)
> <p>This paper presents the Imputer, a neural sequence model that generates output sequences iteratively via imputations. The Imputer is an iterative generation model, requiring only a constant number of generation steps independent of the number of input or output tokens. The Imputer can be trained to approximately marginalize over all possible alignments between the input and output sequences, and all possible generation orders. We present a tractable dynamic programming training algorithm, which yields a lower bound on the log marginal likelihood. When applied to end-to-end speech recognition, the Imputer outperforms prior non-autoregressive models and achieves competitive results to autoregressive models. On LibriSpeech test-other, the Imputer achieves 11.1 WER, outperforming CTC at 13.0 WER and seq2seq at 12.5 WER.</p> 
### 222.[Continuously Indexed Domain Adaptation](https://proceedings.icml.cc/book/3462.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1417-Paper.pdf)
  Hao Wang, Hao He, Dina Katabi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1417-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1417-Supplemental.pdf)
> <p>Existing domain adaptation focuses on transferring knowledge between domains with categorical indices (e.g., between datasets A and B). However, many tasks involve continuously indexed domains. For example, in medical applications, one often needs to transfer disease analysis and prediction across patients of different ages, where age acts as a continuous domain index. Such tasks are challenging for prior domain adaptation methods since they ignore the underlying relation among domains.</p>  <p>In this paper, we propose the first method for continuously indexed domain adaptation. Our approach combines traditional adversarial adaptation with a novel discriminator that models the encoding-conditioned domain index distribution. Our theoretical analysis demonstrates the value of leveraging the domain index to generate invariant features across a continuous range of domains. Our empirical results show that our approach outperforms the state-of-the-art domain adaption methods on both synthetic and real-world medical datasets.</p> 
### 223.[Evolving Machine Learning Algorithms From Scratch](https://proceedings.icml.cc/book/3463.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1418-Paper.pdf)
  Esteban Real, Chen Liang, David So, Quoc Le [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1418-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1418-Supplemental.pdf)
> <p>Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as AutoML, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that AutoML can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.</p> 
### 224.[Self-Attentive Hawkes Process](https://proceedings.icml.cc/book/3464.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1421-Paper.pdf)
  Qiang Zhang, Aldo Lipani, Omer Kirnap, Emine Yilmaz [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1421-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1421-Supplemental.pdf)
> <p>Capturing the occurrence dynamics is crucial to predicting which type of events will happen next and when. A common method to do this is Hawkes processes. To enhance their capacity, recurrent neural networks (RNNs) have been incorporated due to RNNsâ successes in processing sequential data such as languages. Recent evidence suggests self-attention is more competent than RNNs in dealing with languages. However, we are unaware of the effectiveness of selfattention in the context of Hawkes processes. This study attempts to fill the gap by designing a self-attentive Hawkes process (SAHP). The SAHP employed self-attention to summarize influence from history events and compute the probability of the next event. One deficit of the conventional self-attention is that position embeddings only considered order numbers in a sequence, which ignored time intervals between temporal events. To overcome this deficit, we modified the conventional method by translating time intervals into phase shifts of sinusoidal functions. Experiments on goodness-of-fit and prediction tasks showed the improved capability of SAHP. Furthermore, the SAHP is more interpretable than RNN-based counterparts because the learnt attention weights revealed contributions of one event type to the happening of another type. To the best of our knowledge, this is the first work that studies the effectiveness of self-attention in Hawkes processes</p> 
### 225.[On hyperparameter tuning in general clustering problemsm](https://proceedings.icml.cc/book/3465.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1425-Paper.pdf)
  Xinjie Fan, Yuguang Yue, Purnamrita Sarkar, Y. X. Rachel Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1425-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1425-Supplemental.pdf)
> <p>Tuning hyperparameters for unsupervised learning problems is difficult in general due to the lack of ground truth for validation. However, the success of most clustering methods depends heavily on the correct choice of the involved hyperparameters. Take for example the Lagrange multipliers of penalty terms in semidefinite programming (SDP) relaxations of community detection in networks, or the bandwidth parameter needed in the Gaussian kernel used to construct similarity matrices for spectral clustering. Despite the popularity of these clustering algorithms, there are not many provable methods for tuning these hyperparameters. In this paper, we provide a overarching framework with provable guarantees for tuning hyperparameters in the above class of problems under two different models. Our framework can be augmented with a cross validation procedure  to do model selection  as well. In a variety of simulation and real data experiments, we show that our framework outperforms other widely used tuning procedures in a broad range of parameter settings.</p> 
### 226.[Communication-Efficient Distributed Stochastic AUC Maximization with Deep Neural Networks](https://proceedings.icml.cc/book/3466.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1428-Paper.pdf)
  Zhishuai Guo, Mingrui Liu, Zhuoning Yuan, Li Shen, Wei Liu, Tianbao Yang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1428-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1428-Supplemental.pdf)
> <p>In this paper, we study distributed algorithms for large-scale AUC maximization with a deep neural network as a predictive model. <br /> Although distributed learning techniques have been investigated extensively  in deep learning, they are not directly applicable to stochastic AUC maximization with deep neural networks due to its striking differences from standard loss minimization problems (e.g., cross-entropy).  Towards addressing this challenge,  we propose and analyze a communication-efficient distributed optimization algorithm  based on a {\it non-convex concave} reformulation of the AUC maximization, in which the communication of both the primal variable and the dual variable between each worker and the parameter server only occurs after multiple steps of gradient-based updates in each worker.  Compared with the naive parallel version of an existing algorithm that computes stochastic gradients at individual machines and averages them for updating the model parameter, our algorithm requires a much less number of communication rounds and still achieves linear speedup in theory. To the best of our knowledge, this is the \textbf{first} work that solves the {\it non-convex concave min-max} problem for  AUC maximization with deep neural networks in a communication-efficient distributed manner while still maintaining the linear speedup property in theory.   Our experiments on several benchmark datasets show the effectiveness of our algorithm and also confirm our theory. </p> 
### 227.[Adaptive Region-Based Active Learning](https://proceedings.icml.cc/book/3467.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1431-Paper.pdf)
  Corinna Cortes, Giulia DeSalvo, Claudio Gentile, Mehryar Mohri, Ningshan Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1431-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1431-Supplemental.pdf)
> <p>We present a new active learning algorithm that adaptively partitions the input space into a finite number of regions, and subsequently seeks a distinct predictor for each region, while actively requesting labels. We prove theoretical guarantees for both the generalization error and the label complexity of our algorithm, and analyze the number of regions defined by the algorithm under some mild assumptions. We also report the results of an extensive suite of experiments on several real-world datasets demonstrating substantial empirical benefits over existing single-region and non-adaptive region-based active learning baselines.</p> 
### 228.[Robust Outlier Arm Identification](https://proceedings.icml.cc/book/3468.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1432-Paper.pdf)
  Yinglun Zhu, Sumeet Katariya, Robert Nowak [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1432-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1432-Supplemental.pdf)
> <p>We study the problem of Robust Outlier Arm Identification (ROAI), where the goal is to identify arms whose expected rewards deviate substantially from the majority, by adaptively sampling from their reward distributions. We compute the outlier threshold using the median and median absolute deviation of the expected rewards. This is a robust choice for the threshold compared to using the mean and standard deviation, since it can correctly identify all outlier arms even in the presence of extreme outlier values. Our setting is different from existing pure exploration problems where the threshold is pre-specified as a given value or rank. This is useful in applications where the goal is to identify the set of promising items but the cardinality of this set is unknown, such as finding promising drugs for a new disease or identifying items favored by a population. We propose two computationally efficient delta-PAC algorithms for ROAI, which includes the first UCB-style algorithm for outlier detection, and derive upper bounds on their sample complexity. We also prove a matching, up to logarithmic factors, worst case lower bound for the problem, indicating that our upper bounds are generally unimprovable. Experimental results show that our algorithms are both robust and at least 5x sample efficient compared to state-of-the-art.</p> 
### 229.Provably Efficient Exploration in Policy Optimization [:chains:](https://proceedings.icml.cc/book/3469.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1438-Paper.pdf)
  Qi Cai, Zhuoran Yang, Chi Jin, Zhaoran Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1438-Metadata.json)
> While policy-based reinforcement learning (RL) achieves tremendous successes in practice, it is significantly less understood in theory, especially compared with value-based RL. In particular, it remains elusive how to design a provably efficient policy optimization algorithm that incorporates exploration. To bridge such a gap, this paper proposes an Optimistic variant of the Proximal Policy Optimization algorithm (OPPO), which follows an &quot;optimistic version&quot; of the policy gradient direction. This paper proves that, in the problem of episodic Markov decision process with linear function approximation, unknown transition, and adversarial reward with full-information feedback, OPPO achieves $\tilde{O}(\sqrt{d^3 H^3 T})$ regret. Here $d$ is the feature dimension, $H$ is the episode horizon, and $T$ is the total number of steps. To the best of our knowledge, OPPO is the first provably efficient policy optimization algorithm that explores.
### 230.[Striving for simplicity and performance in off-policy DRL: Output Normalization and Non-Uniform Sampling](https://proceedings.icml.cc/book/3470.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1451-Paper.pdf)
  Che Wang, Yanqiu Wu, Quan Vuong, Keith Ross [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1451-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1451-Supplemental.pdf)
> <p>We aim to develop off-policy DRL algorithms that not only exceed state-of-the-art performance but are also simple and minimalistic. For standard continuous control benchmarks, Soft Actor Critic (SAC), which employs entropy maximization, currently provides state-of-the-art performance. We first demonstrate that the entropy term in SAC addresses action saturation due to the bounded nature of the action spaces. With this insight, we propose a streamlined algorithm with a simple normalization scheme or with inverted gradients. We show that both approaches can match SAC's sample efficiency performance without the need of entropy maximization. We then propose a simple non-uniform sampling method for selecting transitions from the replay buffer during training. Extensive experimental results demonstrate that our proposed sampling scheme leads to state of the art sample efficiency on challenging continuous control tasks. We combine all of our findings into one simple algorithm, which we call Streamlined Off Policy with Emphasizing Recent Experience, for which we provide robust public-domain code. </p> 
### 231.[Multidimensional Shape Constraints](https://proceedings.icml.cc/book/3471.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1458-Paper.pdf)
  Maya Gupta, Erez Louidor, Oleksandr Mangylov, Nobu Morioka, Tamann Narayan, Sen Zhao [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1458-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1458-Supplemental.pdf)
> <p>We propose new multi-input shape constraints across four intuitive categories:  complements, diminishers, dominance, and unimodality constraints. We show these shape constraints can be checked and even enforced when training machine-learned models for linear models, generalized additive models, and the nonlinear function class of multi-layer lattice models. Toy examples and real-world experiments illustrate how the different shape constraints can be used to increase interpretability and better regularize machine-learned models. </p> 
### 232.[Fast Deterministic CUR Matrix Decomposition with Accuracy Assurance](https://proceedings.icml.cc/book/3472.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1463-Paper.pdf)
  Yasutoshi Ida, Sekitoshi Kanai, Yasuhiro Fujiwara, Tomoharu Iwata, Koh Takeuchi, Hisashi Kashima [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1463-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1463-Supplemental.pdf)
> <p>The deterministic CUR matrix decomposition is a low-rank approximation method to analyze a data matrix. It has attracted considerable attention due to its high interpretability, which results from the fact that the decomposed matrices consist of subsets of the original columns and rows of the data matrix. The subset is obtained by optimizing an objective function with sparsity-inducing norms via coordinate descent. However, the existing algorithms for optimization incur high computation costs. This is because coordinate descent iteratively updates all the parameters in the objective until convergence. This paper proposes a fast deterministic CUR matrix decomposition. Our algorithm safely skips unnecessary updates by efficiently evaluating the optimality conditions for the parameters to be zeros. In addition, we preferentially update the parameters that must be nonzeros. Theoretically, our approach guarantees the same result as the original approach. Experiments demonstrate that our algorithm speeds up the deterministic CUR while achieving the same accuracy.</p> 
### 233.Operation-Aware Soft Channel Pruning using Differentiable Masks [:chains:](https://proceedings.icml.cc/book/3473.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1485-Paper.pdf)
  Minsoo Kang, Bohyung Han [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1485-Metadata.json)
> <p>We propose a simple but effective data-driven channel pruning algorithm, which compresses deep neural networks effectively by exploiting the characteristics of operations in a differentiable way. The proposed approach makes a joint consideration of batch normalization (BN) and rectified linear unit (ReLU) for channel pruning; it estimates how likely each feature map is to be deactivated by the two successive operations and prunes the channels that have high probabilities. To this end, we learn differentiable masks for individual channels and make soft decisions throughout the optimization procedure, which allows to explore larger search space and train more stable networks. The proposed formulation combined with the training framework enables us to identify compressed models even without a separate procedure of fine-tuning. We perform extensive experiments and achieve outstanding performance in terms of the accuracy of output networks given the same amount of resources when compared with the state-of-the-art methods.</p> 
### 234.[Normalized Loss Functions for Deep Learning with Noisy Labels](https://proceedings.icml.cc/book/3474.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1502-Paper.pdf)
  Xingjun Ma, Hanxun Huang, Yisen Wang, Simone Romano, Sarah Erfani, James Bailey [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1502-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1502-Supplemental.pdf)
> <p>Robust loss functions are essential for training accurate deep neural networks (DNNs) in the presence of noisy (incorrect) labels. It has been shown that the commonly used Cross Entropy (CE) loss is not robust to noisy labels. Whilst new loss functions have been designed, they are only partially robust. In this paper, we theoretically show by applying a simple normalization that: \emph{any loss can be made robust to noisy labels}. However, in practice, simply being robust is not sufficient for a loss function to train accurate DNNs. By investigating several robust loss functions, we find that they suffer from a problem of {\em underfitting}. To address this, we propose a framework to build robust loss functions called \emph{Active Passive Loss} (APL). APL combines two robust loss functions that mutually boost each other. Experiments on benchmark datasets demonstrate that the family of new loss functions created by our APL framework can consistently outperform state-of-the-art methods by large margins, especially under large noise rates such as 60\% or 80\% incorrect labels.</p> 
### 235.[Learning Deep Kernels for Non-Parametric Two-Sample Tests](https://proceedings.icml.cc/book/3475.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1503-Paper.pdf)
  Feng Liu, Wenkai Xu, Jie Lu, Guangquan Zhang, Arthur Gretton, D.J. Sutherland [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1503-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1503-Supplemental.pdf)
> <p>We propose a class of kernel-based two-sample tests, which aim to determine whether two sets of samples are drawn from the same distribution. Our tests are constructed from kernels parameterized by deep neural nets, trained to maximize test power. These tests adapt to variations in distribution smoothness and shape over space, and are especially suited to high dimensions and complex data. By contrast, the simpler kernels used in prior kernel testing work are spatially homogeneous, and adaptive only in lengthscale. We explain how this scheme includes popular classifier-based two-sample tests as a special case, but improves on them in general. We provide the first proof of consistency for the proposed adaptation method, which applies both to kernels on deep features and to simpler radial basis kernels or multiple kernel learning. In experiments, we establish the superior performance of our deep kernels in hypothesis testing on benchmark and real-world data.</p> 
### 236.DeBayes: a Bayesian method for debiasing network embeddings [:chains:](https://proceedings.icml.cc/book/3476.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1517-Paper.pdf)
  Maarten Buyl, Tijl De Bie [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1517-Metadata.json)
> <p>As machine learning algorithms are increasingly deployed for high-impact automated decision making, ethical and increasingly also legal standards demand that they treat all individuals fairly, without discrimination based on their age, gender, race or other sensitive traits. In recent years much progress has been made on ensuring fairness and reducing bias in standard machine learning settings. Yet, for network embedding, with applications in vulnerable domains ranging from social network analysis to recommender systems, current options remain limited both in number and performance. We thus propose DeBayes: a conceptually elegant Bayesian method that is capable of learning debiased embeddings by using a biased prior. Our experiments show that these representations can then be used to perform link prediction that is significantly more fair in terms of popular metrics such as demographic parity and equalized opportunity.</p> 
### 237.[Principled learning method for Wasserstein distributionally robust optimization with local perturbations](https://proceedings.icml.cc/book/3477.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1520-Paper.pdf)
  Yongchan Kwon, Wonyoung Kim, Joong-Ho Won, Myunghee Cho Paik [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1520-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1520-Supplemental.pdf)
> <p>Wasserstein distributionally robust optimization (WDRO) attempts to learn a model that minimizes the local worst-case risk in the vicinity of the empirical data distribution defined by Wasserstein ball. While WDRO has received attention as a promising tool for inference since its introduction, its theoretical understanding has not been fully matured. Gao et al. (2017) proposed a minimizer based on a tractable approximation of the local worst-case risk, but without showing risk consistency. In this paper, we propose a minimizer based on a novel approximation theorem and provide the corresponding risk consistency results. Furthermore, we develop WDRO inference for locally perturbed data that include the Mixup (Zhang et al., 2017) as a special case. We show that our approximation and risk consistency results naturally extend to the cases when data are locally perturbed. Numerical experiments demonstrate robustness of the proposed method using image classification datasets. Our results show that the proposed method achieves significantly higher accuracy than baseline models on noisy datasets.</p> 
### 238.[Low-Variance and Zero-Variance Baselines for Extensive-Form Games](https://proceedings.icml.cc/book/3478.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1526-Paper.pdf)
  Trevor Davis, Martin Schmid, Michael Bowling [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1526-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1526-Supplemental.pdf)
> <p>Extensive-form games (EFGs) are a common model of multi-agent interactions with imperfect information. State-of-the-art algorithms for solving these games typically perform full walks of the game tree that can prove prohibitively slow in large games. Alternatively, sampling-based methods such as Monte Carlo Counterfactual Regret Minimization walk one or more trajectories through the tree, touching only a fraction of the nodes on each iteration, at the expense of requiring more iterations to converge due to the variance of sampled values. In this paper, we extend recent work that uses baseline estimates to reduce this variance. We introduce a framework of baseline-corrected values in EFGs that generalizes the previous work. Within our framework, we propose new baseline functions that result in significantly reduced variance compared to existing techniques. We show that one particular choice of such a function --- predictive baseline --- is provably optimal under certain sampling schemes. This allows for efficient computation of zero-variance value estimates even along sampled trajectories.</p> 
### 239.[Converging to Team-Maxmin Equilibria in Zero-Sum Multiplayer Games](https://proceedings.icml.cc/book/3479.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1532-Paper.pdf)
  Youzhi Zhang, Bo An [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1532-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1532-Supplemental.pdf)
> <p>Efficiently computing equilibria for multiplayer games is still an open challenge in computational game theory. This paper focuses on computing Team-Maxmin Equilibria (TMEs), which is an important solution concept for zero-sum multiplayer games where players in a team having the same utility function play against an adversary independently. Existing algorithms are inefficient to compute TMEs in large games, especially when the strategy space is too large to be represented due to limited memory. In two-player games, the Incremental Strategy Generation (ISG) algorithm is an efficient approach to avoid enumerating all pure strategies. However, the study of ISG for computing TMEs is completely unexplored. To fill this gap, we first study the properties of ISG for multiplayer games, showing that ISG converges to a Nash equilibrium (NE) but may not converge to a TME. Second, we design an ISG variant for TMEs (ISGT) by exploiting that a TME is an NE maximizing the teamâs utility and show that ISGT converges to a TME and the impossibility of relaxing conditions in ISGT. Third, to further improve the scalability, we design an ISGT variant (CISGT) by using the strategy space for computing an equilibrium that is close to TME but is easier to be computed as the initial strategy space of ISGT. Finally, extensive experimental results show that CISGT is orders of magnitude faster than ISGT and the state-of-the-art algorithm to compute TMEs in large games.</p> 
### 240.[Landscape Connectivity and Dropout Stability of SGD Solutions for Over-parameterized Neural Networks](https://proceedings.icml.cc/book/3480.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1538-Paper.pdf)
  Alexander Shevchenko, Marco Mondelli [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1538-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1538-Supplemental.pdf)
> <p>The optimization of multilayer neural networks typically leads to a solution with zero training error, yet the landscape can exhibit spurious local minima and the minima can be disconnected. In this paper, we shed light on this phenomenon: we show that the combination of stochastic gradient descent (SGD) and over-parameterization makes the landscape of multilayer neural networks approximately connected and thus more favorable to optimization. More specifically, we prove that SGD solutions are connected via a piecewise linear path, and the increase in loss along this path vanishes as the number of neurons grows large. This result is a consequence of the fact that the parameters found by SGD are increasingly dropout stable as the network becomes wider. We show that, if we remove part of the neurons (and suitably rescale the remaining ones), the change in loss is independent of the total number of neurons, and it depends only on how many neurons are left. Our results exhibit a mild dependence on the input dimension: they are dimension-free for two-layer networks and require the number of neurons to scale linearly with the dimension for multilayer networks. We validate our theoretical findings with numerical experiments for different architectures and classification tasks.</p> 
### 241.[Leveraging Frequency Analysis for Deep Fake Image Recognition](https://proceedings.icml.cc/book/3481.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1539-Paper.pdf)
  Joel Frank, Thorsten Eisenhofer, Lea SchÃ¶nherr, Dorothea Kolossa, Thorsten Holz, Asja Fischer [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1539-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1539-Supplemental.pdf)
> <p>Deep neural networks can generate images that are astonishingly realistic, so much so that it is often hard for untrained humans to distinguish them from actual photos. These achievements have been largely made possible by Generative Adversarial Networks (GANs). While these deep fake images have been thoroughly investigated in the image domain - a classical approach from the area of image forensics - an analysis in the frequency domain has been missing. This paper addresses this shortcoming and our results reveal, that in frequency space, GAN-generated images exhibit severe artifacts that can be easily identified. We perform a comprehensive analysis, showing that these artifacts are consistent across different neural network architectures, data sets, and resolutions. In a further investigation, we demonstrate that these artifacts are caused by upsampling operations found in all current GAN architectures, indicating a structural and fundamental problem in the way images are generated via GANs. Based on this analysis, we demonstrate how the frequency representation can be used to automatically identify deep fake images, surpassing state-of-the-art methods.</p> 
### 242.[Tails of Lipschitz Triangular Flows](https://proceedings.icml.cc/book/3482.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1552-Paper.pdf)
  Priyank Jaini, Ivan Kobyzev, Yaoliang Yu, Marcus Brubaker [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1552-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1552-Supplemental.pdf)
> <p>We investigate the ability of popular flow models to capture tail-properties of a target density by studying the increasing triangular maps used in these flow methods acting on a tractable source density. We show that the density quantile functions of the source and target density provide a precise characterization of the slope of transformation required to capture tails in a target density. We further show that any Lipschitz-continuous transport map acting on a source density will result in a density with similar tail properties as the source, highlighting the trade-off between the importance of choosing a complex source density and a sufficiently expressive transformation to capture desirable properties of a target density. Subsequently, we illustrate that flow models like Real-NVP, MAF, and Glow as implemented lack the ability to capture a distribution with non-Gaussian tails. We circumvent this problem by proposing tail-adaptive flows consisting of a source distribution that can be learned simultaneously with the triangular map to capture tail-properties of a target density. We perform several synthetic and real-world experiments to complement our theoretical findings. </p> 
### 243.[Deep Coordination Graphs](https://proceedings.icml.cc/book/3483.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1557-Paper.pdf)
  Wendelin Boehmer, Vitaly Kurin, Shimon Whiteson [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1557-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1557-Supplemental.pdf)
> <p>This paper introduces the deep coordination graph (DCG) for collaborative multi-agent reinforcement learning. DCG strikes a flexible trade-off between representational capacity and generalization by factoring the joint value function of all agents according to a coordination graph into payoffs between pairs of agents. The value can be maximized by local message passing along the graph, which allows training of the value function end-to-end with Q-learning. Payoff functions are approximated with deep neural networks that employ parameter sharing and low-rank approximations to significantly improve sample efficiency. We show that DCG can solve predator-prey tasks that highlight the relative overgeneralization pathology, as well as challenging StarCraft II micromanagement tasks.</p> 
### 244.Voice Separation with an Unknown Number of Multiple Speakers [:chains:](https://proceedings.icml.cc/book/3484.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1558-Paper.pdf)
  Eliya Nachmani, Yossi Adi, Lior Wolf [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1558-Metadata.json)
> <p>We present a new method for separating a mixed audio sequence, in which multiple voices speak simultaneously. The new method employs gated neural networks that are trained to separate the voices at multiple processing steps, while maintaining the speaker in each output channel fixed. A different model is trained for every number of possible speakers, and a the model with the largest number of speakers is employed to select the actual number of speakers in a given sample. Our method greatly outperforms the current state of the art, which, as we show, is not competitive for more than two speakers. </p> 
### 245.[Predicting Choice with Set-Dependent Aggregation](https://proceedings.icml.cc/book/3485.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1559-Paper.pdf)
  Nir Rosenfeld, Kojin Oshiba, Yaron Singer [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1559-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1559-Supplemental.pdf)
> <p>Providing users with alternatives to choose from is an essential component of many online platforms, making the accurate prediction of choice vital to their success. A renewed interest in learning choice models has led to improved modeling power, but most current methods are either limited in the type of choice behavior they capture, cannot be applied to large-scale data, or both.</p>  <p>Here we propose a learning framework for predicting choice that is accurate, versatile, and theoretically grounded. Our key modeling point is that to account for how humans choose, predictive models must be expressive enough to accommodate complex choice patterns but structured enough to retain statistical efficiency. Building on recent results in economics, we derive a class of models that achieves this balance, and propose a neural implementation that allows for scalable end-to-end training. Experiments on three large choice datasets demonstrate the utility of our approach.</p> 
### 246.[Thompson Sampling Algorithms for Mean-Variance Bandits](https://proceedings.icml.cc/book/3486.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1567-Paper.pdf)
  Qiuyu Zhu, Vincent Tan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1567-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1567-Supplemental.pdf)
> <p>The multi-armed bandit (MAB) problem is a classical learning task that exemplifies the exploration-exploitation tradeoff.  However, standard formulations do not take into account risk. In online decision making systems, risk is a primary concern. In this regard, the mean-variance risk measure is one of the most common objective functions. Existing algorithms for mean-variance optimization in the context of MAB problems have unrealistic assumptions on the reward distributions. We develop Thompson Sampling-style algorithms for mean-variance MAB and provide comprehensive regret analyses for Gaussian and Bernoulli bandits with fewer assumptions. Our algorithms achieve the best known regret bounds for mean-variance MABs and also attain the information-theoretic bounds in some parameter regimes. Empirical simulations show that our algorithms significantly outperform existing LCB-based algorithms for all risk tolerances.</p> 
### 247.[Differentiable Likelihoods for Fast Inversion of &#x27;Likelihood-Free&#x27; Dynamical Systems](https://proceedings.icml.cc/book/3487.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1580-Paper.pdf)
  Hans Kersting, Nicholas KrÃ¤mer, Martin Schiegg, Christian Daniel, Michael Schober, Philipp Hennig [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1580-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1580-Supplemental.pdf)
> <p>Likelihood-free (a.k.a. simulation-based) inference problems are inverse problems with expensive, or intractable, forward models. ODE inverse problems are commonly treated as likelihood-free, as their forward map has to be numerically approximated by an ODE solver. This, however, is not a fundamental constraint but just a lack of functionality in classic ODE solvers, which do not return a likelihood but a point estimate. To address this shortcoming, we employ Gaussian ODE filtering (a probabilistic numerical method for ODEs) to construct a local Gaussian approximation to the likelihood. This approximation yields tractable estimators for the gradient and Hessian of the (log-)likelihood. Insertion of these estimators into existing gradient-based optimization and sampling methods engenders new solvers for ODE inverse problems. We demonstrate that these methods outperform standard likelihood-free approaches on three benchmark-systems.</p> 
### 248.[Debiased Sinkhorn barycenters](https://proceedings.icml.cc/book/3488.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1584-Paper.pdf)
  Hicham Janati, Marco Cuturi, Alexandre Gramfort [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1584-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1584-Supplemental.pdf)
> <p>Entropy regularization in optimal transport (OT) has been the driver of many recent interests for Wasserstein metrics and barycenters in machine learning. It allows to keep the appealing geometrical properties of the unregularized Wasserstein distance while having a significantly lower complexity thanks to Sinkhorn's algorithm. However, entropy brings some inherent smoothing bias, resulting for example in blurred barycenters. This side effect has prompted an increasing temptation in the community to settle for a slower algorithm such as log-domain stabilized Sinkhorn which breaks the parallel structure that can be leveraged on GPUs, or even go back to unregularized OT. Here we show how this bias is tightly linked to the reference measure that defines the entropy regularizer and propose debiased Sinkhorn barycenters that preserve the best of worlds: fast Sinkhorn-like iterations without entropy smoothing. Theoretically, we prove that this debiasing is perfect for Gaussian distributions with equal variance. Empirically, we illustrate the reduced blurring and the computational advantage.</p> 
### 249.[Double Trouble in Double Descent:  Bias and Variance(s) in the Lazy Regime](https://proceedings.icml.cc/book/3489.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1589-Paper.pdf)
  StÃ©phane d&#x27;Ascoli, Maria Refinetti, Giulio Biroli, Florent Krzakala [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1589-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1589-Supplemental.zip)
> Deep neural networks can achieve remarkable generalization performances while interpolating the training data. Rather than the U-curve emblematic of the bias-variance trade-off, their test error often follows a ``double descent&quot;---a mark of the beneficial role of overparametrization. In this work, we develop a quantitative theory for this phenomenon in the so-called lazy learning regime of neural networks, by considering the problem of learning a high-dimensional function with random features regression. We obtain a precise asymptotic expression for the bias-variance decomposition of the test error, and show that the bias displays a phase transition at the interpolation threshold, beyond it which it remains constant. We disentangle the variances stemming from the sampling of the dataset, from the additive noise corrupting the labels, and from the initialization of the weights. We demonstrate that the latter two contributions are the crux of the double descent: they lead to the overfitting peak at the interpolation threshold and to the decay of the test error upon overparametrization. We quantify how they are suppressed by ensembling the outputs of $K$ independently initialized estimators. For $K\rightarrow \infty$, the test error is monotonously decreasing and remains constant beyond the interpolation threshold. We further compare the effects of overparametrizing, ensembling and regularizing. Finally, we present numerical experiments on classic deep learning setups to show that our results hold qualitatively in realistic lazy learning scenarios. 
### 250.[Explore, Discover and Learn: Unsupervised Discovery of State-Covering Skills](https://proceedings.icml.cc/book/3490.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1592-Paper.pdf)
  Victor Campos, Alexander Trott, Caiming Xiong, Richard Socher, Xavier Giro-i-Nieto, Jordi  Torres [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1592-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1592-Supplemental.pdf)
> <p>Acquiring abilities in the absence of a task-oriented reward function is at the frontier of reinforcement learning research. This problem has been studied through the lens of \textit{empowerment}, which draws a connection between option discovery and information theory. Information-theoretic skill discovery methods have garnered much interest from the community, but little research has been conducted in understanding their limitations.  Through theoretical analysis and empirical evidence, we show that existing algorithms suffer from a common limitation -- they discover options that provide a poor coverage of the state space. In light of this, we propose \textit{Explore, Discover and Learn} (EDL), an alternative approach to information-theoretic skill discovery. Crucially, EDL optimizes the same information-theoretic objective derived from the empowerment literature, but addresses the optimization problem using different machinery. We perform an extensive evaluation of skill discovery methods on controlled environments and show that EDL offers significant advantages, such as overcoming the coverage problem, reducing the dependence of learned skills on the initial state, and allowing the user to define a prior over which behaviors should be learned.</p> 
### 251.[Sparsified Linear Programming for Zero-Sum Equilibrium Finding](https://proceedings.icml.cc/book/3491.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1597-Paper.pdf)
  Brian Zhang, Tuomas Sandholm [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1597-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1597-Supplemental.pdf)
> <p>Computational equilibrium finding in large zero-sum extensive-form imperfect-information games has led to significant recent AI breakthroughs. The fastest algorithms for the problem are new forms of counterfactual regret minimization (Brown &amp; Sandholm, 2019). In this paper we present a totally different approach to the problem, which is competitive and often orders of magnitude better than the prior state of the art. The equilibrium-finding problem can be formulated as a linear program (LP) (Koller et al., 1994), but solving it as an LP has not been scalable due to the memory requirements of LP solvers, which can often be quadratically worse than CFR-based algorithms. We give an efficient practical algorithm that factors a large payoff matrix into a product of two matrices that are typically dramatically sparser. This allows us to express the equilibrium-finding problem as a linear program with size only a logarithmic factor worse than CFR, and thus allows linear program solvers to run on such games. With experiments on poker endgames, we demonstrate in practice, for the first time, that modern linear program solvers are competitive against even game-specific modern variants of CFR in solving large extensive-form games, and can be used to compute exact solutions unlike iterative algorithms like CFR.</p> 
### 252.[Extra-gradient with player sampling for faster convergence in n-player games](https://proceedings.icml.cc/book/3492.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1599-Paper.pdf)
  Samy Jelassi, Carles Domingo-Enrich, Damien Scieur, Arthur Mensch, Joan Bruna [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1599-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1599-Supplemental.zip)
> <p>Data-driven modeling increasingly requires to find a Nash equilibrium in multi-player games, e.g. when training GANs. In this paper, we analyse a new extra-gradient method for Nash equilibrium finding, that performs gradient extrapolations and updates on a random subset of players at each iteration. This approach provably exhibits a better rate of convergence than full extra-gradient for non-smooth convex games with noisy gradient oracle. We propose an additional variance reduction mechanism to obtain speed-ups in smooth convex games. Our approach makes extrapolation amenable to massive multiplayer settings, and brings empirical speed-ups, in particular when using a heuristic cyclic sampling scheme.Â Most importantly, it allows to train faster and better GANs and mixtures of GANs.</p> 
### 253.[Entropy Minimization In Emergent Languages](https://proceedings.icml.cc/book/3493.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1600-Paper.pdf)
  Eugene Kharitonov, Rahma Chaabouni, Diane Bouchacourt, Marco Baroni [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1600-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1600-Supplemental.pdf)
> <p>There is a growing interest in studying the languages emerging when neural agents are jointly trained to solve tasks requiring communication through a discrete channel.  We investigate here the information-theoretic complexity of such languages, focusing on the basic two-agent, one-exchange setup. We find that, under common training procedures, the emergent languages are subject to an entropy minimization pressure that has also been detected in human language, whereby the mutual information between the communicating agent's inputs and the messages is minimized, within the range afforded by the need for successful communication. This pressure is amplified as we increase communication channel discreteness. Further, we observe that stronger discrete-channel-driven entropy minimization leads to representations with increased robustness to overfitting and adversarial attacks. We conclude by discussing the implications of our findings for the study of natural and artificial communication systems.</p> 
### 254.[Spectral Clustering with Graph Neural Networks for Graph Pooling](https://proceedings.icml.cc/book/3494.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1614-Paper.pdf)
  Filippo Maria Bianchi, Daniele Grattarola, Cesare Alippi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1614-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1614-Supplemental.pdf)
> <p>Spectral clustering (SC) is a popular clustering technique to find strongly connected communities on a graph. SC can be used in Graph Neural Networks (GNNs) to implement pooling operations that aggregate nodes belonging to the same cluster. However, the eigendecomposition of the Laplacian is expensive and, since clustering results are graph-specific, pooling methods based on SC must perform a new optimization for each new sample. In this paper, we propose a graph clustering approach that addresses these limitations of SC. We formulate a continuous relaxation of the normalized minCUT problem and train a GNN to compute cluster assignments that minimize this objective.  Our GNN-based implementation is differentiable, does not require to compute the spectral decomposition, and learns a clustering function that can be quickly evaluated on out-of-sample graphs. From the proposed clustering method, we design a graph pooling operator that overcomes some important limitations of state-of-the-art graph pooling techniques and achieves the best performance in several supervised and unsupervised tasks.</p> 
### 255.[VFlow: More Expressive Generative Flows with Variational Data Augmentation](https://proceedings.icml.cc/book/3495.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1619-Paper.pdf)
  Jianfei Chen, Cheng Lu, Biqi Chenli, Jun Zhu, Tian Tian [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1619-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1619-Supplemental.pdf)
> <p>Generative flows are promising tractable models for density modeling that define probabilistic distributions with invertible transformations. However, tractability imposes architectural constraints on generative flows. In this work, we study a previously overlooked constraint that all the intermediate representations must have the same dimensionality with the data due to invertibility, limiting the width of the network. We propose VFlow to tackle this constraint on dimensionality. VFlow augments the data with extra dimensions and defines a maximum evidence lower bound (ELBO) objective for estimating the distribution of augmented data jointly with the variational data augmentation distribution. Under mild assumptions, we show that the maximum ELBO solution of VFlow is always better than the original maximum likelihood solution. For image density modeling on the CIFAR-10 dataset, VFlow achieves a new state-of-the-art 2.98 bits per dimension.</p> 
### 256.Fully Parallel Hyperparameter Search: Reshaped Space-Filling [:chains:](https://proceedings.icml.cc/book/3496.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1620-Paper.pdf)
  Marie-Liesse Cauwet, Camille Couprie, Julien Dehos, Pauline Luc, Jeremy Rapin, Morgane Riviere, Fabien Teytaud, Olivier Teytaud, Nicolas Usunier [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1620-Metadata.json)
> <p>Space-filling designs such as Low Discrepancy Sequence (LDS), Latin Hypercube Sampling (LHS) and Jittered Sampling (JS) were proposed for fully parallel hyperparameter search, and were shown to be more effective than random and grid search. We prove that LHS and JS outperform random search only by a constant factor. Consequently, we introduce a new sampling approach based on the reshaping of the search distribution, and we show both theoretically and numerically that it leads to significant gains over random search. Two methods are proposed for the reshaping: Recentering (when the distribution of the optimum is known), and Cauchy transformation (when the distribution of the optimum is unknown). The proposed methods are first validated on artificial experiments and simple real-world tests on clustering and Salmon mappings. Then we demonstrate that they drive performance improvement in a wide range of expensive artificial intelligence tasks, namely attend/infer/repeat, video next frame segmentation forecasting and progressive generative adversarial networks.</p> 
### 257.[Discount Factor as a Regularizer in Reinforcement Learning ](https://proceedings.icml.cc/book/3497.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1623-Paper.pdf)
  Ron Amit, Kamil Ciosek, Ron Meir [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1623-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1623-Supplemental.pdf)
> <p>Specifying a Reinforcement Learning (RL) task involves choosing a suitable planning horizon, which is typically modeled by an evaluation discount factor. It is known that applying RL algorithms with a discount set lower than the evaluation discount factor can act as a regularizer, improving performance in the limited data regime. Yet the exact nature of this regularizer has not been investigated. In this work, we fill in this gap. For TD learning and expected SARSA, we show an explicit equivalence between using a reduced discount factor and adding an explicit regularization term to the algorithm loss. For a fixed policy, we argue that chains with a uniform stationary distribution and a fast mixing rate are amenable to regularization with a reduced discount. We validate this conclusion with extensive experiments in discrete and continuous domains, using tabular and functional representations.</p> 
### 258.[On Learning Sets of Symmetric Elements](https://proceedings.icml.cc/book/3498.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1625-Paper.pdf)
  Haggai Maron, Or Litany, Gal Chechik, Ethan Fetaya [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1625-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1625-Supplemental.pdf)
> <p>Learning from unordered sets is a fundamental learning setup, which is attracting increasing attention. Research in this area has focused on the case where elements of the set are represented by feature vectors, and far less emphasis has been given to the common case where set elements themselves adhere to certain symmetries. That case is relevant to numerous applications, from deblurring image bursts to multi-view 3D shape recognition and reconstruction. In this paper, we present a principled approach to learning sets of general symmetric elements. We first characterize the space of linear layers that are equivariant both to element reordering and to the inherent symmetries of elements, like translation in the case of images. We further show that networks that are composed of these layers, called Deep Sets for Symmetric elements layers (DSS), are universal approximators of both invariant and equivariant functions. DSS layers are also straightforward to implement. Finally, we show that they improve over existing set-learning architectures in a series of experiments with images, graphs, and point-clouds.</p> 
### 259.[Non-convex Learning via Replica Exchange Stochastic Gradient MCMC](https://proceedings.icml.cc/book/3499.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1632-Paper.pdf)
  Wei Deng, Qi Feng, Liyao Gao, Faming Liang, Guang Lin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1632-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1632-Supplemental.pdf)
> <p>Replica exchange method (RE), also known as parallel tempering, is an important technique for accelerating the convergence of the conventional Markov Chain Monte Carlo (MCMC) algorithms. However, such a method requires the evaluation of the energy function based on the full dataset and is not scalable to big data. The na\"ive implementation of RE in mini-batch settings introduces large biases, which cannot be directly extended to the stochastic gradient MCMC (SG-MCMC), the standard sampling method for simulating from deep neural networks (DNNs). In this paper, we propose an adaptive replica exchange SG-MCMC (reSG-MCMC) to automatically correct the bias and study the corresponding properties. The analysis implies an acceleration-accuracy trade-off in the numerical discretization of a Markov jump process in a stochastic environment. Empirically, we test the algorithm through extensive experiments on various setups and obtain the state-of-the-art results on CIFAR10, CIFAR100, and SVHN in both supervised learning and semi-supervised learning tasks.</p> 
### 260.[Learning Similarity Metrics for Numerical Simulations](https://proceedings.icml.cc/book/3500.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1635-Paper.pdf)
  Georg Kohl, Kiwon Um, Nils Thuerey [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1635-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1635-Supplemental.pdf)
> <p>We propose a neural network-based approach that computes a stable and generalizing metric (LSiM) to compare data from a variety of numerical simulation sources. We focus on scalar time-dependent 2D data that commonly arises from motion and transport-based partial differential equations (PDEs). Our method employs a Siamese network architecture that is motivated by the mathematical properties of a metric. We leverage a controllable data generation setup with PDE solvers to create increasingly different outputs from a reference simulation in a controlled environment. A central component of our learned metric is a specialized loss function that introduces knowledge about the correlation between single data samples into the training process. To demonstrate that the proposed approach outperforms existing metrics for vector spaces and other learned, image-based metrics, we evaluate the different methods on a large range of test data. Additionally, we analyze generalization benefits of an adjustable training data difficulty and demonstrate the robustness of LSiM via an evaluation on three real-world data sets.</p> 
### 261.[FR-Train: A mutual information-based approach to fair and robust training](https://proceedings.icml.cc/book/3501.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1637-Paper.pdf)
  Yuji Roh, Kangwook Lee, Steven Whang, Changho Suh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1637-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1637-Supplemental.zip)
> <p>Trustworthy AI is a critical issue in machine learning where, in addition to training a model that is accurate, one must consider both fair and robust training in the presence of data bias and poisoning. However, the existing model fairness techniques mistakenly view poisoned data as an additional bias, resulting in severe performance degradation. To fix this problem, we propose FR-Train, which holistically performs fair and robust model training. We provide a mutual information-based interpretation of an existing adversarial training-based fairness-only method, and apply this idea to architect an additional discriminator that can identify poisoned data using a clean validation set and reduce its influence. In our experiments, FR-Train shows almost no decrease in fairness and accuracy in the presence of data poisoning by both mitigating the bias and defending against poisoning. We also demonstrate how to construct clean validation sets using crowdsourcing, and release new benchmark datasets.</p> 
### 262.[Real-Time Optimisation for Online Learning in Auctions](https://proceedings.icml.cc/book/3502.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1640-Paper.pdf)
  Lorenzo Croissant, Marc Abeille, ClÃ©ment CalauzÃ¨nes [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1640-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1640-Supplemental.zip)
> <p>In display advertising, a small group of sellers and bidders face each other in up to 10^{12} auctions a day. In this context, revenue maximisation via monopoly price learning is a high-value problem for sellers. By nature, these auctions are online and produce a very high frequency stream of data. This results in a computational strain that requires algorithms be real-time. Unfortunately, existing methods, inherited from the batch setting, suffer O(\sqrt(t)) time/memory complexity at each update, prohibiting their use. In this paper, we provide the first algorithm for online learning of monopoly prices in online auctions whose update is constant in time and memory.</p> 
### 263.[Graph Random Neural Features for Distance-Preserving Graph Representations](https://proceedings.icml.cc/book/3503.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1649-Paper.pdf)
  Daniele Zambon, Cesare Alippi, Lorenzo Livi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1649-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1649-Supplemental.pdf)
> <p>We present Graph Random Neural Features (GRNF), a novel embedding method from graph-structured data to real vectors based on a family of graph neural networks.  The embedding naturally deals with graph isomorphism and preserves the metric structure of the graph domain, in probability.  In addition to being an explicit embedding method, it also allows us to efficiently and effectively approximate graph metric distances (as well as complete kernel functions); a criterion to select the embedding dimension trading off the approximation accuracy with the computational cost is also provided.  GRNF can be used within traditional processing methods or as a training-free input layer of a graph neural network.  The theoretical guarantees that accompany GRNF ensure that the considered graph distance is metric, hence allowing to distinguish any pair of non-isomorphic graphs. </p> 
### 264.[Modulating Surrogates for Bayesian Optimization](https://proceedings.icml.cc/book/3504.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1651-Paper.pdf)
  Erik Bodin, Markus Kaiser, Ieva Kazlauskaite, Zhenwen Dai, Neill Campbell, Carl Henrik Ek [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1651-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1651-Supplemental.pdf)
> <p>Bayesian optimization (BO) methods often rely on the assumption that the objective function is well-behaved, but in practice, this is seldom true for real-world objectives even if noise-free observations can be collected. Common approaches, which try to model the objective as precisely as possible, often fail to make progress by spending too many evaluations modeling irrelevant details. We address this issue by proposing surrogate models that focus on the well-behaved structure in the objective function, which is informative for search, while ignoring detrimental structure that is challenging to model from few observations. First, we demonstrate that surrogate models with appropriate noise distributions can absorb challenging structures in the objective function by treating them as irreducible uncertainty. Secondly, we show that a latent Gaussian process is an excellent surrogate for this purpose, comparing with Gaussian processes with standard noise distributions. We perform numerous experiments on a range of BO benchmarks and find that our approach improves reliability and performance when faced with challenging objective functions.</p> 
### 265.[Convolutional Kernel Networks for Graph-Structured Data](https://proceedings.icml.cc/book/3505.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1656-Paper.pdf)
  Dexiong Chen, Laurent Jacob, Julien Mairal [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1656-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1656-Supplemental.pdf)
> <p>We introduce a family of multilayer graph kernels and establish new links between graph convolutional neural networks and kernel methods. Our approach generalizes convolutional kernel networks to graph-structured data, by representing graphs as a sequence of feature maps, where each node carries information about local graph substructures. On the one hand, the kernel point of view offers an unsupervised, expressive, and easy-to-regularize data representation, which is useful when limited samples are available. On the other hand, our model can also be trained end-to-end on large-scale data, leading to new types of graph convolutional neural networks.  We show that our method achieves state-of-the-art performance on several graph classification benchmarks, while offering simple model interpretation.</p> 
### 266.[Improving the Sample and Communication Complexity for Decentralized Non-Convex Optimization: Joint Gradient Estimation and Tracking](https://proceedings.icml.cc/book/3506.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1657-Paper.pdf)
  Haoran Sun, Songtao Lu, Mingyi Hong [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1657-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1657-Supplemental.pdf)
> Many modern large-scale machine learning problems benefit from decentralized and stochastic optimization. Recent works have shown that utilizing both decentralized computing and local stochastic gradient estimates can outperform state-of-the-art centralized algorithms, in applications involving highly non-convex problems, such as training deep neural networks. 	 	 In this work, we propose a decentralized stochastic algorithm to deal with certain smooth non-convex problems where there are $m$ nodes in the system, and each node has a large number of samples (denoted as $n$). Differently from the majority of the existing decentralized learning algorithms for either stochastic or finite-sum problems, our focus is given to {\it both} reducing the total communication rounds among the nodes, while accessing the minimum number of local data samples. In particular, we propose an algorithm named D-GET (decentralized gradient estimation and tracking), which jointly performs decentralized gradient estimation (which estimates the local gradient using a subset of local samples) {\it and} gradient tracking (which tracks the global full gradient using local estimates). We show that, to achieve certain $\epsilon$  stationary solution of the deterministic finite sum problem, the proposed algorithm achieves an $\mathcal{O}(mn^{1/2}\epsilon^{-1})$ sample complexity and an $\mathcal{O}(\epsilon^{-1})$ communication complexity. These bounds significantly improve upon the best existing bounds of $\mathcal{O}(mn\epsilon^{-1})$ and $\mathcal{O}(\epsilon^{-1})$, respectively. Similarly, for online problems, the proposed method achieves an $\mathcal{O}(m \epsilon^{-3/2})$ sample complexity and  an $\mathcal{O}(\epsilon^{-1})$ communication complexity, while the best existing bounds are  $\mathcal{O}(m\epsilon^{-2})$ and $\mathcal{O}(\epsilon^{-2})$.
### 267.[Proper Network Interpretability Helps Adversarial Robustness in Classification](https://proceedings.icml.cc/book/3507.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1661-Paper.pdf)
  Akhilan Boopathy, Sijia Liu, Gaoyuan Zhang, Cynthia Liu, Pin-Yu Chen, Shiyu Chang, Luca Daniel [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1661-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1661-Supplemental.pdf)
> <p>Recent works have empirically shown that there exist adversarial examples that can be hidden from neural network interpretability (namely, making network interpretation maps visually similar), and interpretability is itself susceptible to adversarial attacks. In this paper, we theoretically show that with a proper measurement of interpretation, it is actually difficult to prevent prediction-evasion adversarial attacks from causing interpretability discrepancy, as confirmed by experiments on MNIST, CIFAR-10 and Restricted ImageNet. Spurred by that, we develop an interpretability-aware defensive scheme built only on robust interpretation (without the need of resorting to adversarial loss minimization). We show that our defense achieves both robust classification and robust interpretation, outperforming state-of-the-art adversarial training methods against   attacks of large perturbation in particular.</p> 
### 268.Generalization Guarantees for Sparse Kernel Approximation with Entropic Optimal Features [:chains:](https://proceedings.icml.cc/book/3508.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1662-Paper.pdf)
  Liang Ding, Rui Tuo, Shahin Shahrampour [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1662-Metadata.json)
> Despite their success, kernel methods suffer from a massive computational cost in practice. In this paper, in lieu of commonly used kernel expansion with respect to $N$ inputs, we develop a novel optimal design maximizing the entropy among kernel features. This procedure results in a kernel expansion with respect to entropic optimal features (EOF), improving the data representation dramatically due to features dissimilarity. Under mild technical assumptions, our generalization bound shows that with only $O(N^{\frac{1}{4}})$ features (disregarding logarithmic factors), we can achieve the optimal statistical accuracy (i.e., $O(1/\sqrt{N})$). The salient feature of our design is its sparsity that significantly reduces the time and space cost. Our numerical experiments on benchmark datasets verify the superiority of EOF over the state-of-the-art in kernel approximation. 
### 269.[Understanding the Impact of Model Incoherence on Convergence of Incremental SGD with Random Reshuffle](https://proceedings.icml.cc/book/3509.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1666-Paper.pdf)
  Shaocong Ma, Yi Zhou [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1666-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1666-Supplemental.pdf)
> <p>Although SGD with random reshuffle has been widely-used in machine learning applications, there is a limited understanding of how model characteristics affect the convergence of the algorithm. In this work, we introduce model incoherence to characterize the diversity of model characteristics and study its impact on convergence of SGD with random reshuffle \shaocong{under weak strong convexity}. Specifically, {\em minimizer incoherence} measures the discrepancy between the global minimizers of a sample loss and those of the total loss and affects the convergence error of SGD with random reshuffle.  In particular, we show that the variable sequence generated by SGD with random reshuffle converges to a certain global minimizer of the total loss under full minimizer coherence. The other {\em curvature incoherence} measures the quality of condition numbers of the sample losses and determines the convergence rate of SGD.  With model incoherence, our results show that SGD has a faster convergence rate and smaller convergence error under random reshuffle than those under random sampling, and hence provide justifications to the superior practical performance of SGD with random reshuffle.</p> 
### 270.Learning Opinions in Social Networks [:chains:](https://proceedings.icml.cc/book/3510.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1670-Paper.pdf)
  Vincent Conitzer, Debmalya Panigrahi, Hanrui Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1670-Metadata.json)
> <p>We study the problem of learning opinions in social networks.  The learner observes the states of some sample nodes from a social network, and tries to infer the states of other nodes, based on the structure of the network.  We show that sample-efficient learning is impossible when the network exhibits strong noise, and give a polynomial-time algorithm for the problem with nearly optimal sample complexity when the network is sufficiently stable.</p> 
### 271.[Latent Variable Modelling with Hyperbolic Normalizing Flows](https://proceedings.icml.cc/book/3511.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1674-Paper.pdf)
  Joey Bose, Ariella Smofsky, Renjie Liao, Prakash Panangaden, Will Hamilton [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1674-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1674-Supplemental.pdf)
> The choice of approximate posterior distributions plays a central role in stochastic variational inference (SVI). One effective solution is the use of normalizing flows \cut{defined on Euclidean spaces} to construct flexible posterior distributions.  However, one key limitation of existing normalizing flows is that they are restricted to the Euclidean space and are ill-equipped to model data with an underlying hierarchical structure. To address this fundamental limitation, we present the first extension of normalizing flows to hyperbolic spaces.  We first elevate normalizing flows to hyperbolic spaces using coupling transforms defined on the tangent bundle, termed Tangent Coupling ($\mathcal{TC}$).  We further introduce Wrapped Hyperboloid Coupling ($\mathcal{W}\mathbb{H}C$), a fully invertible and learnable transformation that explicitly utilizes the geometric structure of hyperbolic spaces, allowing for expressive posteriors while being efficient to sample from. We demonstrate the efficacy of our novel normalizing flow over hyperbolic VAEs and Euclidean normalizing flows.  Our approach achieves improved performance on density estimation, as well as reconstruction of real-world graph data, which exhibit a hierarchical structure.  Finally, we show that our approach can be used to power a generative model over hierarchical data using hyperbolic latent variables. 
### 272.[StochasticRank: Global Optimization of Scale-Free Discrete Functions](https://proceedings.icml.cc/book/3512.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1680-Paper.pdf)
  Aleksei Ustimenko, Liudmila Prokhorenkova [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1680-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1680-Supplemental.pdf)
> <p>In this paper, we introduce a powerful and efficient framework for the direct optimization of ranking metrics. The problem is ill-posed due to the discrete structure of the loss, and to deal with that, we introduce two important techniques: a stochastic smoothing and a novel gradient estimate based on partial integration. We also address the problem of smoothing bias and present a universal solution for a proper debiasing. To guarantee the global convergence of our method, we adopt a recently proposed Stochastic Gradient Langevin Boosting algorithm. Our algorithm is implemented as a part of the CatBoost gradient boosting library and outperforms the existing approaches on several learning to rank datasets. In addition to ranking metrics, our framework applies to any scale-free discreet loss function.</p> 
### 273.[Working Memory Graphs](https://proceedings.icml.cc/book/3513.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1696-Paper.pdf)
  Ricky Loynd, Roland Fernandez, Asli Celikyilmaz, Adith Swaminathan, Matthew Hausknecht [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1696-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1696-Supplemental.pdf)
> <p>Transformers have increasingly outperformed gated RNNs in obtaining new state-of-the-art results on supervised tasks involving text sequences.  Inspired by this trend, we study the question of how Transformer-based models can improve the performance of sequential decision-making agents. We present the Working Memory Graph (WMG), an agent that employs multi-head self-attention to reason over a dynamic set of vectors representing observed and recurrent state. We evaluate WMG in three environments featuring factored observation spaces: a Pathfinding environment that requires complex reasoning over past observations, BabyAI gridworld levels that involve text instructions, and Sokoban which emphasizes future planning. We find that the combination of WMG's Transformer-based architecture with factored observation spaces leads to significant gains in learning efficiency compared to other architectures across all tasks. Our results imply that for environments where it is possible to factorize environment observations, WMG's Transformer-based architecture can dramatically boost sample efficiency.</p> 
### 274.Learning to Combine Top-Down and Bottom-Up Signals in Recurrent Neural Networks with Attention over Modules [:chains:](https://proceedings.icml.cc/book/3514.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1698-Paper.pdf)
  Sarthak  Mittal, Alex Lamb, Anirudh Goyal, Vikram Voleti, Murray Shanahan, Guillaume Lajoie, Michael Mozer, Yoshua Bengio [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1698-Metadata.json)
> <p>Robust perception relies on both bottom-up and top-down signals.  Bottom-up signals consist of what's directly observed through sensation.  Top-down signals consist of beliefs and expectations based on past experience and the current reportable short-term memory, such as how the phrase `peanut butter and ...' will be completed.  The optimal combination of bottom-up and top-down information remains an open question, but the manner of combination must be dynamic and both context and task dependent. To effectively utilize the wealth of potential top-down information available, and to prevent the cacophony of intermixed signals in a bidirectional architecture, mechanisms are needed to restrict information flow.  We explore deep recurrent neural net architectures in which bottom-up and top-down signals are dynamically combined using attention.  Modularity of the architecture further restricts the sharing and communication of information. Together, attention and modularity direct information flow, which leads to reliable performance improvements in perceptual and language tasks, and in particular improves robustness to distractions and noisy data.  We demonstrate on a variety of benchmarks in language modeling, sequential image classification, video prediction and reinforcement learning that the \emph{bidirectional} information flow can improve results over strong baselines.  </p> 
### 275.[Spread Divergence](https://proceedings.icml.cc/book/3515.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1716-Paper.pdf)
  Mingtian Zhang, Peter Hayes, Thomas Bird, Raza Habib, David Barber [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1716-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1716-Supplemental.pdf)
> For distributions $p$ and $q$ with different supports, the divergence $\div{p}{q}$ may not exist. We define a spread divergence $\sdiv{p}{q}$ on modified $p$ and $q$ and describe sufficient conditions for the existence of such a divergence. We demonstrate how to maximize the discriminatory power of a given divergence by parameterizing and learning the spread. We also give examples of using a spread divergence to train and improve implicit generative models, including linear models (Independent Components Analysis) and non-linear models (Deep Generative Networks). 
### 276.[Optimizing Black-box Metrics with Adaptive Surrogates](https://proceedings.icml.cc/book/3516.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1724-Paper.pdf)
  Qijia Jiang, Olaoluwa Adigun, Harikrishna Narasimhan, Mahdi Milani Fard, Maya Gupta [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1724-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1724-Supplemental.pdf)
> <p>We address the problem of training models with black-box and hard-to-optimize metrics by expressing the metric as a monotonic function of a small number of easy-to-optimize surrogates. We pose the training problem as an optimization over a relaxed surrogate space, which we solve by estimating local gradients for the metric and performing inexact convex projections. We analyze  gradient estimates based on finite differences and local linear interpolations, and show convergence of our approach under smoothness  assumptions with respect to the surrogates. Experimental results on classification and ranking problems verify the proposal performs on par with methods that know the mathematical formulation, and adds notable value when the form of the metric is unknown.</p> 
### 277.[Domain Adaptive Imitation Learning](https://proceedings.icml.cc/book/3517.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1732-Paper.pdf)
  Kuno Kim, Yihong Gu, Jiaming Song, Shengjia Zhao, Stefano Ermon [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1732-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1732-Supplemental.pdf)
> <p>We study the question of how to imitate tasks across domains with discrepancies such as embodiment, viewpoint, and dynamics mismatch. Many prior works require paired, aligned demonstrations and an additional RL step that requires environment interactions. However, paired, aligned demonstrations are seldom obtainable and RL procedures are expensive.  In this work, we formalize the Domain Adaptive Imitation Learning (DAIL) problem - a unified framework for imitation learning in the presence of viewpoint, embodiment, and/or dynamics mismatch. Informally, DAIL is the process of learning how to perform a task optimally, given demonstrations of the task in a distinct domain. We propose a two step approach to DAIL: alignment followed by adaptation. In the alignment step we execute a novel unsupervised MDP alignment algorithm, Generative Adversarial MDP Alignment (GAMA), to learn state and action correspondences from \emph{unpaired, unaligned} demonstrations. In the adaptation step we leverage the correspondences to zero-shot imitate tasks across domains. To describe when DAIL is feasible via alignment and adaptation, we introduce a theory of MDP alignability. We experimentally evaluate GAMA against baselines in embodiment, viewpoint, and dynamics mismatch scenarios where aligned demonstrations don't exist and show the effectiveness of our approach</p> 
### 278.[A general recurrent state space framework for modeling neural dynamics during decision-making](https://proceedings.icml.cc/book/3518.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1733-Paper.pdf)
  David Zoltowski, Jonathan Pillow, Scott Linderman [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1733-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1733-Supplemental.pdf)
> <p>An open question in systems and computational neuroscience is how neural circuits accumulate evidence towards a decision. Fitting models of decision-making theory to neural activity helps answer this question, but current approaches limit the number of these models that we can fit to neural data. Here we propose a general framework for modeling neural activity during decision-making. The framework includes the canonical drift-diffusion model and enables extensions such as multi-dimensional accumulators, variable and collapsing boundaries, and discrete jumps. Our framework is based on constraining the parameters of recurrent state space models, for which we introduce a scalable variational Laplace-EM inference algorithm. We applied the modeling approach to spiking responses recorded from monkey parietal cortex during two decision-making tasks. We found that a two-dimensional accumulator better captured the trial-averaged responses of a set of parietal neurons than a single accumulator model. Next, we identified a variable lower boundary in the responses of a parietal neuron during a random dot motion task.</p> 
### 279.[An Imitation Learning Approach for Cache Replacement](https://proceedings.icml.cc/book/3519.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1735-Paper.pdf)
  Evan Liu, Milad Hashemi, Kevin Swersky, Parthasarathy Ranganathan, Junwhan Ahn [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1735-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1735-Supplemental.pdf)
> <p>Program execution speed critically depends on reducing cache misses, as cache misses are orders of magnitude slower than hits.  To reduce cache misses, we focus on the problem of cache replacement: choosing which cache line to evict upon inserting a new line.  This is challenging because it requires planning far ahead and currently there is no known practical solution.  As a result, current replacement policies typically resort to heuristics designed for specific common access patterns, which fail on more diverse and complex access patterns.  In contrast, we propose an imitation learning approach to automatically learn cache access patterns by leveraging Beladyâs, an oracle policy that computes the optimal eviction decision given the future cache accesses.  While directly applying Belady's is infeasible since the future is unknown, we train a policy conditioned only on past accesses that accurately approximates Belady's even on diverse and complex access patterns.  When evaluated on four of the most memory-intensive SPEC applications, our learned policy reduces cache miss rates by 15% over the current state of the art.  In addition, on a large-scale web search benchmark, our learned policy reduces cache miss rates by 66% over a conventional LRU policy.  We release a Gym environment to facilitate research in this area, as data is plentiful, and further advancements can have significant real-world impact.</p> 
### 280.[Revisiting Training Strategies and Generalization Performance in Deep Metric Learning](https://proceedings.icml.cc/book/3520.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1739-Paper.pdf)
  Karsten Roth, Timo Milbich, Samrath Sinha, Prateek Gupta, Bjorn Ommer, Joseph Paul Cohen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1739-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1739-Supplemental.pdf)
> <p>Deep Metric Learning (DML) is arguably one of the most influential lines of research for learning visual similarities with many proposed approaches every year. Although the field benefits from the rapid progress, the divergence in training protocols, architectures, and parameter choices make an unbiased comparison difficult. To provide a consistent reference point, we revisit the most widely used DML objective functions and conduct a study of the crucial parameter choices as well as the commonly neglected mini-batch sampling process. Under consistent comparison, DML objectives show much higher saturation than indicated by literature. Further based on our analysis, we uncover a correlation between the embedding space density and compression to the generalization performance of DML models. Exploiting these insights, we propose a simple, yet effective, training regularization to reliably boost the performance of ranking-based DML models on various standard benchmark datasets; code and a publicly accessible WandB-repo are available at https://github.com/Confusezius/Revisiting<em>Deep</em>Metric<em>Learning</em>PyTorch.</p> 
### 281.[Temporal Phenotyping using Deep Predictive Clustering of Disease Progression](https://proceedings.icml.cc/book/3521.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1742-Paper.pdf)
  Changhee Lee, Mihaela van der Schaar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1742-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1742-Supplemental.pdf)
> <p>Due to the wider availability of modern electronic health records, patient care data is often being stored in the form of time-series. Clustering such time-series data is crucial for patient phenotyping, anticipating patientsâ prognoses by identifying âsimilarâ patients, and designing treatment guidelines that are tailored to homogeneous patient subgroups. In this paper, we develop a deep learning approach for clustering time-series data, where each cluster comprises patients who share similar future outcomes of interest (e.g., adverse events, the onset of comorbidities). To encourage each cluster to have homogeneous future outcomes, the clustering is carried out by learning discrete representations that best describe the future outcome distribution based on novel loss functions. Experiments on two real-world datasets show that our model achieves superior clustering performance over state-of-the-art benchmarks and identifies meaningful clusters that can be translated into actionable information for clinical decision-making.</p> 
### 282.Countering Language Drift with Seeded Iterated Learning [:chains:](https://proceedings.icml.cc/book/3522.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1746-Paper.pdf)
  Yuchen Lu, Soumye Singhal, Florian Strub, Aaron Courville, Olivier Pietquin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1746-Metadata.json)
> <p>Supervised learning methods excel at capturing statistical properties of language when trained over large text corpora. Yet, these models often produce inconsistent outputs in goal-oriented language setting as they are not trained to complete the underlying task. Moreover, as soon as the agents are fine-tuned to maximize task completion, they suffer from the so-called language drift phenomenon: they slowly lose syntactic and semantic properties of language as they only focus on solving the task. In this paper, we propose a generic approach to counter language drift by using iterated learning. We iterate between finetuning agents with interactive training steps, and periodically replacing them with new agents that are seeded from last iteration and trained to imitate the latest finetuned models. Iterated learning does not require external syntactic constraint nor semantic knowledge, making it a valuable task-agnostic finetuning protocol. We first explore iterated learning in the Lewis Game. We then scale-up the approach in the translation game. In both settings our results show that iterated learning drastically counters language drift as well as improves the task completion metric.</p> 
### 283.[Stochastic Gauss-Newton Algorithms for Nonconvex Compositional Optimization](https://proceedings.icml.cc/book/3523.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1773-Paper.pdf)
  Quoc Tran-Dinh, Nhan Pham, Lam Nguyen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1773-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1773-Supplemental.pdf)
> We develop two new stochastic Gauss-Newton algorithms for solving a class of stochastic non-convex compositional optimization problems frequently arising in practice. We consider both the expectation and finite-sum settings under standard assumptions. We use both standard stochastic and SARAH estimators for approximating function values and Jacobians. In the expectation case, we establish $O(\varepsilon^{-2})$ iteration complexity to achieve a stationary point in expectation and estimate the total number of stochastic oracle calls for both function values and its Jacobian, where $\varepsilon$ is a desired accuracy. In the finite sum case, we also estimate the same iteration complexity and the total oracle calls with high probability. To our best knowledge, this is the first time such global stochastic oracle complexity is established for stochastic Gauss-Newton methods. We illustrate our theoretical results via numerical examples on both synthetic and real datasets.
### 284.[Strategyproof Mean Estimation from Multiple-Choice Questions](https://proceedings.icml.cc/book/3524.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1775-Paper.pdf)
  Anson Kahng, Gregory Kehne, Ariel Procaccia [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1775-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1775-Supplemental.zip)
> <p>Given n values possessed by n agents, we study the problem of estimating the mean by truthfully eliciting agents' answers to multiple-choice questions about their values. We consider two natural candidates for estimation error: mean squared error (MSE) and mean absolute error (MAE). We design a randomized estimator which is asymptotically optimal for both measures in the worst case. In the case where prior distributions over the agents' values are known, we give an optimal, polynomial-time algorithm for MSE, and show that the task of computing an optimal estimate for MAE is #P-hard. Finally, we demonstrate empirically that knowledge of prior distributions gives a significant edge.</p> 
### 285.[Sequential Cooperative Bayesian Inference](https://proceedings.icml.cc/book/3525.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1777-Paper.pdf)
  Junqi Wang, Pei Wang, Patrick Shafto [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1777-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1777-Supplemental.pdf)
> <p>Cooperation is often implicitly assumed when learning from other agents. Cooperation implies that the agent selecting the data, and the agent learning from the data, have the same goal, that the learner infer the intended hypothesis. Recent models in human and machine learning have demonstrated the possibility of cooperation. We seek foundational theoretical results for cooperative inference by Bayesian agents through sequential data. We develop novel approaches analyzing consistency, rate of convergence and stability of Sequential Cooperative Bayesian Inference (SCBI). Our analysis of the effectiveness, sample efficiency and robustness show that cooperation is not only possible but theoretically well-founded. We discuss implications for human-human and human-machine cooperation.</p> 
### 286.[Spectral Graph Matching and Regularized Quadratic Relaxations: Algorithm and Theory](https://proceedings.icml.cc/book/3526.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1778-Paper.pdf)
  Zhou Fan, Cheng Mao, Yihong Wu, Jiaming Xu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1778-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1778-Supplemental.pdf)
> Graph matching, also known as network alignment, aims at recovering the latent vertex correspondence between two unlabeled, edge-correlated weighted graphs. To tackle this task, we propose a spectral method, GRAph Matching by Pairwise eigen-Alignments (GRAMPA), which first constructs a similarity matrix as a weighted sum of outer products between all pairs of eigenvectors of the two graphs, and then outputs a matching by a simple rounding procedure. For a universality class of correlated Wigner models, GRAMPA achieves exact recovery of the latent matching between two graphs with edge correlation $1 - 1/\mathrm{polylog}(n)$ and average degree at least $\mathrm{polylog}(n)$. This matches the state-of-the-art guarantees for polynomial-time algorithms established for correlated Erd\H{o}s-R\&#x27;{e}nyi graphs, and significantly improves over existing spectral methods. The superiority of GRAMPA is also demonstrated on a variety of synthetic and real datasets, in terms of both statistical accuracy and computational efficiency.
### 287.[Zeno++: Robust Fully Asynchronous SGD](https://proceedings.icml.cc/book/3527.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1780-Paper.pdf)
  Cong Xie, Sanmi Koyejo, Indranil Gupta [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1780-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1780-Supplemental.pdf)
> <p>We propose Zeno++, a new robust asynchronous Stochastic Gradient Descent(SGD) procedure, intended to  tolerate Byzantine failures of  workers. In contrast to previous work, Zeno++ removes several unrealistic restrictions on worker-server communication, now allowing for fully asynchronous updates from anonymous workers, for arbitrarily stale worker updates, and for the possibility of an unbounded number of Byzantine workers. The key idea is to estimate the descent of the loss value after the candidate gradient is applied, where large descent values indicate that the update results in optimization progress. We prove the convergence of Zeno++ for non-convex problems under Byzantine failures. Experimental results show that Zeno++ outperforms existing Byzantine-tolerant asynchronous SGD algorithms.</p> 
### 288.[Network Pruning by Greedy Subnetwork Selection](https://proceedings.icml.cc/book/3528.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1781-Paper.pdf)
  Mao Ye, Chengyue Gong, Lizhen Nie, Denny Zhou, Adam Klivans, Qiang Liu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1781-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1781-Supplemental.pdf)
> <p>Recent works on network pruning show that large deep neural networks are often highly redundant and one can find much smaller subnetworks with much lower computational cost without a significant drop of accuracy. Most existing methods of network pruning are based on eliminating unnecessary neurons from the large networks. In this work, we study a greedy forward selection approach following the opposite direction, which starts from an empty network, and gradually adds good neurons from the large network.  Theoretically, we show that the small networks pruned using our method achieve provably lower loss than small networks trained from scratch with the same size. It implies that the learned weight of large networks is important to the small pruned models. Practically, for architectures in mobile setting, we find that fine-tuning networks pruned using our method outperforms training them from scratch. Our method improves all the prior arts on learning compact networks, using architectures such as ResNet, MobilenetV2, MobileNetV3 and ProxylessNet on ImageNet. Our theory and empirical results highlight the benefits of fine-tuning networks from large models over training from scratch, which is different from the findings of Liu et al. (2019b). </p> 
### 289.[Logarithmic Regret for Learning Linear Quadratic Regulators Efficiently](https://proceedings.icml.cc/book/3529.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1802-Paper.pdf)
  Asaf Cassel, Alon Cohen, Tomer Koren [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1802-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1802-Supplemental.pdf)
> <p>We consider the problem of learning in Linear Quadratic Control systems whose transition parameters are initially unknown. Recent results in this setting have demonstrated efficient learning algorithms with regret growing with the square root of the number of decision steps.  We present new efficient algorithms that achieve, perhaps surprisingly,regret that scales only (poly-)logarithmically with the number of steps, in two scenarios: when only the state transition matrix A is unknown, and when only the state-action transition matrix B is unknown and the optimal policy satisfies a certain non-degeneracy condition.  On the other hand, we give a lower bound which shows that when the latter condition is violated, square root regret is unavoidable.</p> 
### 290.[Hierarchical Verification for Adversarial Robustness](https://proceedings.icml.cc/book/3530.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1808-Paper.pdf)
  Cong Han Lim, Raquel Urtasun, Ersin Yumer [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1808-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1808-Supplemental.pdf)
> <p>We introduce a new framework for the exact pointwise âp robustness verification problem that exploits the layer-wise geometric structure of deep feed-forward networks with rectified linear activations (ReLU networks). The activation regions of the network partition the input space, and one can verify the âp robustness around a point by checking all the activation regions within the desired radius. The GeoCert algorithm (Jordan et al., NeurIPS 2019) treats this partition as a generic polyhedral complex to detect which region to check next. Instead, our LayerCert framework considers the nested hyperplane arrangement structure induced by the layers of the ReLU network and explores regions in a hierarchical manner. We show that, under certain conditions on the algorithm parameters, LayerCert provably reduces the number and size of the convex programs that one needs to solve compared to GeoCert. Furthermore, the LayerCert framework allows one to incorporate lower bounding routines based on convex relaxations to further improve performance. Experimental results demonstrate that LayerCert can significantly reduce both the number of convex programs solved and the wall-clock time over the state-of-the-art.</p> 
### 291.[BINOCULARS for efficient, nonmyopic sequential experimental design](https://proceedings.icml.cc/book/3531.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1809-Paper.pdf)
  Shali Jiang, Henry Chai, Javier Gonzalez, Roman Garnett [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1809-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1809-Supplemental.zip)
> <p>Finite-horizon sequential experimental design (SED) arises naturally in many contexts, including hyperparameter tuning in machine learning among more traditional settings. Computing the optimal policy for such problems requires solving Bellman equations, which are generally intractable. Most existing work resorts to severely myopic approximations by limiting the decision horizon to only a single time-step, which can underweight exploration in favor of exploitation. We present BINOCULARS: Batch-Informed NOnmyopic Choices, Using Long-horizons for Adaptive, Rapid SED, a general framework for deriving efficient, nonmyopic approximations to the optimal experimental policy. Our key idea is simple and surprisingly effective: we first compute a one-step optimal batch of experiments, then select a single point from this batch to evaluate. We realize BINOCULARS for Bayesian optimization and Bayesian quadrature -- two notable example problems with radically different objectives -- and demonstrate that BINOCULARS significantly outperforms significantly outperforms myopic alternatives in real-world scenarios.</p> 
### 292.[On the Global Optimality of Model-Agnostic Meta-Learning](https://proceedings.icml.cc/book/3532.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1816-Paper.pdf)
  Lingxiao Wang, Qi Cai, Zhuoran Yang, Zhaoran Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1816-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1816-Supplemental.zip)
> <p>Model-agnostic meta-learning (MAML) formulates the meta-learning as a bilevel optimization problem where the inner level solves each subtask based on a shared prior, while the outer level searches for the optimal shared prior based on its aggregated perfor- mance over the subtasks. Despite its empirical success, MAML remains less understood theoretically, especially in terms of its global optimality due to the nonconvexity of the meta-objective (outer-level objective). To bridge such a gap between theory and practice, we characterize the optimality gap of the stationary points attained by MAML for both reinforcement learning and supervised learning, where both the inner- and outer-level problems are solved via first-order optimization methods. In particular, our characterization connects the optimality gap of such stationary points with (i) the functional geometry of the inner-level objective and (ii) the representation power of function approximators, including both linear models and neural networks. To the best of our knowledge, our analysis establishes the global optimality of MAML with the nonconvex meta-objective for the first time.</p> 
### 293.[Breaking the Curse of Many Agents: Provable Mean Embedding $Q$-Iteration for Mean-Field Reinforcement Learning](https://proceedings.icml.cc/book/3533.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1819-Paper.pdf)
  Lingxiao Wang, Zhuoran Yang, Zhaoran Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1819-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1819-Supplemental.zip)
> <p>Multi-agent reinforcement learning (MARL) achieves significant empirical successes. However, MARL suffers from the curse of many agents. In this paper, we exploit the symmetry of agents in MARL. In the most generic form, we study a mean-field MARL problem. Such a mean-field MARL is defined on mean-field states, which are distributions that are supported on continuous space. Based on the mean embedding of the distributions, we propose MF-FQI algorithm, which solves the mean-field MARL and establishes a non-asymptotic analysis for MF-FQI algorithm. We highlight that MF-FQI algorithm enjoys a ``blessing of many agents'' property in the sense that a larger number of observed agents improves the performance of MF-FQI algorithm.</p> 
### 294.[Learning with Bounded Instance- and Label-dependent Label Noise](https://proceedings.icml.cc/book/3534.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1820-Paper.pdf)
  Jiacheng Cheng, Tongliang Liu, Kotagiri Ramamohanarao, Dacheng Tao [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1820-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1820-Supplemental.pdf)
> Instance- and Label-dependent label Noise (ILN) widely exists in real-world datasets but has been rarely studied. In this paper, we focus on Bounded Instance- and Label-dependent label Noise (BILN), a particular case of ILN where the label noise rates---the probabilities that the true labels of examples flip into the corrupted ones---have upper bound less than $1$. Specifically, we introduce the concept of distilled examples, i.e. examples whose labels are identical with the labels assigned for them by the Bayes optimal classifier, and prove that under certain conditions classifiers learnt on distilled examples will converge to the Bayes optimal classifier. Inspired by the idea of learning with distilled examples, we then propose a learning algorithm with theoretical guarantees for its robustness to BILN. At last, empirical evaluations on both synthetic and real-world datasets show effectiveness of our algorithm in learning with BILN.
### 295.[Transparency Promotion with Model-Agnostic Linear Competitors](https://proceedings.icml.cc/book/3535.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1828-Paper.pdf)
   Hassan Rafique, Tong Wang, Qihang Lin, Arshia Singhani [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1828-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1828-Supplemental.zip)
> <p>We propose a novel type of hybrid model for multi-class classification, which utilizes competing linear models to collaborate with an existing black-box model, promoting transparency in the decision-making process. Our proposed hybrid model, Model-Agnostic Linear Competitors (MALC), brings together the interpretable power of linear models and the good predictive performance of the state-of-the-art black-box models. We formulate the training of a MALC model as a convex optimization problem, which optimizes the predictive accuracy and transparency (defined as the percentage of data captured by the linear models) in the objective function. Experiments show that MALC offers more model flexibility for users to balance transparency and accuracy, in contrast to the currently available choice of either a pure black-box model or a pure interpretable model. The human evaluation also shows that more users are likely to choose MALC for this model flexibility when comparing with interpretable models and black-box models.</p> 
### 296.[Learning Mixtures of Graphs from Epidemic Cascades ](https://proceedings.icml.cc/book/3536.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1829-Paper.pdf)
  Jessica Hoffmann, Soumya Basu, Surbhi Goel, Constantine Caramanis [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1829-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1829-Supplemental.pdf)
> <p>We consider the problem of learning the weighted edges of a balanced mixture of two undirected graphs from epidemic cascades. While mixture models are popular modeling tools, algorithmic development with rigorous guarantees has lagged. Graph mixtures are apparently no exception: until now, very little is known about whether this problem is solvable. </p>  <pre><code> To the best of our knowledge, we establish the first necessary and sufficient conditions for this problem to be solvable in polynomial time on edge-separated graphs. When the conditions are met, i.e., when the graphs are connected with at least three edges, we give an efficient algorithm for learning the weights of both graphs with optimal sample complexity (up to log factors).    We give complementary results and provide sample-optimal (up to log factors) algorithms for mixtures of directed graphs of out-degree at least three, and for mixture of undirected graphs of unbalanced and/or unknown priors. </code></pre> 
### 297.[Implicit differentiation of Lasso-type models for hyperparameter optimization](https://proceedings.icml.cc/book/3537.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1831-Paper.pdf)
  Quentin Bertrand, Quentin Klopfenstein, Mathieu Blondel, Samuel Vaiter, Alexandre Gramfort, Joseph Salmon [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1831-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1831-Supplemental.pdf)
> <p>Setting regularization parameters for Lasso-type estimators is notoriously difficult, though crucial for obtaining the best accuracy. The most popular hyperparameter optimization approach is grid-search on a held-out dataset. However, grid-search requires to choose a predefined grid of parameters and scales exponentially in the number of parameters. Another class of approaches casts hyperparameter optimization as a bi-level optimization problem, typically solved by gradient descent. The key challenge for these approaches is the estimation of the gradient w.r.t. the hyperparameters. Computing that gradient via forward or backward automatic differentiation usually suffers from high memory comsumption, while implicit differentiation typically involves solving a linear system which can be prohibitive and numerically unstable. In addition, implicit differentiation usually assumes smooth loss functions, which is not the case of Lasso-type problems. This work introduces an efficient implicit differentiation algorithm, without matrix inversion, tailored for Lasso-type problems. Our proposal scales to high-dimensional data by leveraging the sparsity of the solutions. Empirically, we demonstrate that the proposed method outperforms a large number of standard methods for hyperparameter optimization.</p> 
### 298.[Latent Space Factorisation and Manipulation via Matrix Subspace Projection](https://proceedings.icml.cc/book/3538.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1832-Paper.pdf)
  Xiao Li, Chenghua Lin, Ruizhe Li, Chaozheng Wang, Frank Guerin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1832-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1832-Supplemental.pdf)
> <p>We tackle the problem disentangling the latent space of an autoencoder in order to separate labelled attribute information from other characteristic information. This then allows us to change selected attributes while preserving other information. Our method, matrix subspace projection, is much simpler than previous approaches to latent space factorisation, for  example not requiring multiple discriminators or a careful weighting among loss functions. Furthermore our new model can be applied to autoencoders as a plugin, and works across diverse domains such as images or text. We demonstrate the utility of our method for attribute manipulation in autoencoders trained across varied domains, using both human evaluation and automated methods. The quality of generation of our new model (e.g. reconstruction, conditional generation) is highly competitive to a number of strong baselines. </p> 
### 299.[Active World Model Learning in Agent-rich Environments with Progress Curiosity](https://proceedings.icml.cc/book/3539.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1837-Paper.pdf)
  Kuno Kim, Megumi Sano, Julian De Freitas, Nick Haber, Daniel Yamins [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1837-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1837-Supplemental.pdf)
> World models are a family of predictive models that solve self-supervised problems on how the world evolves. Humans learn world models by curiously exploring their environment, in the process acquiring compact abstractions of high bandwidth sensory inputs, the ability to plan across long temporal horizons, and an understanding of the behavioral patterns of other agents. In this work, we study how to design such a curiosity-driven Active World Model Learning (AWML) system. To do so, we simulate a curious agent building world models while visually exploring a 3D physical environment rich with distillations of representative real-world stimuli. We propose an AWML system driven by $\gamma$-Progress: a scalable and effective learning progress-based curiosity signal. We show that $\gamma$-Progress is robust to &quot;white noise&quot; and naturally gives rise to an exploration policy that allocates attention in a balanced manner, with a preference towards agents displaying complex yet learnable behaviors. As a result, our $\gamma$-Progress driven controller achieves significantly higher AWML performance than baseline controllers equipped with state-of-the-art exploration strategies such as Random Network Distillation and Model Disagreement. 
### 300.[SDE-Net: Equipping Deep Neural Networks with Uncertainty Estimates](https://proceedings.icml.cc/book/3540.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1840-Paper.pdf)
  Lingkai Kong, Jimeng Sun, Chao Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1840-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1840-Supplemental.pdf)
> <p>Uncertainty quantification is a fundamental yet unsolved problem for deep learning. The Bayesian framework provides a principled way of uncertainty estimation but is often not scalable to modern deep neural nets (DNNs) that have a large number of parameters. Non-Bayesian methods are simple to implement but often conflate different sources of uncertainties and require huge computing resources.  We propose a new method for quantifying uncertainties of DNNs from a dynamical system perspective.  The core of our method is to view DNN transformations as state evolution of a stochastic dynamical system and introduce a Brownian motion term for capturing epistemic uncertainty. Based on this perspective, we propose a neural stochastic differential equation model (SDE-Net) which consists of (1) a drift net that controls the system to fit the predictive function; and (2) a diffusion net that captures epistemic uncertainty. We theoretically analyze the existence and uniqueness of the solution to SDE-Net.  Our experiments demonstrate that the SDE-Net model can outperform existing uncertainty estimation methods across a series of tasks where uncertainty plays a fundamental role.</p> 
### 301.[GANs May Have No Nash Equilibria](https://proceedings.icml.cc/book/3541.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1847-Paper.pdf)
  Farzan Farnia, Asuman Ozdaglar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1847-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1847-Supplemental.pdf)
> <p>Generative adversarial networks (GANs) represent a zero-sum game between two machine players, a generator and a discriminator, designed to learn the distribution of data. While GANs have achieved state-of-the-art performance in several benchmark learning tasks, GAN minimax optimization still poses great theoretical and empirical challenges. GANs trained using first-order optimization methods commonly fail to converge to a stable solution where the players cannot improve their objective, i.e., the Nash equilibrium of the underlying game. Such issues raise the question of the existence of Nash equilibria in the GAN zero-sum game. In this work, we show through several theoretical and numerical results that indeed GAN zero-sum games may not have any Nash equilibria. To characterize an equilibrium notion applicable to GANs, we consider the equilibrium of a new zero-sum game with an objective function given by a proximal operator applied to the original objective, a solution we call the proximal equilibrium. Unlike the Nash equilibrium, the proximal equilibrium captures the sequential nature of GANs, in which the generator moves first followed by the discriminator. We prove that the optimal generative model in Wasserstein GAN problems provides a proximal equilibrium. Inspired by these results, we propose a new approach, which we call proximal training, for solving GAN problems. We discuss several numerical experiments demonstrating the existence of proximal equilibria in GAN problems.</p> 
### 302.[Gradient Temporal-Difference Learning with Regularized Corrections](https://proceedings.icml.cc/book/3542.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1857-Paper.pdf)
  Sina Ghiassian, Andrew Patterson, Shivam Garg, Dhawal Gutpa, Adam White, Martha White [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1857-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1857-Supplemental.pdf)
> <p>Value function learning remains a critical component of many reinforcement learning systems. Many algorithms are based on temporal difference (TD) updates, which have well-documented divergence issues, even though potentially sound alternatives exist like Gradient TD. Unsound approaches like Q-learning and TD remain popular because divergence seems rare in practice and these algorithms typically perform well. However, recent work with large neural network learning systems reveals that instability is more common than previously thought. Practitioners face a difficult dilemma: choose an easy to use and performant TD method, or a more complex algorithm that is more sound but harder to tune, less sample efficient, and underexplored with control. In this paper, we introduce a new method called TD with Regularized Corrections (TDRC), that attempts to balance ease of use, soundness, and performance. It behaves as well as TD, when TD performs well, but is sound even in cases where TD diverges. We characterize the expected update for TDRC, and show that it inherits soundness guarantees from Gradient TD, and converges to the same solution as TD. Empirically, TDRC exhibits good performance and low parameter sensitivity across several problems.</p> 
### 303.[Online mirror descent and dual averaging: keeping pace in the dynamic case](https://proceedings.icml.cc/book/3543.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1863-Paper.pdf)
  Huang Fang, Victor Sanches Portella, Nick Harvey, Michael Friedlander [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1863-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1863-Supplemental.pdf)
> <p>Online mirror descent (OMD) and dual averaging (DA) are two fundamental algorithms for online convex optimization. They are known to have very similar (or even identical) performance guarantees in most scenarios when a \emph{fixed} learning rate is used. However, for \emph{dynamic} learning rates OMD is provably inferior to DA. It is known that, with a dynamic learning rate, OMD can suffer linear regret, even in common settings such as prediction with expert advice. This hints that the relationship between OMD and DA is not fully understood at present.</p>  <p>In this paper, we modify the OMD algorithm by a simple technique that we call stabilization. We give essentially the same abstract regret bound for stabilized OMD and DA by modifying the classical OMD convergence analysis in a careful and modular way, yielding proofs that we believe to be clean and flexible. Simple corollaries of these bounds show that OMD with stabilization and DA enjoy the same performance guarantees in many applications even under dynamic learning rates. We also shed some light on the similarities between OMD and DA and show simple conditions under which stabilized OMD and DA generate the same iterates.</p> 
### 304.[Choice Set Optimization Under Discrete Choice Models of Group Decisions](https://proceedings.icml.cc/book/3544.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1865-Paper.pdf)
  Kiran Tomlinson, Austin Benson [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1865-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1865-Supplemental.pdf)
> <p>The way that people make choices or exhibit preferences can be strongly affected by the set of available alternatives, often called the choice set. Furthermore, there are usually heterogeneous preferences, either at an individual level within small groups or within sub-populations of large groups. Given the availability of choice data, there are now many models that capture this behavior in order to make effective predictions. However, there is little work in understanding how directly changing the choice set can be used to influence a group's preferences or decisions. Here, we use discrete choice modeling to develop an optimization framework of such interventions for several problems of group influence, including maximizing agreement or disagreement and promoting a particular choice. We show that these problems are NP-hard in general but imposing restrictions reveals a fundamental boundary: promoting an item is easier than maximizing agreement or disagreement. After, we design approximation algorithms for the hard problems and show that they work extremely well for real-world choice data.</p> 
### 305.[Complexity of Finding Stationary Points of Nonconvex Nonsmooth Functions](https://proceedings.icml.cc/book/3545.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1881-Paper.pdf)
  Jingzhao Zhang, Hongzhou Lin, Stefanie Jegelka, Suvrit Sra, Ali Jadbabaie [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1881-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1881-Supplemental.pdf)
> <p>We provide the first non-asymptotic analysis for finding stationary points of nonsmooth, nonconvex functions. In particular, we study the class of Hadamard semi-differentiable functions, perhaps the largest class of nonsmooth functions for which the chain rule of calculus holds. This class contains important examples such as ReLU neural networks and others with non-differentiable activation functions. First, we show that finding an epsilon-stationary point with first-order methods is impossible in finite time. Therefore, we introduce the notion of (delta, epsilon)-stationarity, a generalization that allows for a point to be within distance delta of an epsilon-stationary point and reduces to epsilon-stationarity for smooth functions. We propose a series of randomized first-order methods and analyze their complexity of finding a (delta, epsilon)-stationary point. Furthermore, we provide a lower bound and show that our stochastic algorithm has min-max optimal dependence on delta. Empirically, our methods perform well for training ReLU neural networks.</p> 
### 306.[Multi-Agent Routing Value Iteration Network](https://proceedings.icml.cc/book/3546.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1891-Paper.pdf)
  Quinlan Sykora, Mengye Ren, Raquel Urtasun [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1891-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1891-Supplemental.pdf)
> <p>Multi-agent coordination and routing is a complex problem and has a wide range of applications in areas from vehicle fleet coordination to autonomous mapping. Whereas traditional methods are not designed for realistic environments such as sparse connectivity and unknown traffics and are often slow in runtime; in this paper, we propose a graph neural network based model that is able to perform multiagent routing in a sparsely connected graph with dynamically changing traffic conditions, outperforming existing methods.</p>  <p>Our learned communication module in the proposed model enables the agents to coordinate online and adapt to changes to their environment. We also show that our model trained with only two agents on graphs with a maximum of twenty-five nodes can easily generalize to five agents with a hundred nodes.</p> 
### 307.[Adversarial Attacks on Copyright Detection Systems](https://proceedings.icml.cc/book/3547.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1894-Paper.pdf)
  Parsa Saadatpanah, Ali Shafahi, Tom Goldstein [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1894-Metadata.json)
> <p>It is well-known that many machine learning models are susceptible to adversarial attacks, in which an attacker evades a classifier by making small perturbations to inputs. This paper discusses how industrial copyright detection tools, which serve a central role on the web, are susceptible to adversarial attacks. We discuss a range of copyright detection systems, and why they are particularly vulnerable to attacks. These vulnerabilities are especially apparent for neural network based systems. As proof of concept, we describe a well-known music identification method and implement this system in the form of a neural net.  We then attack this system using simple gradient methods, and show that it is easily broken with white box attacks. By scaling these perturnations up, we are able to create transfer attacks on industrial systems, such as the AudioTag copyright detector and YouTube's Content ID system, using perturbations that are audible but significantly smaller than a random baseline. Our goal is to raise awareness of the threats posed by adversarial examples in this space and to highlight the importance of hardening copyright detection systems to attacks.</p> 
### 308.[Differentiating through the FrÃ©chet Mean](https://proceedings.icml.cc/book/3548.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1896-Paper.pdf)
  Aaron Lou, Isay Katsman, Qingxuan Jiang, Serge Belongie, Ser Nam Lim, Christopher De Sa [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1896-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1896-Supplemental.pdf)
> <p>Recent advances in deep representation learning on Riemannian manifolds extend classical deep learning operations to better capture the geometry of the manifold. One possible extension is the FrÃ©chet mean, the generalization of the Euclidean mean; however, it has been difficult to apply because it lacks a closed form with an easily computable derivative. In this paper, we show how to differentiate through the FrÃ©chet mean for arbitrary Riemannian manifolds. Then, focusing on hyperbolic space, we derive explicit gradient expressions and a fast, accurate, and hyperparameter-free FrÃ©chet mean solver. This fully integrates the FrÃ©chet mean into the hyperbolic neural network pipeline. To demonstrate this integration, we present two case studies. First, we apply our FrÃ©chet mean to the existing Hyperbolic Graph Convolutional Network, replacing its projected aggregation to obtain state-of-the-art results on datasets with high hyperbolicity. Second, to demonstrate the FrÃ©chet meanâs capacity to generalize Euclidean neural network operations, we develop a hyperbolic batch normalization method that gives an improvement parallel to the one observed in the Euclidean setting.</p> 
### 309.[Online Learning for Active Cache Synchronization](https://proceedings.icml.cc/book/3549.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1917-Paper.pdf)
  Andrey Kolobov, Sebastien Bubeck, Julian Zimmert [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1917-Metadata.json)
> Existing multi-armed bandit (MAB) models make two implicit assumptions: an arm generates a payoff only when it is played, and the agent observes every payoff that is generated. This paper introduces synchronization bandits, a MAB variant where all arms generate costs at all times, but the agent observes an arm&#x27;s instantaneous cost only when the arm is played. Synchronization MABs are inspired by online caching scenarios such as Web crawling, where an arm corresponds to a cached item and playing the arm means downloading its fresh copy from a server. While not refreshed, each cached item grows progressively stale with time, continuously generating stochastic costs due to degraded cache performance, but the cache doesn&#x27;t know how much until it refreshes the item and computes the difference between the itemâs fresh version and the old one. We present MirrorSync, an online learning algorithm for synchronization bandits, establish an adversarial regret of $O(T^{2/3})$ for it, and show how to make it efficient in practice.
### 310.[PoKED: A Semi-Supervised System for Word Sense Disambiguation](https://proceedings.icml.cc/book/3550.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1929-Paper.pdf)
  Feng Wei [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1929-Metadata.json)
> <p>Word Sense Disambiguation (WSD) is an open problem in Natural Language Processing, which is challenging and useful in both supervised and unsupervised settings where all the words in any given text need to be disambiguated without sufficient labeled data. Typically, Most WSD systems use the sentence or a small window of words around the target word as the context for disambiguation, as their computational complexity scales exponentially with the size of the context. In this paper, we propose a semi-supervised neural system, Position-wise Orthogonal Knowledge-Enhanced Disambiguator (PoKED), which allows attention-driven, long-range dependency modeling for word sense disambiguation tasks. The proposed PoKED incorporates position-wise encoding into an orthogonal framework and applies a knowledge-based attentive neural model to solve the WSD problem. Our proposed unsupervised language model is trained over unlabelled corpus, and then the pre-trained language model is capable of abstracting the surrounding context of polyseme instances in labeled corpus into context embeddings. We further utilize the semantic relations in the WordNet, by extracting semantic level inter-word connections from each document-sentence pair in the WSD dataset, and allows us to control the amount of the extraction results by setting a hyperparameter. Our experimental results from standard benchmarks show that our proposed system, PoKED, can achieve competitive performance compared with state-of-the-art knowledge-based WSD systems.</p> 
### 311.[A Finite-Time Analysis of  Q-Learning with Neural Network Function Approximation](https://proceedings.icml.cc/book/3551.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1930-Paper.pdf)
  Pan Xu, Quanquan Gu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1930-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1930-Supplemental.zip)
> Q-learning with neural network function approximation (neural Q-learning for short) is among the most prevalent deep reinforcement learning algorithms. Despite its empirical success, the non-asymptotic convergence rate of neural Q-learning remains virtually unknown. In this paper, we present a finite-time analysis of a neural Q-learning algorithm, where the data are generated from a Markov decision process and the action-value function is approximated by a deep ReLU neural network. We prove that neural Q-learning finds the optimal policy with $O(1/\sqrt{T})$ convergence rate if the neural function approximator is sufficiently overparameterized, where $T$ is the number of iterations. To our best knowledge, our result is the first finite-time analysis of neural Q-learning under non-i.i.d. data assumption.
### 312.[Understanding and Stabilizing GANs&#x27; Training Dynamics Using Control Theory](https://proceedings.icml.cc/book/3552.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1933-Paper.pdf)
  Kun Xu, Chongxuan Li, Jun Zhu, Bo Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1933-Metadata.json)
> <p>Generative adversarial networks (GANs) are effective in generating realistic images but the training is often unstable. There are existing efforts that model the training dynamics of GANs in the parameter space but the analysis cannot directly motivate practically effective stabilizing methods. To this end, we present a conceptually novel perspective from control theory to directly model the dynamics of GANs in the frequency domain and provide simple yet effective methods to stabilize GAN's training. We first analyze the training dynamic of a prototypical Dirac GAN and adopt the widely-used closed-loop control (CLC) to improve its stability. We then extend CLC to stabilize the training dynamic of normal GANs, which can be implemented as an L2 regularizer on the output of the discriminator. Empirical results show that our method can effectively stabilize the training and obtain state-of-the-art performance on data generation tasks.</p> 
### 313.[Scalable Nearest Neighbor Search for Optimal Transport](https://proceedings.icml.cc/book/3553.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1937-Paper.pdf)
  Arturs Backurs, Yihe Dong, Piotr Indyk, Ilya Razenshteyn, Tal Wagner [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1937-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1937-Supplemental.pdf)
> <p>The Optimal Transport (a.k.a. Wasserstein) distance is an increasingly popular similarity measure for rich data domains, such as images or text documents.  This raises the necessity for fast nearest neighbor search algorithms according to this distance, which poses a substantial computational bottleneck on massive datasets.</p>  <p>In this work we introduce Flowtree, a fast and accurate approximation algorithm for the Wasserstein-1 distance. We formally analyze its approximation factor and running time.  We perform extensive experimental evaluation of nearest neighbor search algorithms in the W_1 distance on real-world dataset.  Our results show that compared to previous state of the art, Flowtree achieves up to 7.4 times faster running time.</p> 
### 314.[Supervised learning: no loss no cry](https://proceedings.icml.cc/book/3554.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1939-Paper.pdf)
  Richard Nock, Aditya Menon [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1939-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1939-Supplemental.pdf)
> <p>Supervised learning requires the specification of a loss function to minimise. While the theory of admissible losses from both a computational and statistical perspective is well-developed, these offer a panoply of different choices. In practice, this choice is typically made in an \emph{ad hoc} manner. In hopes of making this procedure more principled, the problem of \emph{learning the loss function} for a downstream task (e.g., classification) has garnered recent interest. However, works in this area have been generally empirical in nature.</p>  <p>In this paper,  we revisit the {\sc SLIsotron} algorithm of Kakade et al. (2011) through a novel lens,  derive a generalisation based on Bregman divergences, and show how it provides a principled procedure for learning the loss. In detail,  we cast {\sc SLIsotron} as learning a loss from a family of composite square losses. By interpreting this through the lens of \emph{proper losses}, we derive a generalisation of {\sc SLIsotron} based on Bregman divergences. The resulting {\sc BregmanTron} algorithm jointly learns the loss along with the classifier.  It comes equipped with a simple guarantee of convergence for the loss it learns, and its set of possible outputs comes with a guarantee of agnostic approximability of Bayes rule. Experiments indicate that the {\sc BregmanTron} significantly outperforms the {\sc SLIsotron}, and that the loss it learns can be minimized by other algorithms for different tasks, thereby opening the interesting problem of \textit{loss transfer} between domains.</p> 
### 315.[Label-Noise Robust Domain Adaptation](https://proceedings.icml.cc/book/3555.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1942-Paper.pdf)
  Xiyu Yu, Tongliang Liu, Mingming Gong, Kun Zhang, Kayhan Batmanghelich, Dacheng Tao [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1942-Metadata.json)
> Domain adaptation aims to correct the classifiers when faced with distribution shift between source (training) and target (test) domains. State-of-the-art domain adaptation methods make use of deep networks to extract domain-invariant representations. However, existing methods assume that all the instances in the source domain are correctly labeled; while in reality, it is unsurprising that we may obtain a source domain with noisy labels. In this paper, we first investigate how label noise could adversely affect existing domain adaptation methods in various scenarios. Focusing on the generalized target shift scenario, where both label distribution $P_Y$ and the class-conditional distribution $P_{X|Y}$ can change, we propose a new Denoising Conditional Invariant Component (DCIC) framework, which provably ensures (1) extracting invariant representations given examples with noisy labels in the source domain and unlabeled examples in the target domain and (2) estimating the label distribution in the target domain with no bias. Experimental results on both synthetic and real-world data verify the effectiveness of the proposed method.
### 316.[Description Based Text Classification with Reinforcement Learning](https://proceedings.icml.cc/book/3556.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1944-Paper.pdf)
  Wei Wu, Duo Chai, Qinghong Han, Fei Wu, Jiwei Li [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1944-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1944-Supplemental.pdf)
> <p>The task of text classification is usually divided into two stages: text feature extraction and classification. In this standard formalization, categories are merely represented as indexes in the label vocabulary, and the model lacks for explicit instructions on what to classify. Inspired by the current trend of formalizing NLP problems as question answering tasks, we propose a new framework for text classification, in which each category label is associated with a category description. Descriptions are generated by hand-crafted templates or using abstractive/extractive models from reinforcement learning. The concatenation of the description and the text is fed to the classifier to decide whether or not the current label should be assigned to the text. The proposed strategy forces the model to attend to the most salient texts with respect to the label, which can be regarded as a hard version of attention, leading to better performances. We observe significant performance boosts over strong baselines on a wide range of text classification tasks including single-label classification, multi-label classification and multi-aspect sentiment analysis.</p> 
### 317.[Bandits for BMO Functions](https://proceedings.icml.cc/book/3557.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1959-Paper.pdf)
  Tianyu Wang, Cynthia Rudin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1959-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1959-Supplemental.zip)
> We study the bandit problem where the underlying expected reward is a Bounded Mean Oscillation (BMO) function. BMO functions are allowed to be discontinuous and unbounded, and are useful in modeling signals with singularities in the domain.  For example, BMO functions can model the intensity field of several radioactive emitting sources.  A bandit BMO algorithm can help us quickly locate the strongest emitting source. We develop a toolset for BMO bandits, and provide an algorithm that can achieve poly-log $\delta$-regret -- a regret measured against an arm that is optimal after removing a $\delta$-sized portion of the arm space. 
### 318.[Cost-effectively Identifying Causal Effect When Only Response Variable Observable](https://proceedings.icml.cc/book/3558.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1967-Paper.pdf)
  Tian-Zuo Wang, Xi-Zhu Wu, Sheng-Jun Huang, Zhi-Hua Zhou [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1967-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1967-Supplemental.pdf)
> <p>In many real tasks, we care about how to make decisions other than mere predictions on an event, e.g. how to increase the revenue next month instead of knowing it will drop. The key is to identify the causal effects on the desired event. Pearl proposed do-calculus to make it given the knowledge of causal structure (Pearl, 2009). But sometimes, we have to discover it at first. In this paper, we propose a novel solution for this challenging task where only the response variable is observable under intervention. By an active strategy introducing limited interventions and exploiting the exact distribution of the response variable, the proposed approach can cost-effectively identify the causal effect of each intervention, and thus guide the decision-making. Theoretical analysis along with empirical studies is presented to show that our approach can achieve causal effect identification with fewer interventions.</p> 
### 319.[Learning with Multiple Complementary Labels](https://proceedings.icml.cc/book/3559.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1969-Paper.pdf)
  LEI FENG, Takuo Kaneko, Bo Han, Gang Niu, Bo An, Masashi Sugiyama [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1969-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1969-Supplemental.pdf)
> <p>A complementary label (CL) simply indicates an incorrect class of an example, but learning with CLs results in multi-class classifiers that can predict the correct class. Unfortunately, the problem setting of previous research only allows a single CL for each example, which notably limits its potential since our labelers may easily identify multiple complementary labels (MCLs) to one example. In this paper, we propose a novel problem setting to allow MCLs for each example and two ways for learning with MCLs. In the first way, we design two wrappers that decompose MCLs into many single CLs in different manners, so that we could use any method for learning with CLs. However, we find that the supervision information that MCLs hold is conceptually diluted after decomposition. Thus, in the second way, we derive an unbiased risk estimator; minimizing it processes each set of MCLs as a whole and possesses an estimation error bound. In addition, we improve the second way into minimizing properly chosen upper bounds for practical implementation. Experiments show that the former way works well for learning with MCLs while the latter is even better on various benchmark datasets.</p> 
### 320.[Contrastive Multi-View Representation Learning on Graphs](https://proceedings.icml.cc/book/3560.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1971-Paper.pdf)
  Kaveh Hassani, Amir Hosein Khasahmadi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1971-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1971-Supplemental.pdf)
> <p>We introduce a self-supervised approach for learning node and graph level  representations by contrasting structural views of graphs. We show that unlike  visual representation learning, increasing the number of views to more than two or  contrasting multi-scale encodings do not improve performance, and the best  performance is achieved by contrasting encodings from first-order neighbors and  a graph diffusion. We achieve new state-of-the-art results in self-supervised  learning on 8 out of 8 node and graph classification benchmarks under the linear  evaluation protocol. For example, on Cora (node) and Reddit-Binary (graph)  classification benchmarks, we achieve 86.8% and 84.5% accuracy, which are  5.5% and 2.4% relative improvements over previous state-of-the-art. When  compared to supervised baselines, our approach outperforms them in 4 out of 8  benchmarks.</p> 
### 321.[A Chance-Constrained Generative Framework for Sequence Optimization](https://proceedings.icml.cc/book/3561.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1976-Paper.pdf)
  Xianggen Liu, Jian Peng, Qiang Liu, Sen  Song  [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1976-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1976-Supplemental.pdf)
> <p>Deep generative modeling has achieved many successes for continuous data generation, such as producing realistic images and controlling their properties (e.g., styles). However, the development of generative modeling techniques for optimizing discrete data, such as sequences or strings, still lags behind largely due to the challenges in modeling complex and long-range constraints, including both syntax and semantics, in discrete structures. For example, to generate a string representing a molecule structure or a mathematical expression with a  desired quantitative property, we need to both ensure the validity of the generated string subject to a grammar and model the string representation so that it is predictive of the property.  In this paper, we formulate the sequence optimization task as a chance-constrained sampling problem. The key idea is to enforce a high probability of generating valid sequences and also optimizes the property of interest. We propose a novel minmax algorithm based a tightening of the chance constraint, by jointly tightening a bound of the valid chance and optimizing the expected property. Extensive experimental results in three domains, including arithmetic expressions, Python programs, and SMILES strings for molecules, demonstrate the superiority of our approach over the existing sequence optimization methods. In particular, it is able to achieve the state-of-the-art performance in the molecule optimization task where the current best methods are graph-based.</p> 
### 322.[dS^2LBI: Exploring Structural Sparsity on Deep Network via Differential Inclusion Paths](https://proceedings.icml.cc/book/3562.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1977-Paper.pdf)
  Yanwei Fu, Chen Liu, Donghao Li, Xinwei Sun, Jinshan ZENG, Yuan Yao [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1977-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/1977-Supplemental.pdf)
> <p>Over-parameterization is ubiquitous nowadays in training neural networks to benefit both optimization in seeking global optima and generalization in reducing prediction error. However, compressive networks are desired in many real world applications and direct training of small networks may be trapped in local optima. In this paper, instead of pruning or distilling over-parameterized models to compressive ones, we propose a new approach based on differential inclusions of inverse scale spaces. Specifically, it generates a family of models from simple to complex ones that couples a pair of parameters to simultaneously train over-parameterized deep models and structural sparsity of which on weights of fully connected (fc) and convolutional layers. Such a differential inclusion scheme has a simple discretization, proposed as deep Structural Splitting Linearized Bregman Iteration (dS^2LBI), whose global convergence analysis in deep learning is established that from any initializations, algorithmic iterations converge to a critical point of empirical risks. Experimental evidence shows that gS^2LBI achieve comparable and even better performance than the competitive optimizers in exploring the structural sparsity of several widely used backbones on the benchmark datasets. Remarkably, with early stopping, gS2LBI unveils âwinning ticketsâ, i.e., the effective sparse structure with comparable test accuracy to over-parameterized models after retraining.</p> 
### 323.[Sparse Subspace Clustering with Entropy-Norm](https://proceedings.icml.cc/book/3563.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/1982-Paper.pdf)
  Liang Bai, Jiye Liang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/1982-Metadata.json)
> <p>Sparse subspace clustering (SSC) and spectral clustering (SC) are both state-of-the-art methods to identify complex clusters in high-dimensional input space. However, there are few researches to discuss the relation between them. Therefore, in this paper, we provide an explicit theoretical connection between them from the respective of learning a data similarity matrix. We show that spectral clustering with Gaussian kernel can be viewed as sparse subspace clustering with entropy-norm (SSC+E). Compared to existing SSC algorithms, the SSC+E algorithm can obtain a sparse, analytical, symmetrical and nonnegative similarity matrix. Besides, it makes use of Gaussian kernel to compute the sparse similarity matrix of objects, which can avoid the complex computation of the sparse optimization program of SSC. Finally, we provide the experimental analysis to compare the efficiency and effectiveness of sparse subspace clustering and spectral clustering on ten benchmark data sets. The theoretical and experimental analysis can well help users for the selection of high-dimensional data clustering algorithms.</p> 
### 324.[On the Generalization Effects of Linear Transformations in Data Augmentation](https://proceedings.icml.cc/book/3564.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2002-Paper.pdf)
  Sen Wu, Hongyang Zhang, Gregory Valiant, Christopher Re [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2002-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2002-Supplemental.pdf)
> <p>Data augmentation is a powerful technique to improve performance in applications such as image and text classification tasks. Yet, there is little rigorous understanding of why and how various augmentations work. In this work, we consider a family of linear transformations and study their effects on the ridge estimator in an over-parametrized linear regression setting. First, we show that transformations which preserve the labels of the data can improve estimation by enlarging the span of the training data. Second, we show that transformations which mix data can improve estimation by playing a regularization effect. Finally, we validate our theoretical insights on MNIST.</p>  <p>Based on the insights, we propose an augmentation scheme that searches over the space of transformations by how uncertain the model is about the transformed data. We validate our proposed scheme on image and text datasets. For example, our method outperforms RandAugment by 1.24% on CIFAR-100 using Wide-ResNet-28-10. Furthermore, we achieve comparable accuracy to the SoTA Adversarial Autoaugment on CIFAR datasets.</p> 
### 325.[Sparse Shrunk Additive Models](https://proceedings.icml.cc/book/3565.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2013-Paper.pdf)
  Hong Chen, guodong liu, Heng Huang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2013-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2013-Supplemental.pdf)
> <p>Most existing feature selection methods in literature are linear models, so that the nonlinear relations between features and response variables are not considered. Meanwhile, in these feature selection models, the interactions between features are often ignored or just discussed under prior structure information. To address these challenging issues, we consider the problem of sparse additive models for high-dimensional nonparametric regression with the allowance of the flexible interactions between features. A new method, called as sparse shrunk additive models (SSAM), is proposed to explore the structure information among features. This method bridges sparse kernel regression and sparse feature selection. Theoretical results on the convergence rate and sparsity characteristics of SSAM are established by the novel analysis techniques with integral operator and concentration estimate. In particular, our algorithm and theoretical analysis only require the component functions to be continuous and bounded, which are not necessary to be in reproducing kernel Hilbert spaces. Experiments on both synthetic and real-world data demonstrate the effectiveness of the proposed approach.</p> 
### 326.[Unsupervised Discovery of Interpretable Directions in the GAN Latent Space](https://proceedings.icml.cc/book/3566.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2025-Paper.pdf)
  Andrey Voynov, Artem Babenko [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2025-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2025-Supplemental.pdf)
> <p>The latent spaces of GAN models often have semantically meaningful directions. Moving in these directions corresponds to human-interpretable image transformations, such as zooming or recoloring, enabling a more controllable generation process. However, the discovery of such directions is currently performed in a supervised manner, requiring human labels, pretrained models, or some form of self-supervision. These requirements severely restrict a range of directions existing approaches can discover. In this paper, we introduce an unsupervised method to identify interpretable directions in the latent space of a pretrained GAN model. By a simple model-agnostic procedure, we find directions corresponding to sensible semantic manipulations without any form of (self-)supervision. Furthermore, we reveal several non-trivial findings, which would be difficult to obtain by existing methods, e.g., a direction corresponding to background removal. As an immediate practical benefit of our work, we show how to exploit this finding to achieve competitive performance for weakly-supervised saliency detection. The implementation of our method is available online.</p> 
### 327.[DropNet: Reducing Neural Network Complexity via Iterative Pruning](https://proceedings.icml.cc/book/3567.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2026-Paper.pdf)
  Chong Min John Tan, Mehul Motani [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2026-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2026-Supplemental.pdf)
> <p>Modern deep neural networks require a significant amount of computing time and power to train and deploy, which limits their usage on edge devices. Inspired by the iterative weight pruning in the Lottery Ticket Hypothesis, we propose DropNet, an iterative pruning method which prunes nodes/filters to reduce network complexity. DropNet iteratively removes nodes/filters with the lowest average post-activation value across all training samples. Empirically, we show that DropNet is robust across a wide range of scenarios, including MLPs and CNNs using the MNIST and CIFAR datasets. We show that up to 90% of the nodes/filters can be removed without any significant loss of accuracy. The final pruned network performs well even with reinitialisation of the weights and biases. DropNet also achieves similar accuracy to an oracle which greedily removes nodes/filters one at a time to minimise training loss, highlighting its effectiveness.</p> 
### 328.[Self-supervised Label Augmentation via Input Transformations](https://proceedings.icml.cc/book/3568.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2048-Paper.pdf)
  Hankook Lee, Sung Ju Hwang, Jinwoo Shin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2048-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2048-Supplemental.pdf)
> <p>Self-supervised learning, which learns by constructing artificial labels given only the input signals, has recently gained considerable attention for learning representations with unlabeled datasets, i.e., learning without any human-annotated supervision. In this paper, we show that such a technique can be used to significantly improve the model accuracy even under fully-labeled datasets. Our scheme trains the model to learn both original and self-supervised tasks, but is different from conventional multi-task learning frameworks that optimize the summation of their corresponding losses. Our main idea is to learn a single unified task with respect to the joint distribution of the original and self-supervised labels, i.e., we augment original labels via self-supervision. This simple, yet effective approach allows to train models easier by relaxing a certain invariant constraint during learning the original and self-supervised tasks simultaneously. It also enables an aggregated inference which combines the predictions from different augmentations to improve the prediction accuracy. Furthermore, we propose a novel knowledge transfer technique, which we refer to as self-distillation, that has the effect of the aggregated inference in a single (faster) inference. We demonstrate the large accuracy improvement and wide applicability of our framework on various fully-supervised settings, e.g., the few-shot and imbalanced classification scenarios.</p> 
### 329.[Mapping natural-language problems to formal-language solutions using structured neural representations](https://proceedings.icml.cc/book/3569.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2067-Paper.pdf)
  Kezhen Chen, Qiuyuan Huang, Hamid Palangi, Paul Smolensky, Ken Forbus, Jianfeng Gao [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2067-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2067-Supplemental.pdf)
> <p>Generating formal-language programs represented by relational tuples, such as Lisp programs or mathematical operations, from natural-language problems is a challenging task because it requires explicitly capturing discrete symbolic structural information implicit in the input. However, most general neural sequence models do not explicitly capture such structural information, limiting their performance on these tasks. In this paper, we propose a new encoder-decoder model based on a structured neural representation, Tensor Product Representations (TPRs), for generating formal-language solutions from natural-language, called TP-N2F. The encoder of TP-N2F employs TPR <code>binding' to encode natural-language symbolic structure in vector space and the decoder uses TPR</code>unbinding' to generate, in symbolic space, a sequential program represented by relational tuples, each consisting of a relation (or operation) and a number of arguments. TP-N2F considerably outperforms LSTM-based seq2seq models on two benchmarks and creates new state-of-the-art results. Ablation studies show that improvements can be attributed to the use of structured TPRs explicitly in both the encoder and decoder. Analysis of the learned structures shows how TPRs enhance the interpretability of TP-N2F.</p> 
### 330.[Transformation of ReLU-based recurrent neural networks from discrete-time to continuous-time](https://proceedings.icml.cc/book/3570.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2079-Paper.pdf)
  Zahra Monfared, Daniel Durstewitz [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2079-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2079-Supplemental.pdf)
> <p>Recurrent neural networks (RNN) as used in machine learning are commonly formulated in discrete time, i.e. as recursive maps. This brings a lot of advantages for training models on data, e.g. for the purpose of time series prediction or dynamical systems identification, as powerful and efficient inference algorithms exist for discrete time systems and numerical integration of differential equations is not necessary. On the other hand, mathematical analysis of dynamical systems inferred from data is often more convenient and enables additional insights if these are formulated in continuous time, i.e. as systems of ordinary (or partial) differential equations (ODE). Here we show how to perform such a translation from discrete to continuous time for a particular class of ReLU-based RNN. We prove three theorems on the mathematical equivalence between the discrete and continuous time formulations under a variety of conditions, and illustrate how to use our mathematical results on different machine learning and nonlinear dynamical systems examples.</p> 
