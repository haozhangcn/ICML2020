# ICML2020-2
ICML2020 papers with abstract [:link:](https://proceedings.icml.cc/book/2020)

### 331.[Implicit Geometric Regularization for Learning Shapes](https://proceedings.icml.cc/book/3571.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2086-Paper.pdf)
  Amos Gropp, Lior Yariv, Niv Haim, Matan Atzmon, Yaron Lipman [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2086-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2086-Supplemental.pdf)
> <p>Representing shapes as level-sets of neural networks has been recently proved to be useful for different shape analysis and reconstruction tasks. So far, such representations were computed using either: (i) pre-computed implicit shape representations; or (ii) loss functions explicitly defined over the neural level-sets. </p>  <p>In this paper we offer a new paradigm for computing high fidelity implicit neural representations directly from raw data (i.e., point clouds, with or without normal information). We observe that a rather simple loss function, encouraging the neural network to vanish on the input point cloud and to have a unit norm gradient, possesses an implicit geometric regularization property that favors smooth and natural zero level-set surfaces, avoiding bad zero-loss solutions.  We provide a theoretical analysis of this property for the linear case, and show that, in practice, our method leads to state-of-the-art implicit neural representations with higher level-of-details and fidelity compared to previous methods. </p> 
### 332.[Influence Diagram Bandits](https://proceedings.icml.cc/book/3572.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2093-Paper.pdf)
  Tong Yu, Branislav Kveton, Zheng Wen, Ruiyi Zhang, Ole J. Mengshoel [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2093-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2093-Supplemental.pdf)
> <p>We propose a novel framework for structured bandits, which we call influence diagram bandit. Our framework captures complicated statistical dependencies between actions, latent variables, and observations; and unifies and extends many existing models, such as combinatorial semi-bandits, cascading bandits, and low-rank bandits. We develop novel online learning algorithms that allow us to act efficiently in our models. The key idea is to track a structured posterior distribution of model parameters, either exactly or approximately. To act, we sample model parameters from their posterior and then use the structure of the influence diagram to find the most optimistic actions under the sampled parameters. We experiment with three structured bandit problems: cascading bandits, online learning to rank in the position-based model, and rank-1 bandits. Our algorithms achieve up to about 3 times higher cumulative reward than baselines.</p> 
### 333.[Information Particle Filter Tree: An Online Algorithm for POMDPs with Belief-Based Rewards on Continuous Domains](https://proceedings.icml.cc/book/3573.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2113-Paper.pdf)
  Johannes Fischer, Ömer Sahin Tas [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2113-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2113-Supplemental.pdf)
> <p>Partially Observable Markov Decision Processes (POMDPs) inherently gather the information necessary to act optimally under uncertainties. The framework can be extended to model pure information gathering tasks by considering belief-based rewards. This allows us to use reward shaping to guide POMDP planning to informative beliefs by using a weighted combination of the original reward and the expected information gain as the objective. In this work we propose a novel online algorithm, Information Particle Filter Tree (IPFT), to solve problems with belief-dependent rewards on continuous domains. It simulates particle-based belief trajectories in a Monte Carlo Tree Search (MCTS) approach to construct a search tree in the belief space. The evaluation shows that the consideration of information gain greatly improves the performance in problems where information gathering is an essential part of the optimal policy.</p> 
### 334.[Convergence Rates of Variational Inference in Sparse Deep Learning](https://proceedings.icml.cc/book/3574.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2115-Paper.pdf)
  Badr-Eddine Chérief-Abdellatif [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2115-Metadata.json)
> <p>Variational inference is becoming more and more popular for approximating intractable posterior distributions in Bayesian statistics and machine learning. Meanwhile, a few recent works have provided theoretical justification and new insights on deep neural networks for estimating smooth functions in usual settings such as nonparametric regression. In this paper, we show that variational inference for sparse deep learning retains precisely the same generalization properties than exact Bayesian inference. In particular, we show that a wise choice of the neural network architecture leads to near-minimax rates of convergence for H\"older smooth functions. Additionally, we show that the model selection framework over the architecture of the network via ELBO maximization does not overfit and adaptively achieves the optimal rate of convergence.</p> 
### 335.[Unsupervised Transfer Learning for Spatiotemporal Predictive Networks](https://proceedings.icml.cc/book/3575.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2121-Paper.pdf)
  Zhiyu Yao, Yunbo Wang, Mingsheng Long, Jianmin Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2121-Metadata.json)
> <p>This paper explores a new research problem of unsupervised transfer learning across multiple spatiotemporal prediction tasks. Unlike most existing transfer learning methods that focus on fixing the discrepancy between supervised tasks, we study how to transfer knowledge from a zoo of unsupervisedly learned models towards another predictive network. Our motivation is that models from different sources are expected to understand the complex spatiotemporal dynamics from different perspectives, and thus provide an effective supplement to the new task, even if this task already has sufficient training data. Technically, we propose a differentiable framework named transferable memory. It adaptively distills knowledge from a bank of memory states of predictive networks, and then applies it to the target network with a novel recurrent structure called transferable memory unit (TMU). Compared with finetuning, our approach yields significant improvements on three benchmarks for spatiotemporal prediction, and benefits the target task even from less relevant pretext tasks.</p> 
### 336.[DINO: Distributed Newton-Type Optimization Method](https://proceedings.icml.cc/book/3576.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2125-Paper.pdf)
  Rixon Crane, Fred Roosta [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2125-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2125-Supplemental.zip)
> <p>We present a novel communication-efficient Newton-type algorithm for finite-sum optimization over a distributed computing environment. Our method, named DINO, overcomes both theoretical and practical shortcomings of similar existing methods. Under minimal assumptions, we guarantee global sub-linear convergence of DINO to a first-order stationary point for general non-convex functions and arbitrary data distribution over the network. Furthermore, for functions satisfying Polyak-Lojasiewicz (PL) inequality, we show that DINO enjoys a linear convergence rate. Our proposed algorithm is practically parameter free, in that it will converge regardless of the selected hyper-parameters, which are easy to tune. Additionally, its sub-problems are simple linear least-squares, for which efficient solvers exist, and numerical simulations demonstrate the efficiency of DINO as compared with similar alternatives.</p> 
### 337.[Quantum Expectation-Maximization for Gaussian Mixture Models](https://proceedings.icml.cc/book/3577.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2139-Paper.pdf)
  Alessandro Luongo, Iordanis Kerenidis, Anupam Prakash [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2139-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2139-Supplemental.pdf)
> <p>We define a quantum version of Expectation-Maximization (QEM), a fundamental tool in unsupervised machine learning, often used to solve Maximum Likelihood (ML) and Maximum A Posteriori (MAP) estimation problems. We use QEM to fit a Gaussian Mixture Model, and show how to generalize it to fit mixture models with base distributions in the exponential family. Given quantum access to a dataset, our algorithm has convergence and precision guarantees similar to the classical algorithm, while the runtime is polylogarithmic in the number of elements in the training set and polynomial in other parameters, such as the dimension of the feature space and the number of components in the mixture. We discuss the performance of the algorithm on datasets that are expected to be classified successfully by classical EM and provide guarantees for its runtime.</p> 
### 338.[Consistent Structured Prediction with Max-Min Margin Markov Networks](https://proceedings.icml.cc/book/3578.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2140-Paper.pdf)
  Alex Nowak, Francis Bach, Alessandro Rudi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2140-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2140-Supplemental.zip)
> Max-margin methods for binary classification such as the support vector machine (SVM) have been extended to the structured prediction setting under the name of max-margin Markov networks ($M^3N$), or more generally structural SVMs. These methods are able to model interactions between output parts and incorporate a cost between labels. Unfortunately, these methods are inconsistent when the relationship between inputs and labels is far from deterministic. To overcome such limitations, in this paper we go beyond max-margin, defining the learning problem in terms of a ``max-min&#x27;&#x27; margin formulation. The resulting method, which we name max-min margin Markov networks ($M^4N$), provides a correction of the $M^3N$ loss that is key to achieve consistency in the general case. In this paper, we prove consistency and finite sample generalization bounds for $M^4N$ and provide an explicit algorithm to compute the estimator. The algorithm has strong statistical and computational guarantees: in a worst case scenario it achieves a generalization error of $O(1/\sqrt{n})$ for a total cost of $O(n\sqrt{n})$ marginalization-oracle calls, which have essentially the same cost as the max-oracle from $M^3N$. Experiments on multi-class classification and handwritten character recognition demonstrate the effectiveness of the proposed method over $M^3N$ networks.
### 339.[Concentration bounds for CVaR estimation: The cases of light-tailed and heavy-tailed distributions](https://proceedings.icml.cc/book/3579.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2156-Paper.pdf)
  Prashanth L.A., Krishna Jagannathan, Ravi Kolla [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2156-Metadata.json)
> <p>Conditional Value-at-Risk (CVaR) is a widely used risk metric in applications such as finance. We derive concentration bounds for CVaR estimates, considering separately the cases of sub-Gaussian, light-tailed and heavy-tailed distributions. For the sub-Gaussian and light-tailed cases, we use a classical CVaR estimator based on the empirical distribution constructed from the samples. For heavy-tailed random variables, we assume a mild `bounded moment' condition, and derive a concentration bound for a truncation-based estimator. Our concentration bounds exhibit exponential decay in the sample size, and are tighter than those available in the literature for the above distribution classes. To demonstrate the applicability of our concentration results, we consider the CVaR optimization problem in a multi-armed bandit setting. Specifically, we address (i) the best CVaR-arm identification problem under a fixed budget; and (ii) CVaR-based regret minimization. Using our CVaR concentration bounds, we derive an upper-bound on the probability of incorrect identification for (i), and a regret guarantee for (ii).</p> 
### 340.[Robust Pricing in Dynamic Mechanism Design](https://proceedings.icml.cc/book/3580.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2157-Paper.pdf)
  Yuan Deng, Sébastien Lahaie, Vahab Mirrokni [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2157-Metadata.json)
> <p>Motivated by the repeated sale of online ads via auctions, optimal pricing in repeated auctions has attracted a large body of research. While dynamic mechanisms offer powerful techniques to improve on both revenue and efficiency by optimizing auctions across different items, their reliance on exact distributional information of buyers' valuations (present and future) limits their use in practice. In this paper, we propose robust dynamic mechanism design. We develop a new framework to design dynamic mechanisms that are robust to both estimation errors in value distributions and strategic behavior. We apply the framework in learning environments, leading to the first policy that achieves provably low regret against the optimal dynamic mechanism in contextual auctions, where the dynamic benchmark has full and accurate distributional information.</p> 
### 341.[Nested Subspace Arrangement for Representation of Relational Data](https://proceedings.icml.cc/book/3581.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2159-Paper.pdf)
  Nozomi Hata, Shizuo Kaji, Akihiro Yoshida, Katsuki Fujisawa [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2159-Metadata.json)
> Studies of acquiring appropriate continuous representations of a discrete objects such as graph and knowledge based data have been conducted by many researches in the field of machine learning. In this paper, we introduce Nested SubSpace arrangement (NSS arrangement), a comprehensive framework for representation learning. We show that existing embedding techniques can be regarded as a member of NSS arrangement. Based on the concept of the NSS arrangement, we implemented Disk-ANChor ARrangement (DANCAR), a representation learning method specializing to reproduce general graphs. Numerical experiments have shown that DANCAR has successfully embedded WordNet in ${\mathbb R}^{20}$ with the F1 score of 99.3\% in the reconstruction task. DANCAR is also suitable for visualization to understand the characteristics of graph.
### 342.[Equivariant Neural Rendering](https://proceedings.icml.cc/book/3582.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2167-Paper.pdf)
  Emilien Dupont, Miguel Bautista Martin, Alex Colburn, Aditya Sankar, Joshua Susskind, Qi Shan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2167-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2167-Supplemental.pdf)
> <p>We propose a framework for learning neural scene representations directly from images, without 3D supervision. Our key insight is that 3D structure can be imposed by ensuring that the learned representation transforms like a real 3D scene. Specifically, we introduce a loss which enforces equivariance of the scene representation with respect to 3D transformations. Our formulation allows us to infer and render scenes in real time while achieving comparable results to models requiring minutes for inference. In addition, we introduce two challenging new datasets for scene representation and neural rendering, including scenes with complex lighting and backgrounds. Through experiments, we show that our model achieves compelling results on these datasets as well as on standard ShapeNet benchmarks.</p> 
### 343.[Bounding the fairness and accuracy of classifiers from population statistics](https://proceedings.icml.cc/book/3583.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2168-Paper.pdf)
  Sivan Sabato, Elad Yom-Tov [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2168-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2168-Supplemental.pdf)
> <p>We consider the study of a classification model whose properties are impossible to estimate using a validation set, either due to the absence of such a set or because access to the classifier, even as a black-box, is impossible. Instead, only aggregate statistics on the rate of positive predictions in each of several sub-populations are available, as well as the true rates of positive labels in each of these sub-populations.  We show that these aggregate statistics can be used to lower-bound the discrepancy of a classifier, which is a measure that balances inaccuracy and unfairness. To this end, we define a new measure of unfairness, equal to the fraction of the population on which the classifier behaves differently, compared to its global, ideally fair behavior, as defined by the measure of equalized odds.  We propose an efficient and practical procedure for finding the best possible lower bound on the discrepancy of the classifier, given the aggregate statistics, and demonstrate in experiments the empirical tightness of this lower bound, as well as its possible uses on various types of problems, ranging from estimating the quality of voting polls to measuring the effectiveness of patient identification from internet search queries. The code and data are available at https://github.com/sivansabato/bfa.</p> 
### 344.[Healing Gaussian Process Experts](https://proceedings.icml.cc/book/3584.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2170-Paper.pdf)
  samuel cohen, Rendani Mbuvha, Tshilidzi Marwala, Marc Deisenroth [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2170-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2170-Supplemental.pdf)
> <p>Gaussian processes are nonparametric Bayesian models that have been applied to regression and classification problems. One of the approaches to alleviate their cubic training cost is the use of local GP experts trained on subsets of the data. While these expert models allow for massively distributed computation, their predictions can suffer from erratic behaviour of the mean or unrealistic uncertainty quantification. In this paper, we provide a solution to these problems for multiple expert models, including the generalised product of experts and the robust Bayesian committee machine. Furthermore, we leverage the optimal transport literature and propose a new expert model that averages predictions of local experts by computing their Wasserstein barycenter, which can be applied to both regression and classification settings.</p> 
### 345.[Beyond UCB: Optimal and Efficient Contextual Bandits with Regression Oracles](https://proceedings.icml.cc/book/3585.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2171-Paper.pdf)
  Dylan Foster, Alexander Rakhlin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2171-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2171-Supplemental.pdf)
> <p>A fundamental challenge in contextual bandits is to develop flexible, general-purpose algorithms with computational requirements no worse than classical supervised learning tasks such as classification and regression. Algorithms based on regression have shown promising empirical success, but theoretical guarantees have remained elusive except in special cases. We provide the first universal and optimal reduction from contextual bandits to online regression. We show how to transform any oracle for online regression with a given value function class into an algorithm for contextual bandits with the induced policy class, with no overhead in runtime or memory requirements. We characterize the minimax rates for contextual bandits with general, potentially nonparametric function classes, and show that our algorithm is minimax optimal whenever the oracle obtains the optimal rate for regression. Compared to previous results, our algorithm requires no distributional assumptions beyond realizability, and works even when contexts are chosen adversarially.</p> 
### 346.[Simple and Deep Graph Convolutional Networks](https://proceedings.icml.cc/book/3586.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2172-Paper.pdf)
  Ming Chen, Zhewei Wei, Zengfeng Huang, Bolin Ding, Yaliang Li [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2172-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2172-Supplemental.pdf)
> <p>Graph convolutional networks (GCNs) are a powerful deep learning approach for graph-structured data.  Recently, GCNs and subsequent variants have shown superior performance in various application areas on real-world datasets. Despite their success, most of the current GCN models are shallow, due to the {\em over-smoothing} problem. In this paper, we study the problem of designing and analyzing deep graph convolutional networks.  We propose the GCNII, an extension of the vanilla GCN model with two simple yet effective techniques: {\em Initial residual} and {\em Identity mapping}. We provide theoretical and empirical evidence that the two techniques effectively relieves the problem of over-smoothing. Our experiments show that the deep GCNII model outperforms the state-of-the-art methods on various semi- and full-supervised tasks.  </p> 
### 347.[Projection-free Distributed Online Convex Optimization with $O(\sqrt{T})$ Communication Complexity](https://proceedings.icml.cc/book/3587.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2175-Paper.pdf)
  Yuanyu Wan, Wei-Wei Tu, Lijun Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2175-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2175-Supplemental.pdf)
> To deal with complicated constraints via locally light computation in distributed online learning, recent study has presented a projection-free algorithm called distributed online conditional gradient (D-OCG), and achieved an $O(T^{3/4})$ regret bound, where $T$ is the number of prediction rounds. However, in each round, the local learners of D-OCG need to communicate with their neighbors to share the local gradients, which results in a high communication complexity of $O(T)$. In this paper, we first propose an improved variant of D-OCG, namely D-BOCG, which enjoys an $O(T^{3/4})$ regret bound with only $O(\sqrt{T})$ communication complexity. The key idea is to divide the total prediction rounds into $\sqrt{T}$ equally-sized blocks, and only update the local learners in the beginning of each block by performing iterative linear optimization steps. Furthermore, to handle the more challenging bandit setting, in which only the loss value is available, we incorporate the classical one-point gradient estimator into D-BOCG, and obtain similar theoretical guarantees.
### 348.[Meta Variance Transfer: Learning to Augment from the Others](https://proceedings.icml.cc/book/3588.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2222-Paper.pdf)
  Seong-Jin Park, Seungju Han, Ji-won Baek, Insoo Kim, Juhwan Song, Hae Beom Lee, Jae-Joon Han, Sung Ju Hwang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2222-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2222-Supplemental.pdf)
> <p>Humans have the ability to robustly recognize objects with various factors of variations such as nonrigid transformation, background noise, and change in lighting conditions. However, deep learning frameworks generally require huge amount of data with instances under diverse variations, to train a robust model. To alleviate the need of collecting large data and better learn from scarce samples, we propose a novel meta-learning method which learns to transfer factors of variations from one class to another, such that it can improve the classification performance on unseen examples. Transferred variations generate virtual samples that augment the feature space of the target class during training, simulating upcoming query samples with similar variations. By sharing factors of variations across different classes, the model becomes more robust to variations in the unseen examples and tasks using small number of examples per class. We validate our model on multiple benchmark datasets for few-shot classification and face recognition, on which our model significantly improves the performance of the base model, outperforming relevant baselines.</p> 
### 349.[Coresets for Clustering in Graphs of Bounded Treewidth](https://proceedings.icml.cc/book/3589.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2231-Paper.pdf)
  Daniel Baker, Vladimir Braverman, Lingxiao Huang, Shaofeng H.-C. Jiang, Robert Krauthgamer, Xuan Wu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2231-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2231-Supplemental.pdf)
> We initiate the study of coresets for clustering in graph metrics, i.e., the shortest-path metric of edge-weighted graphs. Such clustering problems are essential to data analysis and used for example in road networks and data visualization. A coreset is a compact summary of the data that approximately preserves the clustering objective for every possible center set, and it offers significant efficiency improvements in terms of running time, storage, and communication, including in streaming and distributed settings. Our main result is a near-linear time construction of a coreset for k-Median in a general graph $G$, with size $O_{\epsilon, k}(\tw(G))$ where $\tw(G)$ is the treewidth of $G$, and we complement the construction with a nearly-tight size lower bound. The construction is based on the framework of Feldman and Langberg [STOC 2011], and our main technical contribution, as required by this framework, is a uniform bound of $O(\tw(G))$ on the shattering dimension under any point weights. We validate our coreset on real-world road networks, and our scalable algorithm constructs tiny coresets with high accuracy, which translates to a massive speedup of existing approximation algorithms such as local search for graph k-Median.
### 350.[On Breaking Deep Generative Model-based Defenses and Beyond](https://proceedings.icml.cc/book/3590.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2236-Paper.pdf)
  Yanzhi Chen, Renjie Xie, Zhanxing Zhu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2236-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2236-Supplemental.pdf)
> <p>Deep neural networks have been proven to be vulnerable to the so-called adversarial attacks. Recently there have been efforts to defend such attacks with deep generative models. These defenses often involve an inversion phase that they first seek the latent representation that best matches with the input, then use this representation for prediction. Such defenses are often difficult to attack due to the non-analytical gradients. In this work, we develop a new gradient approximation attack to break these defenses. The idea is to view the inversion phase as a dynamical system, through which we extract the gradient with respect to the input by tracing its recent trajectory. An amortized strategy is further developed to accelerate the attack. Experiments show that our attack outperforms state-of-the-art approaches (e.g Backward Pass Differential Approximation) with unprecedented low distortions. Additionally, our empirical results reveal a key defect of current deep generative model-based defenses that it may not realize the on-manifold conjecture expectedly.</p> 
### 351.[Exploration Through Bias: Revisiting Biased Maximum Likelihood Estimation in Stochastic Multi-Armed Bandits](https://proceedings.icml.cc/book/3591.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2244-Paper.pdf)
  Xi Liu, Ping-Chun Hsieh, Yu Heng Hung, Anirban  Bhattacharya, P. Kumar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2244-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2244-Supplemental.pdf)
> <p>We propose a new family of bandit algorithms, that are formulated in a general way based on the Biased Maximum Likelihood Estimation (BMLE) method originally appearing in the adaptive control literature. We design the reward-bias term to tackle the exploration and exploitation tradeoff for stochastic bandit problems. We provide a general recipe for the BMLE algorithm and derive a simple explicit closed-form expression for the index of an arm for exponential family reward distributions. We prove that the derived BMLE indices achieve a logarithmic finite-time regret bound and hence attain order-optimality, for both exponential families and the cases beyond parametric distributions. Through extensive simulations, we demonstrate that the proposed algorithms achieve regret performance comparable to the best of several state-of-the-art baseline methods, while being computationally efficient in comparison to other best-performing methods. The generality of the proposed approach makes it possible to address more complex models, including general adaptive control of Markovian systems.</p> 
### 352.[Bisection-Based Pricing for Repeated Contextual Auctions against Strategic Buyer](https://proceedings.icml.cc/book/3592.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2249-Paper.pdf)
  Anton Zhiyanov, Alexey Drutsa [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2249-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2249-Supplemental.pdf)
> We are interested in learning algorithms that optimize revenue in repeated contextual posted-price auctions where a single seller faces a single strategic buyer. In our setting, the buyer  maximizes his expected cumulative discounted surplus, and his valuation of a good is assumed to be a fixed function of a $d$-dimensional context (feature) vector. We introduce a novel deterministic learning algorithm that is based on ideas of the Bisection method and has strategic regret upper bound of $O(\log^2 T)$. Unlike previous works, our algorithm does not require any assumption on the distribution of context information, and the regret guarantee holds for any realization of feature vectors (adversarial upper bound). To construct our algorithm we non-trivially adopted techniques of integral geometry to act against buyer strategicness and improved the penalization trick to work in contextual auctions.
### 353.[Haar Graph Pooling](https://proceedings.icml.cc/book/3593.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2250-Paper.pdf)
  Yuguang Wang, Ming Li, Zheng Ma, Guido Montufar, Xiaosheng Zhuang, Yanan Fan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2250-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2250-Supplemental.pdf)
> <p>Deep Graph Neural Networks (GNNs) are useful models for graph classification and graph-based regression tasks. In these tasks, graph pooling is a critical ingredient by which GNNs adapt to input graphs of varying size and structure. We propose a new graph pooling operation based on compressive Haar transforms --- \emph{HaarPooling}. HaarPooling implements a cascade of pooling operations; it is computed by following a sequence of clusterings of the input graph. A HaarPooling layer transforms a given input graph to an output graph with a smaller node number and the same feature dimension; the compressive Haar transform filters out fine detail information in the Haar wavelet domain. In this way, all the HaarPooling layers together synthesize the features of any given input graph into a feature vector of uniform size. Such transforms provide a sparse characterization of the data and preserve the structure information of the input graph. GNNs implemented with standard graph convolution layers and HaarPooling layers achieve state of the art performance on diverse graph classification and regression problems.</p> 
### 354.[Explaining Groups of Points in Low-Dimensional Representations](https://proceedings.icml.cc/book/3594.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2264-Paper.pdf)
  Gregory Plumb, Jonathan Terhorst, Sriram Sankararaman, Ameet Talwalkar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2264-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2264-Supplemental.pdf)
> <p>A common workflow in data exploration is to learn a low-dimensional representation of the data, identify groups of points in that representation, and examine the differences between the groups to determine what they represent.  We treat this as an interpretable machine learning problem by leveraging the model that learned the low-dimensional representation to help identify the key differences between the groups.  To solve this problem, we introduce a new type of explanation, a Global Counterfactual Explanation (GCE), and our algorithm, Transitive Global Translations (TGT), for computing GCEs.   TGT identifies the differences between each pair of groups using compressed sensing but constrains those pairwise differences to be consistent among all of the groups.  Empirically, we demonstrate that TGT is able to identify explanations that accurately explain the model while being relatively sparse, and that these explanations match real patterns in the data. </p> 
### 355.[Learning Portable Representations for High-Level Planning](https://proceedings.icml.cc/book/3595.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2270-Paper.pdf)
  Steven James, Benjamin Rosman, George Konidaris [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2270-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2270-Supplemental.pdf)
> <p>We present a framework for autonomously learning a portable representation that describes a collection of low-level continuous environments. We show that these abstract representations can be learned in a task-independent egocentric space \textit{specific to the agent} that, when grounded with problem-specific information, are provably sufficient for planning. We demonstrate transfer in two different domains, where an agent learns a portable, task-independent symbolic vocabulary, as well as rules expressed in that vocabulary, and then learns to instantiate those rules on a per-task basis. This reduces the samples required to learn a representation of a new task.</p> 
### 356.[Adaptive Estimator Selection for Off-Policy Evaluation](https://proceedings.icml.cc/book/3596.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2273-Paper.pdf)
  Yi Su, Pavithra Srinath, Akshay Krishnamurthy [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2273-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2273-Supplemental.pdf)
> <p>We develop a generic data-driven method for estimator selection in off-policy policy evaluation settings. We establish a strong performance guarantee for the method, showing that it is competitive with the oracle estimator, up to a constant factor. Via in-depth case studies in contextual bandits and reinforcement learning, we demonstrate the generality and applicability of the method. We also perform comprehensive experiments, demonstrating the empirical efficacy of our approach and comparing with related approaches. In both case studies, our method compares favorably with existing methods.</p> 
### 357.[Doubly Stochastic Variational Inference for Neural Processes with Hierarchical Latent Variables](https://proceedings.icml.cc/book/3597.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2280-Paper.pdf)
  Qi Wang, Herke van Hoof [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2280-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2280-Supplemental.pdf)
> <p>Neural processes (NPs) constitute a family of variational approximate models for stochastic processes with promising properties in computational efficiency and uncertainty quantification. These processes use neural networks with latent variable inputs to induce a predictive distribution. However, the expressiveness of vanilla NPs is limited as they only use a global latent variable, while target-specific local variation may be crucial sometimes. To address this challenge, we investigate NPs systematically and present a new variant of NP model that we call Doubly Stochastic Variational Neural Process (DSVNP). This model combines the global latent variable and local latent variables for prediction. We evaluate this model in several experiments, and our results demonstrate competitive prediction performance in multi-output regression and uncertainty estimation in classification.</p> 
### 358.[Generative Flows with Matrix Exponential](https://proceedings.icml.cc/book/3598.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2283-Paper.pdf)
  Changyi Xiao, Ligang Liu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2283-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2283-Supplemental.zip)
> <p>Flow-based generative models are a family of generative models which enjoy the properties of tractable exact likelihood and efficient training and sampling. They are composed of a sequence of invertible functions. In this paper, we incorporate matrix exponential into generative flows. Matrix exponential is a map from matrices to invertible matrices, this property is suitable for generative flows. Based on matrix exponential, we propose matrix exponential coupling layers which are a general case of affine coupling layers and a stable version of invertible 1 x 1 convolutions which do not collapse during training. And we modify the networks architecture to make training stable and significantly speed up the training process. Our experiments show that our model achieves great performance on density estimation amongst flow-based models.</p> 
### 359.[Composable Sketches for  Functions of Frequencies: Beyond the Worst Case](https://proceedings.icml.cc/book/3599.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2290-Paper.pdf)
  Edith Cohen, Ofir Geri, Rasmus Pagh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2290-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2290-Supplemental.zip)
> Recently there has been increased interest in using machine learning techniques to improve classical algorithms. In this paper we study when it is possible to construct compact, composable sketches  for weighted sampling and statistics estimation according to functions of data frequencies.  Such structures are now central components of large-scale data analytics and machine learning pipelines. Many common functions, however, such as thresholds and $p$th frequency moments with $p&gt;2$, are known to require polynomial size sketches in the worst case.  We explore performance beyond the worst case under two different types of assumptions.  The first is having access to noisy \emph{advice} on item frequencies. This continues the line of work of Hsu et al.~(ICLR 2019), who assume predictions are provided by a machine learning model.  The second is providing guaranteed performance on a restricted class of input frequency distributions that are better aligned with what is observed in practice. This extends the work on heavy hitters under Zipfian distributions in a seminal paper of Charikar et al.~(ESA 2002). Surprisingly, we show analytically and empirically that ``in practice&#x27;&#x27; small polylogarithmic-size sketches provide accuracy for ``hard&#x27;&#x27; functions.
### 360.[Self-concordant analysis of Frank-Wolfe algorithm](https://proceedings.icml.cc/book/3600.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2292-Paper.pdf)
  Mathias Staudigl, Pavel Dvurechenskii, Shimrit Shtern, Kamil Safin, Petr Ostroukhov [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2292-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2292-Supplemental.pdf)
> <p>Projection-free optimization via different variants of the Frank-Wolfe (FW) method has become one of the cornerstones in optimization for machine learning since in many cases the linear minimization oracle is much cheaper to implement than projections and some sparsity needs to be preserved. In a number of applications, e.g. Poisson inverse problems or quantum state tomography, the loss is given by a self-concordant (SC) function having unbounded curvature, implying absence of theoretical guaranteesfor the existing FW methods. We use the theory of SC functions to provide a new adaptive step size for FW methods and prove global convergence rate O(1/k), k being the iteration counter. If the problem can be represented by a local linear minimization oracle, we are the first to propose a FW method with linear convergence rate without assuming neither strong convexity nor a Lipschitz continuous gradient.</p> 
### 361.[Towards non-parametric drift detection via Dynamic Adapting Window Independence Drift Detection (DAWIDD)](https://proceedings.icml.cc/book/3601.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2298-Paper.pdf)
  Fabian Hinder, André Artelt, CITEC Barbara Hammer [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2298-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2298-Supplemental.pdf)
> <p>The notion of concept drift refers to the phenomenon that the distribution, which is underlying the observed data, changes over time; as a consequence machine learning models may become inaccurate and need adjustment. Many online learning schemes include drift detection to actively detect and react to observed changes. Yet, reliable drift detection constitutes a challenging problem in particular in the context of high dimensional data, varying drift characteristics, and the absence of a parametric model such as a classification scheme which reflects the drift. In this paper we present a novel concept drift detection method, Dynamic Adapting Window Independence Drift Detection (DAWIDD), which aims for non-parametric drift detection of diverse drift characteristics. For this purpose, we establish a mathematical equivalence of the presence of drift to the dependency of specific random variables in an according drift process. This allows us to rely on independence tests rather than parametric models or the classification loss, resulting in a fairly robust scheme to universally detect different types of drift, as is also confirmed in experiments. </p> 
### 362.[Non-Stationary Bandits with Intermediate Observations](https://proceedings.icml.cc/book/3602.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2302-Paper.pdf)
  Claire Vernade, András György, Timothy Mann [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2302-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2302-Supplemental.pdf)
> Online recommender systems often face long delays in receiving feedback, especially when optimizing for some long-term metrics. While mitigating the effects of delays in learning is well-understood in stationary environments, the problem becomes much more challenging when the environment changes. In fact, if the timescale of the change is comparable to the delay, it is impossible to learn about the environment, since the available observations are already obsolete. However, the arising issues can be addressed if intermediate signals are available without delay, such that given those signals, the long-term behavior of the system is stationary. To model this situation, we  introduce the problem of stochastic, non-stationary, delayed bandits with intermediate observations. We develop a computationally efficient algorithm based on $\UCRL$, and prove sublinear regret guarantees for its performance. Experimental results demonstrate that our method is able to learn in non-stationary delayed environments where existing methods fail. 
### 363.[Does label smoothing mitigate label noise?](https://proceedings.icml.cc/book/3603.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2305-Paper.pdf)
  Michal Lukasik, Srinadh Bhojanapalli, Aditya Menon, Sanjiv Kumar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2305-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2305-Supplemental.pdf)
> <p>Label smoothing is commonly used in training deep learning models, wherein one-hot training labels are mixed with uniform label vectors. Empirically, smoothing has been shown to improve both predictive performance and model calibration. In this paper, we study whether label smoothing is also effective as a means of coping with label noise. While label smoothing apparently amplifies this problem --- being equivalent to injecting symmetric noise to the labels --- we show how it relates to a general family of loss-correction techniques from the label noise literature. Building on this connection, we show that label smoothing can be competitive with loss-correction techniques under label noise. Further, we show that when performing distillation under label noise, label smoothing of the teacher can be beneficial; this is in contrast to recent findings for noise-free problems, and sheds further light on settings where label smoothing is beneficial.</p> 
### 364.[Proving the Lottery Ticket Hypothesis: Pruning is All You Need](https://proceedings.icml.cc/book/3604.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2313-Paper.pdf)
  Eran Malach, Gilad Yehudai, Shai Shalev-Schwartz, Ohad Shamir [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2313-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2313-Supplemental.pdf)
> <p>The lottery ticket hypothesis (Frankle and Carbin, 2018), states that a randomly-initialized network contains a small subnetwork such that, when trained in isolation, can compete with the performance of the original network.      We prove an even stronger hypothesis (as was also conjectured in Ramanujan et al., 2019), showing that for every bounded distribution and every target network with bounded weights, a sufficiently over-parameterized neural network with random weights contains a subnetwork with roughly the same accuracy as the target network, without any further training. </p> 
### 365.[Linear bandits with Stochastic Delayed Feedback](https://proceedings.icml.cc/book/3605.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2321-Paper.pdf)
  Claire Vernade, Alexandra Carpentier, Tor Lattimore, Giovanni Zappella, Beyza Ermis, Michael Brueckner [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2321-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2321-Supplemental.pdf)
> <p>Stochastic linear bandits are a natural and well-studied model for structured exploration/exploitation problems and are widely used in applications such as on-line marketing and recommendation. One of the main challenges faced by practitioners hoping to apply existing algorithms is that usually the feedback is randomly delayed and delays are only partially observable. For example, while a purchase is usually observable some time after the display, the decision of not buying is never explicitly sent to the system. In other words, the learner only observes delayed positive events. We formalize this problem as a novel stochastic delayed linear bandit and propose OTFLinUCB and OTFLinTS, two computationally efficient algorithms able to integrate new information as it becomes available and to deal with the permanently censored feedback. We prove optimal O(d\sqrt{T}) bounds on the regret of the first algorithm and study the dependency on delay-dependent parameters. Our model, assumptions and results are validated by experiments on simulated and real data.</p> 
### 366.[Time Series Deconfounder: Estimating Treatment Effects over Time in the Presence of Hidden Confounders](https://proceedings.icml.cc/book/3606.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2331-Paper.pdf)
  Ioana Bica, Ahmed Alaa, Mihaela van der Schaar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2331-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2331-Supplemental.pdf)
> <p>The estimation of treatment effects is a pervasive problem in medicine. Existing methods for estimating treatment effects from longitudinal observational data assume that there are no hidden confounders. This assumption is not testable in practice and, if it does not hold, leads to biased estimates. In this paper, we develop the Time Series Deconfounder, a method that leverages the assignment of multiple treatments over time to enable the estimation of treatment effects in the presence of multi-cause hidden confounders. The Time Series Deconfounder uses a novel recurrent neural network architecture with multitask output to build a factor model over time and infer substitute confounders that render the assigned treatments conditionally independent.  Then it performs causal inference using the substitute confounders. We provide a theoretical analysis for obtaining unbiased causal effects of time-varying exposures using the Time Series Deconfounder. Using both simulations and real data to show the effectiveness of our method in deconfounding the estimation of treatment responses in longitudinal data. </p> 
### 367.[Negative Sampling in Semi-Supervised learning](https://proceedings.icml.cc/book/3607.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2333-Paper.pdf)
  John Chen, Vatsal Shah, Anastasios Kyrillidis [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2333-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2333-Supplemental.pdf)
> <p>We introduce Negative Sampling in Semi-Supervised Learning (NS^3L), a simple, fast, easy to tune algorithm for semi-supervised learning (SSL). NS^3L is motivated by the success of negative sampling/contrastive estimation. We demonstrate that adding the NS^3L loss to state-of-the-art SSL algorithms, such as the Virtual Adversarial Training (VAT), significantly improves upon vanilla VAT and its variant, VAT with Entropy Minimization. By adding the NS^3L loss to MixMatch, the current state-of-the-art approach on semi-supervised tasks, we observe significant improvements over vanilla MixMatch. We conduct extensive experiments on the CIFAR10, CIFAR100, SVHN and STL10 benchmark datasets. Finally, we perform an ablation study for NS3L regarding its hyperparameter tuning.</p> 
### 368.[Adaptive Sketching for Fast and Convergent Canonical Polyadic Decomposition](https://proceedings.icml.cc/book/3608.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2334-Paper.pdf)
  Alex Gittens, Kareem Aggour, Bülent Yener [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2334-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2334-Supplemental.pdf)
> <p>This work considers the canonical polyadic decomposition (CPD) of tensors using proximally regularized sketched alternating least squares algorithms. First, it establishes a sublinear rate of convergence for proximally regularized sketched CPD algorithms under two natural conditions that are known to be satisfied by many popular forms of sketching. Second, it demonstrates that the iterative nature of CPD algorithms can be exploited algorithmically to choose more performant sketching rates. This is accomplished by introducing CPD-MWU, a proximally-regularized sketched alternating least squares algorithm that adaptively selects the sketching rate at each iteration. On both synthetic and real data we observe that for noisy tensors CPD-MWU produces decompositions of comparable accuracy to the standard CPD decomposition in less time, often half the time; for ill-conditioned tensors, given the same time budget, CPD-MWU produces decompositions with an order-of-magnitude lower relative error. For a representative real- world dataset CPD-MWU produces residual errors on average 20% lower than CPRAND-MIX and 44% lower than SPALS, two recent sketched CPD algorithms.</p> 
### 369.[Private Counting from Anonymous Messages: Near-Optimal Accuracy with Vanishing Communication Overhead](https://proceedings.icml.cc/book/3609.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2341-Paper.pdf)
  Badih Ghazi, Ravi Kumar, Pasin Manurangsi, Rasmus Pagh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2341-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2341-Supplemental.pdf)
> <p>Differential privacy (DP) is a formal notion for quantifying the privacy loss of algorithms.  Algorithms in the central model of DP achieve high accuracy but make the strongest trust assumptions whereas those in the local DP model make the weakest trust assumptions but incur substantial accuracy loss. The shuffled DP model [Bittau et al 2017, Erlingsson et al 2019, Cheu et al 19] has recently emerged as a feasible middle ground between the central and local models, providing stronger trust assumptions than the former while promising higher accuracies than the latter.</p>  <p>In this paper, we obtain practical communication-efficient algorithms in the shuffled DP model for two basic aggregation primitives: 1) binary summation, and 2) histograms over a moderate number of buckets.  Our algorithms achieve accuracy that is arbitrarily close to that of central DP algorithms with an expected communication per user essentially matching what is needed without any privacy constraints!</p>  <p>We demonstrate the practicality of our algorithms by experimentally evaluating them and comparing their performance to several widely-used protocols such as Randomized Response [Warner 1965] and RAPPOR [Erlingsson et al. 2014].</p> 
### 370.[On the Generalization Benefit of Noise in Stochastic Gradient Descent](https://proceedings.icml.cc/book/3610.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2343-Paper.pdf)
  Samuel Smith, Erich Elsen, Soham De [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2343-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2343-Supplemental.pdf)
> <p>It has long been argued that minibatch stochastic gradient descent can generalize better than large batch gradient descent in deep neural networks. However recent papers have questioned this claim, arguing that this effect is simply a consequence of suboptimal hyperparameter tuning or insufficient compute budgets when the batch size is large. In this paper, we perform carefully designed experiments and rigorous hyperparameter sweeps on a range of popular models, which verify that small or moderately large batch sizes can substantially outperform very large batches on the test set. This occurs even when both models are trained for the same number of iterations and large batches achieve smaller training losses. Our results confirm that the noise in stochastic gradients can enhance generalization. We study how the optimal learning rate schedule changes as the epoch budget grows, and we provide a theoretical account of our observations based on the stochastic differential equation perspective of SGD dynamics.</p> 
### 371.[Momentum-Based Policy Gradient Methods](https://proceedings.icml.cc/book/3611.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2345-Paper.pdf)
  Feihu Huang, Shangqian Gao, Jian Pei, Heng Huang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2345-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2345-Supplemental.zip)
> Policy gradient methods are a class of powerful algorithms in reinforcement learning (RL). More recently, some variance reduced policy gradient methods have been developed to improve sample efficiency and obtain a near-optimal sample complexity $O(\epsilon^{-3})$ for finding an $\epsilon$-stationary point of non-concave performance function in model-free RL. However, the practical performances of these variance reduced policy gradient methods are not consistent with their near-optimal sample complexity, because these methods require large batches and strict learning rates to achieve this optimal complexity. In the paper, thus, we propose a class of efficient momentum-based policy gradient methods, which use adaptive learning rates and do not require large batches. Specifically, we propose a fast important-sampling momentum-based policy gradient (IS-MBPG) method by using the important sampling technique. Meanwhile, we also propose a fast hessian-aided momentum-based policy gradient (HA-MBPG) method via using the semi-hessian information. In theoretical analysis, we prove that our algorithms also have the sample complexity $O(\epsilon^{-3})$, as the existing best policy gradient methods. In the experiments, we use some benchmark tasks to demonstrate the effectiveness of algorithms.
### 372.[Knowing The What But Not The Where in Bayesian Optimization](https://proceedings.icml.cc/book/3612.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2351-Paper.pdf)
  Vu Nguyen, Michael Osborne [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2351-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2351-Supplemental.pdf)
> <p>Bayesian optimization has demonstrated impressive success in finding the optimum input x∗ and output f ∗ = f(x∗) = max f(x) of a black-box function f . In some applications, however, the optimum output is known in advance and the goal is to find the corresponding optimum input. Existing work in Bayesian optimization (BO) has not effectively exploited the knowledge of f ∗ for optimization. In this paper, we consider a new setting in BO in which the knowledge of the optimum output is available. Our goal is to exploit the knowledge about f ∗ to search for the input x∗ efficiently. To achieve this goal, we first transform the Gaussian process surrogate using the information about the optimum output. Then, we propose two acquisition functions, called confidence bound minimization and expected regret minimization, which exploit the knowledge about the optimum output to identify the optimum input more efficient. We show that our approaches work intuitively and quantitatively better performance against standard BO methods. We demonstrate real applications in tuning a deep reinforcement learning algorithm on the CartPole problem and XGBoost on Skin Segmentation dataset in which the optimum values are publicly available.</p> 
### 373.[Robust Bayesian Classification Using An Optimistic Score Ratio](https://proceedings.icml.cc/book/3613.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2354-Paper.pdf)
  Viet Anh Nguyen, Nian Si, Jose Blanchet [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2354-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2354-Supplemental.pdf)
> <p>We consider the optimistic score ratio for robust  Bayesian classification when the class-conditional distribution of the features is not perfectly known. The optimistic score searches for the distribution that is most plausible to explain the observed test sample among all distributions belonging to the class-dependent ambiguity set which is prescribed using a moment-based divergence. We show that the classification approach using optimistic score ratio is conceptually attractive, delivers rigorous statistical guarantees and is computationally tractable. We showcase the power of the proposed optimistic score ratio classifier on both synthetic and empirical data.</p> 
### 374.[Boosted Histogram Transform for Regression](https://proceedings.icml.cc/book/3614.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2360-Paper.pdf)
  Yuchao Cai, Hanyuan Hang, Hanfang Yang, Zhouchen Lin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2360-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2360-Supplemental.zip)
> In this paper, we propose a boosting algorithm for regression problems called \textit{boosted histogram transform for regression} (BHTR) based on histogram transforms composed of random rotations, stretchings, and translations. From the theoretical perspective, we first prove fast convergence rates for BHTR under the assumption that the target function lies in the spaces $C^{0,\alpha}$. Moreover, if the target function resides in the subspace $C^{1,\alpha}$, by establishing the upper bound of the convergence rate for the boosted regressor, i.e. BHTR, and the lower bound for base regressors, i.e. histogram transform regressors (HTR), we manage to explain the benefits of the boosting procedure. In the experiments, compared with other state-of-the-art algorithms such as gradient boosted regression tree (GBRT), Breiman&#x27;s forest, and kernel-based methods, our BHTR algorithm shows promising performance on both synthetic and real datasets.
### 375.[Stochastic bandits with arm-dependent delays](https://proceedings.icml.cc/book/3615.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2361-Paper.pdf)
  Anne Gael Manegueu, Claire Vernade, Alexandra Carpentier, Michal Valko [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2361-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2361-Supplemental.zip)
> <p>Significant work has been recently dedicated to the stochastic delayed bandit setting because of its relevance in applications. The applicability of existing algorithms is however restricted by the fact that strong assumptions are often made on the delay distributions, such as full observability, restrictive shape constraints, or uniformity over arms. In this work, we weaken them significantly and only assume that there is a bound on the tail of the delay. In particular, we cover the important case where the delay distributions vary across arms, and the case where the delays are heavy-tailed. Addressing these difficulties, we propose a simple but efficient UCB-based algorithm called the PATIENTBANDITS. We provide both problem-dependent and problem-independent bounds on the regret as well as performance lower bounds.</p> 
### 376.[Projective Preferential Bayesian Optimization](https://proceedings.icml.cc/book/3616.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2377-Paper.pdf)
  Petrus Mikkola, Milica Todorović, Jari Järvi, Patrick Rinke, Samuel Kaski [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2377-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2377-Supplemental.pdf)
> <p>Bayesian optimization is an effective method for finding extrema of a black-box function. We propose a new type of Bayesian optimization for learning user preferences in high-dimensional spaces. The central assumption is that the underlying objective function cannot be evaluated directly, but instead a minimizer along a projection can be queried, which we call a projective preferential query. The form of the query allows for feedback that is natural for a human to give, and which enables interaction. This is demonstrated in a user experiment in which the user feedback comes in the form of optimal position and orientation of a molecule adsorbing to a surface. We demonstrate that our framework is able to find a global minimum of a high-dimensional black-box function, which is an infeasible task for existing preferential Bayesian optimization frameworks that are based on pairwise comparisons.</p> 
### 377.[On Relativistic f-Divergences](https://proceedings.icml.cc/book/3617.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2391-Paper.pdf)
  Alexia Jolicoeur-Martineau [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2391-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2391-Supplemental.pdf)
> We take a more rigorous look at Relativistic Generative Adversarial Networks (RGANs) and prove that the objective function of the discriminator is a statistical divergence for any concave function $f$ with minimal properties ($f(0)=0$, $f&#x27;(0) \neq 0$, $\sup_x f(x)&gt;0$). We devise additional variants of relativistic $f$-divergences. We show that the Wasserstein distance is weaker than $f$-divergences which are weaker than relativistic $f$-divergences. Given the good performance of RGANs, this suggests that Wasserstein GAN does not performs well primarily because of the weak metric, but rather because of regularization and the use of a relativistic discriminator. We introduce the minimum-variance unbiased estimator (MVUE) for Relativistic paired GANs (RpGANs; originally called RGANs which could bring confusion) and show that it does not perform better. We show that the estimator of Relativistic average GANs (RaGANs) is asymptotically unbiased and that the finite-sample bias is small; removing this bias does not improve performance.
### 378.[A Flexible Framework for Nonparametric Graphical Modeling that Accommodates Machine Learning](https://proceedings.icml.cc/book/3618.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2397-Paper.pdf)
  Yunhua Xiang, Noah Simon [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2397-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2397-Supplemental.pdf)
> <p>Graphical modeling has been broadly useful for exploring the dependence structure among features in a dataset. However, the strength of graphical modeling hinges on our ability to encode and estimate conditional dependencies. In particular, commonly used measures such as partial correlation are only meaningful under strongly parametric (in this case, multivariate Gaussian) assumptions. These assumptions are unverifiable, and there is often little reason to believe they hold in practice. In this paper, we instead consider 3 non-parametric measures of conditional dependence. These measures are meaningful without structural assumptions on the multivariate distribution of the data. In addition, we show that for 2 of these measures there are simple, strong plug-in estimators that require only the estimation of a conditional mean. These plug-in estimators (1) are asymptotically linear and non-parametrically efficient, (2) allow incorporation of flexible machine learning techniques for conditional mean estimation, and (3) enable the construction of valid Wald-type confidence intervals. In addition, by leveraging the influence function of these estimators, one can obtain intervals with simultaneous coverage guarantees for all pairs of features.</p> 
### 379.[The Natural Lottery Ticket Winner: Reinforcement Learning with Ordinary Neural Circuits](https://proceedings.icml.cc/book/3619.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2398-Paper.pdf)
  Ramin Hasani, Mathias Lechner, Alexander Amini, Daniela Rus, Radu Grosu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2398-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2398-Supplemental.pdf)
> <p>We propose a neural information processing system which is obtained by re-purposing the function of a biological neural circuit model to govern simulated and real-world control tasks. Inspired by the structure of the nervous system of the soil-worm, C. elegans, we introduce ordinary neural circuits (ONCs), defined as the model of biological neural circuits reparameterized for the control of alternative tasks. We first demonstrate that ONCs realize networks with higher maximum flow compared to arbitrary wired networks. We then learn instances of ONCs to control a series of robotic tasks, including the autonomous parking of a real-world rover robot. For reconfiguration of the purpose of the neural circuit, we adopt a search-based optimization algorithm. Ordinary neural circuits perform on par and, in some cases, significantly surpass the performance of contemporary deep learning models. ONC networks are compact, 77% sparser than their counterpart neural controllers, and their neural dynamics are fully interpretable at the cell-level.</p> 
### 380.[Schatten Norms in Matrix Streams: Hello Sparsity, Goodbye Dimension](https://proceedings.icml.cc/book/3620.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2399-Paper.pdf)
  Aditya Krishnan, Roi Sinoff, Robert Krauthgamer, Vladimir Braverman [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2399-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2399-Supplemental.pdf)
> <p>Spectral functions of large matrices contains important structural information about the underlying data, and is thus becoming increasingly important. Many times, large matrices representing real-world data are sparse or doubly sparse (i.e., sparse in both rows and columns), and are accessed as a stream of updates, typically organized in row-order. In this setting, where space (memory) is the limiting resource, all known algorithms require space that is polynomial in the dimension of the matrix, even for sparse matrices. We address this challenge by providing the first algorithms whose space requirement is independent of the matrix dimension, assuming the matrix is doubly-sparse and presented in row-order. Our algorithms approximate the Schatten p-norms, which we use in turn to approximate other spectral functions, such as logarithm of the determinant, trace of matrix inverse, and Estrada index. We validate these theoretical performance bounds by numerical experiments on real-world matrices representing social networks. We further prove that multiple passes are unavoidable in this setting, and show extensions of our primary technique, including a trade-off between space requirements and number of passes.</p> 
### 381.[Control Frequency Adaptation via Action Persistence in Batch Reinforcement Learning](https://proceedings.icml.cc/book/3621.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2405-Paper.pdf)
  Alberto Maria Metelli, Flavio Mazzolini, Lorenzo Bisi, Luca Sabbioni, Marcello Restelli [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2405-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2405-Supplemental.pdf)
> <p>The choice of the control frequency of a system has a relevant impact on the ability of \emph{reinforcement learning algorithms} to learn a highly performing policy. In this paper, we introduce the notion of \emph{action persistence} that consists in the repetition of an action for a fixed number of decision steps, having the effect of modifying the control frequency. We start analyzing how action persistence affects the performance of the optimal policy, and then we present a novel algorithm, \emph{Persistent Fitted Q-Iteration} (PFQI), that extends FQI, with the goal of learning the optimal value function at a given persistence. After having provided a theoretical study of PFQI and a heuristic approach to identify the optimal persistence, we present an experimental campaign on benchmark domains to show the advantages of action persistence and proving the effectiveness of our persistence selection method.</p> 
### 382.[Minimax Rate for Learning From Pairwise Comparisons in the BTL Model](https://proceedings.icml.cc/book/3622.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2406-Paper.pdf)
  Julien Hendrickx, Alex Olshevsky, Venkatesh Saligrama [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2406-Metadata.json)
> <p>We consider the problem of learning the qualities w<em>1, ... , w</em>n of a collection of items by performing noisy comparisons among them. We assume there is a fixed ``comparison graph'' and every neighboring pair of items is compared k times. We will study the popular Bradley-Terry-Luce model,  where the probability that item i wins a  comparison against j equals w<em>i/(w</em>i + w<em>j).  We are interested in how the expected error in estimating the vector w = (w</em>1, ... , w_n) behaves in the regime when the number of comparisons k is large.</p>  <p>Our contribution is the determination of the minimax rate up to a constant factor. We   show that this rate is achieved by a simple algorithm based on weighted least squares, with weights determined from the empirical outcomes of the comparisons. This algorithm can be implemented  in nearly linear time in the total number of comparisons.</p> 
### 383.[Interferometric Graph Transform: a Deep Unsupervised Graph Representation](https://proceedings.icml.cc/book/3623.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2411-Paper.pdf)
  Edouard Oyallon [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2411-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2411-Supplemental.pdf)
> <p>We propose the Interferometric Graph Transform (IGT), which is a new class of deep unsupervised graph convolutional neural network for building graph representations. Our first contribution is to propose a generic, complex-valued spectral graph architecture obtained from a generalization of the Euclidean Fourier transform. We show that our learned representation consists of both discriminative and invariant features, thanks to a novel greedy concave objective. From our experiments, we conclude that our learning procedure exploits the topology of the spectral domain, which is normally a flaw of spectral methods, and in particular our method can recover an analytic operator for vision tasks. We test our algorithm on various and challenging tasks such as image classification (MNIST, CIFAR-10), community detection (Authorship, Facebook graph) and action recognition from 3D skeletons videos (SBU, NTU), exhibiting a new state-of-the-art in spectral graph unsupervised settings.</p> 
### 384.[Stochastic Differential Equations with Variational Wishart Diffusions](https://proceedings.icml.cc/book/3624.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2419-Paper.pdf)
  Martin Jørgensen, Marc Deisenroth, Hugh Salimbeni [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2419-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2419-Supplemental.pdf)
> <p>We present a Bayesian non-parametric way of inferring stochastic differential equations for both regression tasks and continuous-time dynamical modelling. The work has high emphasis on the stochastic part of the differential equation, also known as the diffusion, and modelling it by means of Wishart processes. Further, we present a semiparametric approach that allows the framework to scale to high dimensions. This successfully leads us onto how to model both latent and autoregressive temporal systems with conditional heteroskedastic noise. We provide experimental evidence that modelling diffusion often improves performance and that this randomness in the differential equation can be essential to avoid overfitting.</p> 
### 385.[What Can Learned Intrinsic Rewards Capture?](https://proceedings.icml.cc/book/3625.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2425-Paper.pdf)
  Zeyu Zheng, Junhyuk Oh, Matteo Hessel, Zhongwen Xu, Manuel Kroiss, Hado van Hasselt, David Silver, Satinder Singh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2425-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2425-Supplemental.pdf)
> <p>The objective of a reinforcement learning agent is to behave so as to maximise the sum of a suitable scalar function of state: the reward. These rewards are typically given and immutable. In this paper, we instead consider the proposition that the reward function itself can be a good locus of learned knowledge. To investigate this, we propose a scalable meta-gradient framework for learning useful intrinsic reward functions across multiple lifetimes of experience. Through several proof-of-concept experiments, we show that it is feasible to learn and capture knowledge about long-term exploration and exploitation into a reward function. Furthermore, we show that unlike policy transfer methods that capture <code>how'' the agent should behave, the learned reward functions can generalise to other kinds of agents and to changes in the dynamics of the environment by capturing</code>what'' the agent should strive to do.</p> 
### 386.[Random extrapolation for primal-dual coordinate descent](https://proceedings.icml.cc/book/3626.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2433-Paper.pdf)
  Ahmet Alacaoglu, Olivier Fercoq, Volkan Cevher [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2433-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2433-Supplemental.zip)
> <p>We introduce a randomly extrapolated primal-dual coordinate descent method that automatically adapts to the sparsity of the data matrix as well as the favorable structures of the objective function in optimization. Our method can update only a subset of primal and dual variables with sparse data, and it can provably use large step sizes with dense data, retaining the benefits of the specific methods designed for each case. In addition to key adaptivity to the sparsity, our method attains fast convergence guarantees in favorable cases \textit{without any modifications}. In particular, we prove linear convergence under metric subregularity, which applies to strongly convex-strongly concave problems, linear programs and piecewise linear quadratic functions. We also show almost sure convergence of the sequence and optimal sublinear convergence rates for the primal-dual gap and objective values in the worst case. Numerical evidence demonstrates the state-of-the-art empirical performance of our method in sparse and dense settings, matching and improving the existing methods over different applications with real data.</p> 
### 387.[Reinforcement Learning with Differential Privacy](https://proceedings.icml.cc/book/3627.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2453-Paper.pdf)
  Giuseppe Vietri, Borja de Balle Pigem, Steven Wu, Akshay Krishnamurthy [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2453-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2453-Supplemental.pdf)
> <p>Motivated by high-stakes decision-making domains like personalized medicine where user information is inherently sensitive, we design privacy preserving exploration policies for episodic reinforcement learning (RL). We first provide a meaningful privacy formulation using the notion of joint differential privacy (JDP)--a strong variant of differential privacy for settings where each user receives their own sets of output (e.g., policy recommendations). We then develop a private optimism-based learning algorithm that simultaneously achieves strong PAC and regret bounds, and enjoys a JDP guarantee. Our algorithm only pays for a moderate privacy cost on exploration: in comparison to the non-private bounds, the privacy parameter only appears in lower-order terms.  Finally, we present lower bounds on sample complexity and regret for reinforcement learning subject to JDP.</p> 
### 388.[Median Matrix Completion: from Embarrassment to Optimality](https://proceedings.icml.cc/book/3628.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2463-Paper.pdf)
  Weidong Liu, Xiaojun Mao, Raymond K. W. Wong [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2463-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2463-Supplemental.pdf)
> <p>In this paper, we consider matrix completion with absolute deviation loss and obtain an estimator of the median matrix. Despite several appealing properties of median, the non-smooth absolute deviation loss leads to computational challenge for large-scale data sets which are increasingly common among matrix completion problems. A simple solution to large-scale problems is parallel computing. However, embarrassingly parallel fashion often leads to inefficient estimators. Based on the idea of pseudo data, we propose a novel refinement step, which turns such inefficient estimators into a rate (near-)optimal matrix completion procedure. The refined estimator is an approximation of a regularized least median estimator, and therefore not an ordinary regularized empirical risk estimator. This leads to a non-standard analysis of asymptotic behaviors. Empirical results are also provided to confirm the effectiveness of the proposed method.</p> 
### 389.[Improved Optimistic Algorithms for Logistic Bandits](https://proceedings.icml.cc/book/3629.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2468-Paper.pdf)
  Louis Faury, Marc Abeille, Clément Calauzènes, Olivier Fercoq [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2468-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2468-Supplemental.zip)
> The generalized linear bandit framework has attracted a lot of attention in recent years by extending the well-understood linear setting and allowing to model richer reward structures. It notably covers the logistic model, widely used when rewards are binary. For logistic bandits, the frequentist regret guarantees of existing algorithms are $\tilde{\mathcal{O}}(\kappa \sqrt{T})$, where $\kappa$ is a problem-dependent constant. Unfortunately, $\kappa$ can be arbitrarily large as it scales exponentially with the size of the decision set. This may lead to significantly loose regret bounds and poor empirical performance. In this work, we study the logistic bandit with a focus on the prohibitive dependencies introduced by $\kappa$. We propose a new optimistic algorithm based on a finer examination of the non-linearities of the reward function. We show that it enjoys a $\tilde{\mathcal{O}}(\sqrt{T})$ regret with no dependency in $\kappa$, but for a second order term. Our analysis is based on a new tail-inequality for self-normalized martingales, of independent interest.
### 390.[Learning to Rank Learning Curves](https://proceedings.icml.cc/book/3630.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2472-Paper.pdf)
  Martin Wistuba, Tejaswini Pedapati [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2472-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2472-Supplemental.pdf)
> <p>Many automated machine learning methods, such as those for hyperparameter and neural architecture optimization, are computationally expensive because they involve training many different model configurations. In this work, we present a new method that saves computational budget by terminating poor configurations early on in the training. In contrast to existing methods, we consider this task as a ranking and transfer learning problem. We qualitatively show that by optimizing a pairwise ranking loss and leveraging learning curves from other data sets, our model is able to effectively rank learning curves without having to observe many or very long learning curves. We further demonstrate that our method can be used to accelerate a neural architecture search by a factor of up to 100 without a significant performance degradation of the discovered architecture. In further experiments we analyze the quality of ranking, the influence of different model components as well as the predictive behavior of the model.</p> 
### 391.[Model Fusion with Kullback--Leibler Divergence](https://proceedings.icml.cc/book/3631.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2474-Paper.pdf)
  Sebastian Claici, Mikhail Yurochkin, Soumya Ghosh, Justin Solomon [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2474-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2474-Supplemental.pdf)
> <p>We propose a method to fuse posterior distributions learned from heterogeneous datasets. Our algorithm relies on a mean field assumption for both the fused model and the individual dataset posteriors, and proceeds in a simple assign-and-average approach. The components of the dataset posteriors are assigned to the proposed global model components by solving a regularized variant of the assignment problem. The global components are then updated based on these assignments by their mean under a KL divergence. For exponential family variational distributions, our formulation leads to an efficient non-parametric algorithm for computing the fused model. Our algorithm is easy to describe and implement, efficient, and performs competitive with state-of-the-art when tested on motion capture analysis, topic modeling, and federated learning of Bayesian neural networks.</p> 
### 392.[Randomization matters How to defend against strong adversarial attacks](https://proceedings.icml.cc/book/3632.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2479-Paper.pdf)
  Rafael Pinot, Raphael Ettedgui, Geovani Rizk, Yann Chevaleyre, Jamal Atif [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2479-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2479-Supplemental.pdf)
> <p>\emph{Is there a classifier that ensures optimal robustness against all adversarial attacks?} This paper answers this question by adopting a game-theoretic point of view. We show that adversarial attacks and defenses form an \emph{infinite} zero-sum game where classical results (e.g. Nash or Sion theorems) do not apply. We demonstrate the non-existence of a Nash equilibrium in our game when the classifier and the adversary are both deterministic, hence giving a negative answer to the above question in the deterministic regime. Nonetheless, the question remains open in the randomized regime. We tackle this problem by showing that, under mild conditions on the dataset distribution, any deterministic classifier can be outperformed by a randomized one. This gives arguments for using randomization, and leads us to a new algorithm for building randomized classifiers that are robust to \emph{strong} adversarial attacks. Empirical results validate our theoretical analysis, and show that our defense method considerably outperforms Adversarial Training against state-of-the-art attacks.</p> 
### 393.[Evolutionary Topology Search for Tensor Network Decomposition](https://proceedings.icml.cc/book/3633.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2484-Paper.pdf)
  Chao Li, Zhun Sun [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2484-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2484-Supplemental.zip)
> <p>Tensor network (TN) decomposition is a promising framework to represent extremely high-dimensional problems with few parameters. However, it is challenging to search the (near-)optimal topological structure for TN decomposition, since the number of possible solutions exponentially grows with increasing the order of tensor. In this paper, we claim that this issue can be practically tackled by evolutionary algorithms in an efficient manner. We encode the complex topological structures into binary string, and develop a simple yet efficient genetic-based algorithm (GA) to search the optimal topology on Hamming space. The experimental results by both synthetic and real-world data demonstrate that our method can efficiently discovers the groundtruth topology or even better structures with few number of generations, and significantly boost the representational power of TN decomposition compared with well-known tensor-train (TT) or tensor-ring (TR) models.</p> 
### 394.[Quadratically Regularized Subgradient Methods for Weakly Convex Optimization with Weakly Convex Constraints](https://proceedings.icml.cc/book/3634.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2489-Paper.pdf)
  Runchao Ma, Qihang Lin, Tianbao Yang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2489-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2489-Supplemental.pdf)
> <p>Optimization models with non-convex constraints arise in many tasks in machine learning, e.g., learning with fairness constraints or Neyman-Pearson classification with non-convex loss. Although many efficient methods have been developed with theoretical convergence guarantees for non-convex unconstrained problems, it remains a challenge to design provably efficient algorithms for problems with non-convex functional constraints. This paper proposes a class of subgradient methods for constrained optimization where the objective function and the constraint functions are weakly convex and nonsmooth. Our methods solve a sequence of strongly convex subproblems, where a quadratic regularization term is added to both the objective function and each constraint function. Each subproblem can be solved by various algorithms for strongly convex optimization. Under a uniform Slater’s condition, we establish the computation complexities of our methods for finding a nearly stationary point.</p> 
### 395.[Scalable and Efficient Comparison-based Search without Features](https://proceedings.icml.cc/book/3635.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2496-Paper.pdf)
  Daniyar Chumbalov, Lucas Maystre, Matthias Grossglauser [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2496-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2496-Supplemental.pdf)
> <p>We consider the problem of finding a target object t using pairwise comparisons, by asking an oracle questions of the form “Which object from the pair (i,j) is more similar to t?”. Objects live in a space of latent features, from which the oracle generates noisy answers. First, we consider the non-blind setting where these features are accessible. We propose a new Bayesian comparison-based search algorithm with noisy answers; it has low computational complexity yet is efficient in the number of queries. We provide theoretical guarantees, deriving the form of the optimal query and proving almost sure convergence to the target t. Second, we consider the blind setting, where the object features are hidden from the search algorithm. In this setting, we combine our search method and a new distributional triplet embedding algorithm into one scalable learning framework called Learn2Search. We show that the query complexity of our approach on two real-world datasets is on par with the non-blind setting, which is not achievable using any of the current state-of-the-art embedding methods. Finally, we demonstrate the efficacy of our framework by conducting a movie actors search experiment with real users.</p> 
### 396.[Error-Bounded Correction of Noisy Labels](https://proceedings.icml.cc/book/3636.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2506-Paper.pdf)
  Songzhu Zheng, Pengxiang Wu, Aman Goswami, Mayank Goswami, Dimitris Metaxas, Chao Chen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2506-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2506-Supplemental.pdf)
> <p>To collect large scale annotated data, it is inevitable to introduce label noise, i.e., incorrect class labels. A major challenge is to develop robust deep learning models that achieve high test performance despite training set label noise. We introduce a novel approach that directly cleans labels in order to train a high quality model. Our method leverages statistical principles to correct data labels and has a theoretical guarantee of the correctness. In particular, we use a likelihood ratio test to flip the labels of training data. We prove that the corrected labels are consistent with the true Bayesian optimal classifier with high probability. We incorporate our label correction algorithm into the training of deep neural networks and train models that achieve superior testing performance on multiple public datasets. </p> 
### 397.[Learning with Feature and Distribution Evolvable Streams](https://proceedings.icml.cc/book/3637.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2507-Paper.pdf)
  Zhen-Yu Zhang, Peng Zhao, Yuan Jiang, Zhi-Hua Zhou [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2507-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2507-Supplemental.pdf)
> <p>In many real-world applications, data are often collected in the form of a stream, and thus the feature space of streaming data can evolve over time. For example, in the environmental monitoring task, features can be dynamically vanished or augmented due to the existence of expired old sensors and deployed new sensors. Besides the feature space evolving, it is noteworthy that the data distribution often changes in streaming data. When both feature space and data distribution are evolvable, it is quite challenging to design algorithms with guarantees, particularly the theoretical understanding of generalization ability. To address this difficulty, we propose a novel discrepancy measure for evolving feature space and data distribution named the evolving discrepancy, based on which we provide the generalization error analysis. The theory motivates the design of a learning algorithm, which is further implemented by deep neural networks. We present empirical studies on synthetic data to verify the rationale of the proposed discrepancy measure. Extensive experiments on real-world tasks validate the effectiveness of our algorithm.</p> 
### 398.[On Unbalanced Optimal Transport: An Analysis of Sinkhorn Algorithm](https://proceedings.icml.cc/book/3638.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2508-Paper.pdf)
  Khiem Pham, Khang Le, Nhat Ho, Tung Pham, Hung Bui [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2508-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2508-Supplemental.pdf)
> We provide a computational complexity analysis for the Sinkhorn algorithm that solves the entropic regularized Unbalanced Optimal Transport (UOT) problem between two measures of possibly different masses with at most $n$ components.  We show that the complexity of the Sinkhorn algorithm for finding an $\varepsilon$-approximate solution to the UOT problem is of order  $\widetilde{\mathcal{O}}(n^2/ \varepsilon)$, which is near-linear time. To the best of our knowledge, this complexity is better than the complexity of the Sinkhorn algorithm for solving the Optimal Transport (OT) problem, which is of order $\widetilde{\mathcal{O}}(n^2/\varepsilon^2)$. Our proof technique is based on the geometric convergence of the Sinkhorn updates to the optimal dual solution of the entropic regularized UOT problem and some properties of the primal solution. It is also different from the proof for the complexity of the Sinkhorn algorithm for approximating the OT problem since the UOT solution does not have to meet the marginal constraints.
### 399.[Learning Optimal Tree Models under Beam Search](https://proceedings.icml.cc/book/3639.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2514-Paper.pdf)
  Jingwei Zhuo, Ziru Xu, Wei Dai, Han Zhu, HAN LI, Jian Xu, Kun Gai [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2514-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2514-Supplemental.zip)
> <p>Retrieving relevant targets from an extremely large target set under computation and time limits is a common challenge for information retrieval and recommendation systems. Tree models, which formulate targets as leaves in a tree hierarchy and associate tree nodes with trainable node-wise scorers, have attracted a lot of interests in tackling this challenge due to its logarithmic computational complexity in both training and testing. Tree-based deep models (TDMs) and probabilistic label trees (PLTs) are two kinds of representative tree models. Though achieving many practical successes, existing tree models still suffer from training-testing discrepancy: in testing they usually leverage beam search to retrieve targets from the tree, which is not considered in the training loss function. As a result, even the optimal node-wise scorers with respect to the training loss can lead to suboptimal retrieval results when they are used in testing to retrieve targets via beam search.  In this paper, we take a first step towards understanding the discrepancy by developing the definition of Bayes optimality and calibration under beam search as general analyzing tools, and prove that neither TDMs nor PLTs are Bayes optimal under beam search. To eliminating the discrepancy, we propose a novel training loss function with a beam search based subsampling method for training Bayes optimal tree models under beam search. Experiments on both synthetic and real data verify our analysis and demonstrate the superiority of our methods.</p> 
### 400.[Estimating the Number and Effect Sizes of Non-null Hypotheses](https://proceedings.icml.cc/book/3640.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2515-Paper.pdf)
  Jennifer Brennan, Ramya Korlakai Vinayak, Kevin Jamieson [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2515-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2515-Supplemental.pdf)
> <p>We study the problem of estimating the distribution of effect sizes (the mean of the test statistic under the alternate hypothesis) in a multiple testing setting. Knowing this distribution allows us to calculate the power (type II error) of any experimental design. We show that it is possible to estimate this distribution using an inexpensive pilot experiment, which takes significantly fewer samples than would be required by an experiment that identified the discoveries. Our estimator can be used to guarantee the number of discoveries that will be made using a given experimental design in a future experiment. We prove that this simple and computationally efficient estimator enjoys a number of favorable theoretical properties, and demonstrate its effectiveness on data from a gene knockout experiment on influenza inhibition in Drosophila.</p> 
### 401.[Estimating Model Uncertainty of Neural Network in Sparse Information Form](https://proceedings.icml.cc/book/3641.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2525-Paper.pdf)
  Jongseok Lee, Matthias Humt, Jianxiang Feng, Rudolph Triebel [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2525-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2525-Supplemental.pdf)
> <p>We present a sparse representation of model uncertainty for Deep Neural Networks (DNNs) where the parameter posterior is approximated with an inverse formulation of the Multivariate Normal Distribution (MND), also known as the information form. The key insight of our work is that the information matrix, i.e. the inverse of the covariance matrix tends to be sparse in its spectrum. Therefore, dimensionality reduction techniques such as low rank approximations can be effectively exploited. To achieve this, we develop a novel sparsification algorithm and derive a cost-effective analytical sampler. As a result, we show that the information form of MND can be scalably applied to represent model uncertainty in MND. Our exhaustive theoretical analysis and empirical evaluations on various benchmarks show the competitiveness of our approach over the current methods.</p> 
### 402.[Double-Loop Unadjusted Langevin Algorithm](https://proceedings.icml.cc/book/3642.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2531-Paper.pdf)
  Paul Rolland, Armin Eftekhari, Ali Kavis, Volkan Cevher [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2531-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2531-Supplemental.pdf)
> A well-known first-order method for sampling from  log-concave probability distributions is the Unadjusted Langevin Algorithm (ULA). This work  proposes a new annealing step-size schedule for ULA, which allows to prove new convergence guarantees for sampling from a smooth log-concave distribution, which are not covered by existing state-of-the-art convergence guarantees. To establish this result, we derive a new theoretical bound that relates the Wasserstein distance to total variation distance between any two log-concave distributions that complements the reach of Talagrand $T_2$ inequality. Moreover, applying this new step size schedule to an existing constrained sampling algorithm, we show state-of-the-art convergence rates for sampling from a constrained log-concave distribution, as well as improved dimension dependence.  
### 403.[Growing Action Spaces](https://proceedings.icml.cc/book/3643.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2537-Paper.pdf)
  Gregory Farquhar, Laura  Gustafson, Zeming Lin, Shimon Whiteson, Nicolas Usunier, Gabriel Synnaeve [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2537-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2537-Supplemental.pdf)
> <p>In complex tasks, such as those with large combinatorial action spaces, random exploration may be too inefficient to achieve meaningful learning progress. In this work, we use a curriculum of progressively growing action spaces to accelerate learning. We assume the environment is out of our control, but that the agent may set an internal curriculum by initially restricting its action space. Our approach uses off-policy reinforcement learning to estimate optimal value functions for multiple action spaces simultaneously and efficiently transfers data,  value estimates, and state representations from restricted action spaces to the full task. We show the efficacy of our approach in proof-of-concept control tasks and on challenging large-scale StarCraft micromanagement tasks with large, multi-agent action spaces.</p> 
### 404.[Analytic Marching: An Analytic Meshing Solution from Deep Implicit Surface Networks](https://proceedings.icml.cc/book/3644.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2541-Paper.pdf)
  Jiabao Lei, Kui Jia [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2541-Metadata.json)
> <p>This paper studies a problem of learning surface mesh via implicit functions in an emerging field of deep learning surface reconstruction, where implicit functions are popularly implemented as multi-layer perceptrons (MLPs) with rectified linear units (ReLU). To achieve meshing from the learned implicit functions, existing methods adopt the de-facto standard algorithm of marching cubes; while promising, they suffer from loss of precision learned in the MLPs, due to the discretization nature of marching cubes. Motivated by the knowledge that a ReLU based MLP partitions its input space into a number of linear regions, we identify from these regions analytic cells and faces that are associated with zero-level isosurface of the implicit function, and characterize the conditions under which the identified faces are guaranteed to connect and form a closed, piecewise planar surface. We propose a naturally parallelizable algorithm of analytic marching to exactly recover the mesh captured by a learned MLP. Experiments on deep learning mesh reconstruction verify the advantages of our algorithm over existing ones.</p> 
### 405.[Anderson Acceleration of Proximal Gradient Methods](https://proceedings.icml.cc/book/3645.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2548-Paper.pdf)
  Vien Mai, Mikael Johansson [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2548-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2548-Supplemental.pdf)
> <p>Anderson acceleration is a well-established and simple technique for speeding up fixed-point computations with countless applications. This work introduces novel methods for adapting Anderson acceleration to (non-smooth and constrained) proximal gradient algorithms. Under some technical conditions, we extend the existing local convergence results of Anderson acceleration for smooth fixed-point mappings to the proposed scheme. We also prove analytically that it is not, in general, possible to guarantee global convergence of native Anderson acceleration. We therefore propose a simple scheme for stabilization that combines the global worst-case guarantees of proximal gradient methods with the local adaptation and practical speed-up of Anderson acceleration. We also provide the first applications of Anderson acceleration to non-Euclidean geometry.</p> 
### 406.[Interpretable, Multidimensional, Multimodal Anomaly Detection with Negative Sampling for Detection of Device Failure](https://proceedings.icml.cc/book/3646.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2557-Paper.pdf)
  John Sipple [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2557-Metadata.json)
> <p>In this paper we propose a scalable, unsupervised approach for detecting anomalies in the Internet of Things (IoT). Complex devices are connected daily and eagerly generate vast streams of multidimensional telemetry. These devices often operate in distinct modes based on external conditions (day/night, occupied/vacant, etc.), and to prevent complete or partial system outage, we would like to recognize as early as possible when these devices begin to operate outside the normal modes. We propose an unsupervised anomaly detection method that creates a negative sample from the positive, observed sample, and trains a classifier to distinguish between positive and negative samples. Using the Concentration Phenomenon, we explain why such a classifier ought to establish suitable decision boundaries between normal and anomalous regions, and show how Integrated Gradients can attribute the anomaly to specific dimensions within the anomalous state vector. We have demonstrated that negative sampling with random forest or neural network classifiers yield significantly higher AUC scores compared to state-of-the-art approaches against benchmark anomaly detection datasets, and a multidimensional, multimodal dataset from real climate control devices. Finally, we describe how negative sampling with neural network classifiers have been successfully deployed at large scale to predict failures in real time in over 15,000 climate-control and power meter devices in 145 office buildings within the California Bay Area.</p> 
### 407.[Certified Robustness to Label-Flipping Attacks via Randomized Smoothing](https://proceedings.icml.cc/book/3647.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2565-Paper.pdf)
  Elan Rosenfeld, Ezra Winston, Pradeep Ravikumar, Zico Kolter [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2565-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2565-Supplemental.zip)
> <p>Machine learning algorithms are known to be susceptible to data poisoning attacks, where an adversary manipulates the training data to degrade performance of the resulting classifier. In this work, we propose a strategy for building linear classifiers that are certifiably robust against a strong variant of label flipping, where each test example is targeted independently. In other words, for each test point, our classifier includes a certification that its prediction would be the same had some number of training labels been changed adversarially. Our approach leverages randomized smoothing, a technique that has previously been used to guarantee---with high probability---test-time robustness to adversarial manipulation of the input to a classifier. We derive a variant which provides a deterministic, analytical bound, sidestepping the probabilistic certificates that traditionally result from the sampling subprocedure. Further, we obtain these certified bounds with minimal additional runtime complexity over standard classification and no assumptions on the train or test distributions. We generalize our results to the multi-class case, providing the first multi-class classification algorithm that is certifiably robust to label-flipping attacks.</p> 
### 408.[Responsive Safety in Reinforcement Learning](https://proceedings.icml.cc/book/3648.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2566-Paper.pdf)
  Adam  Stooke, Joshua Achiam, Pieter Abbeel [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2566-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2566-Supplemental.pdf)
> <p>CMDPs formalize the problem of safe reinforcement learning by exposing a cost signal alongside the reward and limiting its accumulation.  Lagrangian method are the most commonly used algorithms for the resulting constrained optimization problem.  Yet they are known to oscillate and overshoot cost limits, causing constraint-violating behavior during training.  In this paper, we aim to correct this shortcoming.  We begin by proposing a novel modification to the classic Lagrangian method: we add a ``proportional'' term to the Lagrange multiplier update and show that it induces favorable learning dynamics through damping.  This intuition leads to our introduction of PID control for the Lagrange multiplier in constrained RL, which we cast as a dynamical system.  We conduct extensive experiments in a deep RL setting, in which our methods set a new state of the art by dramatically reducing constraint violations while maintaining high returns.  Moreover, we show significant improvements in robustness to hyperparameters.  Unlike other recent algorithms, ours remains nearly as simple to derive and implement as the baseline Lagrangian method.</p> 
### 409.[Deep k-NN for Noisy Labels](https://proceedings.icml.cc/book/3649.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2572-Paper.pdf)
  Dara Bahri, Heinrich Jiang, Maya Gupta [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2572-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2572-Supplemental.pdf)
> <p>Modern machine learning models are often trained on examples with noisy labels that hurt performance and are hard to identify. In this paper, we provide an empirical study showing that a simple k-nearest neighbor-based filtering approach on the logit layer of a preliminary model can  remove mislabeled training data and produce more accurate models than some recently proposed methods. We also provide new statistical guarantees into its efficacy.</p> 
### 410.[Learning the piece-wise constant graph structure of a varying Ising model](https://proceedings.icml.cc/book/3650.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2583-Paper.pdf)
  Batiste Le Bars, Pierre Humbert, Argyris Kalogeratos, Nicolas Vayatis [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2583-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2583-Supplemental.zip)
> <p>This work focuses on the estimation of multiple change-points in a time-varying Ising model that evolves piece-wise constantly. The aim is to identify both the moments at which significant changes occur in the Ising model, as well as the underlying graph structures. For this purpose, we propose to estimate the neighborhood of each node by maximizing a penalized version of its conditional log-likelihood. The objective of the penalization is twofold: it imposes sparsity in the learned graphs and, thanks to a fused-type penalty, it also enforces them to evolve piece-wise constantly. Using few assumptions, we provide two change-points consistency theorems. Those are the first in the context of unknown number of change-points detection in time-varying Ising model. Finally, experimental results on several synthetic datasets and a real-world dataset demonstrate the performance of our method.</p> 
### 411.[Stabilizing Transformers for Reinforcement Learning](https://proceedings.icml.cc/book/3651.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2596-Paper.pdf)
  Emilio Parisotto, Francis Song, Jack Rae, Razvan Pascanu, Caglar Gulcehre, Siddhant Jayakumar, Max Jaderberg, Raphael Lopez Kaufman, Aidan Clark, Seb Noury, Matthew Botvinick, Nicolas Heess, Raia Hadsell [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2596-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2596-Supplemental.pdf)
> <p>Owing to their ability to both effectively integrate information over long time horizons and scale to massive amounts of data, self-attention architectures have recently shown breakthrough success in natural language processing (NLP). Harnessing the transformer’s ability to process long time horizons of information could provide a similar performance boost in partially observable reinforcement learning (RL) domains, but the large-scale transformers used in NLP have yet to be successfully applied to the RL setting. In this work we demonstrate that the standard transformer architecture is difficult to optimize, which was previously observed in the supervised learning setting but becomes especially pronounced with RL objectives. We propose architectural modifications that substantially improve the stability and learning speed of the original Transformer and XL variant. The proposed architecture, the Gated Transformer-XL (GTrXL), surpasses LSTMs on challenging memory environments and achieves state-of-the-art results on the multi-task DMLab-30 benchmark suite, exceeding the performance of an external memory architecture. We show that the GTrXL has stability and performance that consistently matches or exceeds a competitive LSTM baseline, including on more reactive tasks where memory is less critical. </p> 
### 412.[An Explicitly Relational Neural Network Architecture](https://proceedings.icml.cc/book/3652.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2604-Paper.pdf)
  Murray Shanahan, Kyriacos Nikiforou, Antonia Creswell, Christos Kaplanis, David Barrett, Marta Garnelo [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2604-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2604-Supplemental.pdf)
> <p>With a view to bridging the gap between deep learning and symbolic AI, we present a novel end-to-end neural network architecture that learns to form propositional representations with an explicitly relational structure from raw pixel data. In order to evaluate and analyse the architecture, we introduce a family of simple visual relational reasoning tasks of varying complexity. We show that the proposed architecture, when pre-trained on a curriculum of such tasks, learns to generate reusable representations that better facilitate subsequent learning on previously unseen tasks when compared to a number of baseline architectures. The workings of a successfully trained model are visualised to shed some light on how the architecture functions.</p> 
### 413.[Harmonic Decompositions of Convolutional Networks](https://proceedings.icml.cc/book/3653.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2609-Paper.pdf)
  Meyer Scetbon, Zaid Harchaoui [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2609-Metadata.json)
> <p>We present a description of function spaces and smoothness classes associated with convolutional networks from a reproducing kernel Hilbert space viewpoint. We establish harmonic decompositions of convolutional networks, that is expansions into sums of elementary functions of feature-representation maps implemented by convolutional networks. The elementary functions are related to the spherical harmonics, a fundamental class of special functions on spheres. These harmonic decompositions allow us to characterize the integral operators associated with convolutional networks, and obtain as a result risk bounds for convolutional networks which highlight their behavior in high dimensions.</p> 
### 414.[Discriminative Jackknife: Quantifying Uncertainty in Deep Learning via Higher-Order Influence Functions](https://proceedings.icml.cc/book/3654.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2610-Paper.pdf)
  Ahmed Alaa, Mihaela van der Schaar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2610-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2610-Supplemental.pdf)
> <p>Deep learning models achieve high predictive accuracy in a broad spectrum of tasks, but rigorously quantifying their predictive uncertainty remains challenging. Usable estimates of predictive uncertainty should (1) cover the true prediction target with a high probability, and (2) discriminate between high- and low-confidence prediction instances. State-of-the-art methods for uncertainty quantification are based predominantly on Bayesian neural networks. However, Bayesian methods may fall short of (1) and (2) — i.e., Bayesian credible intervals do not guarantee frequentist coverage, and approximate posterior inference may undermine discriminative accuracy. To this end, this paper develops the discriminative jackknife (DJ), a frequentist procedure that uses higher-order influence functions (HOIFs) of a trained model parameters to construct a jackknife (leave-one-out) estimator of predictive confidence intervals. The DJ satisfies (1) and (2), is applicable to  a wide range of deep learning models, is easy to implement, and can be applied in a post-hoc fashion without compromising model accuracy. Experiments demonstrate that DJ performs competitively compared to existing Bayesian and non-Bayesian baselines. </p> 
### 415.[Robust Graph Representation Learning via Neural Sparsification](https://proceedings.icml.cc/book/3655.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2611-Paper.pdf)
  Cheng Zheng, Bo Zong, Wei Cheng, Dongjin Song, Jingchao Ni, Wenchao Yu, Haifeng Chen, Wei Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2611-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2611-Supplemental.pdf)
> <p>Graph representation learning serves as the core of important prediction tasks, ranging from product recommendation to fraud detection. Real-life graphs usually have complex information in the local neighborhood, where each node is described by a rich set of features and connects to dozens or even hundreds of neighbors. Despite the success of neighborhood aggregation in graph neural networks, task-irrelevant information is mixed into nodes' neighborhood, making learned models suffer from sub-optimal generalization performance. In this paper, we present NeuralSparse, a supervised graph sparsification technique that improves generalization power by learning to remove potentially task-irrelevant edges from input graphs. Our method takes both structural and non-structural information as input, utilizes deep neural networks to parameterize sparsification processes, and optimizes the parameters by feedback signals from downstream tasks. Under the NeuralSparse framework, supervised graph sparsification could seamlessly connect with existing graph neural networks for more robust performance. Experimental results on both benchmark and private datasets show that NeuralSparse can yield up to 7.2% improvement in testing accuracy when working with existing graph neural networks on node classification tasks.</p> 
### 416.[Semiparametric Nonlinear Bipartite Graph Representation Learning with Provable Guarantees](https://proceedings.icml.cc/book/3656.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2616-Paper.pdf)
  Sen Na, Yuwei Luo, Zhuoran Yang, Zhaoran Wang, Mladen Kolar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2616-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2616-Supplemental.zip)
> <p>Graph representation learning is a ubiquitous task in machine learning where the goal is to embed each vertex into a low-dimensional vector space. We consider the bipartite graph and formalize its representation learning problem as a statistical estimation problem of parameters in a semiparametric exponential family distribution. The bipartite graph is assumed to be generated by a semiparametric exponential family distribution, whose parametric component is given by the proximity of outputs of two one-layer neural networks, while nonparametric (nuisance) component is the base measure. Neural networks take high-dimensional features as inputs and output embedding vectors. In this setting, the representation learning problem is equivalent to recovering the weight matrices. The main challenges of estimation arise from the nonlinearity of activation functions and the nonparametric nuisance component of the distribution. To overcome these challenges, we propose a pseudo-likelihood objective based on the rank-order decomposition technique and focus on its local geometry. We show that the proposed objective is strongly convex in a neighborhood around the ground truth, so that a gradient descent-based method achieves linear convergence rate. Moreover, we prove that the sample complexity of the problem is linear in dimensions (up to logarithmic factors), which is consistent with parametric Gaussian models. However, our estimator is robust to any model misspecification within the exponential family, which is validated in extensive experiments.</p> 
### 417.[Forecasting sequential data using Consistent Koopman Autoencoders](https://proceedings.icml.cc/book/3657.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2620-Paper.pdf)
  Omri Azencot, N. Benjamin Erichson, Vanessa Lin, Michael Mahoney [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2620-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2620-Supplemental.pdf)
> <p>Neural networks are widely used for processing time series data, yet such models often ignore the underlying physical structures in the input measurements. Recently Koopman-based models have been suggested, as a promising alternative to recurrent neural networks,  for forecasting complex high-dimensional dynamical systems. We propose a novel Consistent Koopman Autoencoder that exploits the forward and backward dynamics to achieve long time predictions. Key to our approach is a new analysis where we unravel the interplay between invertible dynamics and their associated Koopman operators. Our architecture and loss function are interpretable from a physical viewpoint, and the computational requirements are comparable to other baselines. We evaluate the proposed algorithm on a wide range of high-dimensional problems, from simple canonical systems such as linear and nonlinear oscillators, to complex ocean dynamics and fluid flows on a curved domain. Overall, our results show that our model yields accurate estimates for significant prediction horizons, while being robust to noise in the input data.</p> 
### 418.[Scalable Identification of Partially Observed Systems with Certainty-Equivalent EM](https://proceedings.icml.cc/book/3658.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2629-Paper.pdf)
  Kunal Menda, Jean de Becdelievre, Jayesh K. Gupta, Ilan Kroo, Mykel Kochenderfer, Zachary Manchester [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2629-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2629-Supplemental.pdf)
> <p>System identification is a key step for model-based control, estimator design, and output prediction. This work considers the offline identification of partially observed nonlinear systems. We empirically show that the certainty-equivalent approximation to expectation-maximization can be a reliable and scalable approach for high-dimensional deterministic systems, which are common in robotics. We formulate certainty-equivalent expectation-maximization as block coordinate-ascent, and provide an efficient implementation. The algorithm is tested on a simulated system of coupled Lorenz attractors, demonstrating its ability to identify high-dimensional systems that can be intractable for particle-based approaches. Our approach is also used to identify the dynamics of an aerobatic helicopter. By augmenting the state with unobserved fluid states, a model is learned that predicts the acceleration of the helicopter better than state-of-the-art approaches. The codebase for this work is available at https://github.com/sisl/CEEM.</p> 
### 419.[Learning to Score Behaviors for Guided Policy Optimization](https://proceedings.icml.cc/book/3659.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2630-Paper.pdf)
  Aldo Pacchiano, Jack Parker-Holder, Yunhao Tang, Krzysztof Choromanski, Anna Choromanska, Michael Jordan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2630-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2630-Supplemental.pdf)
> <p>We introduce a new approach for comparing reinforcement learning policies, using Wasserstein distances (WDs) in a newly defined latent behavioral space. We show that by utilizing the dual formulation of the WD, we can learn score functions over policy behaviors that can in turn be used to lead policy optimization towards (or away from) (un)desired behaviors. Combined with smoothed WDs, the dual formulation allows us to devise efficient algorithms that take stochastic gradient descent steps through WD regularizers. We incorporate these regularizers into two novel on-policy algorithms, Behavior-Guided Policy Gradient and Behavior-Guided Evolution Strategies, which we demonstrate can outperform existing methods in a variety of challenging environments. We also provide an open source demo.</p> 
### 420.[Improved Communication Cost in Distributed PageRank Computation – A Theoretical Study](https://proceedings.icml.cc/book/3660.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2637-Paper.pdf)
  Siqiang Luo [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2637-Metadata.json)
> PageRank is a widely used approach for measuring the importance of a node in a graph. Computing PageRank is a fundamental task in numerous applications including web search, machine learning and recommendation systems. The importance of computing PageRanks in a distributed environment has been recognized due to the rapid growth of the graph size in real world. However, only a few previous works can provide a provable complexity and accuracy for distributed PageRank computation. Given a constant $d&gt;0$ and a graph of $n$ nodes and under the well-known congested-clique distributed model, the state-of-the-art approach, Radar-Push, uses $O(\log\log{n}+\log{d})$ communication rounds to approximate the PageRanks within a relative error $O(\frac{1}{\log^d{n}})$. However, Radar-Push entails as large as $O(\log^{2d+3}{n})$ bits of bandwidth (e.g., the communication cost between a pair of nodes per round) in the worst case. In this paper, we provide a new algorithm that uses asymptotically the same communication rounds while significantly improves the bandwidth from $O(\log^{2d+3}{n})$ bits to $O(d\log^3{n})$ bits. To the best of our knowledge, our distributed PageRank algorithm is the first to achieve $o(d\log{n})$ communication rounds with $O(d\log^3{n})$ bits of bandwidth in approximating PageRanks with relative error $O(\frac{1}{\log^d{n}})$ under the congested-clique model. 
### 421.[Learning Autoencoders with Relational Regularization](https://proceedings.icml.cc/book/3661.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2640-Paper.pdf)
  Hongteng Xu, Dixin Luo, Ricardo Henao, Svati Shah, Lawrence Carin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2640-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2640-Supplemental.pdf)
> <p>We propose a new algorithmic framework for learning autoencoders of data distributions.  In this framework, we minimize the discrepancy between the model distribution and the target one, with relational regularization on learnable latent prior.  This regularization penalizes the fused Gromov-Wasserstein (FGW) distance between the latent prior and its corresponding posterior, which allows us to learn a structured prior distribution associated with the generative model in a flexible way.  Moreover, it helps us co-train multiple autoencoders even if they are with heterogeneous architectures and incomparable latent spaces.  We implement the framework with two scalable algorithms, making it applicable for both probabilistic and deterministic autoencoders.  Our relational regularized autoencoder (RAE) outperforms existing methods, e.g., variational autoencoder, Wasserstein autoencoder, and their variants, on generating images.  Additionally, our relational co-training strategy of autoencoders achieves encouraging results in both synthesis and real-world multi-view learning tasks.</p> 
### 422.[Neural Contextual Bandits with UCB-based Exploration](https://proceedings.icml.cc/book/3662.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2647-Paper.pdf)
  Dongruo Zhou, Lihong Li, Quanquan Gu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2647-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2647-Supplemental.pdf)
> We study the stochastic contextual bandit problem, where the reward is generated from an unknown bounded function with additive noise. We propose the NeuralUCB algorithm, which leverages the representation power of deep neural networks and uses a neural network-based random feature mapping to construct an upper confidence bound (UCB) of reward for efficient exploration. We prove that, under mild assumptions, NeuralUCB achieves $\tilde O(\sqrt{T})$ regret,  where $T$ is the number of rounds. To the best of our knowledge, our algorithm is the first neural network-based contextual bandit algorithm with near-optimal regret guarantee. We also show the algorithm is empirically competitive against representative baselines in a number of benchmarks.
### 423.[Super-efficiency of automatic differentiation for functions defined as a minimum](https://proceedings.icml.cc/book/3663.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2648-Paper.pdf)
  Pierre Ablin, Gabriel Peyré, Thomas Moreau [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2648-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2648-Supplemental.pdf)
> <p>In min-min optimization or max-min optimization, one has to compute the gradient of a function defined as a minimum. In most cases, the minimum has no closed-form, and an approximation is obtained via an iterative algorithm. There are two usual ways of estimating the gradient of the function: using either an analytic formula obtained by assuming exactness of the approximation, or automatic differentiation through the algorithm. In this paper, we study the asymptotic error made by these estimators as a function of the optimization error. We find that the error of the automatic estimator is close to the square of the error of the analytic estimator, reflecting a super-efficiency phenomenon. The convergence of the automatic estimator greatly depends on the convergence of the Jacobian of the algorithm. We analyze it for gradient descent and stochastic gradient descent and derive convergence rates for the estimators in these cases. Our analysis is backed by numerical experiments on toy problems and on Wasserstein barycenter computation. Finally, we discuss the computational complexity of these estimators and give practical guidelines to chose between them.</p> 
### 424.[PowerNorm: Rethinking Batch Normalization in Transformers](https://proceedings.icml.cc/book/3664.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2650-Paper.pdf)
  Sheng Shen, Zhewei Yao, Amir Gholaminejad, Michael Mahoney, Kurt Keutzer [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2650-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2650-Supplemental.pdf)
> <p>The standard normalization method for neural network (NN) models used in Natural Language Processing (NLP) is layer normalization (LN).This is different than batch normalization (BN), which is widely-adopted in Computer Vision. The preferred use of LN in NLP is principally due to the empirical observation that a (naive/vanilla) use of BN leads to significant performance degradation for NLP tasks; however, a thorough understanding of the underlying reasons for this is not always evident. In this paper, we perform a systematic study of NLP transformer models to understand why BN has a poor performance, as compared to LN. We find that the statistics of NLP data across the batch dimension exhibit large fluctuations throughout training. This results in instability, if BN is naively implemented. To address this, we propose Power Normalization (PN), a novel normalization scheme that resolves this issue by (i) relaxing zero-mean normalization in BN, (ii) incorporating a running quadratic mean instead of per batch statistics to stabilize fluctuations, and (iii) using an approximate backpropagation for incorporating the running statistics in the forward pass. We show theoretically, under mild assumptions, that PN leads to a smaller Lipschitz constant for the loss, compared with BN. Furthermore, we prove that the approximate backpropagation scheme leads to bounded gradients. We extensively test PN for transformers on a range of NLP tasks, and we show that it significantly outperforms both LN and BN.  In particular, PN outperforms LN by 0.4/0.6 BLEU on IWSLT14/WMT14 and 5.6/3.0 PPL on PTB/WikiText-103. We make our code publicly available at https://github.com/sIncerass/powernorm.</p> 
### 425.[Invertible generative models for inverse problems: mitigating representation error and dataset bias](https://proceedings.icml.cc/book/3665.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2655-Paper.pdf)
  Muhammad Asim, Max Daniels, Oscar Leong, Paul Hand, Ali Ahmed [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2655-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2655-Supplemental.pdf)
> <p>Trained generative models have shown remarkable performance as priors for inverse problems in imaging.  For example, Generative Adversarial Network priors permit recovery of test images from 5-10x fewer measurements than sparsity priors.  Unfortunately, these models may be unable to represent any particular image because of architectural choices, mode collapse, and bias in the training dataset. In this paper, we demonstrate that invertible neural networks, which have zero representation error by design, can be effective natural signal priors at inverse problems such as denoising, compressive sensing, and inpainting.  Given a trained generative model, we study the empirical risk formulation of the desired inverse problem under a regularization that promotes high likelihood images, either directly by penalization or algorithmically by initialization. For compressive sensing, invertible priors can yield higher accuracy than sparsity priors across almost all undersampling ratios.  For the same accuracy on test images, they can use 10-20x fewer measurements.  We demonstrate that invertible priors can yield better reconstructions than GAN priors for images that have rare features of variation within the biased training set, including out-of-distribution natural images.  We additionally compare performance for compressive sensing to unlearned methods, such as the deep decoder, and we establish theoretical bounds on expected recovery error in the case of a linear invertible model.</p> 
### 426.[Acceleration for Compressed Gradient Descent in Distributed Optimization](https://proceedings.icml.cc/book/3666.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2658-Paper.pdf)
  Zhize Li, Dmitry Kovalev, Xun Qian, Peter Richtarik [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2658-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2658-Supplemental.zip)
> Due to the high communication cost in distributed and federated learning problems, methods relying on sparsification or quantization of communicated messages are becoming increasingly popular. While in other contexts the best performing gradient-type  methods invariably rely on some form of acceleration to reduce the number of iterations, there are no methods which combine the benefits of both  gradient compression and acceleration. In this paper, we remedy this situation and propose the first {\em accelerated compressed gradient descent (ACGD)} methods. In the single machine regime, we prove that ACGD enjoys the rate $O((1+\omega)\sqrt{\nicefrac{L}{\mu}}\log \nicefrac{1}{\epsilon})$ for $\mu$-strongly convex problems and $O((1+\omega)\sqrt{\nicefrac{L}{\epsilon}})$ for convex problems, respectively, where $L$ is the smoothness constant and $\omega$ is the variance parameter of an unbiased compression operator. Our results improve upon the existing non-accelerated rates $O\left((1+\omega)\nicefrac{L}{\mu}\log \nicefrac{1}{\epsilon}\right)$ and $O\left((1+\omega)\nicefrac{L}{\epsilon}\right)$, respectively, and recover the best known rates of accelerated gradient descent as a special case when no compression ($\omega=0$) is applied. We further propose a distributed variant  of ACGD and establish the rate $\tilde{O}\left(\omega+\sqrt{\nicefrac{L}{\mu}} +\sqrt{(\nicefrac{\omega}{n}+\sqrt{\nicefrac{\omega}{n}})\nicefrac{\omega L}{\mu}}\right)$, where $n$ is the number of machines and $\tilde{O}$ hides the logarithmic factor $\log \nicefrac{1}{\epsilon}$ . This improves upon the previous best result $\tilde{O}\left(\omega + \nicefrac{L}{\mu}+\nicefrac{\omega L}{n\mu} \right)$ achieved by the DIANA method. Finally, we conduct several experiments on real-world datasets which corroborate  our theoretical results and confirm the practical superiority of our methods.
### 427.[Neural Networks are Convex Regularizers: Exact Polynomial-time Convex Optimization Formulations for Two-Layer Networks](https://proceedings.icml.cc/book/3667.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2660-Paper.pdf)
  Mert Pilanci, Tolga Ergen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2660-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2660-Supplemental.pdf)
> <p>We develop exact representations of two layer neural networks with rectified linear units in terms of a single convex program with number of variables polynomial in the number of training samples and number of hidden neurons. Our theory utilizes semi-infinite duality and minimum norm regularization. Moreover, we show that certain standard multi-layer convolutional neural networks are equivalent to L1 regularized linear models in a polynomial sized discrete Fourier feature space. We also introduce exact semi-definite programming representations of convolutional and fully connected linear multi-layer networks which are polynomial size in both the sample size and dimension. </p> 
### 428.[Learning Quadratic Games on Networks](https://proceedings.icml.cc/book/3668.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2663-Paper.pdf)
  Yan Leng, Xiaowen Dong, Junfeng Wu, Alex `Sandy&#x27; Pentland [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2663-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2663-Supplemental.pdf)
> <p>Individuals, or organizations, cooperate with or compete against one another in a wide range of practical situations. In the economics literature, such strategic interactions are often modeled as games played on networks, where an individual's payoff depends not only on her action but also that of her neighbors. The current literature has largely focused on analyzing the characteristics of network games in the scenario where the structure of the network, which is represented by a graph, is known beforehand. It is often the case, however, that the actions of the players are readily observable while the underlying interaction network remains hidden. In this paper, we propose two novel frameworks for learning, from the observations on individual actions, network games with linear-quadratic payoffs, and in particular the structure of the interaction network. Our frameworks are based on the Nash equilibrium of such games and involve solving a joint optimization problem for the graph structure and the individual marginal benefits. We test the proposed frameworks in synthetic settings and further study several factors that affect their learning performance. Moreover, with experiments on three real world examples, we show that our methods can effectively and more accurately learn the games than the baselines. The proposed approach is among the first of its kind for {learning quadratic games, and have both theoretical and practical implications for understanding strategic interactions in a network environment.</p> 
### 429.[Margin-aware Adversarial Domain Adaptation with Optimal Transport](https://proceedings.icml.cc/book/3669.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2666-Paper.pdf)
  Sofien Dhouib, Ievgen Redko, Carole Lartizien [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2666-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2666-Supplemental.pdf)
> <p>In this paper, we propose a new theoretical analysis of unsupervised domain adaptation that relates notions of large margin separation, adversarial learning and optimal transport. This analysis generalizes previous work on the subject by providing a bound on the target margin violation rate, thus reflecting a better control of the quality of separation between classes in the target domain than bounding the misclassification rate. The bound also highlights the benefit of a large margin separation on the source domain for adaptation and introduces an optimal transport (OT) based distance between domains that has the virtue of being task-dependent, contrary to other approaches. From the obtained theoretical results, we derive a novel algorithmic solution for domain adaptation that introduces a novel shallow OT-based adversarial approach and outperforms other OT-based DA baselines on several simulated and real-world classification tasks.</p> 
### 430.[The Sample Complexity of Best-$k$ Items Selection from Pairwise Comparisons](https://proceedings.icml.cc/book/3670.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2667-Paper.pdf)
  Wenbo Ren, Jia Liu, Ness Shroff [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2667-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2667-Supplemental.pdf)
> This paper studies the sample complexity (aka number of comparisons) bounds for the active best-$k$ items selection from pairwise comparisons. From a given set of items, the learner can make pairwise comparisons on every pair of items, and each comparison returns an independent noisy result about the preferred item. At any time, the learner can adaptively choose a pair of items to compare according to past observations (i.e., active learning). The learner&#x27;s goal is to find the (approximately) best-$k$ items with a given confidence while trying to use as few comparisons as possible. In this paper, we study two problems: (i) finding the probably approximately correct (PAC) best-$k$ items and (ii) finding the exact best-$k$ items, both under strong stochastic transitivity and stochastic triangle inequality. For PAC best-$k$ items selection, we first show a lower bound and then propose an algorithm whose sample complexity upper bound matches the lower bound up to a constant factor. For the exact best-$k$ items selection, we first prove a worst-instance lower bound. We then propose two algorithms based on our PAC best items selection algorithms, of which one works for $k=1$ and is sample complexity optimal up to a loglog factor, and the other works for all values of $k$ and is sample complexity optimal up to a log factor. 
### 431.[GraphOpt: Learning Optimization Models of Graph Formation](https://proceedings.icml.cc/book/3671.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2675-Paper.pdf)
  Rakshit Trivedi, Jiachen Yang, Hongyuan Zha [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2675-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2675-Supplemental.pdf)
> <p>Formation mechanisms are fundamental to the study of complex networks, but learning them from observations is challenging. In real-world domains, one often has access only to the final constructed graph, instead of the full construction process, and observed graphs exhibit complex, non-local structural properties. In this work, we propose GraphOpt, an end-to-end framework that jointly learns an implicit model of graph structure formation and discovers an underlying optimization mechanism in the form of a latent objective function. The learned objective can serve as an explanation for the observed graph properties, thereby lending itself to transfer across different graphs within a given domain. GraphOpt poses link formation in graphs as a sequential  decision-making process and solves it using an efficient maximum entropy based inverse reinforcement learning algorithm. Further, it employs a novel continuous latent action space induced from node representations  to promote scalability. We demonstrate empirically that GraphOpt discovers a latent objective and a robust stochastic policy that enable construction of graphs with properties similar to those in observed graph, transfer across graphs with different characteristics, and exhibit competitive performance on conventional downstream tasks such as link prediction, without being explicitly trained on these new graphs or task.</p> 
### 432.[Distributionally Robust Policy Evaluation and Learning in Offline Contextual Bandits](https://proceedings.icml.cc/book/3672.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2684-Paper.pdf)
  Nian Si, Fan Zhang, Zhengyuan Zhou, Jose Blanchet [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2684-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2684-Supplemental.zip)
> <p>Policy learning using historical observational data is an important problem that has found widespread applications. However, existing literature rests on the crucial assumption that the future environment where the learned policy will be deployed is the same as the past environment that has generated the data–an assumption that is often false or too coarse an approximation. In this paper, we lift this assumption and aim to learn a distributionally robust policy with bandit observational data. We propose a novel learning algorithm that is able to learn a robust policy to adversarial perturbations and unknown covariate shifts. We first present a policy evaluation procedure in the ambiguous environment and also give a heuristic algorithm to solve the distributionally robust policy learning problems efficiently. Additionally, we provide extensive simulations to demonstrate the robustness of our policy.</p> 
### 433.[Incremental Sampling Without Replacement for Sequence Models](https://proceedings.icml.cc/book/3673.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2688-Paper.pdf)
  Kensen Shi, David Bieber, Charles Sutton [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2688-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2688-Supplemental.pdf)
> <p>Sampling is a fundamental technique, and sampling without replacement is often desirable when duplicate samples are not beneficial. Within machine learning, sampling is useful for generating diverse outputs from a trained model. We present an elegant procedure for sampling without replacement from a broad class of randomized programs, including generative neural models that construct outputs sequentially. Our procedure is efficient even for exponentially-large output spaces. Unlike prior work, our approach is incremental, i.e., samples can be drawn one at a time, allowing for increased flexibility. We also present a new estimator for computing expectations from samples drawn without replacement. We show that incremental sampling without replacement is applicable to many domains, e.g., program synthesis and combinatorial optimization.</p> 
### 434.[Variable Skipping for Autoregressive Range Density Estimation](https://proceedings.icml.cc/book/3674.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2693-Paper.pdf)
  Eric Liang, Zongheng Yang, Ion Stoica, Pieter Abbeel, Yan Duan, Peter Chen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2693-Metadata.json)
> <p>Deep autoregressive models compute point likelihood estimates of individual data points. However, many applications (i.e., database cardinality estimation), require estimating range densities, a capability that is under-explored by current neural density estimation literature. In these applications, fast and accurate range density estimates over high-dimensional data directly impact user-perceived performance. In this paper, we explore a technique for accelerating range density estimation over deep autoregressive models. This technique, called variable skipping, exploits the sparse structure of range density queries to avoid sampling unnecessary variables during approximate inference. We show that variable skipping provides 10-100x efficiency improvements, enables complex applications such as text pattern matching, and can be realized via a simple data augmentation procedure without changing the usual maximum likelihood objective.</p> 
### 435.[TaskNorm: Rethinking Batch Normalization for Meta-Learning](https://proceedings.icml.cc/book/3675.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2696-Paper.pdf)
  John Bronskill, Jonathan Gordon, James Requeima, Sebastian Nowozin, Richard Turner [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2696-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2696-Supplemental.pdf)
> <p>Modern meta-learning approaches for image classification rely on increasingly deep networks to achieve state-of-the-art performance, making batch normalization an essential component of meta-learning pipelines. However, the hierarchical nature of the meta-learning setting presents several challenges that can render conventional batch normalization ineffective, giving rise to the need to rethink normalization in this setting.  We evaluate a range of approaches to batch normalization for meta-learning scenarios, and develop a novel approach that we call TaskNorm. Experiments on fourteen datasets demonstrate that the choice of batch normalization has a dramatic effect on both classification accuracy and training time for both gradient based- and gradient-free meta-learning approaches. Importantly, TaskNorm is found to consistently improve performance. Finally, we provide a set of best practices for normalization that will allow fair comparison of meta-learning algorithms.</p> 
### 436.[Scalable Gaussian Process Regression for Kernels with a Non-Stationary Phase](https://proceedings.icml.cc/book/3676.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2702-Paper.pdf)
  Jan Graßhoff, Alexandra Jankowski, Philipp Rostalski [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2702-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2702-Supplemental.pdf)
> <p>The application of Gaussian processes (GPs) to large data sets is limited due to heavy memory and computational requirements. A variety of methods has been proposed to enable scalability, one of which is to exploit structure in the kernel matrix. Previous methods, however, cannot easily deal with non-stationary processes. This paper investigates an efficient GP framework, that extends structured kernel interpolation methods to GPs with a non-stationary phase. We particularly treat mixtures of non-stationary processes, which are commonly used in the context of separation problems e.g. in biomedical signal processing. Our approach employs multiple sets of non-equidistant inducing points to account for the non-stationarity and retrieve Toeplitz and Kronecker structure in the kernel matrix allowing for efficient inference and kernel learning. The approach is demonstrated on numerical examples and large biomedical datasets.</p> 
### 437.[Transformer Hawkes Process](https://proceedings.icml.cc/book/3677.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2705-Paper.pdf)
  Simiao Zuo, Haoming Jiang, Zichong Li, Tuo Zhao, Hongyuan Zha [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2705-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2705-Supplemental.pdf)
> <p>Modern data acquisition routinely produce massive amounts of event sequence data in various domains, such as social media, healthcare, and financial markets. These data often exhibit complicated short-term and long-term temporal dependencies. However, most of the existing recurrent neural network-based point process models fail to capture such dependencies, and yield unreliable prediction performance. To address this issue, we propose a Transformer Hawkes Process (THP) model, which leverages the self-attention mechanism to capture long-term dependencies and meanwhile enjoys computational efficiency. Numerical experiments on various datasets show that THP outperforms existing models in terms of both likelihood and event prediction accuracy by a notable margin. Moreover, THP is quite general and can incorporate additional structural knowledge. We provide a concrete example, where THP achieves improved prediction performance for learning multiple point processes when incorporating their relational information.</p> 
### 438.[An EM Approach to Non-autoregressive Conditional Sequence Generation](https://proceedings.icml.cc/book/3678.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2711-Paper.pdf)
  Zhiqing Sun, Yiming Yang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2711-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2711-Supplemental.pdf)
> <p>Autoregressive (AR) models have been the dominating approach to conditional sequence generation, but are suffering from the issue of high inference latency.  Non-autoregressive (NAR) models have been recently proposed to reduce the latency by generating all output tokens in parallel but could only achieve inferior accuracy compared to their autoregressive counterparts, primarily due to a difficulty in dealing with the multi-modality in sequence generation.  This paper proposes a new approach that jointly optimizes both AR and NAR models in a unified Expectation-Maximization (EM) framework. In the E-step, an AR model learns to approximate the regularized posterior of the NAR model. In the M-step, the NAR model is updated on the new posterior and selects the training examples for the next AR model. This iterative process can effectively guide the system to remove the multi-modality in the output sequences and remedy the multi-modality problem. To our knowledge, this is the first EM approach to NAR sequence generation. We evaluate our method on the task of machine translation. Experimental results on benchmark data sets show that the proposed approach achieves competitive, if not better, performance with existing NAR models and significantly reduces the inference latency.</p> 
### 439.[Variance Reduction in Stochastic Particle-Optimization Sampling](https://proceedings.icml.cc/book/3679.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2712-Paper.pdf)
  Jianyi Zhang, Yang Zhao, Changyou Chen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2712-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2712-Supplemental.pdf)
> <p>Stochastic particle-optimization sampling (SPOS) is a recently-developed scalable Bayesian sampling framework that unifies stochastic gradient MCMC (SG-MCMC) and Stein variational gradient descent (SVGD) algorithms based on Wasserstein gradient flows. With a rigorous non-asymptotic convergence theory developed recently, SPOS avoids the particle-collapsing pitfall of SVGD. Nevertheless, variance reduction in SPOS has never been studied. In this paper, we bridge the gap by presenting several variance-reduction techniques for SPOS. Specifically, we propose three variants of variance-reduced SPOS, called SAGA particle-optimization sampling (SAGA-POS), SVRG particle optimization sampling (SVRG-POS) and a variant of SVRG-POS which avoids full gradient computations, denoted as SVRG-POS+. Importantly, we provide non-asymptotic convergence guarantees for these algorithms in terms of 2- Wasserstein metric and analyze their complexities. Remarkably, the results show our algorithms yield better convergence rates than existing variance reduced variants of stochastic Langevin dynamics, even though more space is required to store the particles in training. Our theory well aligns with experimental results on both synthetic and real datasets.</p> 
### 440.[CLUB: A Contrastive Log-ratio Upper Bound of Mutual Information](https://proceedings.icml.cc/book/3680.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2718-Paper.pdf)
  Pengyu Cheng, Weituo Hao, Shuyang Dai, Jiachang Liu, Zhe Gan, Lawrence Carin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2718-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2718-Supplemental.pdf)
> <p>Mutual information (MI) minimization has gained considerable interests in various machine learning tasks. However, estimating and minimizing MI in high-dimensional spaces remains a challenging problem, especially when only samples, rather than distribution forms, are accessible. Previous works mainly focus on MI lower bound approximations, which is not applicable to MI minimization problems. In this paper, we propose a novel Contrastive Log-ratio Upper Bound (CLUB) of mutual information. We provide theoretical analysis to the properties of CLUB and its variational approximation. Based on this upper bound, we introduce an accelerated MI minimization training scheme, which bridges MI minimization with contrastive learning and negative sampling. Simulation studies on Gaussian and Bernoulli distributions show the reliable estimation ability of CLUB. Real-world MI minimization experiments, including domain adaptation and information bottleneck, further demonstrate the effectiveness of the proposed method.</p> 
### 441.[State Space Expectation Propagation: Efficient Inference Schemes for Temporal Gaussian Processes](https://proceedings.icml.cc/book/3681.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2722-Paper.pdf)
  William Wilkinson, Paul Chang, Michael Andersen, Arno Solin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2722-Metadata.json)
> <p>We formulate expectation propagation (EP), a state-of-the-art method for approximate Bayesian inference, as a nonlinear Kalman smoother, showing that it generalises a wide class of classical smoothing algorithms. Specifically we show how power EP recovers the Extended and Unscented Kalman smoothers, with the distinction between the two being the choice of method for performing moment matching. EP provides some benefits over the traditional methods via introduction of the so-called cavity distribution, and by allowing fractional updates. We combine these benefits with the computational efficiency of Kalman smoothing, and provide extensive empirical analysis demonstrating the efficacy of various algorithms under this unifying framework. The resulting schemes enable inference in Gaussian process models in linear time complexity in the number of data, making them ideal for large temporal and spatio-temporal scenarios. Our results show that an extension of the Extended Kalman filter in which the linearisations are iteratively refined via EP-style updates is both efficient and performant, whilst its ease of implementation makes it a convenient plug-and-play approach to many non-conjugate regression and classification problems.</p> 
### 442.[Training Neural Networks for and by Interpolation](https://proceedings.icml.cc/book/3682.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2730-Paper.pdf)
  Leonard Berrada, M. Pawan Kumar, Andrew Zisserman [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2730-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2730-Supplemental.pdf)
> <p>In modern supervised learning, many deep neural networks are able to interpolate the data: the empirical loss can be driven to near zero on all samples simultaneously. In this work, we explicitly exploit this interpolation property for the design of a new optimization algorithm for deep learning, which we term Adaptive Learning-rates for Interpolation with Gradients (ALI-G). ALI-G retains the two main advantages of Stochastic Gradient Descent (SGD), which are (i) a low computational cost per iteration and (ii) good generalization performance in practice. At each iteration, ALI-G exploits the interpolation property to compute an adaptive learning-rate in closed form. In addition, ALI-G clips the learning-rate to a maximal value, which we prove to be helpful for non-convex problems. Crucially, in contrast to the learning-rate of SGD, the maximal learning-rate of ALI-G does not require a decay schedule. This makes ALI-G considerably easier to tune than SGD. We prove the convergence of ALI-G in various stochastic settings. Notably, we tackle the realistic case where the interpolation property is satisfied up to some tolerance. We also provide experiments on a variety of deep learning architectures and tasks: (i) learning a differentiable neural computer; (ii) training a wide residual network on the SVHN data set; (iii) training a Bi-LSTM on the SNLI data set; and (iv) training wide residual networks and densely connected networks on the CIFAR data sets. ALI-G produces state-of-the-art results among adaptive methods, and even yields comparable performance with SGD, which requires manually tuned learning-rate schedules. Furthermore, ALI-G is simple to implement in any standard deep learning framework and can be used as a drop-in replacement in existing code.</p> 
### 443.[Learning Representations that Support Extrapolation](https://proceedings.icml.cc/book/3683.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2731-Paper.pdf)
  Taylor Webb, Zachary Dulberg, Steven Frankland, Alexander Petrov, Randall O&#x27;Reilly, Jonathan Cohen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2731-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2731-Supplemental.pdf)
> <p>Extrapolation -- the ability to make inferences that go beyond the scope of one's experiences -- is a hallmark of human intelligence. By contrast, the generalization exhibited by contemporary neural network algorithms is largely limited to interpolation between data points in their training corpora. In this paper, we consider the challenge of learning representations that support extrapolation. We introduce a novel visual analogy benchmark that allows the graded evaluation of extrapolation as a function of distance from the convex domain defined by the training data. We also introduce a simple technique, context normalization, that encourages representations that emphasize the relations between objects. We find that this technique enables a significant improvement in the ability to extrapolate, considerably outperforming a number of competitive techniques.</p> 
### 444.[ Topic Modeling via Full Dependence Mixtures](https://proceedings.icml.cc/book/3684.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2732-Paper.pdf)
  Dan  Fisher, Mark Kozdoba, Shie Mannor [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2732-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2732-Supplemental.pdf)
> <p>In this paper we introduce a new approach to topic modelling that scales to  large datasets by  using  a compact representation of the data and by leveraging the GPU architecture. <br /> In this approach, topics are learned directly from the <br /> co-occurrence data of the corpus. In particular, we introduce a novel mixture model which we term the Full Dependence Mixture (FDM) model. FDMs model  second moment under  general generative  assumptions on the data. While there is previous work on topic  modeling using second moments,  we develop a direct stochastic  optimization procedure for fitting an FDM with a single Kullback  Leibler objective. Moment methods in general have the benefit that  an iteration no longer needs to scale with the size of the corpus.  Our approach allows us to leverage standard  optimizers and GPUs for the problem of topic modeling. In  particular, we evaluate the approach on two large datasets,  NeurIPS papers and a Twitter corpus, with a large number of  topics, and show that the approach performs comparably or better than the standard benchmarks.</p> 
### 445.[Instance-hiding Schemes for Private Distributed Learning](https://proceedings.icml.cc/book/3685.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2735-Paper.pdf)
  Yangsibo Huang, Zhao Song, Sanjeev Arora, Kai Li [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2735-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2735-Supplemental.pdf)
> <p>An important problem today is how to allow a group of decentralized entities to compute on their private data on a centralized deep net while protecting data privacy. Classic cryptographic techniques are too inefficient, so other methods have recently been suggested, e.g., differentially private Federated Learning. Here, a new method is introduced, inspired by the classic notion of {\em instance hiding} in cryptography. It uses the Mixup technique, proposed by {Zhang et al, ICLR 2018} as a way to improve generalization and robustness. Usual mixup involves training on nonnegative combinations of inputs. The new ideas in the current paper are: (a) new variants of mixup with negative as well as positive coefficients, and extend the sample-wise mixup to be pixel-wise.  (b) Experiments demonstrating the effectiveness of this in protecting privacy against known attacks while preserving utility. (c)  Theoretical analysis suggesting why this method is effective, using ideas from analyses of attacks. (d) Estimates of security and the release of a challenge dataset to allow the design of attack schemes.</p> 
### 446.[The Implicit Regularization of Stochastic Gradient Flow for Least Squares](https://proceedings.icml.cc/book/3686.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2740-Paper.pdf)
  Alnur Ali, Edgar Dobriban, Ryan Tibshirani [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2740-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2740-Supplemental.pdf)
> We study the implicit regularization of mini-batch stochastic gradient descent, when applied to the fundamental problem of least squares regression.  We leverage a continuous-time stochastic differential equation having the same moments as stochastic gradient descent, which we call stochastic gradient flow.  We give a bound on the excess risk of stochastic gradient flow at time $t$, over ridge regression with tuning parameter $\lambda = 1/t$.  The bound may be computed from explicit constants (e.g., the mini-batch size, step size, number of iterations), revealing precisely how these quantities drive the excess risk.  Numerical examples show the bound can be small, indicating a tight relationship between the two estimators.  We give a similar result relating the coefficients of stochastic gradient flow and ridge.  These results hold under no conditions on the data matrix $X$, and across the entire optimization path (not just at convergence).
### 447.[Decentralised Learning with Random Features and Distributed Gradient Descent](https://proceedings.icml.cc/book/3687.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2742-Paper.pdf)
  Dominic Richards, Patrick Rebeschini, Lorenzo Rosasco [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2742-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2742-Supplemental.pdf)
> <p>We investigate the generalisation performance of Distributed Gradient Descent with implicit regularisation and random features in the homogenous setting where a network of agents are given data sampled independently from the same unknown distribution. Along with reducing the memory footprint, random features are particularly convenient in this setting as they provide a common parameterisation across agents that allows to overcome previous difficulties in implementing decentralised kernel regression. Under standard source and capacity assumptions, we establish high probability bounds on the predictive performance for each agent as a function of the step size, number of iterations, inverse spectral gap of the communication matrix and number of random features. By tuning these parameters, we obtain statistical rates that are minimax optimal with respect to the total number of samples in the network. The algorithm provides a linear improvement over single-machine gradient descent in memory cost and, when agents hold enough data with respect to the network size and inverse spectral gap, a linear speed up in computational run-time for any network topology. We present simulations that show how the number of random features, iterations and samples impact predictive performance.</p> 
### 448.[Hierarchical Generation of Molecular Graphs using Structural Motifs](https://proceedings.icml.cc/book/3688.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2743-Paper.pdf)
  Wengong Jin, Regina Barzilay, Tommi Jaakkola [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2743-Metadata.json)
> <p>Graph generation techniques are increasingly being adopted for drug discovery. Previous graph generation approaches have utilized relatively small molecular building blocks such as atoms or simple cycles, limiting their effectiveness to smaller molecules. Indeed, as we demonstrate, their performance degrades significantly for larger molecules. In this paper, we propose a new hierarchical graph encoder-decoder that employs significantly larger and more flexible graph motifs as basic building blocks. Our encoder produces a multi-resolution representation for each molecule in a fine-to-coarse fashion, from atoms to connected motifs. Each level integrates the encoding of constituents below with the graph at that level. Our autoregressive coarse-to-fine decoder adds one motif at a time, interleaving the decision of selecting a new motif with the process of resolving its attachments to the emerging molecule. We evaluate our model on multiple molecule generation tasks, including polymers, and show that our model significantly outperforms previous state-of-the-art baselines.</p> 
### 449.[Composing Molecules with Multiple Property Constraints](https://proceedings.icml.cc/book/3689.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2748-Paper.pdf)
  Wengong Jin, Regina Barzilay, Tommi Jaakkola [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2748-Metadata.json)
> <p>Drug discovery aims to find novel compounds with specified chemical property profiles. In terms of generative modeling, the goal is to learn to sample molecules in the intersection of multiple property constraints. This task becomes increasingly challenging when there are many property constraints. We propose to offset this complexity by composing molecules from a vocabulary of substructures that we call molecular rationales. These rationales are identified from molecules as substructures that are likely responsible for each property of interest. We then learn to expand rationales into a full molecule using graph generative models. Our final generative model composes molecules as mixtures of multiple rationale completions, and this mixture is fine-tuned to preserve the properties of interest. We evaluate our model on various drug design tasks and demonstrate significant improvements over state-of-the-art baselines in terms of accuracy, diversity, and novelty of generated compounds.</p> 
### 450.[Data preprocessing to mitigate bias: A maximum entropy based approach](https://proceedings.icml.cc/book/3690.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2750-Paper.pdf)
  Elisa Celis, Vijay Keswani, Nisheeth Vishnoi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2750-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2750-Supplemental.pdf)
> <p>Data containing human or social features may over- or under-represent groups with respect to salient social attributes such as gender or race, which can lead to biases in downstream applications. Prior approaches towards preprocessing data to mitigate such biases either reweigh the points in the dataset or set up a constrained optimization problem on the domain to minimize a metric of bias. However, the former do not learn a distribution over the entire domain and the latter do not scale well with the domain size. This paper presents an optimization framework that can be used as a data preprocessing method towards mitigating bias: It can learn distributions over large domains and controllably adjust the representation rates of protected groups and/or achieve target fairness metrics such as statistical parity, yet remains close to the empirical distribution induced by the given dataset. Our approach appeals to the principle of maximum entropy, which states that amongst all distributions satisfying a given set of constraints, we should choose the one closest in KL-divergence to a given prior. While maximum entropy distributions can succinctly encode distributions over large domains, they can be difficult to compute. Our main technical contribution is an instantiation of the maximum entropy framework for our set of constraints and priors, which encode our bias mitigation goals, that runs in time polynomial in the dimension of the data. Empirically, we observe that samples from the learned distribution have desired representation rates and statistical rates, and when used for training a classifier incurs only a slight loss in accuracy while maintaining fairness properties.</p> 
### 451.[On Efficient Low Distortion Ultrametric Embedding](https://proceedings.icml.cc/book/3691.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2751-Paper.pdf)
  Vincent Cohen-Addad, Karthik C. S., Guillaume Lagarde [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2751-Metadata.json)
> A classic problem in unsupervised learning and data analysis is to find simpler and easy-to-visualize representations of the data that preserve its essential properties. A widely-used method to preserve the underlying hierarchical structure of the data while reducing its complexity is to find an embedding of the data into a tree or an ultrametric. The most popular algorithms for this task are the classic &quot;linkage&quot; algorithms (single, average, or complete).  However, these methods exhibit a quite prohibitive running time of $\Theta(n^2)$.  In this paper, we provide a new algorithm which takes as input a set of points $P$ in $R^d$, and for every $c\ge 1$, runs in time $n^{1+O(1/c^2)}$ to output an ultrametric $\Delta$ such that for any two points $u,v$ in $P$, we have $\Delta(u,v)$ is within a multiplicative factor of $5c$ to the distance between $u$ and $v$ in the &quot;best&quot; ultrametric representation of $P$. Here, the best ultrametric is the ultrametric $\Delta^*$ that minimizes the maximum distance distortion with respect to the $\ell_2$ distance, namely that minimizes $\max_{u,v \in P} \Delta^*(u,v)/||u-v||_2$.&quot;  We complement the above result by showing that under popular complexity theoretic assumptions, for every constant $\epsilon&gt;0$,  no algorithm with running time $n^{2-\epsilon}$  can distinguish between inputs that admit isometric embedding and inputs that can incur a distortion of 3/2 in L∞ -metric.   Finally, we present empirical evaluation on classic machine learning datasets and show that the output of our algorithm is comparable to the output of the linkage algorithms while achieving a much faster running time.
### 452.[Global Concavity and Optimization in a Class of Dynamic Discrete Choice Models](https://proceedings.icml.cc/book/3692.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2760-Paper.pdf)
  Yiding Feng, Ekaterina Khmelnitskaya, Denis Nekipelov [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2760-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2760-Supplemental.pdf)
> <p>Discrete choice models with unobserved heterogeneity are commonly used Econometric models for dynamic Economic behavior which have been adopted in practice to predict behavior of individuals and firms from schooling and job choices to strategic decisions in market competition. These models feature optimizing agents who choose among a finite set of options in a sequence of periods and receive choice-specific payoffs that depend on both variables that are observed by the agent and recorded in the data and variables that are only observed by the agent but not recorded in the data. Existing work in Econometrics assumes that optimizing agents are fully rational and requires finding a functional fixed point to find the optimal policy. We show that in an important class of discrete choice models the value function is globally concave in the policy. That means that simple algorithms that do not require fixed point computation, such as the policy gradient algorithm, globally converge to the optimal policy. This finding can both be used to relax behavioral assumption regarding the optimizing agents and to facilitate Econometric analysis of dynamic behavior. In particular, we demonstrate significant computational advantages in using a simple implementation policy gradient algorithm over existing "nested fixed point" algorithms used in Econometrics.</p> 
### 453.[Efficient Policy Learning from Surrogate-Loss Classification Reductions](https://proceedings.icml.cc/book/3693.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2767-Paper.pdf)
  Andrew Bennett, Nathan Kallus [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2767-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2767-Supplemental.pdf)
> <p>Recent work on policy learning from observational data has highlighted the importance of efficient policy evaluation and has proposed reductions to weighted (cost-sensitive) classification. But, efficient policy evaluation need not yield efficient estimation of policy parameters. We consider the estimation problem given by a weighted surrogate-loss classification with any score function, either direct, inverse-propensity-weighted, or doubly robust. We show that, under a correct specification assumption, the weighted classification formulation need not be efficient for policy parameters. We draw a contrast to actual (possibly weighted) binary classification, where correct specification implies a parametric model, while for policy learning it only implies a semi-parametric model. In light of this, we instead propose an estimation approach based on generalized method of moments, which is efficient for the policy parameters. We propose a particular method based on recent developments on solving moment problems using neural networks and demonstrate the efficiency and regret benefits of this method empirically.</p> 
### 454.[On Contrastive Learning for Likelihood-free Inference ](https://proceedings.icml.cc/book/3694.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2772-Paper.pdf)
  Conor Durkan, Iain Murray, George Papamakarios [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2772-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2772-Supplemental.pdf)
> <p>Likelihood-free methods perform parameter inference in stochastic simulator models where evaluating the likelihood is intractable but sampling synthetic data is possible. One class of methods for this likelihood-free problem uses a classifier to distinguish between pairs of parameter-observation samples generated using the simulator and samples drawn from some reference distribution, implicitly learning a density ratio proportional to the likelihood. Another popular class of methods proposes to fit a conditional distribution to the parameter posterior directly, and a particular recent variant allows for the use of flexible neural density estimators for this task. In this work, we show that both of these approaches can be unified under a general contrastive learning scheme, and clarify how they should be run and compared.</p> 
### 455.[Obtaining Adjustable Regularization for Free via Iterate Averaging](https://proceedings.icml.cc/book/3695.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2773-Paper.pdf)
  Jingfeng Wu, Vladimir Braverman, Lin Yang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2773-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2773-Supplemental.pdf)
> <p>Regularization for optimization is a crucial technique to avoid overfitting in machine learning. In order to obtain the best performance, we usually train a model by tuning the regularization parameters. It becomes costly, however, when a single round of training takes significant amount of time. Very recently, Neu and Rosasco show that if we run stochastic gradient descent (SGD) on linear regression problems, then by averaging the SGD iterates properly, we obtain a regularized solution. It left open whether the same phenomenon can be achieved for other optimization problems and algorithms. In this paper, we establish a complete theory by showing an averaging scheme that provably converts the iterates of SGD on an arbitrary strongly convex and smooth objective function to its regularized counterpart with an adjustable regularization parameter. Our approaches can be used for accelerated and preconditioned optimization methods as well. We further show that the same methods work empirically on more general optimization objectives including neural networks. In sum, we obtain adjustable regularization for free for a large class of optimization problems and resolve an open question raised by Neu and Rosasco.</p> 
### 456.[Invariant Risk Minimization Games](https://proceedings.icml.cc/book/3696.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2777-Paper.pdf)
  Kartik Ahuja, Karthikeyan Shanmugam, Kush Varshney, Amit Dhurandhar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2777-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2777-Supplemental.pdf)
> <p>The standard risk minimization paradigm of machine learning is brittle when operating in environments whose test distributions are different from the training distribution due to spurious correlations. Training on data from many environments and finding invariant predictors reduces the effect of spurious features by concentrating models on features that have a causal relationship with the outcome. In this work, we pose such invariant risk minimization as finding the Nash equilibrium of an ensemble game among several environments. By doing so, we develop a simple training algorithm that uses best response dynamics and, in our experiments, yields similar or better empirical accuracy with much lower variance than the challenging bi-level optimization problem of Arjovsky et.al 2019. One key theoretical contribution is showing that the set of Nash equilibria for the proposed game are equivalent to the set of invariant predictors for any finite number of environments, even with nonlinear classifiers and transformations. As a result, our method also retains the generalization guarantees to a large set of environments shown in Arjovsky et.al 2019. The proposed algorithm adds to the collection of successful game-theoretic machine learning algorithms such as generative adversarial networks.</p> 
### 457.[Video Prediction via Example Guidance](https://proceedings.icml.cc/book/3697.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2778-Paper.pdf)
  Jingwei Xu, Harry (Huazhe) Xu, Bingbing Ni, Xiaokang Yang, Trevor Darrell [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2778-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2778-Supplemental.pdf)
> <p>In video prediction tasks, one major challenge is to capture the multi-modal nature of future contents and dynamics. In this work, we propose a simple yet effective framework that can predict diverse and plausible future states. The key insight is that the potential distribution of a sequence could be approximated with analogous ones in a repertoire of training pool, namely, expert examples. By further incorporating a novel optimization scheme into the training procedure, plausible and diverse predictions can be sampled efficiently from distribution constructed from the retrieved examples.  Meanwhile, our method could be seamlessly integrated with existing stochastic predictive models; significant enhancement is observed with comprehensive experiments in both quantitative and qualitative aspects. We also demonstrate the generalization ability to predict the motion of unseen class, i.e., without access to corresponding data during training phase.</p> 
### 458.[Learning Discrete Structured Representations by Adversarially Maximizing Mutual Information](https://proceedings.icml.cc/book/3698.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2785-Paper.pdf)
  Karl Stratos, Sam Wiseman [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2785-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2785-Supplemental.pdf)
> <p>We propose learning discrete structured representations from unlabeled data by maximizing the mutual information between a structured latent variable and a target variable. Calculating mutual information is intractable in this setting. Our key technical contribution is an adversarial objective that can be used to tractably estimate mutual information assuming only the feasibility of cross entropy calculation. We develop a concrete realization of this general formulation with Markov distributions over binary encodings. We report critical and unexpected findings on practical aspects of the objective such as the choice of variational priors. We apply our model on document hashing and show that it outperforms current best baselines based on straight-through estimators and vector quantization. It also yields highly compressed interpretable representations.</p> 
### 459.[Reinforcement Learning in Feature Space: Matrix Bandit, Kernels, and Regret Bound](https://proceedings.icml.cc/book/3699.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2789-Paper.pdf)
  Lin Yang, Mengdi Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2789-Metadata.json)
> Exploration in reinforcement learning (RL) suffers from the curse of dimensionality when the state-action space is large. A common practice is to parameterize the high-dimensional value and policy functions using given features. However existing methods either have no theoretical guarantee or suffer a regret that is exponential in the planning horizon $H$.In this paper, we propose an online RL algorithm, namely the MatrixRL, that leverages ideas from linear bandit  to learn a low-dimensional representation of the probability  transition model while carefully balancing the exploitation-exploration tradeoff. We show that MatrixRL achieves a regret bound ${O}\big(H^2d\log T\sqrt{T}\big)$ where $d$ is the number of features, independent with the number of state-action pairs. MatrixRL has an equivalent kernelized version, which is able to work with an arbitrary kernel Hilbert space without using explicit features. In this case, the kernelized MatrixRL satisfies a regret bound ${O}\big(H^2\wt{d}\log T\sqrt{T}\big)$, where $\wt{d}$ is the effective dimension of the kernel space.
### 460.[Frequency Bias in Neural Networks for Input of Non-Uniform Density](https://proceedings.icml.cc/book/3700.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2790-Paper.pdf)
  Ronen Basri, Meirav Galun, Amnon Geifman, David Jacobs, Yoni Kasten, Shira Kritchman [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2790-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2790-Supplemental.pdf)
> Recent works have partly attributed the generalization ability of over-parameterized neural networks to frequency bias -- networks trained with gradient descent on data drawn from a uniform distribution find a low frequency fit before high frequency ones. As realistic training sets are not drawn from a uniform distribution, we here use the Neural Tangent Kernel (NTK) model to explore the effect of variable density on training dynamics. Our results, which combine analytic and empirical observations, show that when learning a pure harmonic function of frequency $\kappa$, convergence at a point $\x \in \Sphere^{d-1}$ occurs in time $O(\kappa^d/p(\x))$ where $p(\x)$ denotes the local density at $\x$. Specifically, for data in $\Sphere^1$ we analytically derive the eigenfunctions of the kernel associated with the NTK for two-layer networks. We further prove convergence results for deep, fully connected networks with respect to the spectral decomposition of the NTK. Our empirical study highlights similarities and differences between deep and shallow networks in this model.
### 461.[Constrained Markov Decision Processes via Backward Value Functions](https://proceedings.icml.cc/book/3701.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2791-Paper.pdf)
  Harsh Satija, Philip Amortila, Joelle Pineau [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2791-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2791-Supplemental.pdf)
> <p>Although Reinforcement Learning (RL) algorithms have found tremendous success in simulated domains, they often cannot directly be applied to physical systems, especially in cases where there are hard constraints to satisfy (e.g. on safety or resources). In standard RL, the agent is incentivized to explore any behavior as long as it maximizes rewards, but in the real world, undesired behavior can damage either the system or the agent in a way that breaks the learning process itself. In this work, we model the problem of learning with constraints as a Constrained Markov Decision Process and provide a new on-policy formulation for solving it. A key contribution of our approach is to translate cumulative cost constraints into state-based constraints. Through this, we define a safe policy improvement method which maximizes returns while ensuring that the constraints are satisfied at every step. We provide theoretical guarantees under which the agent converges while ensuring safety over the course of training. We also highlight the computational advantages of this approach. The effectiveness of our approach is demonstrated on safe navigation tasks and in safety-constrained versions of MuJoCo environments, with deep neural networks. </p> 
### 462.[Adding seemingly uninformative labels helps in low data regimes](https://proceedings.icml.cc/book/3702.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2797-Paper.pdf)
  Christos Matsoukas, Albert Bou Hernandez, Yue Liu, Karin Dembrower, Gisele Miranda, Emir Konuk, Johan Fredin Haslum, Athanasios Zouzos, Peter Lindholm, Fredrik Strand, Kevin Smith [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2797-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2797-Supplemental.pdf)
> <p>Evidence suggests that networks trained on large datasets generalize well not solely because of the numerous training examples, but also class diversity which encourages learning of enriched features. This raises the question of whether this remains true when data is scarce - is there an advantage to learning with additional labels in low-data regimes? In this work, we consider a task that requires difficult-to-obtain expert annotations: tumor segmentation in mammography images. We show that, in low-data settings, performance can be improved by complementing the expert annotations with seemingly uninformative labels from non-expert annotators, turning the task into a multi-class problem. We reveal that these gains increase when less expert data is available, and uncover several interesting properties through further studies. We demonstrate our findings on CSAW-S, a new dataset that we introduce here, and confirm them on two public datasets.</p> 
### 463.[When are Non-Parametric Methods Robust?](https://proceedings.icml.cc/book/3703.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2812-Paper.pdf)
  Robi Bhattacharjee, Kamalika Chaudhuri [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2812-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2812-Supplemental.pdf)
> <p>A growing body of research has shown that many classifiers are susceptible to adversarial examples -- small strategic modifications to test inputs that lead to misclassification. In this work, we study general non-parametric methods, with a view towards understanding when they are robust to these modifications. We establish general conditions under which non-parametric methods are r-consistent -- in the sense that they converge to optimally robust and accurate classifiers in the large sample limit. </p>  <p>Concretely, our results show that when data is well-separated, nearest neighbors and kernel classifiers are r-consistent, while histograms are not. For general data distributions, we prove that preprocessing by Adversarial Pruning (Yang et. al., 2019)-- that makes data well-separated -- followed by nearest neighbors or kernel classifiers also leads to r-consistency. </p> 
### 464.[Learning Calibratable Policies using Programmatic Style-Consistency](https://proceedings.icml.cc/book/3704.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2816-Paper.pdf)
  Eric Zhan, Albert Tseng, Yisong Yue, Adith Swaminathan, Matthew Hausknecht [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2816-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2816-Supplemental.pdf)
> <p>We study the important and challenging problem of controllable generation of long-term sequential behaviors.  Solutions to this problem would impact many applications, such as calibrating behaviors of AI agents in games or predicting player trajectories in sports. In contrast to the well-studied areas of controllable generation of images, text,and speech, there are significant challenges that are unique to or exacerbated by generating long-term behaviors: how should we specify the factors of variation to control, and how can we ensure that the generated temporal behavior faithfully demonstrates diverse styles?  In this paper,  we leverage large amounts of raw behavioral data to learn policies that can be calibrated to generate a diverse range of behavior styles (e.g., aggressive versus passive play in sports). Inspired by recent work on leveraging programmatic labeling functions, we present a novel framework that combines imitation learning with data programming to learn style-calibratable policies. Our primary technical contribution is a formal notion of style-consistency as a learning objective, and its integration with conventional imitation learning approaches.  We evaluate our framework using demonstrations from professional basketball players and agents in the MuJoCo physics environment, and show that our learned policies can be accurately calibrated to generate interesting behavior styles in both domains.</p> 
### 465.[Momentum Improves Normalized SGD](https://proceedings.icml.cc/book/3705.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2819-Paper.pdf)
  Ashok Cutkosky, Harsh Mehta [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2819-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2819-Supplemental.pdf)
> We provide an improved analysis of normalized SGD showing that adding momentum provably removes the need for large batch sizes on non-convex objectives. Then, we consider the case of objectives with bounded second derivative and show that in this case a small tweak to the momentum formula allows normalized SGD with momentum to find an $\epsilon$-critical point in $O(1/\epsilon^{3.5})$ iterations, matching the best-known rates without accruing any logarithmic factors or dependence on dimension. We provide an adaptive learning rate schedule that automatically improves convergence rates when the variance in the gradients is small. Finally, we show that our method is effective when employed on popular large scale tasks such as ResNet-50 and BERT pretraining, matching the performance of the disparate methods used to get state-of-the-art results on both tasks.
### 466.[Parameter-free, Dynamic, and Strongly-Adaptive Online Learning](https://proceedings.icml.cc/book/3706.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2820-Paper.pdf)
  Ashok Cutkosky [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2820-Metadata.json)
> We provide a new online learning algorithm that for the first time combines several disparate notions of adaptivity. First, our algorithm obtains a ``parameter-free&#x27;&#x27; regret bound that adapts to the norm of the comparator and the squared norm of the size of the gradients it observes. Second, it obtains a ``strongly-adaptive&#x27;&#x27; regret bound, so that for any given interval of length $N$, the regret over the interval is $\tilde O(\sqrt{N})$. Finally, our algorithm obtains an optimal ``dynamic&#x27;&#x27; regret bound: for any sequence of comparators with path-length $P$, our algorithm obtains regret $\tilde O(\sqrt{PN})$ over intervals of length $N$. Our primary technique for achieving these goals is a new method of combining constrained online learning regret bounds that does not rely on an expert meta-algorithm to aggregate learners.
### 467.[PENNI: Pruned Kernel Sharing for Efficient CNN Inference](https://proceedings.icml.cc/book/3707.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2823-Paper.pdf)
  Shiyu Li, Edward Hanson, Hai Li, Yiran Chen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2823-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2823-Supplemental.pdf)
> <p>Although state-of-the-art (SOTA) CNNs achieve outstanding performance on various tasks, their high computation demand and massive number of parameters make it difficult to deploy these SOTA CNNs onto resource-constrained devices. Previous works on CNN acceleration utilize low-rank approximation of the original convolution layers to reduce computation cost. However, these methods are very difficult to conduct upon sparse models, which limits execution speedup since redundancies within the CNN model are not fully exploited. We argue that kernel granularity decomposition can be conducted with low-rank assumption while exploiting the redundancy within the remaining compact coefficients. Based on this observation, we propose PENNI, a CNN model compression framework that is able to achieve model compactness and hardware efficiency simultaneously by (1) implementing kernel sharing in convolution layers via a small number of basis kernels and (2) alternately adjusting bases and coefficients with sparse constraints. Experiments show that we can prune 97% parameters and 92% FLOPs on ResNet18 CIFAR10 with no accuracy loss, and achieve a 44% reduction in run-time memory consumption and a 53% reduction in inference latency.</p> 
### 468.[Optimal transport mapping via input convex neural networks](https://proceedings.icml.cc/book/3708.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2824-Paper.pdf)
  Ashok Vardhan Makkuva, Amirhossein Taghvaei, Sewoong Oh, Jason Lee [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2824-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2824-Supplemental.pdf)
> <p>In this paper, we present a novel and principled approach to learn the optimal transport between two distributions, from samples. Guided by the optimal transport theory, we learn the optimal Kantorovich potential which induces the optimal transport map. This involves learning two convex functions, by solving a novel minimax optimization. Building upon recent advances in the field of input convex neural networks, we propose a new framework to estimate the optimal transport mapping as the gradient of a convex function that is trained via minimax optimization. Numerical experiments confirm the accuracy of the learned transport map. </p>  <p>Our approach can be readily used to train a deep generative model. When trained between a simple distribution in the latent space and a target distribution, the learned optimal transport map acts as a deep generative model. Although scaling this to a large dataset is challenging, we demonstrate two important strengths over standard adversarial training: robustness and discontinuity. As we seek the optimal transport, the learned generative model provides the same mapping regardless of how we initialize the neural networks. Further, a gradient of a neural network can easily represent discontinuous mappings, unlike standard neural networks that are constrained to be continuous. This allows the learned transport map to match any target distribution with many discontinuous supports and achieve sharp boundaries. </p> 
### 469.[All in the (Exponential) Family: Information Geometry and Thermodynamic Variational Inference](https://proceedings.icml.cc/book/3709.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2826-Paper.pdf)
  Rob Brekelmans, Vaden Masrani, Frank Wood, Greg Ver Steeg, Aram Galstyan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2826-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2826-Supplemental.zip)
> <p>While the Evidence Lower Bound (ELBO) has become a ubiquitous objective for variational inference, the recently proposed Thermodynamic Variational Objective (TVO) leverages thermodynamic integration to provide a tighter and more general family of bounds.  In previous work, the tightness of these bounds was not known, grid search was used to choose a `schedule' of intermediate distributions, and model learning suffered with ostensibly tighter bounds. We interpret the geometric mixture curve common to TVO and related path sampling methods using the geometry of exponential families, which allows us to characterize the gap in TVO bounds as a sum of KL divergences along a given path.  Further, we propose a principled technique for choosing intermediate distributions using equal spacing in the moment parameters of our exponential family.  We demonstrate that this scheduling approach adapts to the shape of the integrand defining the TVO objective and improves overall performance. Additionally, we derive a reparameterized gradient estimator which empirically allows the TVO to benefit from additional, well chosen partitions. Finally, we provide a unified framework for understanding thermodynamic integration and the TVO in terms of Taylor series remainders.</p> 
### 470.[SimGANs: Simulator-Based Generative Adversarial Networks for ECG Synthesis to Improve Deep ECG Classification](https://proceedings.icml.cc/book/3710.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2829-Paper.pdf)
  Tomer Golany, Kira Radinsky, Daniel Freedman [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2829-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2829-Supplemental.pdf)
> <p>Generating training examples for supervised tasks is a long sought after goal in AI. We study the problem of heart signal electrocardiogram (ECG) synthesis for improved heartbeat classification. ECG synthesis is challenging: the generation of training examples for such biological-physiological systems is not straightforward, due to their dynamic nature in which the various parts of the system interact in complex ways. However, an understanding of these dynamics has been developed for years in the form of mathematical process simulators. We study how to incorporate this knowledge into the generative process by leveraging a biological simulator for the task of ECG classification. Specifically, we use a system of ordinary differential equations representing heart dynamics, and incorporate this ODE system into the optimization process of a generative adversarial network to create biologically plausible ECG training examples.  We perform empirical evaluation and show that heart simulation knowledge during the generation process improves ECG classification.</p> 
### 471.[Is There a Trade-Off Between Fairness and Accuracy? A Perspective Using Mismatched Hypothesis Testing](https://proceedings.icml.cc/book/3711.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2831-Paper.pdf)
  Sanghamitra Dutta, Dennis Wei, Hazar Yueksel, Pin-Yu Chen, Sijia Liu, Kush Varshney [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2831-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2831-Supplemental.pdf)
> <p>A trade-off between accuracy and fairness is almost taken as a given in the existing literature on fairness in machine learning. Yet, it is not preordained that accuracy should decrease with increased fairness. Novel to this work, we examine fair classification through the lens of mismatched hypothesis testing: trying to find a classifier that distinguishes between two ideal distributions when given two mismatched distributions that are biased. Using Chernoff information, a tool in information theory, we theoretically demonstrate that, contrary to popular belief, there always exist ideal distributions such that optimal fairness and accuracy (with respect to the ideal distributions) are achieved simultaneously: there is no trade-off. Moreover, the same classifier yields the lack of a trade-off with respect to ideal distributions while yielding a trade-off when accuracy is measured with respect to the given (possibly biased) dataset. To complement our main result, we formulate an optimization to find ideal distributions and derive fundamental limits to explain why a trade-off exists on the given biased dataset. We also derive conditions under which active data collection can alleviate the fairness-accuracy trade-off in the real world. Our results lead us to contend that it is problematic to measure accuracy with respect to data that may reflect bias and inequity, and instead, we should be considering accuracy with respect to ideal, unbiased data.</p> 
### 472.[Convex Calibrated Surrogates for the Multi-Label F-Measure](https://proceedings.icml.cc/book/3712.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2842-Paper.pdf)
  Mingyuan Zhang, Harish Guruprasad Ramaswamy, Shivani Agarwal [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2842-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2842-Supplemental.pdf)
> The F-measure is a widely used performance measure for multi-label classification, where multiple labels can be active in an instance simultaneously (e.g. in image tagging, multiple tags can be active in any image). In particular, the F-measure explicitly balances recall (fraction of active labels predicted to be active) and precision (fraction of labels predicted to be active that are actually so), both of which are important in evaluating the overall performance of a multi-label classifier.  As with most discrete prediction problems, however, directly optimizing the F-measure is computationally hard. In this paper, we explore the question of designing convex surrogate losses that are \emph{calibrated} for the F-measure -- specifically, that have the property that minimizing the surrogate loss yields (in the limit of sufficient data) a Bayes optimal multi-label classifier for the F-measure. We show that the F-measure for an $s$-label problem, when viewed as a $2^s \times 2^s$ loss matrix, has rank at most $s^2+1$, and apply a result of Ramaswamy et al. (2014) to design a family of convex calibrated surrogates for the F-measure. The resulting surrogate risk minimization algorithms can be viewed as decomposing the multi-label F-measure learning problem into $s^2+1$ binary class probability estimation problems. We also provide a quantitative regret transfer bound for our surrogates, which allows any regret guarantees for the binary problems to be transferred to regret guarantees for the overall F-measure problem, and discuss a connection with the algorithm of Dembczynski et al. (2013). Our experiments confirm our theoretical findings.  
### 473.[Learning Robot Skills with Temporal Variational Inference](https://proceedings.icml.cc/book/3713.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2847-Paper.pdf)
  Tanmay Shankar, Abhinav Gupta [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2847-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2847-Supplemental.pdf)
> <p>In this paper, we address the discovery of robotic options from demonstrations in an unsupervised manner. Specifically, we present a framework to jointly learn low-level control policies and higher-level policies of how to use them from demonstrations of a robot performing various tasks. By representing options as continuous latent variables, we frame the problem of learning these options as latent variable inference. We then present a temporally causal variant of variational inference based on a temporal factorization of trajectory likelihoods, that allows us to infer options in an unsupervised manner. We demonstrate the ability of our framework to learn such options across three robotic demonstration datasets.</p> 
### 474.[Adaptive Gradient Descent without Descent](https://proceedings.icml.cc/book/3714.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2854-Paper.pdf)
  Konstantin Mishchenko, Yura Malitsky [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2854-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2854-Supplemental.pdf)
> <p>We present a strikingly simple proof that two rules are sufficient to automate gradient descent: 1) don't increase the stepsize too fast and 2) don't overstep the local curvature. No need for functional values, no line search, no information about the function except for the gradients. By following these rules, you get a method adaptive to the local geometry, with convergence guarantees depending only on smoothness in a neighborhood of a solution. Given that the problem is convex, our method will converge even if the global smoothness constant is infinity. As an illustration, it can minimize arbitrary continuously twice-differentiable convex function. We examine its performance on a range of convex and nonconvex problems, including logistic regression and matrix factorization.</p> 
### 475.[An end-to-end Differentially Private Latent Dirichlet Allocation Using a Spectral Algorithm](https://proceedings.icml.cc/book/3715.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2863-Paper.pdf)
  Christopher DeCarolis, Mukul Ram, Seyed  Esmaeili, Yu-Xiang Wang, Furong Huang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2863-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2863-Supplemental.pdf)
> <p>We provide an end-to-end differentially private spectral algorithm for learning LDA, based on matrix/tensor decompositions, and establish theoretical guarantees on utility/consistency of the estimated model parameters. We represent the spectral algorithm as a computational graph. Noise can be injected along the edges of this graph to obtain differential privacy. We identify subsets of edges, named ``configurations'', such that adding noise to all edges in such a subset guarantees differential privacy of the end-to-end spectral algorithm. We characterize the sensitivity of the edges with respect to the input and thus estimate the amount of noise to be added to each edge for any required privacy level. We then characterize the utility loss  for each configuration as a function of injected noise.  Overall, by combining the sensitivity and utility characterization, we obtain an end-to-end differentially private spectral algorithm for LDA and identify which configurations outperform others under specific regimes. We are the first to achieve utility guarantees under a required level of differential privacy for learning in LDA. We additionally show that our method systematically outperforms differentially private variational inference.</p> 
### 476.[Dual Mirror Descent for Online Allocation Problems](https://proceedings.icml.cc/book/3716.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2866-Paper.pdf)
  Haihao Lu, Santiago Balseiro, Vahab Mirrokni [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2866-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2866-Supplemental.zip)
> <p>We consider online allocation problems with concave revenue functions and resource constraints, which are central problems in revenue management and online advertising. In these settings, requests arrive sequentially during a finite horizon and, for each request, a decision maker needs to choose an action that consumes a certain amount of resources and generates revenue. The revenue function and resource consumption of each request are drawn independently and at random from a probability distribution that is unknown to the decision maker. The objective is to maximize cumulative revenues subject to a constraint on the total consumption of resources. </p>  <p>We design a general class of algorithms that achieve sub-linear expected regret compared to the hindsight optimal allocation. Our algorithms operate in the Lagrangian dual space: they maintain a dual multiplier for each resource that is updated using online mirror descent. By choosing the reference function accordingly, we recover dual sub-gradient descent and dual exponential weights algorithm. The resulting algorithms are simple, efficient, and shown to attain the optimal order of regret when the length of the horizon and the initial number of resources are scaled proportionally. We discuss applications to online bidding in repeated auctions with budget constraints and online proportional matching with high entropy.</p> 
### 477.[Optimal Robust Learning of Discrete Distributions from Batches](https://proceedings.icml.cc/book/3717.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2870-Paper.pdf)
  Ayush Jain, Alon Orlitsky [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2870-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2870-Supplemental.zip)
> <p>Many applications, including natural language processing, sensor networks, collaborative filtering, and federated learning, call for estimating distributions from data collected in batches, some  of which may be untrustworthy, erroneous, faulty, or even adversarial.</p>  <p>Previous estimators for this setting ran in exponential time, and for some regimes required a suboptimal number of batches. We provide the first polynomial-time estimator that is optimal in the number of batches and achieves essentially the best possible estimation accuracy.</p> 
### 478.[BoXHED: Boosted eXact Hazard Estimator with Dynamic covariates](https://proceedings.icml.cc/book/3718.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2882-Paper.pdf)
  Xiaochen Wang, Arash Pakbin, Bobak Mortazavi, Hongyu Zhao, Donald Lee [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2882-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2882-Supplemental.pdf)
> <p>The proliferation of medical monitoring devices makes it possible to track health vitals at high frequency, enabling the development of dynamic health risk scores that change with the underlying readings. Survival analysis, in particular hazard estimation, is well-suited to analyzing this stream of data to predict disease onset as a function of the time-varying vitals. This paper introduces the software package BoXHED (pronounced `box-head') for nonparametrically estimating hazard functions via gradient boosting. BoXHED 1.0 is a novel tree-based implementation of the generic estimator proposed in Lee et al. (2017), which was designed for handling time-dependent covariates in a fully nonparametric manner. BoXHED is also the first publicly available software implementation for Lee et al. (2017). Applying BoXHED to cardiovascular disease onset data from the Framingham Heart Study reveals novel interaction effects among known risk factors, potentially resolving an open question in clinical literature.</p> 
### 479.[Unlabelled Data Improves Bayesian Uncertainty Calibration under Covariate Shift  ](https://proceedings.icml.cc/book/3719.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2888-Paper.pdf)
  Alexander Chan, Ahmed Alaa, Zhaozhi Qian, Mihaela van der Schaar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2888-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2888-Supplemental.pdf)
> <p>Modern neural networks have proven to be powerful function approximators, providing state of the art performance in a wide variety of applications. They however fall short in their ability to quantify their confidence in their predictions, which can be crucial in high-stakes applications involving critical decision-making. Bayesian neural networks (BNNs) aim to solve this problem by placing a prior distribution over the network parameters, thus inducing a posterior predictive distribution that encapsulates any uncertainty about the prediction. While existing variants of BNNs are able to produce reliable, albeit approximate, uncertainty estimates over in-distribution data, it has been shown that they tend to be over-confident in predictions made on target data whose distribution over features differs from the training data, i.e., the covariate shift setup. In this paper, we develop an approximate Bayesian inference scheme based on posterior regularisation, where we use information from unlabelled target data to produce more appropriate uncertainty estimates for ''covariate-shifted'' predictions. Our regulariser can be easily applied to many of the current network architectures and inference schemes --- here, we demonstrate its usefulness in Monte Carlo Dropout, showing that it much more appropriately quantifies its uncertainty with very little extra work. Empirical evaluations demonstrate that our method performs competitively compared to Bayesian and frequentist approaches to uncertainty estimation in neural networks.</p> 
### 480.[Universal Equivariant Multilayer Perceptrons](https://proceedings.icml.cc/book/3720.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2889-Paper.pdf)
  Siamak Ravanbakhsh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2889-Metadata.json)
> <p>Group invariant and equivariant Multilayer Perceptrons (MLP), also known as Equivariant Networks, have achieved remarkable success in learning on a variety of data structures, such as sequences, images, sets, and graphs. Using tools from group theory, this paper proves the universality of a broad class of equivariant MLPs with a single hidden layer.  In particular, it is shown that having a hidden layer on which the group acts regularly is sufficient for universal equivariance (invariance). A corollary is unconditional universality of equivariant MLPs for Abelian groups, such as CNNs with a single hidden layer. A second corollary is the universality of equivariant MLPs with a high-order hidden layer, where we give both group-agnostic bounds and means for calculating group-specific bounds on the order of hidden layer that guarantees universal equivariance (invariance). </p> 
### 481.[Improving generalization by controlling label-noise information in neural network weights](https://proceedings.icml.cc/book/3721.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2896-Paper.pdf)
  Hrayr Harutyunyan, Kyle Reing, Greg Ver Steeg, Aram Galstyan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2896-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2896-Supplemental.pdf)
> In the presence of noisy or incorrect labels, neural networks have the undesirable tendency to memorize information about the noise. Standard regularization techniques such as dropout, weight decay or data augmentation sometimes help, but do not prevent this behavior. If one considers neural network weights as random variables that depend on the data and stochasticity of training, the amount of memorized information can be quantified with the Shannon mutual information between weights and the vector of all training labels given inputs, $I(w : \Y \mid \X)$. We show that for any training algorithm, low values of this term correspond to reduction in memorization of label-noise and better generalization bounds. To obtain these low values, we propose training algorithms that employ an auxiliary network that predicts gradients in the final layers of a classifier without accessing labels. We illustrate the effectiveness of our approach on versions of MNIST, CIFAR-10, and CIFAR-100 corrupted with various noise models, and on a large-scale dataset Clothing1M that has noisy labels.
### 482.[DeepMatch: Balancing Deep Covariate Representations for Causal Inference Using Adversarial Training](https://proceedings.icml.cc/book/3722.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2897-Paper.pdf)
  Nathan Kallus [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2897-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2897-Supplemental.pdf)
> <p>We study optimal covariate balance for causal inferences from observational data when rich covariates and complex relationships necessitate flexible modeling with neural networks. Standard approaches such as propensity weighting and matching/balancing fail in such settings due to miscalibrated propensity nets and inappropriate covariate representations, respectively. We propose a new method based on adversarial training of a weighting and a discriminator network that effectively addresses this methodological gap. This is demonstrated through new theoretical characterizations and empirical results on both synthetic and clinical data showing how causal analyses can be salvaged in such challenging settings.</p> 
### 483.[Bayesian Optimisation over Multiple Continuous and Categorical Inputs](https://proceedings.icml.cc/book/3723.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2906-Paper.pdf)
  Binxin Ru, Ahsan Alvi, Vu Nguyen, Michael Osborne, Stephen Roberts [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2906-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2906-Supplemental.pdf)
> <p>Efficient optimisation of black-box problems that comprise both continuous and categorical inputs is important, yet poses significant challenges. Current approaches, like one-hot encoding, severely increase the dimension of the search space, while separate modelling of category-specific data is sample-inefficient. Both frameworks are not scalable to practical applications involving multiple categorical variables, each with multiple possible values. We propose a new approach, Continuous and Categorical Bayesian Optimisation (CoCaBO), which combines the strengths of multi-armed bandits and Bayesian optimisation to select values for both categorical and continuous inputs. We model this mixed-type space using a Gaussian Process kernel, designed to allow sharing of information across multiple categorical variables; this allows CoCaBO to leverage all available data efficiently. We extend our method to the batch setting and propose an efficient selection procedure that dynamically balances exploration and exploitation whilst encouraging batch diversity.  We demonstrate empirically that our method outperforms existing approaches on both synthetic and real-world optimisation tasks with continuous and categorical inputs.</p> 
### 484.[Generalization and Representational Limits of Graph Neural Networks](https://proceedings.icml.cc/book/3724.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2911-Paper.pdf)
  Vikas Garg, Stefanie Jegelka, Tommi Jaakkola [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2911-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2911-Supplemental.pdf)
> <p>We address two fundamental questions about graph neural networks (GNNs).  First, we prove that several important graph properties cannot be discriminated by GNNs that rely entirely on local information. Such GNNs include the standard message passing models, and more powerful spatial variants that exploit local graph structure (e.g., via relative orientation of messages, or local port ordering) to distinguish neighbors of each node.  Our treatment includes a novel graph-theoretic formalism. </p>  <p>Second, we provide the first data dependent generalization bounds for message passing GNNs.  This analysis explicitly accounts for the local permutation invariance of GNNs. Our bounds are much tighter than existing VC-dimension based guarantees for GNNs, and are comparable to Rademacher bounds for recurrent neural networks.</p> 
### 485.[Multi-Precision Policy Enforced Training (MuPPET) : A Precision-Switching Strategy for Quantised Fixed-Point Training of CNNs](https://proceedings.icml.cc/book/3725.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2917-Paper.pdf)
  Aditya Rajagopal, Diederik Vink, Stylianos Venieris, Christos-Savvas Bouganis [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2917-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2917-Supplemental.pdf)
> <p>Large-scale convolutional neural networks (CNNs) suffer from very long training times, spanning from hours to weeks, limiting the productivity and experimentation of deep learning practitioners. As networks grow in size and complexity, training time can be reduced through low-precision data representations and computations. However, in doing so the final accuracy suffers due to the problem of vanishing gradients. Existing state-of-the-art methods combat this issue by means of a mixed-precision approach utilising two different precision levels, FP32 (32-bit floating-point) and FP16/FP8 (16-/8-bit floating-point), leveraging the hardware support of recent GPU architectures for FP16 operations to obtain performance gains. This work pushes the boundary of quantised training by employing a multilevel optimisation approach that utilises multiple precisions including low-precision fixed-point representations. The novel training strategy, MuPPET, combines the use of multiple number representation regimes together with a precision-switching mechanism that decides at run time the transition point between precision regimes. Overall, the proposed strategy tailors the training process to the hardware-level capabilities of the target hardware architecture and yields improvements in training time and energy efficiency compared to state-of-the-art approaches. Applying MuPPET on the training of AlexNet, ResNet18 and GoogLeNet on ImageNet (ILSVRC12) and targeting an NVIDIA Turing GPU, MuPPET achieves the same accuracy as standard full-precision training with training-time speedup of up to 1.84× and an average speedup of 1.58× across the networks.</p> 
### 486.[LowFER: Low-rank Bilinear Pooling for Link Prediction](https://proceedings.icml.cc/book/3726.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2919-Paper.pdf)
  Saadullah Amin, Stalin Varanasi, Katherine Ann Dunfield, Günter Neumann [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2919-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2919-Supplemental.pdf)
> <p>Knowledge graphs are incomplete by nature, representing only a limited number of observed facts about the world knowledge as relations between entities. An important task in statistical relational learning is that of link prediction or knowledge graph completion to partly address this issue. Both linear and non-linear (deep learning based) models have been proposed to solve the problem, with former being parameter efficient and interpretable. Bilinear models, while expressive, are prone to overfitting and lead to quadratic growth of parameters in number of relations. Simpler models have become more standard, with certain constraints on bilinear maps as relation parameters. In this work, we propose a factorized bilinear pooling model, commonly used in multi-modal learning, for better fusion of entities and relations, leading to an efficient and constraints free model. We prove that our model is fully expressive and provide bounds on the entity and relation embedding dimensions and the factorization rank. Our model naturally generalizes TuckER model (Balazevic et al., 2019), which has shown to generalize other models as special cases, by efficient low-rank approximation without compromising much on performance. The model complexity can be controlled by the factorization rank as opposed to the cubic growth of core tensor in TuckER model when entities and relations share the same space. Empirically, we evaluate on real-world datasets, reaching on par or state-of-the-art performance. In extreme low-ranks, the model already outperforms many of the recently proposed methods.</p> 
### 487.[Parameterized Rate-Distortion Stochastic Encoder](https://proceedings.icml.cc/book/3727.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2921-Paper.pdf)
  Quan Hoang, Trung Le, Dinh Phung [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2921-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2921-Supplemental.pdf)
> <p>We propose a novel gradient-based tractable approach for the Blahut-Arimoto (BA) algorithm to compute the rate-distortion function where the BA algorithm is fully parameterized. This results in a rich and flexible framework to learn a new class of stochastic encoders, termed PArameterized RAte-DIstortion Stochastic Encoder (PARADISE). The framework can be applied to a wide range of settings from semi-supervised, multi-task to supervised and robust learning. We show that the training objective of PARADISE can be seen as a form of regularization that helps improve generalization. With an emphasis on robust learning we further develop a novel posterior matching objective to encourage smoothness on the loss function and show that PARADISE can significantly improve interpretability as well as robustness to adversarial attacks on the CIFAR-10 and ImageNet datasets. In particular, on the CIFAR-10 dataset, our model reduces standard and adversarial error rates in comparison to the state-of-the-art by 50% and 41%, respectively without the expensive computational cost of adversarial training.</p> 
### 488.[Incidence Networks for Geometric Deep Learning](https://proceedings.icml.cc/book/3728.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2924-Paper.pdf)
  Marjan Albooyeh, Daniele Bertolini, Siamak Ravanbakhsh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2924-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2924-Supplemental.pdf)
> <p>Sparse incidence tensors can represent a variety of structured data. For example, we may represent attributed graphs using their node-node, node-edge, or edge-edge incidence matrices. In higher dimensions, incidence tensors can represent simplicial complexes and polytopes. In this paper, we formalize incidence tensors, analyze their structure, and present the family of equivariant networks that operate on them. We show that any incidence tensor decomposes into invariant subsets. This decomposition, in turn, leads to a decomposition of the corresponding equivariant linear maps, for which we prove an efficient pooling-and-broadcasting implementation. We demonstrate the effectiveness of this family of networks by reporting state-of-the-art on graph learning tasks for many targets in the QM9 dataset.</p> 
### 489.[Energy-Based Processes for Exchangeable Data](https://proceedings.icml.cc/book/3729.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2926-Paper.pdf)
  Mengjiao Yang, Bo Dai, Hanjun Dai, Dale Schuurmans [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2926-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2926-Supplemental.pdf)
> <p>Recently there has been growing interest in modeling sets with exchangeability such as point clouds. A shortcoming of current approaches is that they restrict the cardinality of the sets considered or can only express limited forms of distribution over unobserved data. To overcome these limitations, we introduce Energy-Based Processes (EBPs), which extend energy based models to exchangeable data while allowing neural network parameterizations of the energy function. A key advantage of these models is the ability to express more flexible distributions over sets without restricting their cardinality. We develop an efficient training procedure for EBPs that demonstrates state-of-the-art performance on a variety of tasks such as point cloud generation, classification, denoising, and image completion</p> 
### 490.[Deep Isometric Learning for Visual Recognition](https://proceedings.icml.cc/book/3730.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2932-Paper.pdf)
  Haozhi Qi, Chong You, Xiaolong Wang, Yi Ma, Jitendra Malik [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2932-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2932-Supplemental.pdf)
> <p>Initialization, residual learning, and normalization are believed to be three indispensable techniques for training very deep convolutional neural networks and obtaining state-of-the-art performance. This paper shows that deep vanilla ConvNets without normalization nor residual structure can also be trained to achieve surprisingly good performance on standard image recognition benchmarks (ImageNet, and COCO). This is achieved by enforcing the convolution kernels to be near isometric during initialization and training, as well as by using a variant of ReLU that is shifted towards being isometric. Further experiments show that if combined with residual structure, such near isometric networks can achieve performances on par with the standard ResNet, even without normalization at all. </p> 
### 491.[Second-Order Provable Defenses against Adversarial Attacks](https://proceedings.icml.cc/book/3731.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2933-Paper.pdf)
  Sahil Singla, Soheil Feizi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2933-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2933-Supplemental.pdf)
> A robustness certificate against adversarial examples is the minimum distance of a given input to the decision boundary of the classifier (or its lower bound). For {\it any} perturbation of the input with a magnitude smaller than the certificate value, the classification output will provably remain unchanged. Computing exact robustness certificates for neural networks is difficult in general since it requires solving a non-convex optimization. In this paper, we provide computationally-efficient robustness certificates for neural networks with differentiable activation functions in two steps. First, we show that if the eigenvalues of the Hessian of the network (curvatures of the network) are bounded (globally or locally), we can compute a robustness certificate in the $l_2$ norm efficiently using convex optimization. Second, we derive a computationally-efficient differentiable upper bound on the curvature of a deep network. We also use the curvature bound as a regularization term during the training of the network to boost its certified robustness. Putting these results together leads to our proposed {\bf C}urvature-based {\bf R}obustness {\bf C}ertificate (CRC) and {\bf C}urvature-based {\bf R}obust {\bf T}raining (CRT). Our numerical results show that CRT leads to significantly higher certified robust accuracy compared to interval-bound propagation based training.
### 492.[Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention](https://proceedings.icml.cc/book/3732.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2935-Paper.pdf)
  Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, Francois Fleuret [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2935-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2935-Supplemental.pdf)
> Transformers achieve remarkable performance in several tasks but due to their quadratic complexity, with respect to the input&#x27;s length, they are prohibitively slow for very long sequences. To address this limitation, we express the self-attention as a linear dot-product of kernel feature maps and make use of the associativity property of matrix products to reduce the complexity from $\bigO{N^2}$ to $\bigO{N}$, where $N$ is the sequence length. We show that this formulation permits an iterative implementation that dramatically accelerates autoregressive transformers and reveals their relationship to recurrent neural networks. Our \textit{Linear Transformers} achieve similar performance to vanilla Transformers and they are up to 4000x faster on autoregressive prediction of very long sequences.
### 493.[Overfitting in adversarially robust deep learning](https://proceedings.icml.cc/book/3733.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2936-Paper.pdf)
  Eric Wong, Leslie Rice, Zico Kolter [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2936-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2936-Supplemental.pdf)
> <p>It is common practice in deep learning to use overparameterized networks and train for as long as possible; there are numerous studies that show, both theoretically and empirically, that such practices surprisingly do not unduly harm the generalization performance of the classifier. In this paper, we empirically study this phenomenon in the setting of adversarially trained deep networks, which are trained to minimize the loss under worst-case adversarial perturbations. We find that overfitting to the training set does in fact harm robust performance to a very large degree in adversarially robust training across multiple datasets (SVHN, CIFAR-10, CIFAR-100, and ImageNet) and perturbation models (L-infinity and L-2). Based upon this observed effect, we show that the performance gains of virtually all recent algorithmic improvements upon adversarial training can be matched by simply using early stopping. We also show that effects such as the double descent curve do still occur in adversarially trained models, yet fail to explain the observed overfitting.  Finally, we study several classical and modern deep learning remedies for overfitting, including regularization and data augmentation, and find that no approach in isolation improves significantly upon the gains achieved by early stopping. </p> 
### 494.[Rethinking Bias-Variance Trade-off for Generalization of Neural Networks](https://proceedings.icml.cc/book/3734.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2946-Paper.pdf)
  Zitong Yang, Yaodong Yu, Chong You, Jacob Steinhardt, Yi Ma [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2946-Metadata.json)
> <p>The classical bias-variance trade-off predicts that bias decreases and variance increase with model complexity, leading to a U-shaped risk curve. Recent work calls this into question for neural networks and other over-parameterized models, for which it is often observed that larger models generalize better. We provide a simple explanation of this by measuring the bias and variance of neural networks: while the bias is {\em monotonically decreasing} as in the classical theory, the variance is {\em unimodal} or bell-shaped: it increases then decreases with the width of the network. We vary the network architecture, loss function, and choice of dataset and confirm that variance unimodality occurs robustly for all models we considered. The risk curve is the sum of the bias and variance curves and displays different qualitative shapes depending on the relative scale of bias and variance, with the double descent in the recent literature as a special case. We corroborate these empirical results with a theoretical analysis of two-layer linear networks with random first layer. Finally, evaluation on out-of-distribution data shows that most of the drop in accuracy comes from increased bias while variance increases by a relatively small amount. Moreover, we find that deeper models decrease bias and increase variance for both in-distribution and out-of-distribution data.</p> 
### 495.[Boosting for Control of Dynamical Systems](https://proceedings.icml.cc/book/3735.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2948-Paper.pdf)
  Naman Agarwal, Nataly Brukhim, Elad Hazan, Zhou Lu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2948-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2948-Supplemental.pdf)
> <p>We study the question of how to aggregate controllers for dynamical systems in order to improve their performance. To this end, we propose a framework of boosting for online control. Our main result is an efficient boosting algorithm that combines weak controllers into a provably more accurate one. Empirical evaluation on a host of control settings supports our theoretical findings. </p> 
### 496.[Frustratingly Simple Few-Shot Object Detection](https://proceedings.icml.cc/book/3736.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2957-Paper.pdf)
  Xin Wang, Thomas Huang, Joseph Gonzalez, Trevor Darrell, Fisher Yu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2957-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2957-Supplemental.pdf)
> <p>Detecting rare objects with a few examples is an emerging problem. Prior works show meta-learning is a promising approach. But, fine-tuning techniques have drawn scant attention. We find that fine-tuning only the last layer of existing detectors on rare classes is crucial to the few-shot object detection task. Such a simple approach outperforms the meta-learning methods by a large margin on current benchmarks and sometimes even doubles the accuracy of the prior methods. However, the high variance in the few samples often leads to the unreliability of existing benchmarks. We revise the evaluation protocols by sampling multiple groups of training examples to obtain stable comparisons and build new benchmarks based on three datasets: Pascal VOC, COCO and LVIS. Again, our fine-tuning approach establishes a new state of the art on the revised benchmarks.</p> 
### 497.[Data-Dependent Differentially Private Parameter Learning for Directed Graphical Models](https://proceedings.icml.cc/book/3737.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2960-Paper.pdf)
  Amrita Roy Chowdhury, Theodoros Rekatsinas, Somesh Jha [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2960-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2960-Supplemental.pdf)
> Directed graphical models (DGMs) are a class of probabilistic models that are widely used for predictive analysis in sensitive domains such as medical diagnostics. In this paper, we present an algorithm for differentially-private learning of the parameters of a DGM. Our solution optimizes for the utility of inference queries over the DGM and \textit{adds noise that is customized to the properties of the private input dataset and the graph structure of the DGM}. To the best of our knowledge, this is the first explicit data-dependent privacy budget allocation algorithm in the context of DGMs. We compare our algorithm with a standard data-independent approach over a diverse suite of  benchmarks and demonstrate that our solution requires a privacy budget that is roughly $3\times$ smaller to obtain the same or higher utility.
### 498.[Adversarial Risk via Optimal Transport and Optimal Couplings](https://proceedings.icml.cc/book/3738.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2962-Paper.pdf)
  Muni Sreenivas Pydi, Varun Jog [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2962-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2962-Supplemental.pdf)
> <p>The accuracy of modern machine learning algorithms deteriorates severely on adversarially manipulated test data. Optimal adversarial risk quantifies the best error rate of any classifier in the presence of adversaries, and optimal adversarial classifiers are sought that minimize adversarial risk. In this paper, we investigate the optimal adversarial risk and optimal adversarial classifiers from an optimal transport perspective. We present a new and simple approach to show that the optimal adversarial risk for binary classification with 0 − 1 loss function is completely characterized by an optimal transport cost between the probability distributions of the two classes, for a suitably defined cost function. We propose a novel coupling strategy that achieves the optimal transport cost for several univariate distributions like Gaussian, uniform and triangular. Using the optimal couplings, we obtain the optimal adversarial classifiers in these settings and show how they differ from optimal classifiers in the absence of adversaries. Based on our analysis, we evaluate algorithm-independent fundamental limits on adversarial risk for CIFAR-10, MNIST, Fashion-MNIST and SVHN datasets, and Gaussian mixtures based on them.</p> 
### 499.[Decoupled Greedy Learning of CNNs](https://proceedings.icml.cc/book/3739.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2966-Paper.pdf)
  Eugene Belilovsky, Michael Eickenberg, Edouard Oyallon [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2966-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2966-Supplemental.pdf)
> <p>A commonly cited inefficiency of neural network training by back-propagation is the update locking problem: each layer must wait for the signal to propagate through the network before updating. In recent years multiple authors have considered alternatives that can alleviate this issue. In this context, we consider a simpler, but more effective, substitute that uses minimal feedback, which we call Decoupled Greedy Learning (DGL). It is based on a greedy relaxation of the joint training objective, recently shown to be effective in the context of Convolutional Neural Networks (CNNs) on large-scale image classification. We consider an optimization of this objective that permits us to decouple the layer training, allowing for layers or modules in networks to be trained with a potentially linear parallelization in layers. We show theoretically and empirically that this approach converges. Then, we empirically find that it can lead to better generalization than sequential greedy optimization and sometimes end-to-end back-propagation. We show an extension of this approach to asynchronous settings, where modules can operate with large communication delays, is possible with the use of a replay buffer. We demonstrate the effectiveness of DGL on the CIFAR-10 dataset against alternatives and on the large-scale ImageNet dataset.</p> 
### 500.[ACFlow: Flow Models for Arbitrary Conditional Likelihoods](https://proceedings.icml.cc/book/3740.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2968-Paper.pdf)
  Yang Li, Shoaib Akbar, Junier Oliva [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2968-Metadata.json)
> Understanding the dependencies among features of a dataset is at the core of most unsupervised learning tasks. However, a majority of generative modeling approaches are focused solely on the joint distribution $p(x)$ and utilize models where it is intractable to obtain the conditional distribution of some arbitrary subset of features $x_u$ given the rest of the observed covariates $x_o$: $p(x_u \mid x_o)$. Traditional conditional approaches provide a model for a \emph{fixed} set of covariates conditioned on another \emph{fixed} set of observed covariates. Instead, in this work we develop a model that is capable of yielding \emph{all} conditional distributions $p(x_u \mid x_o)$ (for arbitrary $x_u$) via tractable conditional likelihoods. We propose a novel extension of (change of variables based) flow generative models, arbitrary conditioning flow models (ACFlow). ACFlow can be conditioned on arbitrary subsets of observed covariates, which was previously infeasible. We further extend ACFlow to model the joint distributions $p(x)$ and arbitrary marginal distributions $p(x_u)$. We also apply ACFlow to the imputation of features, and develop a unified platform for both multiple and single imputation by introducing an auxiliary objective that provides a principled single ``best guess&#x27;&#x27; for flow models. Extensive empirical evaluations show that our model achieves state-of-the-art performance in modeling arbitrary conditional likelihoods in addition to both single and multiple imputation in synthetic and real-world datasets.
### 501.[Can autonomous vehicles identify, recover from, and adapt to distribution shifts?](https://proceedings.icml.cc/book/3741.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2969-Paper.pdf)
  Angelos Filos, Panagiotis Tigkas, Rowan McAllister, Nicholas Rhinehart, Sergey Levine, Yarin Gal [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2969-Metadata.json)
> <p>Out-of-distribution (OOD) driving scenarios are a common failure of learning agents at deployment, typically leading to arbitrary deductions and poorly-informed decisions. In principle, detection of and adaption to OOD scenes can mitigate their adverse effects. However, no benchmark evaluating OOD detection and adaption currently exists to compare methods. In this paper, we introduce an autonomous car novel-scene benchmark, \texttt{CARNOVEL}, to evaluate the robustness of driving agents to a suite of tasks involving distribution shift. We also highlight the limitations of current approaches to novel driving scenes and propose an epistemic uncertainty-aware planning method, called \emph{robust imitative planning} (RIP). Our method can detect and recover from some distribution shifts, reducing the overconfident but catastrophic extrapolations in out-of-training-distribution scenes. When the model's uncertainty quantification is insufficient to suggest a safe course of action by itself, it is used to query the driver for feedback, enabling sample-efficient online adaptation, a variant of our method we term \emph{adaptive robust imitative planning} (AdaRIP).</p> 
### 502.[Leveraging Procedural Generation to Benchmark Reinforcement Learning](https://proceedings.icml.cc/book/3742.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2971-Paper.pdf)
  Karl Cobbe, Chris Hesse, Jacob Hilton, John Schulman [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2971-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2971-Supplemental.pdf)
> <p>We introduce Procgen Benchmark, a suite of 16 procedurally generated game-like environments designed to benchmark both sample efficiency and generalization in reinforcement learning. We believe that the community will benefit from increased access to high quality training environments, and we provide detailed experimental protocols for using this benchmark. We empirically demonstrate that diverse environment distributions are essential to adequately train and evaluate RL agents, thereby motivating the extensive use of procedural content generation. We then use this benchmark to investigate the effects of scaling model size, finding that larger models significantly improve both sample efficiency and generalization.</p> 
### 503.[The Tree Ensemble Layer: Differentiability meets Conditional Computation](https://proceedings.icml.cc/book/3743.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2974-Paper.pdf)
  Hussein Hazimeh, Natalia Ponomareva, Rahul Mazumder, Zhenyu Tan, Petros Mol [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2974-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2974-Supplemental.pdf)
> Neural networks and tree ensembles are state-of-the-art learners, each with its unique statistical and computational advantages. We aim to combine these advantages by introducing a new layer for neural networks, composed of an ensemble of differentiable decision trees (a.k.a. soft trees). While differentiable trees demonstrate promising results in the literature, in practice they are typically slow in training and inference as they do not support conditional computation. We mitigate this issue by introducing a new sparse activation function for sample routing, and implement true conditional computation by developing specialized forward and backward propagation algorithms that exploit sparsity. Our efficient algorithms pave the way for jointly training over deep and wide tree ensembles using first-order methods (e.g., SGD). Experiments on 23 classification datasets indicate over $10$x speed-ups compared to the differentiable trees used in the literature and over $20$x reduction in the number of parameters compared to gradient boosted trees, while maintaining competitive performance. Moreover, experiments on CIFAR, MNIST, and Fashion MNIST indicate that replacing dense layers in CNNs with our tree layer reduces the  test loss by $7$-$53\%$ and the number of parameters by $8$x. We provide an open-source TensorFlow implementation with a Keras API.
### 504.[Near-Tight Margin-Based Generalization Bounds for Support Vector Machines](https://proceedings.icml.cc/book/3744.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2977-Paper.pdf)
  Allan Grønlund, Lior Kamma, Kasper Green Larsen [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2977-Metadata.json)
> <p>Support Vector Machines (SVMs) are among the most fundamental tools for binary classification. </p>  <p>In its simplest formulation, an SVM produces a hyperplane separating two classes of data using the largest possible margin to the data.  The focus on maximizing the margin has been well motivated through numerous generalization bounds. </p>  <p>In this paper, we revisit and improve the classic generalization bounds in terms of margins.  Furthermore, we complement our new generalization bound by a nearly matching lower bound, thus almost settling the generalization performance of SVMs in terms of margins.</p> 
### 505.[Error Estimation for Sketched SVD](https://proceedings.icml.cc/book/3745.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2978-Paper.pdf)
  Miles Lopes, N. Benjamin Erichson, Michael Mahoney [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2978-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2978-Supplemental.pdf)
> <p>In order to compute fast approximations to the singular value decompositions (SVD) of very large matrices, randomized sketching algorithms have become a leading approach. However, a key practical difficulty of sketching an SVD is that the user does not know how far the sketched singular vectors/values are from the exact ones. Indeed, the user may be forced to rely on analytical worst-case error bounds, which do not account for the unique structure of a given problem. As a result, the lack of tools for error estimation often leads to much more computation than is really necessary. To overcome these challenges, this paper develops a fully data-driven bootstrap method that numerically estimates the actual error of sketched singular vectors/values. In particular, this approach allows the user to inspect the quality of a rough initial SVD, and then adaptively predict how much extra work is needed to reach a given error tolerance. Meanwhile, from a computational standpoint, the proposed method incurs only minor cost, because it operates on the (small) output of a sketching algorithm, and it requires no passes over the (large) matrix being factored. Lastly, the proposed method is supported by theoretical guarantees and a very encouraging set of experimental results.</p> 
### 506.[Goal-Aware Prediction: Learning to Model What Matters](https://proceedings.icml.cc/book/3746.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2981-Paper.pdf)
  Suraj Nair, Silvio Savarese, Chelsea Finn [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2981-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2981-Supplemental.pdf)
> <p>Learned dynamics models combined with both planning and policy learning algorithms have shown promise in enabling artificial agents to learn to perform many diverse tasks with limited supervision. However, one of the fundamental challenges in using a learned forward dynamics model is that there exists a mismatch between the objective of the learned model (future state reconstruction), and the downstream planner or policy (completing a specified task). This issue is exacerbated by vision-based control tasks in diverse real-world environments, where the complexity of the real world dwarfs model capacity. In this paper, we propose to direct prediction towards task relevant information, enabling the model to be aware of the current task and encouraging it to only model relevant quantities of the state space, resulting in a learning objective that more closely matches the downstream task. Further, we do so in an entirely self-supervised manner, without the need for a reward function or image labels. We find that our method more effectively models the relevant parts of a scene conditioned on the goal, and as a result significantly outperforms standard task-agnostic dynamics models and model-free reinforcement learning. </p> 
### 507.[Combinatorial Pure Exploration for Dueling Bandit](https://proceedings.icml.cc/book/3747.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2990-Paper.pdf)
  Wei Chen, Yihan Du, Longbo Huang, Haoyu Zhao [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2990-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2990-Supplemental.pdf)
> <p>In this paper, we study combinatorial pure exploration for dueling bandits (CPE-DB): we have multiple candidates for multiple positions as modeled by a bipartite graph, and in each round we sample a duel of two candidates on one position and observe who wins in the duel, with the goal of finding the best candidate-position matching with high probability after multiple rounds of samples. CPE-DB is an adaptation of the original combinatorial pure exploration for multi-armed bandit (CPE-MAB) problem to the dueling bandit setting. We consider both the Borda winner and the Condorcet winner cases. For Borda winner, we establish a reduction of the problem to the original CPE-MAB setting and design PAC and exact algorithms that achieve both the sample complexity similar to that in the CPE-MAB setting (which is nearly optimal for a subclass of problems)  and polynomial running time per round. For Condorcet winner, we first design a fully polynomial time approximation scheme (FPTAS) for the offline problem of finding the Condorcet winner with known winning probabilities, and then use the FPTAS as an oracle to design a novel pure exploration algorithm CAR-Cond with sample complexity analysis. CAR-Cond is the first algorithm with polynomial running time per round for identifying the Condorcet winner in CPE-DB.</p> 
### 508.[Optimal Sequential Maximization: One Interview is Enough!](https://proceedings.icml.cc/book/3748.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2991-Paper.pdf)
  Moein Falahatgar, Alon Orlitsky, Venkatadheeraj Pichapati [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2991-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2991-Supplemental.zip)
> <p>Maximum selection under probabilistic queries \emph{(probabilistic maximization)} is a fundamental algorithmic problem arising in numerous theoretical and practical contexts.  We derive the first query-optimal sequential algorithm for probabilistic-maximization. Departing from previous assumptions, the algorithm and performance guarantees apply even for infinitely many items, hence in particular do not require a-priori knowledge of the number of items. The algorithm has linear query complexity, and is optimal also in the streaming setting.</p>  <p>To derive these results we consider a probabilistic setting where several candidates for a position are asked multiple questions with the goal of finding who has the highest probability of answering interview questions correctly. Previous work minimized the total number of questions asked by alternating back and forth between the best performing candidates, in a sense, inviting them to multiple interviews.  We show that the same order-wise selection accuracy can be achieved by querying the candidates sequentially, never returning to a previously queried candidate. Hence one interview is enough!</p> 
### 509.[What can I do here? A Theory of Affordances in Reinforcement Learning](https://proceedings.icml.cc/book/3749.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/2993-Paper.pdf)
  Khimya Khetarpal, Zafarali Ahmed, Gheorghe Comanici, David Abel, Doina Precup [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/2993-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/2993-Supplemental.pdf)
> <p>Reinforcement learning algorithms usually assume that all actions are always available to an agent. However, both people and animals understand the general link between the features of their environment and the actions that are feasible. Gibson (1977) coined the term ``affordances'' to describe the fact that certain states enable an agent to do certain actions, in the context of embodied agents. In this paper, we develop a theory of affordances for agents who learn and plan in Markov Decision Processes. Affordances play a dual role in this case. On one hand, they allow faster planning, by reducing the number of actions available in any given situation. On the other hand, they facilitate more efficient and precise learning of transition models from data, especially when such models require function approximation. We establish these properties through theoretical results as well as illustrative examples. We also propose an approach to learn affordances and use it to estimate transition models that are simpler and generalize better.</p> 
### 510.[An end-to-end approach for the verification problem: learning the right distance](https://proceedings.icml.cc/book/3750.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3002-Paper.pdf)
  Joao Monteiro, Isabela Albuquerque, Jahangir Alam, R Devon Hjelm, Tiago Falk [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3002-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3002-Supplemental.pdf)
> <p>In this contribution, we augment the metric learning setting by introducing a parametric pseudo-distance, trained jointly with the encoder. Several interpretations are thus drawn for the learned distance-like model's output. We first show it approximates a likelihood ratio which can be used for hypothesis tests, and that it further induces a large divergence across the joint distributions of pairs of examples from the same and from different classes. Evaluation is performed under the verification setting consisting of determining whether sets of examples belong to the same class, even if such classes are novel and were never presented to the model during training. Empirical evaluation shows such method defines an end-to-end approach for the verification problem, able to attain better performance than simple scorers such as those based on cosine similarity and further outperforming widely used downstream classifiers. We further observe training is much simplified under the proposed approach compared to metric learning with actual distances, requiring no complex scheme to harvest pairs of examples.</p> 
### 511.[Data Valuation using Reinforcement Learning](https://proceedings.icml.cc/book/3751.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3003-Paper.pdf)
  Jinsung Yoon, Sercan Arik, Tomas Pfister [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3003-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3003-Supplemental.pdf)
> <p>Quantifying the value of data is a fundamental problem in machine learning and has multiple important use cases: (1) building insights about the dataset and task, (2) domain adaptation, (3) corrupted sample discovery, and (4) robust learning. We propose Data Valuation using Reinforcement Learning (DVRL), to adaptively learn data values jointly with the predictor model. DVRL uses a data value estimator (DVE) to learn how likely each datum is used in training of the predictor model. DVE is trained using a reinforcement signal that reflects performance on the target task. We demonstrate that DVRL yields superior data value estimates compared to alternative methods across numerous datasets and application scenarios. The corrupted sample discovery performance of DVRL is close to optimal in many regimes (i.e. as if the noisy samples were known apriori), and for domain adaptation and robust learning DVRL significantly outperforms state-of-the-art by 14.6% and 10.8%, respectively. </p> 
### 512.[FormulaZero: Distributionally Robust Online Adaptation via Offline Population Synthesis](https://proceedings.icml.cc/book/3752.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3008-Paper.pdf)
  Aman Sinha, Matthew O&#x27;Kelly, Hongrui Zheng, Rahul Mangharam, John Duchi, Russ Tedrake [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3008-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3008-Supplemental.zip)
> <p>Balancing performance and safety is crucial to deploying autonomous vehicles in multi-agent environments. In particular, autonomous racing is a domain that penalizes safe but conservative policies, highlighting the need for robust, adaptive strategies. Current approaches either make simplifying assumptions about other agents or lack robust mechanisms for online adaptation. This work makes algorithmic contributions to both challenges. First, to generate a realistic, diverse set of opponents, we develop a novel method for self-play based on replica-exchange Markov chain Monte Carlo. Second, we propose a distributionally robust bandit optimization procedure that adaptively adjusts risk aversion relative to uncertainty in beliefs about opponents’ behaviors. We rigorously quantify the tradeoffs in performance and robustness when approximating these computations in real-time motion-planning, and we demonstrate our methods experimentally on autonomous vehicles that achieve scaled speeds comparable to Formula One racecars.</p> 
### 513.[Latent Bernoulli Autoencoder](https://proceedings.icml.cc/book/3753.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3022-Paper.pdf)
  Jiri Fajtl, Vasileios Argyriou, Dorothy Monekosso, Paolo Remagnino [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3022-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3022-Supplemental.pdf)
> <p>In this work, we pose a question whether it is possible to design and train an autoencoder model in an end-to-end fashion to learn latent representations in multivariate Bernoulli space, and achieve performance comparable with the current state-of-the-art variational methods. Moreover, we investigate how to generate novel samples and perform smooth interpolation in the binary latent space.  To meet our objective, we propose a simplified deterministic model with a straight-through estimator to learn the binary latents and show its competitiveness with the latest VAE methods.  Furthermore, we propose a novel method based on a random hyperplane rounding for sampling and smooth interpolation in the multivariate Bernoulli latent space.  Although not a main objective, we demonstrate that our methods perform on par or better than the current state-of-the-art methods on common CelebA, CIFAR-10 and MNIST  datasets. PyTorch code and trained models to reproduce published results  will be released with the camera ready version.</p> 
### 514.[Learning To Stop While Learning To Predict](https://proceedings.icml.cc/book/3754.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3024-Paper.pdf)
  Xinshi Chen, Hanjun Dai, Yu Li, Xin Gao, Le Song [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3024-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3024-Supplemental.pdf)
> <p>There is a recent surge of interest in designing deep architectures based on the update steps in traditional algorithms, or learning neural networks to improve and replace traditional algorithms. While traditional algorithms have certain stopping criteria for outputting results at different iterations, many algorithm-inspired deep models are restricted to a <code>fixed-depth'' for all inputs. Similar to algorithms, the optimal depth of a deep architecture may be different for different input instances, either to avoid</code>over-thinking'', or because we want to compute less for operations converged already. In this paper, we tackle this varying depth problem using a steerable architecture, where a feed-forward deep model and a variational stopping policy are learned together to sequentially determine the optimal number of layers for each input instance. Training such architecture is very challenging. We provide a variational Bayes perspective and design a novel and effective training procedure which decomposes the task into an oracle model learning stage and an imitation stage. Experimentally, we show that the learned deep model along with the stopping policy improves the performances on a diverse set of tasks, including learning sparse recovery, few-shot meta learning, and computer vision tasks.</p> 
### 515.[Accelerating the diffusion-based ensemble sampling by non-reversible dynamics](https://proceedings.icml.cc/book/3755.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3027-Paper.pdf)
  Futoshi Futami, Issei Sato, Masashi Sugiyama [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3027-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3027-Supplemental.zip)
> <p>Posterior distribution approximation is a central task in Bayesian inference. Stochastic gradient Langevin dynamics (SGLD) and its extensions have been widely used practically and studied theoretically. While SGLD updates a single particle at a time, ensemble methods that update multiple particles simultaneously have been recently gathering attention. Compared with the naive parallel-chain SGLD that updates multiple particles independently, ensemble methods update particles with their interactions. Thus, these methods are expected to be more particle-efficient than the naive parallel-chain SGLD because particles can be aware of other particles’ behavior through their interactions. Although ensemble methods demonstrated their superior performance numerically, no theoretical guarantee exists to assure such particle-efficiency and it is unclear whether those ensemble methods are really superior to the naive parallel-chain SGLD in the non-asymptotic settings. To cope with this problem, we propose a novel ensemble method that uses a non-reversible Markov chain for the interaction, and we present a non-asymptotic theoretical analysis for our method. Our analysis shows that, for the first time, the interaction causes a faster convergence rate than the naive parallel-chain SGLD in the non-asymptotic setting if the discretization error is appropriately controlled. Numerical experiments show that we can control the discretization error by tuning the interaction appropriately.</p> 
### 516.[Efficient nonparametric statistical inference on population feature importance using Shapley values](https://proceedings.icml.cc/book/3756.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3042-Paper.pdf)
  Brian Williamson, Jean Feng [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3042-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3042-Supplemental.pdf)
> The true population-level importance of a variable in a prediction task provides useful knowledge about the underlying data-generating mechanism and can help in deciding which measurements to collect in subsequent experiments. Valid statistical inference on this importance is a key component in understanding the population of interest. We present a computationally efficient procedure for estimating and obtaining valid statistical inference on the \textbf{S}hapley \textbf{P}opulation \textbf{V}ariable \textbf{I}mportance \textbf{M}easure (SPVIM). Although the computational complexity of the true SPVIM scales exponentially with the number of variables, we propose an estimator based on randomly sampling only $\Theta(n)$ feature subsets given $n$ observations. We prove that our estimator converges at an asymptotically optimal rate. Moreover, by deriving the asymptotic distribution of our estimator, we construct valid confidence intervals and hypothesis tests. Our procedure has good finite-sample performance in simulations, and for an in-hospital mortality prediction task produces similar variable importance estimates when different machine learning algorithms are applied.
### 517.[Curse of Dimensionality on Randomized Smoothing for Certifiable Robustness](https://proceedings.icml.cc/book/3757.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3044-Paper.pdf)
  Aounon Kumar, Alexander Levine, Tom Goldstein, Soheil Feizi [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3044-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3044-Supplemental.pdf)
> Randomized smoothing, using just a simple isotropic Gaussian distribution, has been shown to produce good robustness guarantees against $\ell_2$-norm bounded adversaries. In this work, we show that extending the smoothing technique to defend against other attack models can be challenging, especially in the high-dimensional regime.  In particular, for a vast class of i.i.d.~smoothing distributions, we prove that the largest $\ell_p$-radius that can be certified decreases as $O(1/d^{\frac{1}{2} - \frac{1}{p}})$ with dimension $d$ for $p &gt; 2$. Notably, for $p \geq 2$, this dependence on $d$ is no better than that of the $\ell_p$-radius that can be certified using isotropic Gaussian smoothing, essentially putting a matching lower bound on the robustness radius. When restricted to {\it generalized} Gaussian smoothing, these two bounds can be shown to be within a constant factor of each other in an asymptotic sense, establishing that Gaussian smoothing provides the best possible results, up to a constant factor, when $p \geq 2$. We present experimental results on CIFAR to validate our theory. For other smoothing distributions, such as, a uniform distribution within an $\ell_1$ or an $\ell_\infty$-norm ball, we show upper bounds of the form $O(1 / d)$ and $O(1 / d^{1 - \frac{1}{p}})$ respectively, which have an even worse dependence on $d$.  
### 518.[Upper bounds for Model-Free Row-Sparse Principal Component Analysis](https://proceedings.icml.cc/book/3758.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3046-Paper.pdf)
  Guanyi Wang, Santanu  Dey [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3046-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3046-Supplemental.zip)
> <p>Sparse principal component analysis (PCA) is a widely-used dimensionality reduction tool in statistics and machine learning. Most methods mentioned in literature are either heuristics for good primal feasible solutions under statistical assumptions or ADMM-type algorithms with stationary/critical points convergence property for the regularized reformulation of sparse PCA. However, none of these methods can efficiently verify the quality of the solutions via comparing current objective values with their dual bounds, especially in model-free case. We propose a new framework that finds out upper (dual) bounds for the sparse PCA within polynomial time via solving a convex integer program (IP). We show that, in the worst-case, the dual bounds provided by the convex IP is within an affine function of the global optimal value. Moreover, in contrast to the semi-definition relaxation, this framework is much easier to scale on large cases. Numerical results on both artificial and real cases are reported to demonstrate the advantages of our method.</p> 
### 519.[Explainable k-Means and k-Medians Clustering](https://proceedings.icml.cc/book/3759.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3047-Paper.pdf)
  Michal Moshkovitz, Sanjoy Dasgupta, Cyrus Rashtchian, Nave Frost [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3047-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3047-Supplemental.pdf)
> <p>Clustering is a popular unsupervised learning method for geometric data. Unfortunately, many clustering algorithms use global properties of the data, and there are no simple explanations for cluster assignments. To improve interpretability, we consider using a small threshold tree to partition a dataset into clusters. This leads to cluster assignments that can be explained by very few feature values in a straightforward manner. We study this problem from a theoretical viewpoint, measuring the output quality by the k-means and k-medians objectives. In terms of negative results, we show that popular top-down decision tree algorithms may lead to clusterings with arbitrarily large cost, and we prove that any explainable clustering must incur an \Omega(\log k) approximation compared to the optimal clustering. On the upper bound side, we design efficient algorithms that produce explainable clusters using a tree with k leaves. For two means/medians, we show that a single threshold cut suffices to achieve a constant factor approximation, which is a surprising result that nearly matches our lower bounds. For general k \geq 2, our algorithm is an O(k) approximation to the optimal k-medians and an O(k^2) approximation to the optimal k-means. Prior to our work, no algorithms were known with provable guarantees independent of the dimensionality and input size. </p> 
### 520.[Reward-Free Exploration for Reinforcement Learning](https://proceedings.icml.cc/book/3760.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3050-Paper.pdf)
  Chi Jin, Akshay Krishnamurthy, Max Simchowitz, Tiancheng Yu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3050-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3050-Supplemental.pdf)
> Exploration is widely regarded as one of the most challenging aspects of reinforcement learning (RL), with many naive approaches succumbing to exponential sample complexity. To isolate the challenges of exploration, we propose the following ``reward-free RL&#x27;&#x27; framework. In the exploration phase, the agent first collects trajectories from an MDP $M$ without a pre-specified reward function. After exploration, it is tasked with computing a near-policies under the transitions of $\mathcal{M}$ for a collection of given reward functions.  This framework is particularly suitable where there are many reward functions of interest, or where the reward function is shaped by an external agent to elicit desired behavior.   We give an efficient algorithm that conducts  $\widetilde{O}(S^2A\mathrm{poly}(H)/\epsilon^2)$ episodes of exploration, and returns $\epsilon$-suboptimal policies for an arbitrary number of reward functions. We achieve this by finding exploratory policies that jointly visit each ``significant&#x27;&#x27; state with probability proportional to its maximum visitation probability under any possible policy. Moreover, our planning procedure can be instantiated by any black-box approximate planner, such as value iteration or natural policy gradient. Finally, we give a nearly-matching $\Omega(S^2AH^2/\epsilon^2)$ lower bound, demonstrating the near-optimality of our algorithm in this setting. 
### 521.[Parametric Gaussian Process Regressors](https://proceedings.icml.cc/book/3761.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3062-Paper.pdf)
  Martin Jankowiak, Geoff Pleiss, Jacob Gardner [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3062-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3062-Supplemental.pdf)
> <p>The combination of inducing point methods with stochastic variational inference has enabled approximate Gaussian Process (GP) inference on large datasets. Unfortunately, the resulting predictive distributions often exhibit substantially underestimated uncertainties. Notably, in the regression case the predictive variance is typically dominated by observation noise, yielding uncertainty estimates that make little use of the input-dependent function uncertainty that makes GP priors attractive. In this work we propose two simple methods for scalable GP regression that address this issue and thus yield substantially improved predictive uncertainties. The first applies variational inference to FITC (Fully Independent Training Conditional; Snelson et. al. 2006). The second bypasses posterior approximations and instead directly targets the posterior predictive distribution. In an extensive empirical comparison with a number of alternative methods for scalable GP regression, we find that the resulting predictive distributions exhibit significantly better calibrated uncertainties and higher log likelihoods--often by as much as half a nat per datapoint.</p> 
### 522.[p-Norm Flow Diffusion for Local Graph Clustering](https://proceedings.icml.cc/book/3762.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3065-Paper.pdf)
  Kimon Fountoulakis, Di Wang, Shenghao Yang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3065-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3065-Supplemental.pdf)
> Local graph clustering and the closely related seed set expansion problem are primitives on graphs that are central to a wide range of analytic and learning tasks such as local clustering, community detection, nodes ranking and feature inference. Prior work on local graph clustering mostly falls into two categories with numerical and combinatorial roots respectively.  In this work, we draw inspiration from both fields and propose a family of convex optimization formulations based on the idea of diffusion with $p$-norm network flow for $p\in (1,\infty)$.   In the context of local clustering, we characterize the optimal solutions for these optimization problems and show their usefulness in finding low conductance cuts around input seed set. In particular, we achieve quadratic approximation of conductance in the case of $p=2$ similar to the Cheeger-type bounds of spectral methods, constant factor approximation when $p\rightarrow\infty$ similar to max-flow based methods, and a smooth transition for general $p$ values in between. Thus, our optimization formulation can be viewed as bridging the numerical and combinatorial approaches, and we can achieve the best of both worlds in terms of speed and noise robustness.   We show that the proposed problem can be solved in strongly local running time for $p\ge 2$ and conduct empirical evaluations on both synthetic and real-world graphs to illustrate our approach compares favorably with existing methods.
### 523.[Low-Rank Bottleneck in Multi-head Attention Models](https://proceedings.icml.cc/book/3763.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3073-Paper.pdf)
  Srinadh Bhojanapalli, Chulhee Yun, Ankit Singh Rawat, Sashank Jakkam Reddi, Sanjiv Kumar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3073-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3073-Supplemental.pdf)
> <p>Attention based Transformer architecture has enabled significant advances in the field of natural language processing. In addition to new pre-training techniques, recent improvements crucially rely on working with a relatively larger embedding dimension for tokens. Unfortunately, this leads to models that are prohibitively large to be employed in the downstream tasks. In this paper we identify one of the important factors contributing to the large embedding size requirement. In particular, our analysis highlights that the scaling between the number of heads and the size of each head in the current architecture gives rise to a low-rank bottleneck in attention heads, causing this limitation, which we further validate with our experiments. As a solution we propose to set the head size of an attention unit to input sequence length, and independent of the number of heads, resulting in multi-head attention layers with provably more expressive power. We empirically show that this allows us to train models with a relatively smaller embedding dimension and with better performance scaling.</p> 
### 524.[LEEP: A New Measure to Evaluate Transferability of Learned Representations](https://proceedings.icml.cc/book/3764.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3080-Paper.pdf)
  Cuong Nguyen, Tal Hassner, Cedric Archambeau, Matthias Seeger [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3080-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3080-Supplemental.pdf)
> <p>We introduce a new measure to evaluate the transferability of representations learned by classifiers. Our measure, the Log Expected Empirical Prediction (LEEP), is simple and easy to compute: when given a classifier trained on a source data set, it only requires running the target data set through this classifier once. We analyze the properties of LEEP theoretically and demonstrate its effectiveness empirically. Our analysis shows that LEEP can predict the performance and convergence speed of both transfer and meta-transfer learning methods, even for small or imbalanced data. Moreover, LEEP outperforms recently proposed transferability measures such as negative conditional entropy and H scores. Notably, when transferring from ImageNet to CIFAR100, LEEP can achieve up to 30% improvement compared to the best competing method in terms of the correlations with actual transfer accuracy.</p> 
### 525.[The FAST Algorithm for Submodular Maximization](https://proceedings.icml.cc/book/3765.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3089-Paper.pdf)
  Adam Breuer, Eric Balkanski, Yaron Singer [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3089-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3089-Supplemental.zip)
> <p>In this paper we describe a new parallel algorithm called Fast Adaptive Sequencing Technique (FAST) for maximizing a monotone submodular function under a cardinality constraint k. This algorithm achieves the optimal 1-1/e approximation guarantee and is orders of magnitude faster than the state-of-the-art on a variety of experiments over real-world data sets.</p>  <p>In the past two years, following the work by Balkanski and Singer there has been a great deal of work on algorithms whose theoretical parallel runtime is exponentially faster than algorithms used for submodular maximization over the past 40 years. Although these algorithms are fast in terms of asymptotic worst case guarantees, it is computationally infeasible to use them in practice. The reason is that the number of rounds and queries they require depends on very large constants as well as high-degree polynomials in terms of the precision and confidence, causing these algorithms to be impractical even on small data sets.  </p>  <p>The design principles behind the FAST algorithm we present here are a significant departure from those of theoretically fast algorithms that have been studied in the past two years. Rather than optimize for theoretical guarantees, the design of FAST introduces several new techniques that achieve remarkable practical and theoretical parallel runtimes. More specifically, the approximation guarantee obtained by FAST is arbitrarily close to 1 − 1/e, its theoretical parallel runtime (adaptivity) is O(log(n) log^2(log k)), and the total number of queries is O(n log log(k)). We show that FAST is orders of magnitude faster than any algorithm for submodular maximization we are aware of, including hyper-optimized parallel versions of state-of-the-art serial algorithms, by running experiments on large data sets.</p> 
### 526.[On the Relation between Quality-Diversity Evaluation and Distribution-Fitting Goal in Text Generation](https://proceedings.icml.cc/book/3766.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3095-Paper.pdf)
  Jianing Li, Yanyan Lan, Jiafeng Guo, Xueqi Cheng [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3095-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3095-Supplemental.zip)
> <p>The goal of text generation models is to fit the underlying real probability distribution of text. For performance evaluation, quality and diversity metrics are usually applied. However, it is still not clear to what extend can the quality-diversity evaluation reflect the distribution-fitting goal. In this paper, we try to reveal such relation in a theoretical approach. We prove that under certain conditions, a linear combination of quality and diversity constitutes a divergence metric between the generated distribution and the real distribution. We also show that the commonly used BLEU/Self-BLEU metric pair fails to match any divergence metric, thus propose CR/NRR as a substitute for quality/diversity metric pair.</p> 
### 527.[Designing Optimal Dynamic Treatment Regimes: A Causal Reinforcement Learning Approach](https://proceedings.icml.cc/book/3767.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3096-Paper.pdf)
  Junzhe Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3096-Metadata.json)
> <p>A dynamic treatment regime (DTR) consists of a sequence of decision rules, one per stage of intervention, that dictates how to determine the treatment assignment to patients based on evolving treatments and covariates' history. These regimes are particularly effective for managing chronic disorders and is arguably one of the critical ingredients underlying more personalized decision-making systems. All reinforcement learning algorithms for finding the optimal DTR in online settings will suffer O(\sqrt{|D<em>{X, S}|T}) regret on some environments, where T is the number of experiments, and D</em>{X, S} is the domains of treatments X and covariates S. This implies T = O (|D<em>{X, S}|) trials to generate an optimal DTR. In many applications, domains of X and S could be so enormous that the time required to ensure appropriate learning may be unattainable. We show that, if the causal diagram of the underlying environment is provided, one could achieve regret that is exponentially smaller than D</em>{X, S}. In particular, we develop two online algorithms that satisfy such regret bounds by exploiting the causal structure underlying the DTR; one is based on the principle of optimism in the face of uncertainty (OFU-DTR), and the other uses the posterior sampling learning (PS-DTR). Finally, we introduce efficient methods to accelerate these online learning procedures by leveraging the abundant, yet biased observational (non-experimental) data.</p> 
### 528.[Global Decision-Making via Local Economic Transactions](https://proceedings.icml.cc/book/3768.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3099-Paper.pdf)
  Michael Chang, Sid Kaushik, S. Matthew Weinberg, Sergey Levine, Thomas Griffiths [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3099-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3099-Supplemental.pdf)
> <p>This paper seeks to establish a mechanism for directing a collection of simple, specialized, self-interested agents to solve what traditionally are posed as monolithic single-agent sequential decision problems with a central global objective. What makes it challenging to use a decentralized approach to collectively optimize a central objective is the difficulty in characterizing the equilibrium strategy profile of non-cooperative games. To overcome this challenge, we design a mechanism for defining the learning environment of each primitive agent for which we know that the optimal solution for the global objective coincides with a Nash equilibrium strategy profile of the agents optimizing their own local objectives. We then derive a learning algorithm for the system and empirically test to what extent the desired equilibrium is achieved. The system functions as an economy of agents that learn the credit assignment process itself by buying and selling to each other the right to operate on the environment state. We also show that redundancy not only enforces credit conservation but also improves robustness against suboptimal equilibria.</p> 
### 529.[Retrieval Augmented Language Model Pre-Training](https://proceedings.icml.cc/book/3769.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3102-Paper.pdf)
  Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, Mingwei Chang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3102-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3102-Supplemental.pdf)
> <p>Language model pre-training has been shown to capture a surprising amount of world knowledge, crucial for NLP tasks such as question answering. However, this knowledge is stored implicitly in the parameters of a neural network, requiring ever-larger networks to cover more facts. To capture knowledge in a more modular and interpretable way, we augment language model pre-training with a latent knowledge retriever, which allows the model to retrieve and attend over documents from a large corpus such as Wikipedia, used during pre-training, fine-tuning and inference. For the first time, we show how to pre-train such a knowledge retriever in an unsupervised manner, using masked language modeling as the learning signal and backpropagating through a retrieval step that considers millions of documents. We demonstrate the effectiveness of Retrieval-Augmented Language Model pre-training (REALM) by fine-tuning on the challenging task of Open-domain Question Answering (Open-QA). We compare against state-of-the-art models for both explicit and implicit knowledge storage on three popular Open-QA benchmarks, and find that we outperform all previous methods by a significant margin (4-16% absolute accuracy), while also providing qualitative benefits such as interpretability and modularity.</p> 
### 530.[Variational Label Enhancement](https://proceedings.icml.cc/book/3770.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3104-Paper.pdf)
  Ning Xu, Yun-Peng Liu, Jun Shu, Xin Geng [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3104-Metadata.json)
> <p>Label distribution  covers a certain number of labels, representing the degree to which each label describes the instance. The learning process on the  instances labeled by label distributions is called label distribution learning (LDL). Unfortunately, many training sets only contain  simple logical labels rather than label distributions due to the difficulty of obtaining the label distributions directly.  To solve this problem,  we consider the label distributions as the latent vectors and  infer the label distributions from the logical labels in the training datasets by using variational inference. After that, we induce a predictive model to train the label distribution data by employing the multi-output regression technique. The recovery experiment  on thirteen real-world LDL  datasets  and the predictive experiment on ten multi-label learning datasets validate the advantage of our approach  over the state-of-the-art  approaches. </p> 
### 531.[Bandits with Adversarial Scaling](https://proceedings.icml.cc/book/3771.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3107-Paper.pdf)
  Thodoris Lykouris, Vahab Mirrokni, Renato Leme [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3107-Metadata.json)
> <p>We study "adversarial scaling", a multi-armed bandit model where rewards have a stochastic and an adversarial component. Our model captures display advertising where the "click-through-rate" can be decomposed to a (fixed across time) arm-quality component and a  non-stochastic user-relevance component (fixed across arms). Despite the relative stochasticity of our model, we demonstrate two settings where most bandit algorithms suffer. On the positive side, we show that two algorithms, one from the action elimination and one from the mirror descent family are adaptive enough to be robust to adversarial scaling. Our results shed light on the robustness of adaptive parameter selection in stochastic bandits, which may be of independent interest.</p> 
### 532.[Eliminating the Invariance on the Loss Landscape of Linear Autoencoders](https://proceedings.icml.cc/book/3772.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3112-Paper.pdf)
  Reza Oftadeh, Jiayi Shen, Zhangyang Wang, Dylan Shell [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3112-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3112-Supplemental.pdf)
> <p>In this paper, we propose a new loss function for linear autoencoders (LAEs) and then analytically identify the structure of the loss surface. Optimizing the conventional Mean Square Error (MSE) loss results in a decoder matrix that spans the principal subspace of the sample covariance of the data, but fails to identify the exact eigenvectors. This shortcoming originates from an invariance that cancels out in the global map. Here, we prove that our loss function eliminates this issue, i.e., the decoder converges to the exact ordered unnormalized eigenvectors of the sample covariance matrix. For this new loss, we characterize the full structure of the loss landscape in the following sense: we establish analytical expression for the set of all critical points, show that it is a subset of critical points of MSE, and that all local minima are still global. However, the invariant global minima under MSE become saddle points under the new loss. Moreover, we show that the order of computational complexity of the loss and its gradients are the same as MSE and, hence, the new loss is not only of theoretical importance but is of practical value, e.g., for low-rank approximation. </p> 
### 533.[What is Local Optimality in Nonconvex-Nonconcave Minimax Optimization?](https://proceedings.icml.cc/book/3773.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3113-Paper.pdf)
  Chi Jin, Praneeth Netrapalli, Michael Jordan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3113-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3113-Supplemental.pdf)
> <p>Minimax optimization has found extensive applications in modern machine learning, in settings such as generative adversarial networks (GANs), adversarial training and multi-agent reinforcement learning. As most of these applications involve continuous nonconvex-nonconcave formulations, a very basic question arises---``what is a proper definition of local optima?''</p>  <p>Most previous work answers this question using classical notions of equilibria from simultaneous games, where the min-player and the max-player act simultaneously. In contrast, most applications in machine learning, including GANs and adversarial training, correspond to sequential games, where the order of which player acts first is crucial (since minimax is in general not equal to maximin due to the nonconvex-nonconcave nature of the problems). The main contribution of this paper is to propose a proper mathematical definition of local optimality for this sequential setting---local minimax, as well as to present its properties and existence results. Finally, we establish a strong connection to a basic local search algorithm---gradient descent ascent (GDA): under mild conditions, all stable limit points of GDA are exactly local minimax points up to some degenerate points.</p> 
### 534.[Lookahead-Bounded Q-learning](https://proceedings.icml.cc/book/3774.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3126-Paper.pdf)
  Ibrahim El Shar, Daniel Jiang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3126-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3126-Supplemental.pdf)
> <p>We introduce the lookahead-bounded Q-learning (LBQL) algorithm, a new, provably convergent variant of Q-learning that seeks to improve the performance of standard Q-learning in stochastic environments through the use of “lookahead” upper and lower bounds. To do this, LBQL employs previously collected experience and each iteration’s state-action values as dual feasible penalties to construct a sequence of sampled information relaxation problems. The solutions to these problems provide estimated upper and lower bounds on the optimal value, which we track via stochastic approximation. These quantities are then used to constrain the iterates to stay within the bounds at every iteration. Numerical experiments confirm the fast convergence of LBQL as compared to the standard Q-learning algorithm and several related techniques.</p> 
### 535.[Learning From Irregularly-Sampled Time Series: A Missing Data Perspective](https://proceedings.icml.cc/book/3775.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3129-Paper.pdf)
  Steven Cheng-Xian Li, Benjamin Marlin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3129-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3129-Supplemental.pdf)
> <p>Irregularly-sampled time series occur in many domains including healthcare. They can be challenging to model because they do not naturally yield a fixed-dimensional representation as required by many standard machine learning models. In this paper, we consider irregular sampling from the perspective of missing data. We model observed irregularly sampled time series data as a sequence of index-value pairs sampled from a continuous but unobserved function. We introduce an encoder-decoder framework for learning from such generic indexed sequences. We propose learning methods for this framework based on variational autoencoders and generative adversarial networks. We focus on the continuous-time case and introduce continuous convolutional layers that can interface with existing neural network architectures. We investigate two applications of this framework: interpolation and time series classification. Experiments show that our models are able to achieve competitive or better classification results on irregularly sampled multivariate time series classification tasks compared to recent RNN models while offering significantly faster training times.</p> 
### 536.[Evaluating the Performance of Reinforcement Learning Algorithms](https://proceedings.icml.cc/book/3776.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3133-Paper.pdf)
  Scott Jordan, Yash Chandak, Daniel Cohen, Mengxue Zhang, Philip Thomas [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3133-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3133-Supplemental.pdf)
> <p>Performance evaluations are critical for quantifying algorithmic advances in reinforcement learning. Recent reproducibility analyses have shown that reported performance results are often inconsistent and difficult to replicate. In this work, we argue that the inconsistency of performance stems from the use of flawed evaluation metrics. Taking a step towards ensuring that reported results are consistent, we propose a new comprehensive evaluation methodology for reinforcement learning algorithms that produces reliable measurements of performance both on a single environment and when aggregated across environments. We demonstrate this method by evaluating a broad class of reinforcement learning algorithms on common benchmark tasks.</p> 
### 537.[Unbiased Risk Estimators Can Mislead: A Case Study of Learning with Complementary Labels](https://proceedings.icml.cc/book/3777.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3134-Paper.pdf)
  Yu-Ting Chou, Gang Niu, Hsuan-Tien Lin, Masashi Sugiyama [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3134-Metadata.json)
> <p>In weakly supervised learning, unbiased risk estimators (URE) are powerful tools for estimating the risk of classifiers when the training distribution differs from the test distribution. However, they lead to overfitting in many problem settings if deep networks are chosen as the classifiers. In this paper, we investigate reasons for such overfitting by studying learning with complementary labels. We argue that the quality of gradient estimation matters more than risk estimation in risk minimization. Theoretically, we find UREs give unbiased gradient estimators (UGE). Empirically, we find UGEs have a huge variance, though the bias is zero; their direction is far away from the true gradient in expectation, though the expected direction is the same as the true gradient. Hence we advocate to use biased risk estimators by taking into account the bias-variance tradeoff and the directional similarity of gradient estimation, and experiments show that they successfully mitigate the overfitting due to UREs/UGEs.</p> 
### 538.[Provable Self-Play Algorithms for Competitive Reinforcement Learning](https://proceedings.icml.cc/book/3778.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3137-Paper.pdf)
  Yu Bai, Chi Jin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3137-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3137-Supplemental.pdf)
>   Self-play, where the algorithm learns by playing against itself without requiring any direct supervision, has become the new weapon in modern Reinforcement Learning (RL) for achieving superhuman performance in practice. However, the majority of exisiting theory in reinforcement learning only applies to the setting where the agent plays against a fixed environment. It remains largely open whether self-play algorithms can be provably effective, especially when it is necessary to manage the exploration/exploitation tradeoff.    We study self-play in competitive reinforcement learning under the setting of Markov games, a generalization of Markov decision processes to the two-player case. We introduce a self-play algorithm---Value Iteration with Upper/Lower Confidence Bound (VI-ULCB), and show that it achieves regret $\tilde{O}(\sqrt{T})$ after playing $T$ steps of the game. The regret is measured by the agent&#x27;s performance against a \emph{fully adversarial} opponent who can exploit the agent&#x27;s strategy at \emph{any} step. We also introduce an explore-then-exploit style algorithm, which achieves a slightly worse regret of $\tilde{O}(T^{2/3})$, but is guaranteed to run in polynomial time even in the worst case. To the best of our knowledge, our work presents the first line of provably sample-efficient self-play algorithms for competitive reinforcement learning.
### 539.[Optimizing Long-term Social Welfare in Recommender Systems: A Constrained Matching Approach](https://proceedings.icml.cc/book/3779.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3138-Paper.pdf)
  Martin Mladenov, Elliot Creager, Omer Ben-Porat, Kevin Swersky, Richard Zemel, Craig Boutilier [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3138-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3138-Supplemental.pdf)
> <p>Most recommender systems (RS) research assumes that a user's utility can be maximized independently of the utility of the other agents (e.g., other users, content providers). In realistic settings, this is often not true -- the dynamics of an RS ecosystem couple the long-term utility of all agents. In this work, we explore settings in which content providers cannot remain viable unless they receive a certain level of user engagement. We formulate this problem as one of equilibrium selection in the induced dynamical system, and show that it can be solved as an optimal constrained matching problem. Our model ensures the system reaches an equilibrium with maximal social welfare supported by a sufficiently diverse set of viable providers. We demonstrate that even in a simple, stylized dynamical RS model, the standard  myopic approach to recommendation - always matching a user to the best provider - performs poorly. We develop several scalable techniques to solve the matching problem, and also draw connections to various notions of user regret and fairness, arguing that these outcomes are fairer in a utilitarian sense.</p> 
### 540.[Semi-Supervised StyleGAN for Disentanglement Learning](https://proceedings.icml.cc/book/3780.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3146-Paper.pdf)
  Weili Nie, Tero Karras, Animesh Garg, Shoubhik Debnath, Anjul Patney, Ankit Patel, Anima Anandkumar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3146-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3146-Supplemental.pdf)
> <p>Disentanglement learning is crucial for obtaining disentangled representations and controllable generation. Current disentanglement methods face several inherent limitations: difficulty with high-resolution images, primarily on learning disentangled representations, and non-identifiability due to the unsupervised setting. To alleviate these limitations, we design new architectures and loss functions based on StyleGAN (Karras et al., 2019), for semi-supervised high-resolution disentanglement learning. We create two complex high-resolution synthetic datasets for systematic testing. We investigate the impact of limited supervision and find that using only 0.25%~2.5% of labeled data is sufficient for good disentanglement on both synthetic and real datasets. We propose new metrics to quantify generator controllability, and observe there may exist a crucial trade-off between disentangled representation learning and controllable generation. We also consider semantic fine-grained image editing to achieve better generalization to unseen images. </p> 
### 541.[The Non-IID Data Quagmire of Decentralized Machine Learning](https://proceedings.icml.cc/book/3781.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3152-Paper.pdf)
  Kevin Hsieh, Amar Phanishayee, Onur Mutlu, Phillip Gibbons [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3152-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3152-Supplemental.pdf)
> <p>Many large-scale machine learning (ML) applications need to perform decentralized learning over datasets generated at different devices and locations. Such datasets pose a significant challenge to decentralized learning because their different contexts result in significant data distribution skew across devices/locations. In this paper, we take a step toward better understanding this challenge by presenting a detailed experimental study of decentralized DNN training on a common type of data skew: skewed distribution of data labels across locations/devices. Our study shows that: (i) skewed data labels are a fundamental and pervasive problem for decentralized learning, causing significant accuracy loss across many ML applications, DNN models, training datasets, and decentralized learning algorithms; (ii) the problem is particularly challenging for DNN models with batch normalization layers; and (iii) the degree of skewness is a key determinant of the difficulty of the problem. Based on these findings, we present SkewScout, a system-level approach that adapts the communication frequency of decentralized learning algorithms to the (skew-induced) accuracy loss between data partitions. We also show that group normalization can recover much of the skew-induced accuracy loss of batch normalization.</p> 
### 542.[On the Noisy Gradient Descent that Generalizes as SGD](https://proceedings.icml.cc/book/3782.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3155-Paper.pdf)
  Jingfeng Wu, Wenqing Hu, Haoyi Xiong, Jun Huan, Vladimir Braverman, Zhanxing Zhu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3155-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3155-Supplemental.pdf)
> <p>The gradient noise of SGD is considered to play a central role in the observed strong generalization abilities of deep learning. While past studies confirm that the magnitude and the covariance structure of gradient noise are critical for regularization, it remains unclear whether or not the class of noise distributions is important. In this work we provide negative results by showing that noises in classes different from the SGD noise can also effectively regularize gradient descent. Our finding is based on a novel observation on the structure of the SGD noise: it is the multiplication of the gradient matrix and a sampling noise that arises from the mini-batch sampling procedure. Moreover, the sampling noises unify two kinds of gradient regularizing noises that belong to the Gaussian class: the one using (scaled) Fisher as covariance and the one using the gradient covariance of SGD as covariance. Finally, thanks to the flexibility of choosing noise class, an algorithm is proposed to perform noisy gradient descent that generalizes well, the variant of which even benefits large batch SGD training without hurting generalization.</p> 
### 543.[Safe screening rules for L0-regression](https://proceedings.icml.cc/book/3783.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3161-Paper.pdf)
  Alper Atamturk, Andres Gomez [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3161-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3161-Supplemental.zip)
> <p>We give safe screening rules to eliminate variables from regression with L0 regularization or cardinality constraint. These rules are based on guarantees that a feature may or may not be selected in an optimal solution.  The screening rules can be computed from a convex relaxation solution in linear time, without solving the L0 optimization problem. Thus, they can be used in a preprocessing step to safely remove variables from consideration apriori.  Numerical experiments on real and synthetic data indicate that,  on average, 76\% of the variables can be fixed to their optimal values, hence, reducing the computational burden for optimization substantially. Therefore, the proposed fast and effective screening rules extend the scope of algorithms for L0 regression to larger data sets.</p> 
### 544.[Single Point Transductive Prediction](https://proceedings.icml.cc/book/3784.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3168-Paper.pdf)
  Nilesh Tripuraneni, Lester Mackey [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3168-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3168-Supplemental.pdf)
> Standard methods in supervised learning separate training and prediction: the model is fit independently of any test points it may encounter. However, can knowledge of the next test point $\mathbf{x}_{\star}$ be exploited to improve prediction accuracy? We address this question in the context of linear prediction, showing how  techniques from semi-parametric inference can be used transductively to combat regularization bias. We first lower bound the $\mathbf{x}_{\star}$ prediction error of ridge regression and the Lasso, showing that they must incur significant bias in certain test directions. We then provide non-asymptotic upper bounds on the $\mathbf{x}_{\star}$ prediction error of two transductive prediction rules. We conclude by showing the efficacy of our methods on both synthetic and real data, highlighting the improvements single point transductive     prediction can provide in settings with distribution shift.
### 545.[History-Gradient Aided Batch Size Adaptation for Variance Reduced Algorithms](https://proceedings.icml.cc/book/3785.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3171-Paper.pdf)
  Kaiyi Ji, Zhe Wang, Bowen Weng, Yi Zhou, Wei  Zhang, Yingbin LIANG [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3171-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3171-Supplemental.pdf)
> <p>Variance-reduced algorithms, although achieve great theoretical performance, can run slowly in practice due to the periodic gradient estimation with a large batch of data. Batch-size adaptation thus arises as a promising approach to accelerate such algorithms. However, existing schemes either apply prescribed batch-size adaption rule or exploit the information along optimization path via additional backtracking and condition verification steps. In this paper, we propose a novel scheme, which eliminates backtracking line search but still exploits the information along optimization path by adapting the batch size via history stochastic gradients. We further theoretically show that such a scheme substantially reduces the overall complexity for popular variance-reduced algorithms SVRG and SARAH/SPIDER for both conventional nonconvex optimization and reinforcement learning problems. To this end, we develop a new convergence analysis framework to handle the dependence of the batch size on history stochastic gradients. Extensive experiments validate the effectiveness of the proposed batch-size adaptation scheme. </p> 
### 546.[Batch Stationary Distribution Estimation](https://proceedings.icml.cc/book/3786.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3172-Paper.pdf)
  Junfeng Wen, Bo Dai, Lihong Li, Dale Schuurmans [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3172-Metadata.json)
> <p>We consider the problem of approximating the stationary distribution of an ergodic Markov chain given a set of sampled transitions. Classical simulation-based approaches assume access to the underlying process so that trajectories of sufficient length can be gathered to approximate stationary sampling. Instead, we consider an alternative setting where a \emph{fixed} set of transitions has been collected beforehand, by a separate, possibly unknown procedure. The goal is still to estimate properties of the stationary distribution, but without additional access to the underlying system. We propose a consistent estimator that is based on recovering a correction ratio function over the given data. In particular, we develop a variational power method (VPM) that provides provably consistent estimates under general conditions. In addition to unifying a number of existing approaches from different subfields, we also find that VPM yields significantly better estimates across a range of problems, including queueing, stochastic differential equations, post-processing MCMC, and off-policy evaluation.</p> 
### 547.[Optimal Statistical Guaratees for Adversarially Robust Gaussian Classification](https://proceedings.icml.cc/book/3787.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3175-Paper.pdf)
  Chen Dan, Yuting Wei, Pradeep Ravikumar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3175-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3175-Supplemental.pdf)
> Adversarial robustness has become a fundamental requirement in modern machine learning applications. Yet, there has been surprisingly little statistical understanding so far. In this paper, we provide the first result of the \emph{optimal} minimax guarantees for the excess risk for adversarially robust classification, under Gaussian mixture model proposed by \cite{schmidt2018adversarially}. The results are stated in terms of the \emph{Adversarial Signal-to-Noise Ratio (AdvSNR)}, which generalizes a similar notion for standard linear classification to the adversarial setting. For the Gaussian mixtures with AdvSNR value of $r$, we prove an excess risk lower bound of order $\Theta(e^{-(\frac{1}{2}+o(1)) r^2} \frac{d}{n})$ and design a computationally efficient estimator that achieves this optimal rate. Our results built upon minimal assumptions while cover a wide spectrum of adversarial perturbations including $\ell_p$ balls for any $p \ge 1$.
### 548.[Generative Adversarial Imitation Learning with Neural Network Parameterization: Global Optimality and Convergence Rate](https://proceedings.icml.cc/book/3788.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3185-Paper.pdf)
  Yufeng Zhang, Qi Cai, Zhuoran Yang, Zhaoran Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3185-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3185-Supplemental.zip)
> <p>Generative adversarial imitation learning (GAIL) demonstrates tremendous success in practice, especially when combined with neural networks. Different from reinforcement learning, GAIL learns both policy and reward function from expert (human) demonstration. Despite its empirical success, it remains unclear whether GAIL with neural networks converges to the globally optimal solution. The major difﬁculty comes from the nonconvex-nonconcave minimax optimization structure. To bridge the gap between practice and theory, we analyze a gradient-based algorithm with alternating updates and establish its sublinear convergence to the globally optimal solution. To the best of our knowledge, our analysis establishes the global optimality and convergence rate of GAIL with neural networks for the ﬁrst time.</p> 
### 549.[A Game Theoretic Perspective on Model-Based Reinforcement Learning](https://proceedings.icml.cc/book/3789.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3189-Paper.pdf)
  Aravind Rajeswaran, Igor Mordatch, Vikash Kumar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3189-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3189-Supplemental.zip)
> <p>We illustrate how game theory is a good framework to understand model-based reinforcement learning (MBRL). We point out that a large class of MBRL algorithms can be viewed as a game between two players: (1) a policy player, which attempts to maximize rewards under the learned model; (2) a model player, which attempts to fit the real-world data collected by the policy player. Their goals need not be aligned, and are often conflicting. We show that stable algorithms for MBRL can be derived by considering a Stackelberg game between the two players. This formulation gives rise to two natural schools of MBRL algorithms based on which player is chosen as the leader in the Stackelberg game, and together encapsulate many existing MBRL algorithms. Through experiments on a suite of continuous control tasks, we validate that algorithms based on our framework lead to stable and sample efficient learning.</p> 
### 550.[(Locally) Differentially Private Combinatorial Semi-Bandits](https://proceedings.icml.cc/book/3790.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3194-Paper.pdf)
  Xiaoyu Chen, Kai Zheng, Zixin Zhou, Yunchang Yang, Wei Chen, Liwei Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3194-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3194-Supplemental.pdf)
> In this paper, we study (locally) differentially private Combinatorial Semi-Bandits (CSB). Compared with private Multi-Armed Bandits (MAB), since the server receives more information from the user, it usually leads to additional dependence over the dimension of feedback, which is a notorious problem in private learning.  Somewhat surprisingly, we show that it is possible to remove this side-effect caused by privacy protection and nearly match corresponding non-private best results. In detail, for general CSB with $B$-bounded smooth reward function in the sense of Chen et al. 2016, we propose a novel algorithm that achieves regret bound $\tilde{\mc{O}}(mB^2\log T / \epsilon)$ over $T$ rounds under $\epsilon$-local differential privacy, where $m$ is the number of base arms. However, for Linear CSB, $B$ equals $K$, where $K$ is the maximum number of feedback in each round, and above bound has an additional $K$ compared with non-private optimal result. We then propose a different algorithm with nearly optimal regret bound $\tilde{\mc{O}}(mK\log T / \epsilon)$ if one cares about $\epsilon$-differential privacy rather than $\epsilon$-local differential privacy. Besides, we also prove some  lower bounds in each setting.
### 551.[Optimizing for the Future in Non-Stationary MDPs](https://proceedings.icml.cc/book/3791.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3200-Paper.pdf)
  Yash Chandak, Georgios Theocharous, Shiv Shankar, Martha White, Sridhar Mahadevan, Philip Thomas [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3200-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3200-Supplemental.pdf)
> <p>Most reinforcement learning methods are based upon the key assumption that the transition dynamics and reward functions are fixed, that is, the underlying Markov decision process (MDP) is stationary. However, in many practical real-world applications, this assumption is clearly violated. We discuss how current methods can have inherent limitations for non-stationary MDPs, and therefore searching a policy that is good for the future, unknown MDP, requires rethinking the optimization paradigm. To address this problem, we develop a method that builds upon ideas from both counter-factual reasoning and curve-fitting to proactively search for a good future policy, without ever modeling the underlying non-stationarity. The effectiveness of the proposed method is demonstrated on problems motivated by real-world applications.</p> 
### 552.[Learning Task-Agnostic Embedding of Multiple Black-Box Experts for Multi-Task Model Fusion](https://proceedings.icml.cc/book/3792.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3219-Paper.pdf)
  Nghia Hoang, Thanh Lam, Bryan Kian Hsiang Low, Patrick Jaillet  [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3219-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3219-Supplemental.pdf)
> <p>Model fusion is an emerging study in collective learning where heterogeneous experts with private data and learning architectures need to combine their black-box knowledge for better performance. Existing literature achieves this via a local knowledge distillation scheme that transfuses the predictive patterns of each pre-trained expert onto a white-box imitator model, which can be incorporated efficiently into a global model. This scheme however does not extend to multi-task scenarios where different experts were trained to solve different tasks and only part of their distilled knowledge is relevant to a new task. To address this multi-task challenge, we develop a new fusion paradigm that represents each expert as a distribution over a spectrum of predictive prototypes, which are isolated from task-specific information encoded within the prototype distribution. The task-agnostic prototypes can then be reintegrated to generate a new model that solves a new task encoded with a different prototype distribution. The fusion and adaptation performance of the proposed framework is demonstrated empirically on several real-world benchmark datasets.</p> 
### 553.[Dual-Path Distillation: A Unified Framework to Improve Black-Box Attacks](https://proceedings.icml.cc/book/3793.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3224-Paper.pdf)
  Yonggang Zhang, Ya Li, Tongliang Liu, Xinmei Tian [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3224-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3224-Supplemental.zip)
> <p>We study the problem of constructing black-box adversarial attacks, where no model information is revealed except for the feedback knowledge of the given inputs. To obtain sufficient knowledge for crafting adversarial examples, previous methods query the target model with inputs that are perturbed with different searching directions. However, these methods suffer from poor query efficiency since the employed searching directions are sampled randomly. To mitigate this issue, we formulate the goal of mounting efficient attacks as an optimization problem in which the adversary tries to fool the target model with a limited number of queries. Under such settings, the adversary has to select appropriate searching directions to reduce the number of model queries. By solving the efficient-attack problem, we find that we need to distill the knowledge in both the path of the adversarial examples and the path of the searching directions. Therefore, we propose a novel framework, dual-path distillation, that utilizes the feedback knowledge not only to craft adversarial examples but also to alter the  searching directions to achieve efficient attacks.  Experimental results suggest that our framework can significantly increase the query efficiency.</p> 
### 554.[Safe Deep Semi-Supervised Learning for Unseen-Class Unlabeled Data](https://proceedings.icml.cc/book/3794.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3231-Paper.pdf)
  Lan-Zhe Guo, Zhen-Yu Zhang, Yuan Jiang, Yufeng Li, Zhi-Hua Zhou [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3231-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3231-Supplemental.pdf)
> Deep semi-supervised learning (SSL) has been shown very effectively. However, its performance is seriously hurt when the class distribution is mismatched, among which a common phenomenon is that unlabeled data contains the classes not seen in labeled data. Efforts on this aspect remain to be limited. This paper proposes a simple and effective safe deep SSL method to alleviate the performance harm caused by it. In theory, the result learned from the new method is never worse than learning from merely labeled data, and it is theoretically guaranteed that its generalization approaches the optimal in the order $O(\sqrt{d\ln(n)/n})$, even faster than the convergence rate in supervised learning associated with massive parameters. In the experiment of benchmark data, unlike the existing deep SSL methods which are no longer as good as supervised learning in 40\% of unseen-class unlabeled data, the new method can still achieve performance gain in more than 60\% of unseen-class unlabeled data. The proposal is suitable for any deep SSL algorithm and can be easily extended to handle other cases of class distribution mismatch.
### 555.[Generalizing Convolutional Neural Networks for Equivariance to Lie Groups on Arbitrary Continuous Data](https://proceedings.icml.cc/book/3795.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3232-Paper.pdf)
  Marc Finzi, Samuel Stanton, Pavel Izmailov, Andrew Wilson [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3232-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3232-Supplemental.pdf)
> <p>The translation equivariance of convolutional layers enables CNNs to generalize well on image problems. While translation equivariance provides a powerful inductive bias for images, we often additionally desire equivariance to other transformations, such as rotations, especially for non-image data. We propose a general method to construct a convolutional layer that is equivariant to transformations from any specified Lie group with a surjective exponential map. Incorporating equivariance to a new group requires implementing only the group exponential and logarithm maps, enabling rapid prototyping. Showcasing the simplicity and generality of our method, we apply the same model architecture to images, ball-and-stick molecular data, and Hamiltonian dynamical systems. For Hamiltonian systems, the equivariance of our models is especially impactful, leading to exact conservation of linear and angular momentum.</p> 
### 556.[Dispersed EM-VAEs for Interpretable Text Generation](https://proceedings.icml.cc/book/3796.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3242-Paper.pdf)
  Wenxian Shi, Hao Zhou, Ning Miao, Lei Li [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3242-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3242-Supplemental.zip)
> <p>Interpretability is important in text generation for guiding the generation with interpretable attributes. Variational auto-encoder (VAE) with Gaussian distribution as prior has been successfully applied in text generation, but it is hard to interpret the meaning of the latent variable. To enhance the controllability and interpretability, one can replace the Gaussian prior with a mixture of Gaussian distributions (GM-VAE), whose mixture components could be related to some latent attributes of data. Unfortunately, straightforward variational training of GM-VAE leads the mode-collapse problem. In this paper, we find that mode-collapse is a general problem for VAEs with exponential family mixture priors.  We propose DEM-VAE, which introduces an extra dispersion term to induce a well-structured latent space. Experimental results show that our approach does obtain a well structured latent space, with which our method outperforms strong baselines in interpretable text generation benchmarks.</p> 
### 557.[Deep Graph Random Process for Relational-Thinking-Based  Speech Recognition](https://proceedings.icml.cc/book/3797.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3253-Paper.pdf)
  Huang Hengguan, Fuzhao Xue, Hao Wang, Ye Wang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3253-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3253-Supplemental.pdf)
> <p>Both relational thinking and relational reasoning lie at the core of human intelligence. While relational reasoning has inspired many perspectives in artificial intelligence, relational thinking is relatively unexplored in solving machine learning problems. It is characterized by initially relying on innumerable unconscious percepts pertaining to relations between new sensory signals and prior knowledge, consequently becoming a recognizable concept or object through coupling of these percepts. Such mental processes are difficult to model in real-world problems such as in conversational automatic speech recognition (ASR), as the percepts (e.g. unconscious mental impressions formed while hearing sounds) are supposed to be innumerable and not directly observable. And yet the dialogue history of the conversation might still reflect such underlying processes, allowing an indirect way of modeling. We present a framework that models a percept as weak relations between a current utterance and its history. We assume the probability of the existence of such a relation to be close to zero due to the unconsciousness of the percept. Given an utterance and its history, our method can generate an infinite number of probabilistic graphs representing percepts and further analytically combine them into a new graph representing strong relations among utterances. This new graph can be further transformed to be task-specific and provide an informative representation for acoustic modeling. Our approach is able to successfully infer relations among utterances without using any relational data during training. Experimental evaluations on ASR tasks including CHiME-2, SWB-30k and CHiME-5 demonstrate the effectiveness and benefits of our method.</p> 
### 558.[Hypernetwork approach to generating point clouds](https://proceedings.icml.cc/book/3798.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3258-Paper.pdf)
  Przemysław Spurek, Sebastian Winczowski, Jacek Tabor, Maciej Zamorski, Maciej Zieba, Tomasz Trzcinski [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3258-Metadata.json)
> <p>In this work, we propose a novel method for generating 3D point clouds that leverage properties of hyper networks. Contrary to the existing methods that learn only the representation of a 3D object, our approach simultaneously finds a representation of the object and its 3D surfaces. The main idea of our HyperCloud method is to build a hyper network that returns weights of a particular neural network (target network) trained to map points from a uniform unit ball distribution into a 3D shape. As a consequence, a particular 3D shape can be generated using point-by-point sampling from the assumed prior distribution and transforming sampled points with the target network. Since the hyper network is based on an auto-encoder architecture trained to reconstruct realistic 3D shapes, the target network weights can be considered a parametrisation of the surface of a 3D shape, and not a standard representation of point cloud usually returned by competitive approaches. The proposed architecture allows to find mesh-based representation of 3D objects in a generative manner, while providing point clouds en pair in quality with the state-of-the-art methods. </p> 
### 559.[On a projective ensemble approach to two sample test for equality of distributions](https://proceedings.icml.cc/book/3799.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3271-Paper.pdf)
  Zhimei Li, Yaowu Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3271-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3271-Supplemental.pdf)
> <p>In this work, we propose a robust test for the multivariate two-sample problem through projective ensemble, which is a generalization of the Cramer-von Mises statistic. The proposed test statistic has a simple closed-form expression without any tuning parameters involved, it is easy to implement can be computed in quadratic time. Moreover, our test is insensitive to the dimension and consistent against all fixed alternatives, it does not require the moment assumption and is robust to the presence of outliers. We study the asymptotic behaviors of the test statistic under the null and two kinds of alternative hypotheses. We also suggest a permutation procedure to approximate critical values and employ its consistency. We demonstrate the effectiveness of our test through extensive simulation studies and a real data application.</p> 
### 560.[Coresets for Data-efficient Training of Machine Learning Models](https://proceedings.icml.cc/book/3800.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3274-Paper.pdf)
  Baharan Mirzasoleiman, Jeff Bilmes, Jure Leskovec [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3274-Metadata.json)
> <p>Incremental gradient (IG) methods, such as stochastic gradient descent and its variants are commonly used for large scale optimization in machine learning. Despite the sustained effort to make IG methods more data-efficient, it remains an open question how to select a training data subset that can theoretically and practically perform on par with the full dataset. Here we develop CRAIG, a method to select a weighted subset (or coreset) of training data that closely estimates the full gradient by maximizing a submodular function. We prove that applying IG to this subset is guaranteed to converge to the (near)optimal solution with the same convergence rate as that of IG for convex optimization. As a result, CRAIG achieves a speedup that is inversely proportional to the size of the subset. To our knowledge, this is the first rigorous method for data-efficient training of general machine learning models. Our extensive set of experiments show that CRAIG, while achieving practically the same solution, speeds up various IG methods by up to 6x for logistic regression and 3x for training deep neural networks.</p> 
### 561.[Searching to Exploit Memorization Effect in Learning with Noisy Labels](https://proceedings.icml.cc/book/3801.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3285-Paper.pdf)
  QUANMING YAO, Hansi Yang, Bo Han, Gang Niu, James Kwok [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3285-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3285-Supplemental.pdf)
> <p>Sample selection approaches are popular in robust learning from noisy labels. However, how to properly control the selection process so that deep networks can benefit from the memorization effect is a hard problem. In this paper, motivated by the success of automated machine learning (AutoML), we model this issue as a function approximation problem.  Specifically, we design a domain-specific search space based on general patterns of the memorization effect and propose a novel Newton algorithm to solve the bi-level optimization problem efficiently.  We further provide a theoretical analysis of the algorithm, which ensures a good approximation to critical points. Experiments are performed on both benchmark and real-world data sets. Results demonstrate that the proposed method is much better than the state-of-the-art noisy-label-learning approaches, and also much more efficient than existing AutoML algorithms.</p> 
### 562.[Randomized Smoothing of All Shapes and Sizes](https://proceedings.icml.cc/book/3802.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3289-Paper.pdf)
  Greg Yang, Tony Duan, J. Edward Hu, Hadi Salman, Ilya Razenshteyn, Jerry Li [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3289-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3289-Supplemental.pdf)
> Randomized smoothing is the current state-of-the-art defense with provable robustness against $\ell_2$ adversarial attacks. Many works have devised new randomized smoothing schemes for other metrics, such as $\ell_1$ or $\ell_\infty$; however, substantial effort was needed to derive such new guarantees. This begs the question: can we find a general theory for randomized smoothing?  We propose a novel framework for devising and analyzing randomized smoothing schemes, and validate its effectiveness in practice. Our theoretical contributions are: (1) we show that for an appropriate notion of &quot;optimal&quot;, the optimal smoothing distributions for any &quot;nice&quot; norms have level sets given by the norm&#x27;s *Wulff Crystal*; (2) we propose two novel and complementary methods for deriving provably robust radii for any smoothing distribution; and, (3) we show fundamental limits to current randomized smoothing techniques via the theory of *Banach space cotypes*. By combining (1) and (2), we significantly improve the state-of-the-art certified accuracy in $\ell_1$ on standard datasets. Meanwhile, we show using (3) that with only label statistics under random input perturbations, randomized smoothing cannot achieve nontrivial certified accuracy against perturbations of $\ell_p$-norm $\Omega(\min(1, d^{\frac{1}{p} - \frac{1}{2}}))$, when the input dimension $d$ is large. We provide code in github.com/tonyduan/rs4a.
### 563.[DeepCoDA: personalized interpretability for compositional health](https://proceedings.icml.cc/book/3803.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3291-Paper.pdf)
  Thomas Quinn, Dang Nguyen, Santu Rana, Sunil Gupta, Svetha Venkatesh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3291-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3291-Supplemental.pdf)
> <p>Interpretability allows the domain-expert to directly evaluate the model's relevance and reliability, a practice that offers assurance and builds trust. In the healthcare setting, interpretable models should implicate relevant biological mechanisms independent of technical factors like data pre-processing. We define personalized interpretability as a measure of sample-specific feature attribution, and view it as a minimum requirement for a precision health model to justify its conclusions. Some health data, especially those generated by high-throughput sequencing experiments, have nuances that compromise precision health models and their interpretation. These data are compositional, meaning that each feature is conditionally dependent on all other features. We propose the DeepCoDA framework to extend precision health modelling to high-dimensional compositional data, and to provide personalized interpretability through patient-specific weights. Our architecture maintains state-of-the-art performance across 25 real-world data sets, all while producing interpretations that are both personalized and fully coherent for compositional data.</p> 
### 564.[Private Query Release Assisted by Public Data](https://proceedings.icml.cc/book/3804.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3293-Paper.pdf)
  Raef Bassily, Albert Cheu, Shay Moran, Aleksandar Nikolov, Jonathan Ullman, Steven Wu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3293-Metadata.json)
> We study the problem of differentially private query release assisted by public data. Given a class $H$ of queries $h:X \rightarrow \{-1, 1\}$, and data set of i.i.d. samples from an unknown distribution $D$, a query-release algorithm is required to output a data structure $G: H \rightarrow [-1, 1]$ such that for any query $h\in H,$ $G(h)$ approximates $E_{x\sim D}[h(x)]$ up to some error $\alpha$. In this problem, the input data set consists of two types of samples: private and public.  The algorithm is required to satisfy differential privacy only with respect to the private samples. We study the limits of this task in terms of private and public sample complexities. First, we show that this task is achievable for any query class of finite VC-dimension using only (roughly) $d/\alpha$ public samples and $\sqrt{p}d^{3/2}/\alpha^2$ private samples, where $d$ is the VC-dimension of the class, and $p$ is the dual VC-dimension. When there are no public samples, there are known examples of classes of VC-dimension one for which this task is impossible under differential privacy (e.g., the class of threshold functions over $R$). Moreover, our upper bound on the public sample complexity is non-trivial since, without private samples, it is known that this task is equivalent to uniform convergence over $H$ which requires at least $d/\alpha^2$ public samples. Next, we give lower bounds on private and public sample complexities with tight dependence on $p$ and $\alpha$. In particular, for the class of decision stumps, we give a lower bound of $\sqrt{p}/\alpha$ on the private sample complexity whenever the number of public samples is $&lt;1/\alpha^2$. Given our upper bound, this shows that the dependence on $\sqrt{p}$ in the private sample complexity is necessary (in the non-trivial regime where the public samples are insufficient to solve the problem on its own). We also give a tight lower bound of $1/\alpha$ on the public sample complexity for a broad family of query classes.
### 565.[Adaptive Droplet Routing in Digital Microfluidic Biochips Using Deep Reinforcement Learning](https://proceedings.icml.cc/book/3805.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3297-Paper.pdf)
  Tung-Che Liang, Zhanwei Zhong, Yaas Bigdeli, Tsung-Yi Ho, Richard Fair, Krishnendu Chakrabarty [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3297-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3297-Supplemental.zip)
> <p>We present and investigate a novel application domain for deep reinforcement learning (RL): droplet routing on digital microfluidic biochips (DMFBs). A DMFB, composed of a two-dimensional electrode array, manipulates discrete fluid droplets to automatically execute biochemical protocols such as high-throughput DNA sequencing and point-of-care clinical diagnosis. However, a major concern associated with the use of DMFBs is that electrodes in a biochip can degrade over time. Droplet-transportation operations associated with the degraded electrodes can fail, thereby compromising the integrity of the bioassay outcome. While it is not feasible to detect the degradation of an electrode by simply examining its appearance, we show that casting droplet transportation as an RL problem enables the training of deep network policies to capture the underlying health conditions of electrodes and to provide reliable fluidic operations. We propose a new RL-based droplet-routing flow that can be used for various sizes of DMFBs, and demonstrate reliable execution of an epigenetic bioassay with the RL droplet router on a fabricated DMFB. To facilitate further research, we also present a simulation environment based on the OpenAI Gym Interface for RL-guided droplet-routing problems on DMFBs.</p> 
### 566.[Continuous-time Lower Bounds for Gradient-based Algorithms](https://proceedings.icml.cc/book/3806.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3305-Paper.pdf)
  Michael Muehlebach, Michael Jordan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3305-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3305-Supplemental.pdf)
> <p>This article derives lower bounds on the convergence rate of continuous-time gradient-based optimization algorithms. The algorithms are subjected to a time-normalization constraint that avoids a reparametrization of time in order to make the discussion of continuous-time convergence rates meaningful. We reduce the multi-dimensional problem to a single dimension, recover well-known lower bounds from the discrete-time setting, and provide insights into why these lower bounds occur. We further explicitly provide algorithms that achieve the proposed lower bounds, even when the function class under consideration includes certain non-convex functions.</p> 
### 567.[A Tree-Structured Decoder for Image-to-Markup Generation](https://proceedings.icml.cc/book/3807.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3307-Paper.pdf)
  Jianshu Zhang, Jun Du, Yongxin Yang, Yi-Zhe Song, Si Wei, Lirong Dai [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3307-Metadata.json)
> <p>Recent encoder-decoder approaches typically employ string decoders to convert images into serialized strings for image-to-markup. However, for tree-structured representational markup, string representations can hardly cope with the structural complexity. In this work, we first show via a set of toy problems that string decoders struggle to decode tree structures, especially as structural complexity increases. We then propose a tree-structured decoder that specifically aims at generating a tree-structured markup. Our decoders works sequentially, where at each step a child node and its parent node are simultaneously generated to form a sub-tree. This sub-tree is consequently used to construct the final tree structure in a recurrent manner. Key to the success of our tree decoder is twofold, (i) it strictly respects the parent-child relationship of trees, and (ii) it explicitly outputs trees as oppose to a linear string. Evaluated on both math formula recognition and chemical formula recognition, the proposed tree decoder is shown to greatly outperform strong string decoder baselines.</p> 
### 568.[Sample Factory: Egocentric 3D Control from Pixels at 100000 FPS with Asynchronous Reinforcement Learning](https://proceedings.icml.cc/book/3808.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3314-Paper.pdf)
  Aleksei Petrenko, Zhehui Huang, Tushar Kumar, Gaurav Sukhatme, Vladlen Koltun [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3314-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3314-Supplemental.pdf)
> Increasing the scale of reinforcement learning experiments has allowed researchers to achieve unprecedented results in both training sophisticated agents for video games, and in sim-to-real transfer for robotics. Typically such experiments rely on large distributed systems and require expensive hardware setups, limiting wider access to this exciting area of research. In this work we aim to solve this problem by optimizing the efficiency and resource utilization of reinforcement learning algorithms instead of relying on distributed computation. We present the &quot;Sample Factory&quot;, a high-throughput training system optimized for a single-machine setting. Our architecture combines a highly efficient, asynchronous, GPU-based sampler with off-policy correction techniques, allowing us to achieve throughput higher than $10^5$ environment frames/second on non-trivial control problems in 3D without sacrificing sample efficiency. We extend Sample Factory to support self-play and population-based training and apply these techniques to train highly capable agents for a multiplayer first-person shooter game. Github: https://github.com/alex-petrenko/sample-factory
### 569.[Scalable Deep Generative Modeling for Sparse Graphs](https://proceedings.icml.cc/book/3809.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3323-Paper.pdf)
  Hanjun Dai, Azade Nazi, Yujia Li, Bo Dai, Dale Schuurmans [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3323-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3323-Supplemental.pdf)
> Learning graph generative models is a challenging task for deep learning and has wide applicability to a range of domains like chemistry, biology and social science. However current deep neural methods suffer from limited scalability: for a graph with $n$ nodes and $m$ edges, existing deep neural methods require $\Omega(n^2)$ complexity by building up the  adjacency matrix. On the other hand, many real world graphs are actually sparse in the sense that $m\ll n^2$. Based on this, we develop a novel autoregressive model, named BiGG, that utilizes this sparsity to avoid generating the full adjacency matrix, and importantly reduces the graph generation time complexity to $O((n + m)\log n)$. Furthermore, during training this autoregressive model can be parallelized with $O(\log n)$ synchronization stages, which makes it much more efficient than other autoregressive models that require $\Omega(n)$. Experiments on several benchmarks show that the proposed approach not only scales to orders of magnitude larger graphs than previously possible with deep autoregressive graph generative models, but also yields better graph generation quality.
### 570.[Closed Loop Neural-Symbolic Learning via Integrating Neural Perception, Grammar Parsing, and Symbolic Reasoning](https://proceedings.icml.cc/book/3810.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3327-Paper.pdf)
  Qing Li, Siyuan Huang, Yining Hong, Yixin Chen, Ying Nian Wu, Song-Chun Zhu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3327-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3327-Supplemental.pdf)
> <p>The goal of neural-symbolic computation is to integrate the connectionist and symbolist paradigms. Prior methods learn the neural-symbolic models using reinforcement learning (RL) approaches, which ignore the error propagation in the symbolic reasoning module and thus converge slowly with sparse rewards. In this paper, we address these issues and close the loop of neural-symbolic learning by (1) introducing the grammar model as a symbolic prior to bridge neural perception and symbolic reasoning, and (2) proposing a novel back-search algorithm which mimics the top-down human-like learning procedure to propagate the error through the symbolic reasoning module efficiently. We further interpret the proposed learning framework as maximum likelihood estimation using Markov chain Monte Carlo sampling and the back-search algorithm as a Metropolis-Hastings sampler. The experiments are conducted on two weakly-supervised neural-symbolic tasks: (1) handwritten formula recognition on the newly introduced HWF dataset; (2) visual question answering on the CLEVR dataset. The results show that our approach significantly outperforms the RL methods in terms of performance, converging speed, and data efficiency. Our code and data are released at https://liqing-ustc.github.io/NGS.</p> 
### 571.[NGBoost: Natural Gradient Boosting for Probabilistic Prediction](https://proceedings.icml.cc/book/3811.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3337-Paper.pdf)
  Tony Duan, Anand Avati, Daisy Ding, Khanh K. Thai, Sanjay Basu, Andrew Ng, Alejandro Schuler [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3337-Metadata.json)
> <p>We present Natural Gradient Boosting (NGBoost), an algorithm for generic probabilistic prediction via gradient boosting. Typical regression models return a point estimate, conditional on covariates, but probabilistic regression models output a full probability distribution over the outcome space, conditional on the covariates. This allows for predictive uncertainty estimation - crucial in applications like healthcare and weather forecasting. NGBoost generalizes gradient boosting to probabilistic regression by treating the parameters of the conditional distribution as targets for a multiparameter boosting algorithm. Furthermore, we show how the Natural Gradient is required to correct the training dynamics of our multiparameter boosting approach. NGBoost can be used with any base learner, any family of distributions with continuous parameters, and any scoring rule. NGBoost matches or exceeds the performance of existing methods for probabilistic prediction while offering additional benefits in flexibility, scalability, and usability. An open-source implementation is available at github.com/stanfordmlgroup/ngboost.</p> 
### 572.[Q-value Path Decomposition for Deep Multiagent Reinforcement Learning](https://proceedings.icml.cc/book/3812.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3354-Paper.pdf)
  Yaodong Yang, Jianye Hao, Guangyong Chen, Hongyao Tang, Yingfeng Chen, Yujing Hu, Changjie Fan, Zhongyu Wei [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3354-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3354-Supplemental.pdf)
> <p>Recently, deep multiagent reinforcement learning (MARL) has become a highly active research area as many real-world problems can be inherently viewed as multiagent systems. A particularly interesting and widely applicable class of problems is the partially observable cooperative multiagent setting, in which a team of agents learns to coordinate their behaviors conditioning on their private observations and commonly shared global reward signals. One natural solution is to resort to the centralized training and decentralized execution paradigm. During centralized training, one key challenge is the multiagent credit assignment: how to allocate the global rewards for individual agent policies for better coordination towards maximizing system-level's benefits. In this paper, we propose a new method called Q-value Path Decomposition (QPD) to decompose the system's global Q-values into individual agents' Q-values. Unlike previous works which restrict the representation relation of the individual Q-values and the global one, we leverage the integrated gradient attribution technique into deep MARL to directly decompose global Q-values along trajectory paths to assign credits for agents. We evaluate QPD on the challenging StarCraft II micromanagement tasks and show that QPD achieves the state-of-the-art performance in both homogeneous and heterogeneous multiagent scenarios compared with existing cooperative MARL algorithms.</p> 
### 573.[Online Learned Continual Compression with Adaptive Quantization Modules](https://proceedings.icml.cc/book/3813.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3358-Paper.pdf)
  Lucas Caccia, Eugene Belilovsky, Massimo Caccia, Joelle Pineau [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3358-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3358-Supplemental.pdf)
> <p>We introduce and study the problem of Online Continual Compression, where one attempts to simultaneously learn to compress and store a representative dataset from a non i.i.d data stream, while only observing each sample once. A naive application of auto-encoder in this setting encounters a major challenge: representations derived from earlier encoder states must be usable by later decoder states. We show how to use discrete auto-encoders to effectively address this challenge and introduce Adaptive Quantization Modules (AQM) to control variation in the compression ability of the module at any given stage of learning.  This enables selecting an appropriate compression for incoming samples, while taking into account overall memory constraints and current progress of the learned compression.  Unlike previous methods, our approach does not require any pretraining, even on challenging datasets. We show that using AQM to replace standard episodic memory in continual learning settings leads to significant gains on continual learning benchmarks with images, LiDAR, and reinforcement learning agents.</p> 
### 574.[Learning What to Defer for Maximum Independent Sets](https://proceedings.icml.cc/book/3814.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3363-Paper.pdf)
  Sungsoo Ahn, Younggyo Seo, Jinwoo Shin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3363-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3363-Supplemental.pdf)
> <p>Designing efficient algorithms for combinatorial optimization appears ubiquitously in various scientific fields. Recently, deep reinforcement learning (DRL) frameworks have gained considerable attention as a new approach: they can automate the design of a solver while relying less on sophisticated domain knowledge of the target problem. However, the existing DRL solvers determine the solution using a number of stages proportional to the size of the solution, which severely limits their applicability to large-scale graphs. In this paper, we seek to resolve this issue by proposing a novel DRL scheme where the agent adaptively shrinks or stretch the number of stages by learning to defer the determination of the solution at each stage. We apply the proposed framework, coined Learning what to Defer (LwD), to the maximum independent set (MIS) problem, and demonstrate its significant improvement over the current state-of-the-art DRL scheme. We also show that LwD can outperform the conventional MIS solvers on large-scale graphs having millions of vertices, under a limited time budget. </p> 
### 575.[Generalized and Scalable Optimal Sparse Decision Trees](https://proceedings.icml.cc/book/3815.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3364-Paper.pdf)
  Jimmy Lin, Chudi Zhong, Diane Hu, Cynthia Rudin, Margo Seltzer [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3364-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3364-Supplemental.pdf)
> <p>Decision tree optimization is notoriously difficult from a computational perspective but essential for the field of interpretable machine learning. Despite efforts over the past 40 years, only recently have optimization breakthroughs been made that have allowed practical algorithms to find optimal decision trees. These new techniques have the potential to trigger a paradigm shift, where, it is possible to construct sparse decision trees to efficiently optimize a variety of objective functions, without relying on greedy splitting and pruning heuristics that often lead to suboptimal solutions. The contribution in this work is to provide a general framework for decision tree optimization that addresses the two significant open problems in the area: treatment of imbalanced data and fully optimizing over continuous variables. We present techniques that produce optimal decision trees over variety of objectives including F-score, AUC, and partial area under the ROC convex hull. We also introduce a scalable algorithm that produces provably optimal results in the presence of continuous variables and speeds up decision tree construction by several order of magnitude relative to  the state-of-the art.</p> 
### 576.[The Effect of Natural Distribution Shift on Question Answering Models](https://proceedings.icml.cc/book/3816.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3366-Paper.pdf)
  John Miller, Karl Krauth, Ludwig Schmidt, Benjamin Recht [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3366-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3366-Supplemental.pdf)
> <p>We build four new test sets for the Stanford Question Answering Dataset (SQuAD) and evaluate the ability of question-answering systems to generalize to new data. In the original Wikipedia domain, we find no evidence of adaptive overfitting despite several years of test-set reuse. On datasets derived from New York Times articles, Reddit posts, and Amazon product reviews, we observe average performance drops of 3.0, 12.6, and 14.0 F1, respectively, across a broad range of models. In contrast, a strong human baseline matches or exceeds the performance of SQuAD models on the original domain and exhibits little to no drop in new domains. Taken together, our results confirm the surprising resilience of the holdout method and emphasize the need to move towards evaluation metrics that incorporate robustness to natural distribution shifts.</p> 
### 577.[Quantized Decentralized Stochastic Learning over Directed Graphs](https://proceedings.icml.cc/book/3817.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3372-Paper.pdf)
  Hossein Taheri, Aryan Mokhtari, Hamed Hassani, Ramtin Pedarsani [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3372-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3372-Supplemental.pdf)
> <p>We consider a decentralized stochastic learning problem where data points are distributed among computing nodes communicating over a directed graph. As the model size gets large, decentralized learning faces a major bottleneck that is the heavy communication load due to each node transmitting large messages (model updates) to its neighbors. To tackle this bottleneck, we propose the quantized decentralized stochastic learning algorithm over directed graphs that is based on the push-sum algorithm in decentralized consensus optimization. More importantly, we prove that our algorithm achieves the same convergence rates of the decentralized stochastic learning algorithm with exact-communication for both convex and non-convex losses. A key technical challenge of the work is to prove exact convergence of the proposed decentralized learning algorithm in the presence of quantization noise with unbounded variance over directed graphs. We provide numerical evaluations that corroborate our main theoretical results and illustrate significant speed-up compared to the exact-communication methods.</p> 
### 578.[Semi-Supervised Learning with Normalizing Flows](https://proceedings.icml.cc/book/3818.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3378-Paper.pdf)
  Pavel Izmailov, Polina Kirichenko, Marc Finzi, Andrew Wilson [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3378-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3378-Supplemental.pdf)
> <p>Normalizing flows transform a latent distribution through an invertible neural network for a flexible and pleasingly simple approach to generative modelling, while preserving an exact likelihood. We propose FlowGMM, an end-to-end approach to generative semi supervised learning with normalizing flows, using a latent Gaussian mixture model. FlowGMM is distinct in its simplicity, unified treatment of labelled and unlabelled data with an exact likelihood, interpretability, and broad applicability beyond image data. We show promising results on a wide range of applications, including AG-News and Yahoo Answers text data, tabular data, and semi-supervised image classification. We also show that FlowGMM can discover interpretable structure, provide real-time optimization-free feature visualizations, and specify well calibrated predictive distributions.</p> 
### 579.[Student Specialization in Deep Rectified Networks With Finite Width and Input Dimension](https://proceedings.icml.cc/book/3819.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3379-Paper.pdf)
  Yuandong Tian [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3379-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3379-Supplemental.pdf)
> We consider a deep ReLU / Leaky ReLU student network trained from the output of a fixed teacher network of the same depth, with Stochastic Gradient Descent (SGD). The student network is \emph{over-realized}: at each layer $l$, the number $n_l$ of student nodes is more than that ($m_l$) of teacher. Under mild conditions on dataset and teacher network, we prove that when the gradient is small at every data sample, each teacher node is \emph{specialized} by at least one student node \emph{at the lowest layer}. For two-layer network, such specialization can be achieved by training on any dataset of \emph{polynomial} size $\cO( K^{5/2} d^3 \epsilon^{-1})$ (sample size including augmentation) until the gradient magnitude drops to $\cO(\epsilon/K^{3/2}\sqrt{d})$, where $d$ is the input dimension, $K = m_1 + n_1$ is the total number of neurons in the lowest layer of teacher and student. To our best knowledge, we are the first to give polynomial sample complexity for student specialization of training two-layer (Leaky) ReLU networks with finite depth and width in teacher-student setting, and finite complexity for the lowest layer specialization in multi-layer case, without parametric assumption of the input (like Gaussian). Our theory suggests that teacher nodes with large fan-out weights get specialized first when the gradient is still large, while others are specialized with small gradient, which suggests inductive bias in training. This shapes the stage of training as empirically observed in multiple previous works. Experiments on synthetic and CIFAR10 verify our findings.
### 580.[Sample Amplification: Increasing Dataset Size even when Learning is Impossible](https://proceedings.icml.cc/book/3820.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3381-Paper.pdf)
  Brian Axelrod, Shivam Garg, Vatsal Sharan, Gregory Valiant [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3381-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3381-Supplemental.pdf)
> <p>Given data drawn from an unknown distribution, D, to what extent is it possible to <code>amplify'' this dataset and faithfully output an even larger set of samples that appear to have been drawn from D? We formalize this question as follows: an (n,m) amplification procedure takes as input n independent draws from an unknown distribution D, and outputs a set of m &gt; n</code>samples'' which must be indistinguishable from m samples drawn iid from D. We consider this sample amplification problem in two fundamental settings: the case where D is an arbitrary discrete distribution supported on k elements, and the case where D is a d-dimensional Gaussian with unknown mean, and fixed covariance matrix. Perhaps surprisingly, we show a valid amplification procedure exists for both of these settings, even in the regime where the size of the input dataset, n, is significantly less than what would be necessary to learn distribution D to non-trivial accuracy. We also show that our procedures are optimal up to constant factors.  Beyond these results, we describe potential applications of such data amplification, and formalize a number of curious directions for future research along this vein. </p> 
### 581.[Alleviating Privacy Attacks via Causal Learning](https://proceedings.icml.cc/book/3821.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3387-Paper.pdf)
  Shruti Tople, Amit Sharma, Aditya Nori [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3387-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3387-Supplemental.pdf)
> <p>Machine learning models, especially deep neural networks have been shown to reveal membership information of inputs in the training data. Such membership inference attacks are a serious privacy concern, for example, patients providing medical records to build a model that detects HIV would not want their identity to be leaked. Further, we show that the attack accuracy amplifies when the model is used to predict samples that come from a different distribution than the training set, which is often the case in real world applications. Therefore, we propose the use of causal learning approaches where a model learns the causal relationship between the input features and the outcome. An ideal causal model is known to be invariant to the training distribution and hence generalizes well to shifts between samples from the same distribution and across different distributions. First, we prove that models learned using causal structure provide stronger differential privacy guarantees than associational models under reasonable assumptions. Next, we show that causal models trained on sufficiently large samples are robust to membership inference attacks across different distributions of datasets and those trained on smaller sample sizes always have lower attack accuracy than corresponding associational models. Finally, we confirm our theoretical claims with experimental evaluation on 4 datasets with moderately complex Bayesian networks and an image dataset of colored MNIST. We observe that neural network-based associational models exhibit upto 80% attack accuracy under different test distributions and sample sizes whereas causal models exhibit attack accuracy close to a random guess. Our results confirm the value of the generalizability of causal models in reducing susceptibility to privacy attacks.</p> 
### 582.[The Intrinsic Robustness of Stochastic Bandits to Strategic Manipulation](https://proceedings.icml.cc/book/3822.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3395-Paper.pdf)
  Zhe Feng, David Parkes, Haifeng Xu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3395-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3395-Supplemental.pdf)
> Motivated by economic applications such as recommender systems, we study the behavior of  stochastic bandits algorithms under \emph{strategic behavior} conducted by rational actors, i.e.,  the arms. Each arm is a \emph{self-interested} strategic player who can modify its own reward whenever pulled, subject to a cross-period budget constraint, in order to maximize its own expected number of times of being pulled. We analyze the robustness of three popular  bandit algorithms: UCB, $\varepsilon$-Greedy, and Thompson Sampling. We prove that all three algorithms achieve a regret upper bound $\mathcal{O}(\max \{ B, K\ln T\})$  where $B$ is the total budget across arms, $K$ is the total number of arms and $T$ is the running time of the algorithms.  This regret guarantee holds for \emph{arbitrary  adaptive} manipulation strategy of  arms.  Our second set of main results shows that this regret bound is \emph{tight}--- in fact, for UCB, it is tight even when we restrict the arms&#x27; manipulation strategies to form a \emph{Nash equilibrium}. We do so by characterizing the Nash equilibrium of the game induced by arms&#x27; strategic manipulations and show a regret lower bound of $\Omega(\max \{ B, K\ln T\})$ at the equilibrium.   
### 583.[Normalized Flat Minima: Exploring Scale Invariant Definition of Flat Minima for Neural Networks Using PAC-Bayesian Analysis](https://proceedings.icml.cc/book/3823.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3399-Paper.pdf)
  Yusuke Tsuzuku, Issei Sato, Masashi Sugiyama [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3399-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3399-Supplemental.zip)
> <p>The notion of flat minima has gained attention as a key metric of the generalization ability of deep learning models. However, current definitions of flatness are known to be sensitive to parameter rescaling. While some previous studies have proposed to rescale flatness metrics using parameter scales to avoid the scale dependence, the normalized metrics lose the direct theoretical connections between flat minima and generalization. In this paper, we first provide generalization error bounds using existing normalized flatness measures. Using the analysis, we then propose a novel normalized flatness metric. The proposed metric enjoys both direct theoretical connections and better empirical correlation to generalization error.</p> 
### 584.[Fiedler Regularization: Learning Neural Networks with Graph Sparsity](https://proceedings.icml.cc/book/3824.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3408-Paper.pdf)
  Edric Tam, David Dunson [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3408-Metadata.json)
> <p>We introduce a novel regularization approach for deep learning that incorporates and respects the underlying graphical structure of the neural network. Existing regularization methods often focus on dropping/penalizing weights in a global manner that ignores the connectivity structures of the neural network. We propose to use the Fiedler value of the neural network's underlying graph as a tool for regularization. We provide theoretical support for this approach via Spectral Graph Theory. We demonstrate the convexity of this penalty and provide an approximate, variational approach for fast computation in practical training of neural networks. We provide bounds on such approximations. We provide an alternative but equivalent formulation of this framework in the form of a structurally weighted L1 penalty, thus linking our approach to sparsity induction. We trained neural networks on various datasets to compare Fiedler Regularization with traditional regularization methods such as Dropout and weight decay. Results demonstrate the efficacy of Fiedler Regularization.</p> 
### 585.[Online Learning with Imperfect Hints](https://proceedings.icml.cc/book/3825.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3411-Paper.pdf)
  Aditya Bhaskara, Ashok Cutkosky, Ravi Kumar, Manish Purohit [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3411-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3411-Supplemental.pdf)
> We consider a variant of the classical online linear optimization problem in which at every step, the online player receives a ``hint&#x27;&#x27; vector before choosing the action for that round. Rather surprisingly, it was shown that if the hint vector is guaranteed to have a positive correlation with the cost vector, then the online player can achieve a regret of $O(\log T)$, thus significantly improving over the $O(\sqrt{T})$ regret in the general setting. However, the result and analysis require the correlation property at \emph{all} time steps, thus raising the natural question: can we design online learning algorithms that are resilient to bad hints?   In this paper we develop algorithms and nearly matching lower bounds for online learning with imperfect hints.  Our algorithms are oblivious to the quality of the hints, and the regret bounds interpolate between the always-correlated hints case and the no-hints case.  Our results also generalize, simplify, and improve upon previous results on optimistic regret bounds, which can be viewed as an additive version of hints.
### 586.[Rate-distortion optimization guided autoencoder for isometric embedding in Euclidean latent space](https://proceedings.icml.cc/book/3826.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3417-Paper.pdf)
  Keizo Kato, Jing Zhou, Tomotake Sasaki, Akira Nakagawa [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3417-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3417-Supplemental.pdf)
> <p>To analyze high-dimensional and complex data in the real world, generative model approach of machine learning aims to reduce the dimension and acquire a probabilistic model of the data. For this purpose, deep-autoencoder based generative models such as variational autoencoder (VAE) have been proposed. However, in previous works, the scale of metrics between the real and the reduced-dimensional space (latent space) is not well-controlled. Therefore, the quantitative impact of the latent variable on real data is unclear. In the end, the probability distribution function (PDF) in the real space cannot be estimated from that of the latent space accurately. To overcome this problem, we propose Rate-Distortion Optimization guided autoencoder. We show our method has the following properties theoretically and experimentally: (i) the columns of Jacobian matrix between two spaces is constantly-scaled orthonormal system and data can be embedded in a Euclidean space isometrically; (ii) the PDF of the latent space is proportional to that of the real space.  Furthermore, to verify the usefulness in the practical application, we evaluate its performance in unsupervised anomaly detection and it outperforms current state-of-the-art methods.</p> 
### 587.[Optimization from Structured Samples for Coverage Functions](https://proceedings.icml.cc/book/3827.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3418-Paper.pdf)
  Wei Chen, Xiaoming Sun, Jialin Zhang, Zhijie Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3418-Metadata.json)
> We revisit the optimization from samples (OPS) model, which studies the problem of optimizing objective functions directly from the sample data. Previous results showed that we cannot obtain a constant approximation ratio for the maximum coverage problem using polynomially many independent samples of the form $\{S_i, f(S_i)\}_{i=1}^t$ (Balkanski et al., 2017), even if coverage functions are $(1 - \epsilon)$-PMAC learnable using these samples (Badanidiyuru et al., 2012), which means most of the function values can be approximately learned very well with high probability. In this work, to circumvent the impossibility result of OPS, we propose a stronger model called optimization from structured samples (OPSS) for coverage functions, where the data samples encode the structural information of the functions. We show that under three general assumptions on the sample distributions, we can design efficient OPSS algorithms that achieve a constant approximation for the maximum coverage problem. We further prove a constant lower bound under these assumptions, which is tight when not considering computational efficiency. Moreover, we also show that if we remove any one of the three assumptions, OPSS for the maximum coverage problem has no constant approximation.
### 588.[Optimal Randomized First-Order Methods for Least-Squares Problems](https://proceedings.icml.cc/book/3828.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3430-Paper.pdf)
  Jonathan Lacotte, Mert Pilanci [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3430-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3430-Supplemental.pdf)
> <p>We provide an exact asymptotic analysis of the performance of some fast randomized algorithms for solving overdetermined least-squares problems. We consider first-order methods, where the gradients are pre-conditioned by an approximation of the Hessian, based itself on a subspace embedding of the data matrix. This class of algorithms encompasses several randomized methods among the fastest solvers for least-squares problems. We focus on two classical embeddings, namely, Gaussian projections and subsampled randomized Hadamard transforms (SRHT). Our key technical innovation is the derivation of the limiting spectral density of SRHT embeddings. Leveraging this novel result, we derive the family of normalized orthogonal polynomials of the SRHT density and we find the optimal pre-conditioned first-order method and its rate of convergence. Our analysis of Gaussian embeddings proceeds similarly, and leverages classical random matrix theory results. In particular, we show that for a given sketch size, SRHT embeddings exhibits a faster rate of convergence than Gaussian embeddings. Then, we propose a new algorithm by optimizing the computational complexity over the choice of the sketching dimension. To our knowledge, our resulting algorithm yields the best known complexity for solving least-squares problems.</p> 
### 589.[Stochastic Optimization for Non-convex Inf-Projection Problems](https://proceedings.icml.cc/book/3829.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3450-Paper.pdf)
  Yan Yan, Yi Xu, Lijun Zhang, Wang Xiaoyu, Tianbao Yang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3450-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3450-Supplemental.pdf)
> <p>In this paper, we study a family of non-convex and possibly non-smooth inf-projection minimization problems, where the target objective function is equal to minimization of a joint function over another variable. This problem include difference of convex (DC) functions and a family of bi-convex functions as special cases. We develop stochastic algorithms and establish their first-order convergence for finding a (nearly) stationary solution of the target non-convex function under different conditions of the component functions. To the best of our knowledge, this is the first work that comprehensively studies stochastic optimization of non-convex inf-projection minimization problems with provable convergence guarantee. Our algorithms enable efficient stochastic optimization of a family of non-decomposable DC functions and a family of bi-convex functions. To demonstrate the power of the proposed algorithms we consider an important application in variance-based regularization, and experiments verify the effectiveness of our inf-projection based formulation and the proposed stochastic algorithm in comparison with previous stochastic algorithms based on the min-max formulation for achieving the same effect.</p> 
### 590.[Convex Representation Learning for Generalized Invariance in Semi-Inner-Product Space](https://proceedings.icml.cc/book/3830.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3475-Paper.pdf)
  Yingyi Ma, Vignesh Ganapathiraman, Yaoliang Yu, Xinhua Zhang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3475-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3475-Supplemental.pdf)
> <p>Invariance (defined in a general sense) has been one of the most effective priors for representation learning.  Direct factorization of parametric models is feasible only for a small range of invariances, while regularization approaches, despite improved generality, lead to nonconvex optimization.  In this work, we develop a \emph{convex} representation learning algorithm for a variety of generalized invariances that can be modeled as semi-norms.  Novel Euclidean embeddings are introduced for kernel representers in a semi-inner-product space, and approximation bounds are established.  This allows invariant representations to be learned efficiently and effectively as confirmed in our experiments, along with accurate predictions.</p> 
### 591.[Neural Kernels Without Tangents](https://proceedings.icml.cc/book/3831.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3479-Paper.pdf)
  Vaishaal Shankar, Alex Fang, Wenshuo Guo, Sara Fridovich-Keil, Jonathan Ragan-Kelley, Ludwig Schmidt, Benjamin Recht [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3479-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3479-Supplemental.pdf)
> <p>We investigate the connections between neural networks and simple building blocks in kernel space. In particular, using well established feature space tools such as direct sum, averaging, and moment lifting, we present an algebra for creating “compositional” kernels from bags of features. We show that these operations correspond to many of the building blocks of “neural tangent kernels (NTK)”. Experimentally, we show that there is a correlation in test error between neural network architectures and the associated kernels. We construct a simple neural network architecture using only 3x3 convolutions, 2x2 average pooling, ReLU, and optimized with SGD and MSE loss that achieves 96% accuracy on CIFAR10, and whose corresponding compositional kernel achieves 90% accuracy. We also use our constructions to investigate the relative performance of neural networks, NTKs, and compositional kernels in the small dataset regime. In particular, we find that compositional kernels outperform NTKs and neural networks outperform both kernel methods.</p> 
### 592.[Linear Lower Bounds and Conditioning of Differentiable Games](https://proceedings.icml.cc/book/3832.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3497-Paper.pdf)
  Adam Ibrahim, Waïss Azizian, Gauthier Gidel, Ioannis Mitliagkas [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3497-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3497-Supplemental.pdf)
> <p>Recent successes of game-theoretic formulations in ML have caused a resurgence of research interest in differentiable games. Overwhelmingly, that research focuses on methods and upper bounds. In this work, we approach the question of fundamental iteration complexity by providing lower bounds to complement the linear (i.e. geometric) upper bounds observed in the literature on a wide class of problems. We cast saddle-point and min-max problems as 2-player games. We leverage tools from single-objective convex optimisation to propose new linear lower bounds for convex-concave games. Notably, we give a linear lower bound for n-player differentiable games, by using the spectral properties of the update operator. We then propose a new definition of the condition number arising from our lower bound analysis. Unlike past definitions, our condition number captures the fact that linear rates are possible in games, even in the absence of strong convex-concavity.</p> 
### 593.[Finite-Time Last-Iterate Convergence for Multi-Agent Learning in Games](https://proceedings.icml.cc/book/3833.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3513-Paper.pdf)
  Tianyi Lin, Zhengyuan Zhou, Panayotis Mertikopoulos, Michael Jordan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3513-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3513-Supplemental.pdf)
> In this paper, we consider multi-agent learning via online gradient descent in a class of games called $\lambda$-cocoercive games, a fairly broad class of games that admits many Nash equilibria and that properly includes unconstrained strongly monotone games. We characterize the finite-time last-iterate convergence rate for joint OGD learning on $\lambda$-cocoercive games; further, building on this result, we develop a fully adaptive OGD learning algorithm that does not require any knowledge of problem parameter (e.g. cocoercive constant $\lambda$) and show, via a novel double-stopping time technique, that this adaptive algorithm achieves same finite-time last-iterate convergence rate as non-adaptive counterpart. Subsequently, we extend OGD learning to the noisy gradient feedback case and establish last-iterate convergence results--first qualitative almost sure convergence, then quantitative finite-time convergence rates-- all under non-decreasing step-sizes. To our knowledge, we provide the first set of results that fill in several gaps of the existing multi-agent online learning literature, where three aspects--finite-time convergence rates, non-decreasing step-sizes, and fully adaptive algorithms have been unexplored before.
### 594.[Communication-Efficient Distributed PCA by Riemannian Optimization](https://proceedings.icml.cc/book/3834.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3520-Paper.pdf)
  Long-Kai Huang, Jialin Pan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3520-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3520-Supplemental.pdf)
> <p>In this paper, we study the leading eigenvector problem in a statistically distributed setting and propose a communication-efficient algorithm based on Riemannian optimization, which trades local computation for global communication. Theoretical analysis shows that the proposed algorithm linearly converges to the centralized empirical risk minimization solution regarding the number of communication rounds. When the number of data points in local machines is sufficiently large, the proposed algorithm achieves a significant reduction of communication cost over existing distributed PCA algorithms. Superior performance in terms of communication cost of the proposed algorithm is verified on real-world and synthetic datasets.</p> 
### 595.[Manifold Identification for Ultimately Communication-Efficient Distributed Optimization](https://proceedings.icml.cc/book/3835.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3524-Paper.pdf)
  Yu-Sheng Li, Wei-Lin Chiang, Ching-pei Lee [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3524-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3524-Supplemental.pdf)
> The expensive inter-machine communication is the bottleneck of distributed optimization. Existing study tackles this problem by shortening the communication rounds, but the reduction of per-round communication cost is not well-studied. This work proposes a progressive manifold identification approach with  sound theoretical justifications to greatly reduce both the communication rounds and the bytes communicated per round for partly smooth regularized problems, which include many large-scale machine learning tasks such as the training of $\ell_1$- and group-LASSO-regularized models. Our method uses an inexact proximal quasi-Newton method to iteratively identify a sequence of low-dimensional smooth manifolds in which the final solution lies, and restricts the model update within the current manifold to lower significantly the per-round communication cost. After identifying the final manifold within which the problem is smooth, we take superlinear-convergent truncated semismooth Newton steps obtained through preconditioned conjugate gradient to largely reduce the communication rounds. Experiments show that when compared with the state of the art, the communication cost of our method is significantly lower and the running time is up to $10$ times faster.
### 596.[When Demands Evolve Larger and Noisier: Learning and Earning in a Growing Environment](https://proceedings.icml.cc/book/3836.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3536-Paper.pdf)
  Feng Zhu, Zeyu Zheng [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3536-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3536-Supplemental.pdf)
> We consider a single-product dynamic pricing problem under a specific non-stationary setting, where the demand grows over time in expectation and possibly gets noisier. The decision maker dynamically sets price and learns the unknown price elasticity, with the goal of maximizing expected cumulative revenue. We prove matching upper and lower bounds on regret and provide near-optimal pricing policies. We show how the change in demand uncertainty over time affects the optimal policy design and demonstrate how the order of optimal regret depends on the magnitude of demand uncertainty evolvement. Moreover, we distinguish between the \textit{any-time} situation and the \textit{fixed-time} situation by whether the seller knows the total number of time periods $T$ in advance or not, and show that they surprisingly render different optimal regret orders. We then extend the demand model to a more general case allowing for an additional intercept term and present a novel and near-optimal algorithm for the extended model. Finally, we consider an analogous non-stationary setting in the canonical multi-armed bandit problem, and points out that the \textit{any-time} situation and the \textit{fixed-time} situation render the same optimal regret order in a simple form, in contrast to the dynamic pricing problem.
### 597.[Being Bayesian about Categorical Probability](https://proceedings.icml.cc/book/3837.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3560-Paper.pdf)
  Taejong Joo, Uijung Chung, Min-Gwan Seo [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3560-Metadata.json)
> <p>Neural networks utilize the softmax as a building block in classification tasks, which contains an overconfidence problem and lacks an uncertainty representation ability. As a Bayesian alternative to the softmax, we consider a random variable of a categorical probability over class labels. In this framework, the prior distribution explicitly models the presumed noise inherent in the observed label, which provides consistent gains in generalization performance in multiple challenging tasks. The proposed method inherits advantages of Bayesian approaches that achieve better uncertainty estimation and model calibration. Our method can be implemented as a plug-and-play loss function with negligible computational overhead compared to the softmax with the cross-entropy loss function.</p> 
### 598.[Context-aware Dynamics Model for Generalization in Model-Based Reinforcement Learning](https://proceedings.icml.cc/book/3838.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3567-Paper.pdf)
  Kimin Lee, Younggyo Seo, Seunghyun Lee, Honglak Lee, Jinwoo Shin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3567-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3567-Supplemental.pdf)
> <p>Model-based reinforcement learning (RL) enjoys several benefits, such as data-efficiency and planning, by learning a model of the environment's dynamics. However, learning a global model that can generalize across different dynamics remains a challenge. To tackle this problem, we decompose the task of learning a global dynamics model into two stages: (a) learning a context latent vector that captures the local dynamics, then (b) predicting the next state conditioned on it. In order to encode dynamics-specific information into the context latent vector, we introduce a novel loss function that encourages the context latent vector to be useful for predicting both forward and backward dynamics. The proposed method achieves superior generalization ability across various simulated robotics and control tasks, compared to existing RL schemes.</p> 
### 599.[Learning Reasoning Strategies in End-to-End Differentiable Proving](https://proceedings.icml.cc/book/3839.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3569-Paper.pdf)
  Pasquale Minervini, Tim Rocktäschel, Sebastian Riedel, Edward Grefenstette, Pontus Stenetorp [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3569-Metadata.json)
> <p>Attempts to render deep learning models interpretable, data-efficient, and robust has seen some success through hybridisation with rule-based systems like Neural Theorem Provers (NTPs). These neuro-symbolic reasoning models can induce interpretable rules and learn representations from data via back-propagation, while providing logical explanations for their predictions.  However, they are restricted by their computational complexity, as they need to consider all possible proof paths for explaining a goal, thus rendering them unfit for large-scale applications. We present Conditional Theorem Provers (CTPs), an extension to NTPs that learns an optimal rule selection strategy via gradient-based optimisation.  We show that CTPs are scalable and yield state-of-the-art results on the CLUTRR dataset, which tests systematic generalisation of neural models. CTPs generalise better than a wide range of baselines when tested on larger graphs than trained on, while producing competitive results on standard link prediction benchmarks.</p> 
### 600.[Fast and Private Submodular and $k$-Submodular Functions Maximization with Matroid Constraints](https://proceedings.icml.cc/book/3840.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3576-Paper.pdf)
  Akbar Rafiey, Yuichi Yoshida [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3576-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3576-Supplemental.pdf)
> The problem of maximizing nonnegative monotone submodular functions under a certain constraint has been intensively studied in the last decade, and a wide range of efficient approximation algorithms have been developed for this problem. Many machine learning problems, including data summarization and influence maximization, can be naturally modeled as the problem of maximizing monotone submodular functions. However, when such applications involve sensitive data about individuals, their privacy concerns should be addressed. In this paper, we study the problem of maximizing monotone submodular functions subject to matroid constraints in the framework of differential privacy. We provide $(1-\frac{1}{\mathrm{e}})$-approximation algorithm which improves upon the previous results in terms of approximation guarantee. This is done with an almost cubic number of function evaluations in our algorithm.  Moreover, we study $k$-submodularity, a natural generalization of submodularity. We give the first $\frac{1}{2}$-approximation algorithm that preserves differential privacy for maximizing monotone $k$-submodular functions subject to matroid constraints. The approximation ratio is asymptotically tight and is obtained with an almost linear number of function evaluations.
### 601.[Streaming Coresets for Symmetric Tensor Factorization](https://proceedings.icml.cc/book/3841.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3579-Paper.pdf)
  Supratim Shit, Anirban Dasgupta, Rachit Chhaya, Jayesh Choudhari [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3579-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3579-Supplemental.pdf)
> Factorizing tensors has recently become an important optimization module in a number of machine learning pipelines, especially in latent variable models. We show how to do this efficiently in the streaming setting. Given a set of $n$ vectors, each in $\~R^d$, we present algorithms to select a sublinear number of these vectors as coreset, while guaranteeing that the CP decomposition of the $p$-moment tensor of the coreset approximates the corresponding decomposition of the $p$-moment tensor computed from the full data. We introduce two novel algorithmic techniques: online filtering and kernelization. Using these two, we   present four algorithms that achieve different tradeoffs of coreset size, update time and working space, beating or matching various state of the art algorithms. In case of matrices (2-ordered tensor) our online row sampling algorithm guarantees $(1 \pm \epsilon)$ relative error spectral approximation. We show applications of our algorithms in learning single topic modeling. 
### 602.[How Good is the Bayes Posterior in Deep Neural Networks Really?](https://proceedings.icml.cc/book/3842.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3581-Paper.pdf)
  Florian Wenzel, Kevin Roth, Bastiaan Veeling, Jakub Swiatkowski, Linh Tran, Stephan Mandt, Jasper Snoek, Tim Salimans, Rodolphe Jenatton, Sebastian Nowozin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3581-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3581-Supplemental.pdf)
> <p>During the past five years the Bayesian deep learning community has developed increasingly accurate and efficient approximate inference procedures that allow for Bayesian inference in deep neural networks.  However, despite this algorithmic progress and the promise of improved uncertainty quantification and sample efficiency there are---as of early 2020---no publicized deployments of Bayesian neural networks in industrial practice.  In this work we cast doubt on the current understanding of Bayes posteriors in popular deep neural networks: we demonstrate through careful MCMC sampling that the posterior predictive induced by the Bayes posterior yields systematically worse predictions when compared to simpler methods including point estimates obtained from SGD.  Furthermore, we demonstrate that predictive performance is improved significantly through the use of a ``cold posterior'' that overcounts evidence.  Such cold posteriors sharply deviate from the Bayesian paradigm but are commonly used as heuristic in Bayesian deep learning papers.  We put forward several hypotheses that could explain cold posteriors and evaluate the hypotheses through experiments.  Our work questions the goal of accurate posterior approximations in Bayesian deep learning: If the true Bayes posterior is poor, what is the use of more accurate approximations?  Instead, we argue that it is timely to focus on understanding the origin of cold posteriors.</p> 
### 603.[Optimally Solving Two-Agent Decentralized POMDPs Under One-Sided Information Sharing ](https://proceedings.icml.cc/book/3843.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3582-Paper.pdf)
  Yuxuan Xie, Jilles Dibangoye, Olivier Buffet [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3582-Metadata.json)
> <p>Optimally solving decentralized partially observable Markov decision processes under either full or no information sharing received significant attention in recent years. However, little is known about how partial information sharing affects existing theory and algorithms. This paper addresses this question for a team of two agents, with one-sided information sharing---\ie both agents have imperfect information about the state of the world, but only one has access to what the other sees and does. From the perspective of a central planner, we show that the original problem can be reformulated into an equivalent information-state Markov decision process and solved as such. Besides, we prove that the optimal value function exhibits a specific form of uniform continuity. We also present a heuristic search algorithm utilizing this property and providing the first results for this family of problems.</p> 
### 604.[Learning Algebraic Multigrid Using Graph Neural Networks](https://proceedings.icml.cc/book/3844.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3595-Paper.pdf)
  Ilay Luz, Meirav Galun, Haggai Maron, Ronen Basri, Irad Yavneh [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3595-Metadata.json)
> <p>Efficient numerical solvers for sparse linear systems are crucial in science and engineering. One of the fastest methods for solving large-scale sparse linear systems is algebraic multigrid (AMG). The main challenge in the construction of AMG algorithms is the selection of the prolongation operator---a problem-dependent sparse matrix which governs the multiscale hierarchy of the solver and is critical to its efficiency. Over many years, numerous methods have been developed for this task, and yet there is no known single right answer except in very special cases. Here we propose a framework for learning AMG prolongation operators for linear systems with sparse symmetric positive (semi-) definite matrices. We train a single graph neural network to learn a mapping from an entire class of such matrices to prolongation operators, using an efficient unsupervised loss function.  Experiments on a broad class of problems demonstrate improved convergence rates compared to classical AMG, demonstrating the potential utility of neural networks for developing sparse system solvers.</p> 
### 605.[Fractal Gaussian Networks: A sparse random graph model based on Gaussian Multiplicative Chaos](https://proceedings.icml.cc/book/3845.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3598-Paper.pdf)
  Subhroshekhar Ghosh, Krishna Balasubramanian, Xiaochuan Yang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3598-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3598-Supplemental.pdf)
> We propose a novel stochastic network model, called Fractal Gaussian Network (FGN), that embodies well-defined and analytically tractable fractal structures. Such fractal structures have been empirically observed in diverse applications. FGNs interpolate continuously between the popular purely random geometric graphs (a.k.a. the Poisson Boolean network), and random graphs with increasingly fractal behavior. In fact, they form a parametric family of sparse random geometric graphs that are parametrised by a fractality parameter $\nu$ which governs the strength of the fractal structure. FGNs are driven by the latent spatial geometry of Gaussian Multiplicative Chaos (GMC), a canonical model of fractality in its own right. We explore the natural question of detecting the presence of fractality and the problem of parameter estimation based on observed network data. Finally, we explore fractality in community structures by unveiling a natural stochastic block model in the setting of FGNs. 
### 606.[Structured Policy Iteration for Linear Quadratic Regulator](https://proceedings.icml.cc/book/3846.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3607-Paper.pdf)
  Youngsuk Park, Ryan Rossi, Zheng Wen, Gang Wu, Handong Zhao [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3607-Metadata.json)
> <p>Linear quadratic regulator (LQR) is one of the most popular frameworks to tackle continuous Markov decision process tasks. With its fundamental theory and tractable optimal policy, LQR has been revisited and analyzed in recent years, in terms of reinforcement learning scenarios such as the model-free or model-based setting. In this paper, we introduce the Structured Policy Iteration (S-PI) for LQR, a method capable of deriving a structured linear policy. Such a structured policy with (block) sparsity or low-rank can have significant advantages over the standard LQR policy: more interpretable, memory-efficient, and well-suited for the distributed setting. In order to derive such a policy, we first cast a regularized LQR problem when the model is known. Then, our Structured Policy Iteration (S-PI) algorithm, which takes a policy evaluation step and a policy improvement step in an iterative manner, can solve this regularized LQR efficiently. We further extend the S-PI algorithm to the model-free setting where a smoothing procedure is adopted to estimate the gradient. In both the known-model and model-free setting, we prove convergence analysis under the proper choice of parameters. Finally, the experiments demonstrate the advantages of S-PI in terms of balancing the LQR performance and level of structure by varying the weight parameter.</p> 
### 607.[T-GD: Transferable GAN-generated Images Detection Framework](https://proceedings.icml.cc/book/3847.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3622-Paper.pdf)
  Hyeonseong Jeon, Young Oh Bang, Junyaup Kim, Simon Woo [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3622-Metadata.json)
> <p>Recent advancements in Generative Adversarial Networks (GANs) enable generating realistic images, which can be possibly misused. Detecting GAN-generated images (GAN-images) become more challenging because of the significant reduction of underlying artifacts and specific patterns. The absence of such traces can hinder detection algorithms to detect GAN-images and transfer knowledge in detecting other types of GAN-images. In this work, we present a robust transferable framework to effectively detect GAN-images, called Transferable GAN-images Detection framework (T-GD). T-GD is composed of a teacher and a student model, which can both iteratively teach and evaluate each other to improve the detection performance. First, we train the teacher model on the source dataset and use it as a starting point for learning the target dataset. For training the student model, we inject noise by mixing up both the source and target dataset, but constrain the weights variation for preserving the starting point. Our approach is a self-training method, but is different from prior approaches by focusing on improving the transferability over GAN-images detection. T-GD achieves a high performance on source dataset, overcoming catastrophic forgetting as well as effectively detecting state-of-the-art GAN-images with only a small volume of data without any metadata information.</p> 
### 608.[Low Bias Low Variance Gradient Estimates for Hierarchical Boolean Stochastic Networks](https://proceedings.icml.cc/book/3848.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3626-Paper.pdf)
  Adeel Pervez, Taco Cohen, Efstratios Gavves [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3626-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3626-Supplemental.pdf)
> <p>Stochastic neural networks with discrete random variables are an important class of models for their expressiveness and interpretability. Since direct differentiation and backpropagation is not possible, Monte Carlo gradient estimation techniques are a popular alternative. Efficient stochastic gradient estimators, such Straight-Through and Gumbel-Softmax, work well for shallow stochastic models. Their performance, however, suffers with hierarchical, more complex models. We focus on hierarchical stochastic networks with multiple layers of Boolean latent variables. To analyze such networks, we introduce the framework of harmonic analysis for Boolean functions to derive an analytic formulation for the bias and variance in the Straight-Through estimator. Exploiting these formulations, we propose \emph{FouST}, a low-bias and low-variance gradient estimation algorithm that is just as efficient. Extensive experiments show that FouST performs favorably compared to state-of-the-art biased estimators and is much faster than unbiased ones.</p> 
### 609.[Learning Flat Latent Manifolds with VAEs](https://proceedings.icml.cc/book/3849.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3631-Paper.pdf)
  Nutan Chen, Alexej Klushyn, Francesco Ferroni, Justin Bayer, Patrick van der Smagt [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3631-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3631-Supplemental.pdf)
> <p>Measuring the similarity between data points often requires domain knowledge, which can in parts be compensated by relying on unsupervised methods such as latent-variable models, where similarity/distance is estimated in a more compact latent space. Prevalent is the use of the Euclidean metric, which has the drawback of ignoring information about similarity of data stored in the decoder, as captured by the framework of Riemannian geometry. We propose an extension to the framework of variational auto-encoders allows learning flat latent manifolds, where the Euclidean metric is a proxy for the similarity between data points. This is achieved by defining the latent space as a Riemannian manifold and by regularising the metric tensor to be a scaled identity matrix. Additionally, we replace the compact prior typically used in variational auto-encoders with a recently presented, more expressive hierarchical one---and formulate the learning problem as a constrained optimisation problem. We evaluate our method on a range of data-sets, including a video-tracking benchmark, where the performance of our unsupervised approach nears that of state-of-the-art supervised approaches, while retaining the computational efficiency of straight-line-based approaches.</p> 
### 610.[Multi-Task Learning with User Preferences: Gradient Descent with Controlled Ascent in Pareto Optimization](https://proceedings.icml.cc/book/3850.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3635-Paper.pdf)
  Debabrata Mahapatra, Vaibhav Rajan [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3635-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3635-Supplemental.pdf)
> <p>Multi-Task Learning (MTL) is a well established learning paradigm for jointly learning models for multiple correlated tasks. Often the tasks conflict requiring trade-offs between them during optimization. Recent advances in multi-objective optimization based MTL  have enabled us to use large-scale deep networks to find one or more Pareto optimal solutions. However, they cannot be used to find exact Pareto optimal solutions satisfying user-specified preferences with respect to task-specific losses, that is not only a common requirement in applications but also a useful way to explore the infinite set of Pareto optimal solutions. We develop the first gradient-based multi-objective MTL algorithm to address this problem. Our unique approach combines multiple gradient descent with carefully controlled ascent, that enables it to trace the Pareto front in a principled manner and makes it robust to initialization. Assuming only differentiability of the task-specific loss functions, we provide theoretical guarantees for convergence. We empirically demonstrate the superiority of our algorithm over state-of-the-art methods.</p> 
### 611.[Transfer Learning without Knowing: Reprogramming Black-box Machine Learning Models with Scarce Data and Limited Resources](https://proceedings.icml.cc/book/3851.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3642-Paper.pdf)
  Yun Yun Tsai, Pin-Yu Chen, Tsung-Yi Ho [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3642-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3642-Supplemental.pdf)
> <p>Current transfer learning methods are mainly based on finetuning a pretrained model with target-domain data. Motivated by the techniques from adversarial machine learning (ML) that are capable of manipulating the model prediction via data perturbations, in this paper we propose a novel approach, black-box adversarial reprogramming (BAR), that repurposes a well-trained black-box ML model (e.g., a prediction API or a proprietary software) for solving different ML tasks, especially in the scenario with scarce data and constrained resources. The rationale lies in exploiting high-performance but unknown ML models to gain learning capability for transfer learning. Using zeroth order optimization and multi-label mapping techniques, BAR can reprogram a black-box ML model solely based on its input-output responses without knowing the model architecture or changing any parameter. More importantly, in the limited medical data setting, on autism spectrum disorder classification, diabetic retinopathy detection, and melanoma detection tasks, BAR outperforms state-of-the-art methods and yields comparable performance to the vanilla adversarial reprogramming method requiring complete knowledge of the target ML model. BAR also outperforms baseline transfer learning approaches by a significant margin, demonstrating cost-effective means and new insights for transfer learning.</p> 
### 612.[On Coresets for Regularized Regression](https://proceedings.icml.cc/book/3852.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3647-Paper.pdf)
  Rachit Chhaya, Supratim Shit, Anirban Dasgupta [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3647-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3647-Supplemental.pdf)
> We study the effect of norm based regularization on the size of coresets for the regularized regression problems. Specifically, given a matrix $ \mathbf{A} \in {\mathbf{R}}^{n \M{x}d}$ with $n\gg d$ and a vector $\mathbf{b} \in \mathbf{R} ^ n $ and $\lambda &gt; 0$, we analyze the size of coresets for regularized versions of regression of the form $||\M{Ax}-\M{b}||_p^r + \lambda||{\M{x}}||_q^s$ . It has been shown for the case of ridge regression ($p,q,r,s=2$) that we can obtain a coreset smaller than the coreset for its unregularized counterpart i.e. least squares regression\cite{avron2017sharper}. However we show that when $r \neq s$, no coreset for some regularized regression can have size smaller than the optimal coreset of the unregularized version. The well known LASSO problem falls under this category and hence does not allow a coreset smaller than the one for least squares regression. We propose a modified version of the LASSO problem and obtain for it a coreset of size smaller than the least square regression. We empirically show that the modified version of LASSO also induces sparsity in solution like the LASSO. We also obtain smaller coresets for $\ell_p$-regression with $\ell_p$-regularization. We extend our methods to multi response regularized regression. Finally, we empirically demonstrate the coreset performance for the modified LASSO and the $\ell_1$-regression with $\ell_1$- regularization.
### 613.[Budgeted Online Influence Maximization](https://proceedings.icml.cc/book/3853.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3649-Paper.pdf)
  Pierre Perrault, Zheng Wen, Michal Valko, Jennifer Healey [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3649-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3649-Supplemental.pdf)
> <p>We introduce a new budgeted framework for online  influence  maximization,   considering the total cost of an advertising campaign instead  of  the  common  cardinality  constraint on a chosen influencer set. Our approach models better the  real-world  setting  where  the cost of influencers varies and advertizers want to find the best value for their overall social advertising budget. We propose an algorithm assuming  an  independent  cascade  diffusion model  and  edge- level  semi-bandit  feedback, and provide both theoretical and experimental results.  Our analysis is also valid for the cardinality-constraint  setting  and  improves the state of the art regret bound in this case.</p> 
### 614.[On the (In)tractability of Computing Normalizing Constants for the Product of Determinantal Point Processes](https://proceedings.icml.cc/book/3854.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3653-Paper.pdf)
  Naoto Ohsaka, Tatsuya Matsuoka [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3653-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3653-Supplemental.pdf)
> We consider the product of determinantal point processes (DPPs), a point process whose probability mass is proportional to the product of principal minors of multiple matrices as a natural, promising generalization of DPPs. We study the computational complexity of computing its normalizing constant, which is among the most essential probabilistic inference tasks. Our complexity-theoretic results (almost) rule out the existence of efficient algorithms for this task, unless input matrices are forced to have favorable structures. In particular, we prove the following: (1) Computing $\sum_{S} \det(\mat{A}_{S,S})^p$ exactly for every (fixed) positive even integer $p$ is UP-hard and Mod3P-hard, which gives a negative answer to an open question posed by Kulesza and Taskar (2012). (2) $\sum_{S} \det(\mat{A}_{S,S}) \det(\mat{B}_{S,S}) \det(\mat{C}_{S,S})$ is NP-hard to approximate within a factor of $ 2^{O(|I|^{1-\epsilon})} $ for any $\epsilon &gt; 0$, where $|I|$ is the input size. This result is stronger than #P-hardness for the case of two matrices by Gillenwater (2014). (3) There exists a $ k^{O(k)} |I|^{O(1)} $-time algorithm for computing $\sum_{S} \det(\mat{A}_{S,S}) \det(\mat{B}_{S,S})$, where $k$ is ``the maximum rank of $\mat{A}$ and $\mat{B}$&#x27;&#x27; or ``the treewidth of the graph formed by non-zero entries of $\mat{A}$ and $\mat{B}$.&#x27;&#x27; Such parameterized algorithms are said to be fixed-parameter tractable.
### 615.[Monte-Carlo Tree Search as Regularized Policy Optimization](https://proceedings.icml.cc/book/3855.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3655-Paper.pdf)
  Jean-Bastien Grill, Florent Altché, Yunhao Tang, Thomas Hubert, Michal Valko, Ioannis Antonoglou, Remi Munos [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3655-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3655-Supplemental.pdf)
> <p>The combination of Monte-Carlo tree search (MCTS) with deep reinforcement learning has led to groundbreaking results in  artificial intelligence. However, AlphaZero, the current state-of-the-art MCTS algorithm still relies on handcrafted  heuristics that are only partially understood. In this paper, we show that AlphaZero's search heuristic, along with other common ones, can be interpreted as an approximation to the solution of a specific regularized policy optimization problem. With this insight, we propose a variant of AlphaZero which uses the exact solution to this policy optimization problem, and show experimentally that it reliably outperforms the original algorithm in multiple domains.</p> 
### 616.[On the Expressivity of Neural Networks for Deep Reinforcement Learning](https://proceedings.icml.cc/book/3856.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3657-Paper.pdf)
  Kefan Dong, Yuping Luo, Tianhe Yu, Chelsea Finn, Tengyu Ma [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3657-Metadata.json)
> <p>We compare the model-free reinforcement learning with the model-based approaches through the lens of the expressive power of neural networks for policies, Q-functions, and dynamics. We show, theoretically and empirically, that even for one-dimensional continuous state space, there are many MDPs whose optimal Q-functions and policies are much more complex than the dynamics. For these MDPs, model-based planning is a favorable algorithm, because the resulting policies can approximate the optimal policy significantly better than a neural network parameterization can, and model-free or model-based policy optimization rely on policy parameterization. Motivated by the theory, we apply a simple multi-step model-based bootstrapping planner (BOOTS) to bootstrap a weak Q-function into a stronger policy. Empirical results show that applying BOOTS on top of model-based or model-free policy optimization algorithms at the test time improves the performance on benchmark tasks.</p> 
### 617.[The k-tied Normal Distribution: A Compact Parameterization of Gaussian Mean Field Posteriors in Bayesian Neural Networks](https://proceedings.icml.cc/book/3857.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3662-Paper.pdf)
  Jakub Swiatkowski, Kevin Roth, Bastiaan Veeling, Linh Tran, Joshua Dillon, Jasper Snoek, Stephan Mandt, Tim Salimans, Rodolphe Jenatton, Sebastian Nowozin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3662-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3662-Supplemental.pdf)
> <p>Variational Bayesian Inference is a popular methodology for approximating posterior distributions over Bayesian neural network weights. Recent work developing this class of methods has explored ever richer parameterizations of the approximate posterior in the hope of improving performance. In contrast, here we share a curious experimental finding that suggests instead restricting the variational distribution to a more compact parameterization. For a variety of deep Bayesian neural networks trained using Gaussian mean-field variational inference, we find that the posterior standard deviations consistently exhibit strong low-rank structure after convergence. This means that by decomposing these variational parameters into a low-rank factorization, we can make our variational approximation more compact without decreasing the models' performance. Furthermore, we find that such factorized parameterizations improve the signal-to-noise ratio of stochastic gradient estimates of the variational lower bound, resulting in faster convergence.</p> 
### 618.[A Generative Model for Molecular Distance Geometry](https://proceedings.icml.cc/book/3858.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3679-Paper.pdf)
  Gregor Simm, Jose Miguel Hernandez-Lobato [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3679-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3679-Supplemental.pdf)
> <p>Computing equilibrium states for many-body systems, such as molecules, is a long-standing challenge. In the absence of methods for generating statistically independent samples, great computational effort is invested in simulating these systems using, for example, Markov chain Monte Carlo. We present a probabilistic model that generates such samples for molecules from their graph representations. Our model learns a low-dimensional manifold that preserves the geometry of local atomic neighborhoods through a principled learning representation that is based on Euclidean distance geometry. In a new benchmark for molecular conformation generation, we show experimentally that our generative model achieves state-of-the-art accuracy. Finally, we show how to use our model as a proposal distribution in an importance sampling scheme to compute molecular properties.</p> 
### 619.[Why bigger is not always better: on finite and infinite neural networks](https://proceedings.icml.cc/book/3859.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3680-Paper.pdf)
  Laurence Aitchison [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3680-Metadata.json)
> <p>Recent work has argued that neural networks can be understood theoretically by taking the number of channels to infinity, at which point the outputs become Gaussian process (GP) distributed. However, we note that infinite Bayesian neural networks lack a key facet of the behaviour of real neural networks: the fixed kernel, determined only by network hyperparameters, implies that they cannot do any form of representation learning. The lack of representation or equivalently kernel learning leads to less flexibility and hence worse performance, giving a potential explanation for the inferior performance of infinite networks observed in the literature (e.g. Novak et al. 2019). We give analytic results characterising the prior over representations and representation learning in finite deep linear networks. We show empirically that the representations in SOTA architectures such as ResNets trained with SGD are much closer to those suggested by our deep linear results than by the corresponding infinite network. This motivates the introduction of a new class of network: infinite networks with bottlenecks, which inherit the theoretical tractability of infinite networks while at the same time allowing representation learning.</p> 
### 620.[Data-Efficient Image Recognition with Contrastive Predictive Coding](https://proceedings.icml.cc/book/3860.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3694-Paper.pdf)
  Olivier Henaff [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3694-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3694-Supplemental.pdf)
> <p>Human observers can learn to recognize new categories of images from a handful of examples, yet doing so with machine perception remains an open challenge. We hypothesize that data-efficient recognition is enabled by representations which make the variability in natural signals more predictable. We therefore revisit and improve Contrastive Predictive Coding, an unsupervised objective for learning such representations. This new implementation produces features which support state-of-the-art linear classification accuracy on the ImageNet dataset. When used as input for non-linear classification with deep neural networks, this representation allows us to use 2-5x less labels than classifiers trained directly on image pixels. Finally, this unsupervised representation substantially improves transfer learning to object detection on PASCAL VOC 2007, surpassing fully supervised pre-trained ImageNet classifiers. </p> 
### 621.[Intrinsic Reward Driven Imitation Learning via Generative Model](https://proceedings.icml.cc/book/3861.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3696-Paper.pdf)
  Xingrui Yu, Yueming LYU, Ivor Tsang [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3696-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3696-Supplemental.pdf)
> <p>Imitation learning in a high-dimensional environment is challenging. Most inverse reinforcement learning (IRL) methods fail to outperform the demonstrator in such a high-dimensional environment, e.g., Atari domain. To address this challenge, we propose a novel reward learning module to generate intrinsic reward signals via a generative model. Our generative method can perform better forward state transition and backward action encoding, which improves the module's dynamics modeling ability in the environment. Thus, our module provides the imitation agent both the intrinsic intention of the demonstrator and a better exploration ability, which is critical for the agent to outperform the demonstrator. Empirical results show that our method outperforms state-of-the-art IRL methods on multiple Atari games, even with one-life demonstration. Remarkably, our method achieves performance that is up to 5 times the performance of the demonstration.</p> 
### 622.[Can Increasing Input Dimensionality Improve Deep Reinforcement Learning?](https://proceedings.icml.cc/book/3862.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3700-Paper.pdf)
  Kei Ota, Tomoaki Oiki, Devesh Jha, Toshisada Mariyama, Daniel Nikovski [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3700-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3700-Supplemental.pdf)
> <p>Deep reinforcement learning (RL) algorithms have recently achieved remarkable successes in various sequential decision making tasks, leveraging advances in methods for training large deep networks. However, these methods usually require large amounts of training data, which is often a big problem for real-world applications. One natural question to ask is whether learning good representations for states and using larger networks helps in learning better policies. In this paper, we try to study if increasing input dimensionality helps improve performance and sample efficiency of model-free deep RL algorithms. To do so, we propose an online feature extractor network (OFENet) that uses neural nets to produce \textit{good} representations to be used as inputs to an off-policy RL algorithm. Even though the high dimensionality of input is usually thought to make learning of RL agents more difficult, we show that the RL agents in fact learn more efficiently with the high-dimensional representation than with the lower-dimensional state observations. We believe that stronger feature propagation together with larger networks allows RL agents to learn more complex functions of states and thus improves the sample efficiency. Through numerical experiments, we show that the proposed method achieves much higher sample efficiency and better performance.</p> 
### 623.[Batch Reinforcement Learning with Hyperparameter  Gradients](https://proceedings.icml.cc/book/3863.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3705-Paper.pdf)
  Byung-Jun Lee, Jongmin Lee, Peter Vrancx, Dongho Kim, Kee-Eung Kim [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3705-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3705-Supplemental.pdf)
> <p>We consider the batch reinforcement learning problem where the agent needs to learn only from a fixed batch of data, without further interaction with the environment. In such a scenario, we want to prevent the optimized policy from deviating too much from the data collection policy since the estimation becomes highly unstable otherwise due to the off-policy nature of the problem. However, imposing this requirement too strongly will result in a policy that merely follows the data collection policy. Unlike prior work where this trade-off is controlled by hand-tuned hyperparameters, we propose a novel batch reinforcement learning approach, batch optimization of policy and hyperparameter (BOPAH), that uses a gradient-based optimization of the hyperparameter using held-out data. We show that BOPAH outperforms other batch reinforcement learning algorithms in tabular and continuous control tasks, by finding a good balance to the trade-off between adhering to the data collection policy and pursuing the possible policy improvement.</p> 
### 624.[Sub-Goal Trees -- a Framework for Goal-Based Reinforcement Learning](https://proceedings.icml.cc/book/3864.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3711-Paper.pdf)
  Tom Jurgenson, Or Avner, Edward Groshev, Aviv Tamar [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3711-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3711-Supplemental.pdf)
> <p>Many AI problems, in robotics and other domains, are goal-directed, essentially seeking a trajectory leading to some goal state. Reinforcement learning (RL), building on Bellman's optimality equation, naturally optimizes for a single goal, yet can be made goal-directed by augmenting the state with the goal. Instead, we propose a new RL framework, derived from a dynamic programming equation for the all pairs shortest path (APSP) problem, which naturally solves goal-directed queries. We show that this approach has computational benefits for both standard and approximate dynamic programming. Interestingly, our formulation prescribes a novel protocol for computing a trajectory: instead of predicting the next state given its predecessor, as in standard RL, a goal-conditioned trajectory is constructed by first predicting an intermediate state between start and goal, partitioning the trajectory into two. Then, recursively, predicting intermediate points on each sub-segment, until a complete trajectory is obtained. We call this trajectory structure a sub-goal tree. Building on it, we additionally extend the policy gradient methodology to recursively predict sub-goals, resulting in novel goal-based algorithms. Finally, we apply our method to neural motion planning, where we demonstrate significant improvements compared to standard RL on navigating a 7-DoF robot arm between obstacles.</p> 
### 625.[A Geometric Approach to Archetypal Analysis via Sparse Projections](https://proceedings.icml.cc/book/3865.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3716-Paper.pdf)
  Vinayak Abrol, Pulkit Sharma [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3716-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3716-Supplemental.pdf)
> <p>Archetypal analysis (AA) aims to extract patterns using self-expressive decomposition of data as convex combinations of extremal points (on the convex hull) of the data. This work presents a computationally efficient greedy AA (GAA) algorithm. GAA leverages the underlying geometry and sparseness property of AA, is scalable to larger datasets, and has significantly faster convergence to existing methods. To achieve this, archetypes are learned via sparse projection of data in linearly transformed space. GAA employs an iterative subset selection approach to identify archetypes based on the sparsity of convex representations. The work further presents the use of GAA algorithm for extended AA models such as robust and kernel AA. Experimental results show that GAA is significantly faster while performing comparable to existing methods for tasks such as classification, data visualization/categorization.</p> 
### 626.[Sequence Generation with Mixed Representations](https://proceedings.icml.cc/book/3866.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3729-Paper.pdf)
  Lijun Wu, Shufang Xie, Yingce Xia, Yang Fan, Jian-Huang Lai, Tao Qin, Tie-Yan Liu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3729-Metadata.json)
> Tokenization is the first step of many natural language processing (NLP) tasks and plays an important role for neural NLP models. Tokenizaton method such as byte-pair encoding (BPE), which can greatly reduce the large vocabulary and deal with out-of-vocabulary words, has shown to be effective and is widely adopted for sequence generation tasks. While various tokenization methods exist, there is no common acknowledgement which is the best. In this work, we propose to leverage the mixed representations from different tokenization methods for sequence generation tasks, in order to boost the model performance with unique characteristics and advantages of individual tokenization methods. Specifically, we introduce a new model architecture to incorporate mixed representations and a co-teaching algorithm to better utilize the diversity of different tokenization methods. Our approach  achieves significant improvements on neural machine translation (NMT) tasks with six language pairs (e.g., English$\leftrightarrow$German, English$\leftrightarrow$Romanian), as well as an abstractive summarization task.
### 627.[Agent57: Outperforming the Atari Human Benchmark](https://proceedings.icml.cc/book/3867.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3732-Paper.pdf)
  Adrià Puigdomenech Badia, Bilal Piot, Steven Kapturowski, Pablo Sprechmann, Oleksandr Vitvitskyi, Zhaohan Guo, Charles Blundell [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3732-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3732-Supplemental.pdf)
> <p>Atari games have been a long-standing benchmark in the reinforcement learning (RL) community for the past decade. This benchmark was proposed to test general competency of RL algorithms. Previous work has achieved good average performance by doing outstandingly well on many games of the set, but very poorly in several of the most challenging games. We propose Agent57, the first deep RL agent that outperforms the standard human benchmark on all 57 Atari games. To achieve this result, we train a neural network which parameterizes a family of policies ranging from very exploratory to purely exploitative. We propose an adaptive mechanism to choose which policy to prioritize throughout the training process. Additionally, we utilize a novel parameterization of the architecture that allows for more consistent and stable learning.</p> 
### 628.[RIFLE: Backpropagation in Depth for Deep Transfer Learning through Re-Initializing the Fully-connected LayEr](https://proceedings.icml.cc/book/3868.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3745-Paper.pdf)
  Xingjian Li, Haoyi Xiong, Haozhe An, Dejing Dou, Cheng-Zhong Xu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3745-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3745-Supplemental.pdf)
> <p>Fine-tuning the deep convolution neural network (CNN) using a pre-trained model helps transfer knowledge learned from larger datasets to the target task. While the accuracy could be largely improved even when the training dataset is small, the transfer learning outcome is similar with the pre-trained one with closed CNN weights[17], as the backpropagation here brings less updates to deeper CNN layers. In this work, we propose RIFLE - a simple yet effective strategy that deepens backpropagation in transfer learning settings, through periodically ReInitializing the Fully-connected LayEr with random scratch during the fine-tuning procedure. RIFLE brings significant perturbation to the backpropagation process and leads to deep CNN weights update, while the affects of perturbation can be easily converged throughout the overall learning procedure. The experiments show that the use of RIFLE significantly improves deep transfer learning accuracy on a wide range of datasets. It outperforms known tricks for the similar purpose, such as dropout, dropconnect, stochastic depth, and cyclic learning rate, under the same settings with 0.5%-2% higher testing accuracy. Empirical cases and ablation studies further indicate RIFLE brings meaningful updates to deep CNN layers with accuracy improved.</p> 
### 629.[Fairwashing explanations with off-manifold detergent](https://proceedings.icml.cc/book/3869.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3760-Paper.pdf)
  Christopher Anders, Ann-Kathrin Dombrowski, Klaus-robert Mueller, Pan Kessel, Plamen Pasliev [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3760-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3760-Supplemental.pdf)
> Explanation methods promise to make black-box classifiers more transparent. As a result, it is hoped that they can act as proof for a sensible, fair and trustworthy decision-making process of the algorithm and thereby increase its acceptance by the end-users. In this paper, we show both theoretically and experimentally that these hopes are presently unfounded. Specifically, we show that, for any classifier $g$, one can always construct another classifier $\tilde{g}$ which has the same behavior on the data (same train, validation, and test error) but has arbitrarily manipulated explanation maps. We derive this statement theoretically using differential geometry and demonstrate it experimentally for various explanation methods, architectures, and datasets. Motivated by our theoretical insights, we then propose a modification of existing explanation methods which makes them significantly more robust.
### 630.[Learning disconnected manifolds: a no GAN&#x27;s land](https://proceedings.icml.cc/book/3870.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3761-Paper.pdf)
  Ugo Tanielian, Thibaut Issenhuth, Elvis Dohmatob, Jeremie Mary [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3761-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3761-Supplemental.pdf)
> <p>Typical architectures of Generative Adversarial Networks make use of a unimodal latent/input distribution transformed by a continuous generator. Consequently, the modeled distribution always has connected support which is cumbersome when learning a disconnected set of manifolds. We formalize this problem by establishing a "no free lunch" theorem for the disconnected manifold learning stating an upper-bound on the precision of the targeted distribution. This is done by building on the necessary existence of a low-quality region where the generator continuously samples data between two disconnected modes.  Finally, we derive a rejection sampling method based on the norm of generator’s Jacobian and show its efficiency on several generators including BigGAN.</p> 
### 631.[Sets Clustering](https://proceedings.icml.cc/book/3871.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3768-Paper.pdf)
  Ibrahim Jubran, Murad Tukan, Alaa Maalouf, Dan Feldman [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3768-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3768-Supplemental.pdf)
> The input to the \emph{sets-$k$-means} problem is an integer $k\geq 1$ and a set $\mathcal{P}=\br{P_1,\cdots,P_n}$ of sets in $\mathbb{R}^d$. The goal is to compute a set $C$ of $k$ centers (points) in $\mathbb{R}^d$ that minimizes the sum $\sum_{P\in \mathcal{P}} \min_{p\in P, c\in C}\left\| p-c \right\|^2$ of squared distances to these sets. An  \emph{$\eps$-core-set} for this problem is a weighted subset of $\mathcal{P}$ that approximates this sum up to $1\pm\varepsilon$ factor, for \emph{every} set $C$ of $k$ centers in $\mathbb{R}^d$. We prove that such a core-set of $O(\log^2{n})$ sets always exists, and can be computed in $O(n\log{n})$ time, for every input $\mathcal{P}$ and every fixed $d,k\geq 1$ and $\varepsilon \in (0,1)$. The result easily generalized for any metric space, distances to the power of $z&gt;0$, and M-estimators that handle outliers. Applying an inefficient but optimal algorithm on this coreset allows us to obtain the first PTAS ($1+\eps$ approximation) for the sets-$k$-means problem that takes time near linear in $n$. This is the first result even for sets-mean on the plane ($k=1$, $d=2$).  Open source code and experimental results for document classification and facility locations are also provided.
### 632.[Variational Autoencoders with Riemannian Brownian Motion Priors](https://proceedings.icml.cc/book/3872.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3786-Paper.pdf)
  Dimitris Kalatzis, David Eklund, Georgios Arvanitidis, Søren Hauberg [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3786-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3786-Supplemental.pdf)
> <p>Variational Autoencoders (VAEs) represent the given data in a low-dimensional latent space, which is generally assumed to be Euclidean. This assumption naturally leads to the common choice of a standard Gaussian prior over continuous latent variables. Recent work has, however, shown that this prior has a detrimental effect on model capacity, leading to subpar performance. We propose that the Euclidean assumption lies at the heart of this failure mode. To counter this, we assume a Riemannian structure over the latent space, which constitutes a more principled geometric view of the latent codes, and replace the standard Gaussian prior with a Riemannian Brownian motion prior. We propose an efficient inference scheme that does not rely on the unknown normalizing factor of this prior. Finally, we demonstrate that this prior significantly increases model capacity using only one additional scalar parameter.</p> 
### 633.[Non-separable Non-stationary random fields](https://proceedings.icml.cc/book/3873.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3803-Paper.pdf)
  Kangrui Wang, Oliver Hamelijnck, Theodoros Damoulas, Mark Steel [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3803-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3803-Supplemental.pdf)
> <p>We describe a framework for constructing non-separable non-stationary random fields that is based on an infinite mixture of convolved stochastic processes. When the mixing process is stationary and the convolution function is non-stationary we arrive at expressive kernels that are available in closed form. When the mixing is non-stationary and the convolution function is stationary the resulting random fields exhibit varying degrees of non-separability that better preserve local structure. These kernels have natural interpretations through corresponding stochastic differential equations (SDEs) and are demonstrated on a range of synthetic benchmarks and spatio-temporal applications in geostatistics and machine learning. We show how a single Gaussian process (GP) with these kernels can computationally and statistically outperform both separable and existing non-stationary non-separable approaches such as treed GPs and deep GP constructions. </p> 
### 634.[Nonparametric Score Estimators](https://proceedings.icml.cc/book/3874.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3804-Paper.pdf)
  Yuhao Zhou, Jiaxin Shi, Jun Zhu [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3804-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3804-Supplemental.pdf)
> <p>Estimating the score, i.e., the gradient of log density function, from a set of samples generated by an unknown distribution is a fundamental task in inference and learning of probabilistic models that involve flexible yet intractable densities. Kernel estimators based on Stein's methods or score matching have shown promise, however their theoretical properties and relationships have not been fully-understood. We provide a unifying view of these estimators under the framework of regularized nonparametric regression. It allows us to analyse existing estimators and construct new ones with desirable properties by choosing different hypothesis spaces and regularizers. A unified convergence analysis is provided for such estimators. Finally, we propose score estimators based on iterative regularization that enjoy computational benefits from curl-free kernels and fast convergence.</p> 
### 635.[A Free-Energy Principle for Representation Learning](https://proceedings.icml.cc/book/3875.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3813-Paper.pdf)
  Yansong Gao, Pratik Chaudhari [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3813-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3813-Supplemental.pdf)
> <p>This paper employs a formal connection of machine learning with thermodynamics to characterize the quality of learnt representations for transfer learning. We discuss how information-theoretic functionals such as rate, distortion and classification loss of a model lie on a convex, so-called equilibrium surface. We prescribe dynamical processes to traverse this surface under constraints, e.g., an iso-classification process that trades off rate and distortion to keep the classification loss unchanged. We demonstrate how this process can be used for transferring representations from a source dataset to a target dataset while keeping the classification loss constant. Experimental validation of the theoretical results is provided on standard image-classification datasets.</p> 
### 636.[Scalable Differential Privacy with Certified Robustness in Adversarial Learning](https://proceedings.icml.cc/book/3876.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3815-Paper.pdf)
  Hai Phan, My T. Thai, Han Hu, Ruoming Jin, Tong Sun, Dejing Dou [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3815-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3815-Supplemental.pdf)
> <p>In this paper, we aim to develop a scalable algorithm to preserve differential privacy (DP) in adversarial learning for deep neural networks (DNNs), with certified robustness to adversarial examples. By leveraging the sequential composition theory in DP, we randomize both input and latent spaces to strengthen our certified robustness bounds. To address the trade-off among model utility, privacy loss, and robustness, we design an original adversarial objective function, based on the post-processing property in DP, to tighten the sensitivity of our model. A new stochastic batch training is proposed to apply our mechanism on large DNNs and datasets, by bypassing the vanilla iterative batch-by-batch training in DP DNNs. An end-to-end theoretical analysis and evaluations show that our mechanism notably improves the robustness and scalability of DP DNNs.</p> 
### 637.[Variational Inference for Sequential Data with Future Likelihood Estimates](https://proceedings.icml.cc/book/3877.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3816-Paper.pdf)
  Geon-Hyeong Kim, Youngsoo Jang, Hongseok Yang, Kee-Eung Kim [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3816-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3816-Supplemental.pdf)
> <p>The recent development of flexible and scalable variational inference algorithms has popularized the use of deep probabilistic models in a wide range of applications. However, learning and reasoning about high-dimensional models with non-differentiable densities are still a challenge. For such a model, inference algorithms struggle to estimate the gradients of variational objectives accurately, due to high variance in their estimates. To tackle this challenge, we present a novel variational inference algorithm for sequential data, which performs well even when the density from the model is not differentiable, for instance, due to the use of discrete random variables. The key feature of our algorithm is that it estimates future likelihoods at all time steps. The estimated future likelihoods form the core of our new low-variance gradient estimator. We formally analyze our gradient estimator from the perspective of variational objective, and show the effectiveness of our algorithm with synthetic and real datasets.</p> 
### 638.[Implicit Learning Dynamics in Stackelberg Games: Equilibria Characterization, Convergence Analysis, and Empirical Study](https://proceedings.icml.cc/book/3878.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3821-Paper.pdf)
  Tanner Fiez, Benjamin Chasnov, Lillian  Ratliff [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3821-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3821-Supplemental.pdf)
> <p>Contemporary work on learning in continuous games has commonly overlooked the hierarchical decision-making structure present in machine learning problems formulated as games, instead treating them as simultaneous play games and adopting the Nash equilibrium solution concept. We deviate from this paradigm and provide a comprehensive study of learning in Stackelberg games. This work provides insights into the optimization landscape of zero-sum games by establishing connections between Nash and Stackelberg equilibria along with the limit points of simultaneous gradient descent. We derive novel gradient-based learning dynamics emulating the natural structure of a Stackelberg game using the Implicit Function Theorem and provide convergence analysis for deterministic and stochastic updates for zero-sum and general-sum games. Notably, in zero-sum games using deterministic updates, we show the only critical points the dynamics converge to are Stackelberg equilibria and provide a local convergence rate. Empirically, the proposed learning dynamics mitigate rotational behavior and exhibit benefits for training Generative Adversarial Networks compared to gradient play.</p> 
### 639.[Let&#x27;s Agree to Agree: Neural Networks Share Classification Order on Real Datasets](https://proceedings.icml.cc/book/3879.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3822-Paper.pdf)
  Guy Hacohen, Leshem Choshen, Daphna Weinshall [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3822-Metadata.json)
> <p>We report a series of robust empirical observations, whereby deep Neural Networks learn the examples in both the training and test sets in a similar order. This phenomenon is observed in all the commonly used benchmarks we evaluated, including many image classification benchmarks, and one text classification benchmark. While this phenomenon is strongest for models of the same architecture, it also crosses architectural boundaries - models of different architectures start by learning the same examples, after which the more powerful model may continue to learn additional examples. We further show that this pattern of results reflects the interplay between the way neural networks learn and benchmark datasets. Thus, when fixing the architecture, we show synthetic datasets where this pattern ceases to exist. When fixing the dataset, we show that other learning paradigms may learn the data in a different order. We hypothesize that our results echo how neural networks discover structure in natural datasets.</p> 
### 640.[Quantile Causal Discovery](https://proceedings.icml.cc/book/3880.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3826-Paper.pdf)
  Natasa Tagasovska, Thibault Vatter, Valérie Chavez-Demoulin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3826-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3826-Supplemental.zip)
> <p>Causal inference using observational data is challenging, especially in the bivariate case. Through the minimum description length principle, we link the postulate of independence between the generating mechanisms of the cause and of the effect given the cause to quantile regression. Based on this theory, we develop Quantile Causal Discovery (QCD), a new method to uncover causal relationships. Because it uses multiple quantile levels instead of the conditional mean only, QCD is adaptive not only to additive, but also to multiplicative or even location-scale generating mechanisms. To illustrate the empirical effectiveness of our approach, we perform an extensive empirical comparison on both synthetic and real datasets. This study shows that QCD is robust across different implementations of the method (i.e., the quantile regression algorithm), computationally efficient, and compares favorably to state-of-the-art methods.</p> 
### 641.[How to Solve Fair k-Center in Massive Data Models](https://proceedings.icml.cc/book/3881.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3827-Paper.pdf)
  Ashish Chiplunkar, Sagar Kale, Sivaramakrishnan Natarajan Ramamoorthy [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3827-Metadata.json)
> <p>Fueled by massive data, important decision making is being automated with the help of algorithms, therefore, fairness in algorithms has become an especially important research topic. In this work, we design new streaming and distributed algorithms for the fair k-center problem that models fair data summarization. The streaming and distributed models of computation have an attractive feature of being able to handle massive data sets that do not fit into main memory. Our main contributions are: (a) the first distributed algorithm; which has provably constant approximation ratio and is extremely parallelizable, and (b) a two-pass streaming algorithm with a provable approximation guarantee matching the best known algorithm (which is not a streaming algorithm). Our algorithms have the advantages of being easy to implement in practice, being fast with linear running times, having very small working memory and communication, and outperforming existing algorithms on several real and synthetic data sets. To complement our distributed algorithm, we also give a hardness result for natural distributed algorithms, which holds for even the special case of k-center.</p> 
### 642.[Bayesian Learning from Sequential Data using Gaussian Processes with Signature Covariances](https://proceedings.icml.cc/book/3882.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3828-Paper.pdf)
  Csaba Toth, Harald Oberhauser [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3828-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3828-Supplemental.zip)
> <p>We develop a Bayesian approach to learning from sequential data by using Gaussian processes (GPs) with so-called signature kernels as covariance functions. This allows to make sequences of different length comparable and to rely on strong theoretical results from stochastic analysis. Signatures capture sequential structure with tensors that can scale unfavourably in sequence length and state space dimension. To deal with this, we introduce a sparse variational approach with inducing tensors. We then combine the resulting GP with LSTMs and GRUs to build larger models that leverage the strengths of each of these approaches and benchmark the resulting GPs on multivariate time series (TS) classification datasets.</p> 
### 643.[Beyond Signal Propagation: Is Feature Diversity Necessary in Deep Neural Network Initialization?](https://proceedings.icml.cc/book/3883.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3840-Paper.pdf)
  Yaniv Blumenfeld, Dar Gilboa, Daniel Soudry [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3840-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3840-Supplemental.pdf)
> Deep neural networks are typically initialized with random weights, with variances chosen to facilitate signal propagation and stable gradients. It is also believed that diversity of features is an important property of these initializations. We construct a deep convolutional network with identical features by initializing almost all the weights to $0$. The architecture also enables perfect signal propagation and stable gradients, and achieves high accuracy on standard benchmarks. This indicates that random, diverse initializations are \textit{not} necessary for training neural networks. An essential element in training this network is a mechanism of symmetry breaking; we study this phenomenon and find that standard GPU operations, which are non-deterministic, can serve as a sufficient source of symmetry breaking to enable training.
### 644.[Dynamic Knapsack Optimization Towards Efficient Multi-Channel Sequential Advertising](https://proceedings.icml.cc/book/3884.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3844-Paper.pdf)
  Xiaotian Hao, Zhaoqing Peng, Yi Ma, Guan Wang, Junqi Jin, Jianye Hao, Shan Chen, Rongquan Bai, Mingzhou Xie, Miao Xu, Zhenzhe Zheng, Chuan Yu, HAN LI, Jian Xu, Kun Gai [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3844-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3844-Supplemental.pdf)
> <p>In E-commerce, advertising is essential for merchants to reach their target users. The typical objective is to maximize the advertiser's cumulative revenue over a period of time under a budget constraint. In real applications, an advertisement (ad) usually needs to be exposed to the same user multiple times until the user finally contributes revenue (e.g., places an order). However, existing advertising systems mainly focus on the immediate revenue with single ad exposures, ignoring the contribution of each exposure to the final conversion, thus usually falls into suboptimal solutions. In this paper, we formulate the sequential advertising strategy optimization as a dynamic knapsack problem. We propose a theoretically guaranteed bilevel optimization framework, which significantly reduces the solution space of the original optimization space while ensuring the solution quality. To improve the exploration efficiency of reinforcement learning, we also devise an effective action space reduction approach. Extensive offline and online experiments show the superior performance of our approaches over state-of-the-art baselines in terms of cumulative revenue.</p> 
### 645.[Stochastically Dominant Distributional Reinforcement Learning](https://proceedings.icml.cc/book/3885.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3862-Paper.pdf)
  John Martin, Michal Lyskawinski, Xiaohu Li, Brendan Englot [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3862-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3862-Supplemental.pdf)
> <p>We describe a new approach for managing aleatoric uncertainty in the Reinforcement Learning paradigm. Instead of selecting actions according to a single statistic, we propose a distributional method based on the second-order stochastic dominance (SSD) relation. This compares the inherent dispersion of random returns induced by actions, producing a more comprehensive and robust evaluation of the environment's uncertainty. The necessary conditions for SSD require estimators to predict quality second moments. To accommodate this, we map the distributional RL problem to a Wasserstein gradient flow, treating the distributional Bellman residual as a potential energy functional. We propose a particle-based algorithm for which we prove optimality and convergence. Our experiments characterize the algorithm performance and demonstrate how uncertainty and performance are better balanced using SSD action selection than with other risk measures.  </p> 
### 646.[Adversarial Robustness Against the Union of Multiple Threat Models](https://proceedings.icml.cc/book/3886.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3863-Paper.pdf)
  Pratyush Maini, Eric Wong, Zico Kolter [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3863-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3863-Supplemental.pdf)
> <p>Owing to the susceptibility of deep learning systems to adversarial attacks, there has been a great deal of work in developing (both empirically and certifiably) robust classifiers.  While most work has defended against a single type of attack, recent work has looked at defending against multiple threat models using simple aggregations of multiple attacks. However, these methods can be difficult to tune, and can easily result in imbalanced degrees of robustness to individual threat models, resulting in a sub-optimal worst-case loss over the combined threat model.  In this work, we develop a natural generalization of the standard PGD-based procedure to incorporate multiple threat models into a single attack, by taking the worst-case over all steepest descent directions. This approach has the advantage of directly converging upon a trade-off between different threat models which minimizes the worst-case performance over the union. With this approach, we are able to train standard architectures which are simultaneously robust against l<em>∞, l</em>2, and l<em>1 attacks, outperforming past approaches on the MNIST and CIFAR10 datasets and achieving adversarial accuracy of 46.1% against the union of (l</em>∞,l<em>2,l</em>1) perturbations with radius= (0.03, 0.5, 12) on the latter, improving upon previous approaches which achieve 40.6% accuracy.</p> 
### 647.[Student-Teacher Curriculum Learning via Reinforcement Learning: Predicting Hospital Inpatient Admission Location](https://proceedings.icml.cc/book/3887.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3870-Paper.pdf)
  Rasheed El-Bouri, David Eyre, Peter Watkinson, Tingting Zhu, David Clifton [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3870-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3870-Supplemental.pdf)
> <p>Accurate and reliable prediction of hospital admission location is important due to resource-constraints and space availability in a clinical setting, particularly when dealing with patients who come from the emergency department. In this work we propose a student-teacher network via reinforcement learning to deal with this specific problem. A representation of the weights of the student network is treated as the state and is fed as an input to the teacher network. The teacher network's action is to select the most appropriate batch of data to train the student network on from a training set sorted according to entropy. By validating on three datasets, not only do we show that our approach outperforms state-of-the-art methods on tabular data and performs competitively on image recognition, but also that novel curricula are learned by the teacher network. We demonstrate experimentally that the teacher network can actively learn about the student network and guide it to achieve better performance than if trained alone.</p> 
### 648.[Option Discovery in the Absence of Rewards with Manifold Analysis](https://proceedings.icml.cc/book/3888.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3873-Paper.pdf)
  Amitay Bar, Ronen Talmon, Ron Meir [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3873-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3873-Supplemental.zip)
> <p>Options have been shown to be an effective tool in reinforcement learning, facilitating improved exploration and learning. In this paper, we present an approach based on spectral graph theory and derive an algorithm that systematically discovers options without access to a specific reward or task assignment. As opposed to the common practice used in previous methods, our algorithm makes full use of the spectrum of the graph Laplacian. Incorporating modes associated with higher graph frequencies unravels domain subtleties, which are shown to be useful for option discovery. Using geometric and manifold-based analysis, we present a theoretical justification for the algorithm. In addition, we showcase its performance on several domains, demonstrating clear improvements compared to competing methods.</p> 
### 649.[Generalisation error in learning with random features and the hidden manifold model](https://proceedings.icml.cc/book/3889.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3887-Paper.pdf)
  Federica Gerace, Bruno Loureiro, Florent Krzakala, Marc Mezard, Lenka Zdeborova [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3887-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3887-Supplemental.pdf)
> <p>We study generalized linear regression and classification for a synthetically generated dataset encompassing different problems of interest, such as learning with random features, neural networks in the lazy training regime, and the hidden manifold model.  We consider the high-dimensional regime and using the replica method from statistical physics, we provide a closed-form expression for the asymptotic generalisation performance in these problems, valid in both the under- and over-parametrised regimes and for a broad choice of generalized linear model loss functions. In particular, we show how to obtain analytically the so-called double descent behaviour for logistic regression with a peak at the interpolation threshold, we illustrate the superiority of orthogonal against random Gaussian projections in learning with random features, and discuss the role played by correlations in the data generated by the hidden manifold model. Beyond the interest in these particular problems, the theoretical formalism introduced in this manuscript provides a path to further extensions to more complex tasks.</p> 
### 650.[Fast and Consistent Learning of Hidden Markov Models by Incorporating Non-Consecutive Correlations](https://proceedings.icml.cc/book/3890.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3896-Paper.pdf)
  Robert Mattila, Cristian Rojas, Eric Moulines, Vikram Krishnamurthy, Bo Wahlberg [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3896-Metadata.json)
> <p>Can the parameters of a hidden Markov model (HMM) be estimated from a single sweep through the observations -- and additionally, without being trapped at a local optimum in the likelihood surface? That is the premise of recent method of moments algorithms devised for HMMs. In these, correlations between consecutive pair- or triplet-wise observations are empirically estimated and used to compute estimates of the HMM parameters. Albeit computationally very attractive, the main drawback is that by restricting to only low-order correlations in the data, information is being neglected which results in a loss of accuracy (compared to standard maximum likelihood schemes). In this paper, we propose extending these methods (both pair- and triplet-based) by also including non-consecutive correlations in a way which does not significantly increase the computational cost (which scales linearly with the number of additional lags included). We prove strong consistency of the new methods, and demonstrate an improved performance in numerical simulations on both synthetic and real-world financial time-series datasets.</p> 
### 651.[Gradient-free Online Learning in Continuous Games with Delayed Rewards](https://proceedings.icml.cc/book/3891.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3922-Paper.pdf)
  Amélie Héliou, Panayotis Mertikopoulos, Zhengyuan Zhou [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3922-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3922-Supplemental.pdf)
> <p>Motivated by applications to online advertising and recommender systems, we consider a game-theoretic model with delayed rewards and asynchronous, payoff-based feedback. In contrast to previous work on delayed multi-armed bandits, we focus on games with continuous action spaces, and we examine the long-run behavior of strategic agents that follow a no-regret learning policy (but are otherwise oblivious to the game being played, the objectives of their opponents, etc.). To account for the lack of a consistent stream of information (for instance, rewards can arrive out of order and with an a priori unbounded delay), we introduce a gradient-free learning policy where payoff information is placed in a priority queue as it arrives. Somewhat surprisingly, we find that under a standard diagonal concavity assumption, the induced sequence of play converges to Nash Equilibrium (NE) with probability 1, even if the delay between choosing an action and receiving the corresponding reward is unbounded.</p> 
### 652.[Pseudo-Masked Language Models for Unified Language Model Pre-Training](https://proceedings.icml.cc/book/3892.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3934-Paper.pdf)
  Hangbo Bao, Li Dong, Furu Wei, Wenhui Wang, Nan Yang, Xiaodong Liu, Yu Wang, Jianfeng Gao, Songhao Piao, Ming Zhou, Hsiao-Wuen Hon [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3934-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3934-Supplemental.pdf)
> <p>We propose to pre-train a unified language model for both autoencoding and partially autoregressive language modeling tasks using a novel training procedure, referred to as a pseudo-masked language model (PMLM). Given an input text with masked tokens, we rely on conventional masks to learn inter-relations between corrupted tokens and context via autoencoding, and pseudo masks to learn intra-relations between masked spans via partially autoregressive modeling. With well-designed position embeddings and self-attention masks, the context encodings are reused to avoid redundant computation. Moreover, conventional masks used for autoencoding provide global masking information, so that all the position embeddings are accessible in partially autoregressive language modeling. In addition, the two tasks pre-train a unified language model as a bidirectional encoder and a sequence-to-sequence decoder, respectively. Our experiments show that the unified language models pre-trained using PMLM achieve new state-of-the-art results on a wide range of natural language understanding and generation tasks across several widely used benchmarks.</p> 
### 653.[Einsum Networks: Fast and Scalable Learning of Tractable Probabilistic Circuits](https://proceedings.icml.cc/book/3893.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3949-Paper.pdf)
  Robert Peharz, Steven Lang, Antonio Vergari, Karl Stelzner, Alejandro Molina, Martin Trapp, Guy Van den Broeck, Kristian Kersting, Zoubin Ghahramani [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3949-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3949-Supplemental.pdf)
> <p>Probabilistic circuits (PCs) are a promising avenue for probabilistic modeling, as they permit a wide range of exact and efficient inference routines. Recent ``deep-learning-style'' implementations of PCs strive for a better scalability, but are still difficult to train on real-world data, due to their sparsely connected computational graphs. In this paper, we propose Einsum Networks (EiNets), a novel implementation design for PCs, improving prior art in several regards. At their core, EiNets combine a large number of arithmetic operations in a single monolithic einsum-operation, leading to speedups and memory savings of up to two orders of magnitude, in comparison to previous implementations. As an algorithmic contribution, we show that the implementation of Expectation-Maximization (EM) can be simplified for PCs, by leveraging automatic differentiation. Furthermore, we demonstrate that EiNets scale well to datasets which were previously out of reach, such as SVHN and CelebA, and that they can be used as faithful generative image models.</p> 
### 654.[Polynomial Tensor Sketch for Element-wise Function of Low-Rank Matrix](https://proceedings.icml.cc/book/3894.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3955-Paper.pdf)
  Insu Han, Haim Avron, Jinwoo Shin [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3955-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3955-Supplemental.zip)
> <p>This paper studies how to sketch element-wise functions of low-rank matrices. Formally, given low-rank matrix A = [Aij] and scalar non-linear function f, we aim for finding an approximated low-rank representation of the (possibly high-rank) matrix [f(Aij)]. To this end, we propose an efficient sketching-based algorithm whose complexity is significantly lower than the number of entries of A, i.e., it runs without accessing all entries of [f(Aij)] explicitly. The main idea underlying our method is to combine a polynomial approximation of f with the existing tensor sketch scheme for approximating monomials of entries of A. To balance the errors of the two approximation components in an optimal manner, we propose a novel regression formula to find polynomial coefficients given A and f. In particular, we utilize a coreset-based regression with a rigorous approximation guarantee. Finally, we demonstrate the applicability and superiority of the proposed scheme under various machine learning tasks.</p> 
### 655.[Inexact Tensor Methods with Dynamic Accuracies](https://proceedings.icml.cc/book/3895.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3958-Paper.pdf)
  Nikita Doikov, Yurii Nesterov [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3958-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3958-Supplemental.pdf)
> In this paper, we study inexact high-order Tensor Methods for solving convex optimization problems with composite objective. At every step of such methods, we use approximate solution of the auxiliary problem, defined by the bound for the residual in function value. We propose two dynamic strategies for choosing the inner accuracy: the first one is decreasing as $1/k^{p + 1}$, where $p \geq 1$ is the order of the method and $k$ is the iteration counter, and the second approach is using for the inner accuracy the last progress in the target objective. We show that inexact Tensor Methods with these strategies achieve the same global convergence rate as in the error-free case. For the second approach we also establish local superlinear rates (for $p \geq 2$), and propose the accelerated scheme. Lastly, we present computational results on a variety of machine learning problems for several methods and different accuracy policies.
### 656.[k-means++:  few more steps yield constant approximation](https://proceedings.icml.cc/book/3896.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3965-Paper.pdf)
  Davin Choo, Christoph Grunau, Julian Portmann, Vaclav Rozhon [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3965-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3965-Supplemental.pdf)
> <p>The k-means++ algorithm of Arthur and Vassilvitskii (SODA 2007) is a state-of-the-art algorithm for solving the k-means clustering problem and is known to give an O(log k) approximation. Recently, Lattanzi and Sohler (ICML 2019) proposed augmenting k-means++ with O(k log log k) local search steps to yield a constant approximation (in expectation) to the k-means clustering problem. In this paper, we improve their analysis to show that, for any arbitrarily small constant epsilon &gt; 0, with only epsilon * k additional local search steps, one can achieve a constant approximation guarantee (with high probability in k), resolving an open problem in their paper.</p> 
### 657.[Radioactive data: tracing through training](https://proceedings.icml.cc/book/3897.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3974-Paper.pdf)
  Alexandre Sablayrolles, Douze Matthijs, Cordelia Schmid, Herve Jegou [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3974-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3974-Supplemental.pdf)
> <p>We want to detect whether a particular image dataset has been used to train a model. We propose a new technique, radioactive data, that makes imperceptible changes to this dataset such that any model trained on it will bear an identifiable mark. The mark is robust to strong variations such as different architectures or optimization methods. Given a trained model, our technique detects the use of radioactive data and provides a level of confidence (p-value). Our experiments on large-scale benchmarks (Imagenet), using standard architectures (Resnet-18, VGG-16, Densenet-121) and training procedures, show that we can detect usage of radioactive data with high confidence (p&lt;0.0001) even when only 1% of the data used to trained our model is radioactive.  Our method is robust to data augmentation and the stochasticity of deep network optimization.  As a result, it offers a much higher signal-to-noise ratio than data poisoning and backdoor methods.</p> 
### 658.[Doubly robust off-policy evaluation with shrinkage ](https://proceedings.icml.cc/book/3898.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3992-Paper.pdf)
  Yi Su, Maria Dimakopoulou, Akshay Krishnamurthy, Miroslav Dudik [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3992-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3992-Supplemental.pdf)
> <p>We propose a new framework for designing estimators for off-policy evaluation in contextual bandits. Our approach is based on the asymptotically optimal doubly robust estimator, but we shrink the importance weights to minimize a bound on the mean squared error, which results in a better bias-variance tradeoff in finite samples. We use this optimization-based framework to obtain three estimators: (a) a weight-clipping estimator, (b) a new weight-shrinkage estimator, and (c) the first shrinkage-based estimator for combinatorial action sets. Extensive experiments in both standard and combinatorial bandit benchmark problems show that our estimators are highly adaptive and typically outperform state-of-the-art methods.</p> 
### 659.[Fast Adaptation to New Environments via Policy-Dynamics Value Functions](https://proceedings.icml.cc/book/3899.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3993-Paper.pdf)
  Roberta Raileanu, Max Goldstein, Arthur Szlam, Facebook Rob Fergus [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3993-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3993-Supplemental.pdf)
> <p>Standard RL algorithms assume fixed environment dynamics and require a significant amount of interaction to adapt to new environments. We introduce Policy-Dynamics Value Functions (PD-VF), a novel approach for rapidly adapting to dynamics different from those previously seen in training. PD-VF explicitly estimates the cumulative reward in a space of policies and environments. An ensemble of conventional RL policies is used to gather experience on training environments, from which embeddings of both policies and environments can be learned. Then, a value function conditioned on both embeddings is trained. At test time, a few actions are sufficient to infer the environment embedding, enabling a policy to be selected by maximizing the learned value function (which requires no additional environment interaction). We show that our method can rapidly adapt to new dynamics on a set of MuJoCo domains. </p> 
### 660.[Neural Clustering Processes](https://proceedings.icml.cc/book/3900.pdf)[ :link: ](https://proceedings.icml.cc/static/paper_files/icml/2020/3997-Paper.pdf)
  Ari Pakman, Yueqi Wang, Catalin Mitelut, JinHyung Lee, Department of Statistics Liam Paninski [Metadata](https://proceedings.icml.cc/static/paper_files/icml/2020/3997-Metadata.json) [Supplemental](https://proceedings.icml.cc/static/paper_files/icml/2020/3997-Supplemental.pdf)
> <p>Probabilistic clustering models (or equivalently, mixture models) are basic building blocks in countless statistical models and involve latent random variables over discrete spaces. For these models, posterior inference methods can be inaccurate and/or very slow. In this work we introduce deep network architectures trained with labeled samples from any generative model of  clustered datasets. At test time, the networks generate approximate posterior samples of cluster labels for any new dataset of arbitrary size. We develop two complementary approaches to this task, requiring  either O(N) or O(K) network forward passes per dataset, where N is the dataset size and  K the number of clusters. Unlike previous approaches, our methods sample the labels of all the data points from a well-defined posterior, and can learn nonparametric Bayesian posteriors since they do not limit the number of mixture components. As a scientific application, we present a novel approach to neural spike sorting for high-density multielectrode arrays. </p> 
